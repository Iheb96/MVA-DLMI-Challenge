{"cells":[{"metadata":{},"cell_type":"markdown","source":"Students : Iheb BEN SALEM/ Anis Yassine BEN MABROUK \nTeam: IBS/ABM"},{"metadata":{},"cell_type":"markdown","source":"\"Code made and tested on kaggle notebooks\"\n\nExecute the next few cells and once you reach the title of first method you are free to jump to any method and excute it independently."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms_\nfrom torch.utils.data import DataLoader, Dataset\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom sklearn.metrics import balanced_accuracy_score\nfrom PIL import Image\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset\ncsvfile=\"/kaggle/input/3md3070-dlmi/trainset/trainset_true.csv\"\ndf_raw=pd.read_csv(csvfile)  \ndf=df_raw\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_val = train_test_split(df, test_size=0.2, random_state=50)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"       ID  LABEL GENDER         DOB  LYMPH_COUNT\n0     P26      1      M   11/3/1933        11.20\n1    P183      1      M   5/15/1942        12.80\n2     P89      1      M   6/19/1935         9.60\n3    P123      1      M   1/27/1931       122.60\n4     P61      1      F    3/5/1931        11.60\n..    ...    ...    ...         ...          ...\n158  P135      1      M  27-08-1951         9.45\n159    P8      0      M  16-05-1975         4.91\n160  P130      0      F  16-05-1943         4.17\n161   P70      1      M  05-09-1987         5.66\n162   P60      0      F   5/23/1993         6.42\n\n[163 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>LABEL</th>\n      <th>GENDER</th>\n      <th>DOB</th>\n      <th>LYMPH_COUNT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P26</td>\n      <td>1</td>\n      <td>M</td>\n      <td>11/3/1933</td>\n      <td>11.20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P183</td>\n      <td>1</td>\n      <td>M</td>\n      <td>5/15/1942</td>\n      <td>12.80</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P89</td>\n      <td>1</td>\n      <td>M</td>\n      <td>6/19/1935</td>\n      <td>9.60</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P123</td>\n      <td>1</td>\n      <td>M</td>\n      <td>1/27/1931</td>\n      <td>122.60</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P61</td>\n      <td>1</td>\n      <td>F</td>\n      <td>3/5/1931</td>\n      <td>11.60</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>P135</td>\n      <td>1</td>\n      <td>M</td>\n      <td>27-08-1951</td>\n      <td>9.45</td>\n    </tr>\n    <tr>\n      <th>159</th>\n      <td>P8</td>\n      <td>0</td>\n      <td>M</td>\n      <td>16-05-1975</td>\n      <td>4.91</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>P130</td>\n      <td>0</td>\n      <td>F</td>\n      <td>16-05-1943</td>\n      <td>4.17</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>P70</td>\n      <td>1</td>\n      <td>M</td>\n      <td>05-09-1987</td>\n      <td>5.66</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>P60</td>\n      <td>0</td>\n      <td>F</td>\n      <td>5/23/1993</td>\n      <td>6.42</td>\n    </tr>\n  </tbody>\n</table>\n<p>163 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[110,2]=\"F\" #fixing a mistake in of the entries.\ndf[df['LABEL'] == 0][\"GENDER\"].value_counts().plot(kind='bar',title=\"Distribution of gender for Label 0\")\nplt.show()\ndf[df['LABEL'] == 1][\"GENDER\"].value_counts().plot(kind='bar',title=\"Distribution of gender for Label 1\")\nplt.show()\n","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport random\nrandom.seed(50)\ntorch.manual_seed(50)\nnp.random.seed(50)\n#Sadly this is not enough to make all algorithms perfectly replicatable. \n#If you run into results relatively different than ours (mostly for ANN),execute the algorithm few more times.","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SVM MIL"},{"metadata":{},"cell_type":"markdown","source":"We use pretrained resnet50 model to do the embedding of the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\npretrained_net = models.resnet50(pretrained=True)\nmodel = torch.nn.Sequential(*list(pretrained_net.children())[:-1])\nmodel.to(device)\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.eval()","execution_count":155,"outputs":[{"output_type":"execute_result","execution_count":155,"data":{"text/plain":"Sequential(\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU(inplace=True)\n  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (5): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (6): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (7): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.transforms as transforms_\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport cv2\nfrom PIL import Image\n\n\nclass DLMI_data_svm(Dataset):\n    def __init__(self, dataframe, root_dir, transforms = None):\n        \"\"\"\n        Args:\n            dataframe \n            mode(string) = \"train\",\"valid\",\"test\" \n            root_dir (string): Directory with the images.\n            transform (optional): Data augmentation\n        \"\"\"        \n        super().__init__()\n        self.df = dataframe\n        self.image_dir = root_dir\n        self.transforms = transforms    \n        self.labels_list=list(self.df.iloc[:,1])\n    \n    def __len__(self):\n        return len(self.labels_list)\n\n\n    def __getitem__(self, index):\n        self.bag_list=[]\n        name=self.df.iloc[index,0]\n        gender=self.df.iloc[index,2]\n        DOB=self.df.iloc[index,3]\n        DOB=int(DOB[-4:])\n\n        path, dirs, files = next(os.walk(self.image_dir+name))\n        i=0\n\n        for file in files:\n            image = Image.open(self.image_dir+name+\"/\"+file)\n\n\n            if(self.transforms!=None):\n                image=self.transforms(image)\n\n            self.bag_list.append(image)\n        label = {\"name\":name,\"nb\":len(files), \"label\":self.labels_list[index]*2-1,\"gender\":gender ,\"DOB\":DOB,\"LYMPH_COUNT\":float(self.df.iloc[index,4])}\n\n        return self.bag_list, label\n","execution_count":156,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain_data_transforms = torchvision.transforms.Compose([\n\n\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ndataset_svm_train=DLMI_data_svm(df_train,\"/kaggle/input/3md3070-dlmi/trainset/\",train_data_transforms)\ndataset_svm_val=DLMI_data_svm(df_val,\"/kaggle/input/3md3070-dlmi/trainset/\",train_data_transforms)","execution_count":157,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We add the age and concentration data to the embdding"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef extract_features(model,dataset):\n    X=[]\n    Y=[]\n    patient=[]\n    for i in range(len(dataset)):\n        image_bag, labels = dataset[i]\n\n        features = model(torch.stack(image_bag).to(device))\n        features = features.view(features.size(0),-1)\n        features = features.cpu().numpy()\n        X.append(features)\n        Y.append(labels[\"label\"])\n        patient.append(labels)\n    return X,Y,patient\n\n\n\n","execution_count":158,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_pca(pca,X_data,P_data):\n    res= []\n    for i in range(len(X_data)):\n        n,f=X_data[i].shape\n        new_data=np.zeros((n,pca.n_components_+4))\n        new_data[:,:-4]=pca.transform(X_data[i])\n        new_data[:,-4]=P_data[i][\"DOB\"]\n        new_data[:,-1]=P_data[i][\"LYMPH_COUNT\"]\n        \n        \n        res.append(new_data)\n    return res","execution_count":160,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,Y_train,P_train=extract_features(model,dataset_svm_train)\nX_val,Y_val,P_val=extract_features(model,dataset_svm_val)\n","execution_count":161,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use PCA to reduce dimentionality of the data and keep only 95% of the variance information."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0].shape","execution_count":162,"outputs":[{"output_type":"execute_result","execution_count":162,"data":{"text/plain":"(170, 2048)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA(n_components = 0.95)\nfrom sklearn.model_selection import train_test_split\n\npca.fit(np.concatenate( X_train, axis=0 ))\n\nX_train_pca = process_pca(pca,X_train,P_train)\nX_val_pca = process_pca(pca,X_val,P_val)","execution_count":163,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"number of pca components\",X_train_pca[0].shape[1])","execution_count":164,"outputs":[{"output_type":"stream","text":"number of pca components 159\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We download Multi-instance svm ,finetune it and use it on our embedding vectors."},{"metadata":{"trusted":true},"cell_type":"code","source":"\n!git clone https://github.com/garydoranjr/misvm\n%cd misvm\n!python setup.py install\n","execution_count":16,"outputs":[{"output_type":"stream","text":"Cloning into 'misvm'...\nremote: Enumerating objects: 198, done.\u001b[K\nremote: Total 198 (delta 0), reused 0 (delta 0), pack-reused 198\u001b[K\nReceiving objects: 100% (198/198), 180.87 KiB | 774.00 KiB/s, done.\nResolving deltas: 100% (109/109), done.\n/kaggle/working/misvm\nrunning install\nrunning bdist_egg\nrunning egg_info\ncreating misvm.egg-info\nwriting misvm.egg-info/PKG-INFO\nwriting dependency_links to misvm.egg-info/dependency_links.txt\nwriting requirements to misvm.egg-info/requires.txt\nwriting top-level names to misvm.egg-info/top_level.txt\nwriting manifest file 'misvm.egg-info/SOURCES.txt'\nwriting manifest file 'misvm.egg-info/SOURCES.txt'\ninstalling library code to build/bdist.linux-x86_64/egg\nrunning install_lib\nrunning build_py\ncreating build\ncreating build/lib\ncreating build/lib/misvm\ncopying misvm/stmil.py -> build/lib/misvm\ncopying misvm/nsk.py -> build/lib/misvm\ncopying misvm/quadprog.py -> build/lib/misvm\ncopying misvm/kernel.py -> build/lib/misvm\ncopying misvm/sbmil.py -> build/lib/misvm\ncopying misvm/misssvm.py -> build/lib/misvm\ncopying misvm/__init__.py -> build/lib/misvm\ncopying misvm/smil.py -> build/lib/misvm\ncopying misvm/sil.py -> build/lib/misvm\ncopying misvm/stk.py -> build/lib/misvm\ncopying misvm/util.py -> build/lib/misvm\ncopying misvm/svm.py -> build/lib/misvm\ncopying misvm/mica.py -> build/lib/misvm\ncopying misvm/cccp.py -> build/lib/misvm\ncopying misvm/mi_svm.py -> build/lib/misvm\ncreating build/bdist.linux-x86_64\ncreating build/bdist.linux-x86_64/egg\ncreating build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/stmil.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/nsk.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/quadprog.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/kernel.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/sbmil.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/misssvm.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/__init__.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/smil.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/sil.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/stk.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/util.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/svm.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/mica.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/cccp.py -> build/bdist.linux-x86_64/egg/misvm\ncopying build/lib/misvm/mi_svm.py -> build/bdist.linux-x86_64/egg/misvm\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/stmil.py to stmil.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/nsk.py to nsk.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/quadprog.py to quadprog.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/kernel.py to kernel.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/sbmil.py to sbmil.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/misssvm.py to misssvm.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/__init__.py to __init__.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/smil.py to smil.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/sil.py to sil.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/stk.py to stk.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/util.py to util.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/svm.py to svm.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/mica.py to mica.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/cccp.py to cccp.cpython-37.pyc\nbyte-compiling build/bdist.linux-x86_64/egg/misvm/mi_svm.py to mi_svm.cpython-37.pyc\ncreating build/bdist.linux-x86_64/egg/EGG-INFO\ncopying misvm.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying misvm.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying misvm.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying misvm.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\ncopying misvm.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\nzip_safe flag not set; analyzing archive contents...\ncreating dist\ncreating 'dist/misvm-1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\nremoving 'build/bdist.linux-x86_64/egg' (and everything under it)\nProcessing misvm-1.0-py3.7.egg\nCopying misvm-1.0-py3.7.egg to /opt/conda/lib/python3.7/site-packages\nAdding misvm 1.0 to easy-install.pth file\n\nInstalled /opt/conda/lib/python3.7/site-packages/misvm-1.0-py3.7.egg\nProcessing dependencies for misvm==1.0\nSearching for cvxopt\nReading https://pypi.org/simple/cvxopt/\nDownloading https://files.pythonhosted.org/packages/bd/a4/eb2eee12fd189d3684abe8564d76fef9c760b30bed333b7e38d939564543/cvxopt-1.2.6-cp37-cp37m-manylinux1_x86_64.whl#sha256=368caf7d2130670e6e48af0d611ae41713a98d7643f7d64a6aeabefad50e76c4\nBest match: cvxopt 1.2.6\nProcessing cvxopt-1.2.6-cp37-cp37m-manylinux1_x86_64.whl\nInstalling cvxopt-1.2.6-cp37-cp37m-manylinux1_x86_64.whl to /opt/conda/lib/python3.7/site-packages\nAdding cvxopt 1.2.6 to easy-install.pth file\n\nInstalled /opt/conda/lib/python3.7/site-packages/cvxopt-1.2.6-py3.7-linux-x86_64.egg\nSearching for scipy==1.5.4\nBest match: scipy 1.5.4\nAdding scipy 1.5.4 to easy-install.pth file\n\nUsing /opt/conda/lib/python3.7/site-packages\nSearching for numpy==1.19.5\nBest match: numpy 1.19.5\nAdding numpy 1.19.5 to easy-install.pth file\nInstalling f2py script to /opt/conda/bin\nInstalling f2py3 script to /opt/conda/bin\nInstalling f2py3.7 script to /opt/conda/bin\n\nUsing /opt/conda/lib/python3.7/site-packages\nFinished processing dependencies for misvm==1.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install \"cvxopt==1.2.4\"","execution_count":17,"outputs":[{"output_type":"stream","text":"Collecting cvxopt==1.2.4\n  Downloading cvxopt-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n\u001b[K     |████████████████████████████████| 11.6 MB 9.1 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: cvxopt\n  Attempting uninstall: cvxopt\n    Found existing installation: cvxopt 1.2.6\n    Uninstalling cvxopt-1.2.6:\n      Successfully uninstalled cvxopt-1.2.6\nSuccessfully installed cvxopt-1.2.4\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import misvm\nMILSVM = misvm.MISVM(kernel='linear',C = 80,max_iters=150)\nMILSVM.fit(X_train, Y_train) \npred_y=MILSVM.predict(X_val)\n","execution_count":166,"outputs":[{"output_type":"stream","text":"Non-random start...\n\nIteration 1...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -7.3399e+01 -1.2258e+01  8e+03  1e+02  8e-12\n 1: -5.9574e+00 -1.0733e+01  2e+02  3e+00  6e-12\n 2: -3.2575e+00 -8.2128e+00  2e+01  2e-01  7e-13\n 3: -2.9293e+00 -5.2181e+00  6e+00  5e-02  3e-13\n 4: -2.8762e+00 -4.1163e+00  2e+00  2e-02  3e-13\n 5: -2.9003e+00 -3.3410e+00  5e-01  3e-03  3e-13\n 6: -2.9420e+00 -3.0897e+00  1e-01  2e-04  3e-13\n 7: -2.9610e+00 -3.0187e+00  6e-02  1e-15  4e-13\n 8: -2.9689e+00 -2.9888e+00  2e-02  2e-15  3e-13\n 9: -2.9731e+00 -2.9808e+00  8e-03  2e-15  6e-13\n10: -2.9750e+00 -2.9776e+00  3e-03  9e-17  2e-12\n11: -2.9758e+00 -2.9766e+00  8e-04  1e-16  2e-12\n12: -2.9762e+00 -2.9764e+00  2e-04  3e-15  3e-12\n13: -2.9763e+00 -2.9763e+00  1e-05  7e-15  6e-12\n14: -2.9763e+00 -2.9763e+00  5e-07  3e-15  2e-11\nOptimal solution found.\nRecomputing classes...\nSelector differences: 2143\nUpdating QP...\n\nIteration 2...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -3.2915e+01 -1.3175e+01  6e+03  8e+01  4e-12\n 1: -5.9141e+00 -1.0057e+01  2e+02  3e+00  3e-12\n 2: -2.9245e+00 -7.1092e+00  3e+01  3e-01  7e-13\n 3: -2.4954e+00 -4.7432e+00  1e+01  1e-01  4e-13\n 4: -2.1882e+00 -4.5131e+00  1e+01  9e-02  3e-13\n 5: -1.8923e+00 -3.8396e+00  5e+00  4e-02  2e-13\n 6: -1.8259e+00 -3.0705e+00  2e+00  1e-02  2e-13\n 7: -1.9598e+00 -2.6463e+00  9e-01  4e-03  3e-13\n 8: -2.0353e+00 -2.5425e+00  6e-01  2e-03  2e-13\n 9: -2.0732e+00 -2.4610e+00  4e-01  2e-15  3e-13\n10: -2.1845e+00 -2.3521e+00  2e-01  2e-15  3e-13\n11: -2.2098e+00 -2.3388e+00  1e-01  2e-15  3e-13\n12: -2.2597e+00 -2.3043e+00  4e-02  2e-15  3e-13\n13: -2.2653e+00 -2.2984e+00  3e-02  3e-16  3e-13\n14: -2.2832e+00 -2.2926e+00  9e-03  3e-15  3e-13\n15: -2.2867e+00 -2.2914e+00  5e-03  6e-15  3e-13\n16: -2.2905e+00 -2.2907e+00  2e-04  6e-15  3e-13\n17: -2.2907e+00 -2.2907e+00  5e-06  2e-15  4e-13\n18: -2.2907e+00 -2.2907e+00  6e-08  1e-15  3e-12\nOptimal solution found.\nRecomputing classes...\nSelector differences: 31\nUpdating QP...\n\nIteration 3...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -3.1411e+01 -1.2998e+01  6e+03  8e+01  4e-12\n 1: -5.8925e+00 -9.8798e+00  2e+02  3e+00  3e-12\n 2: -2.9186e+00 -6.8330e+00  3e+01  3e-01  7e-13\n 3: -2.5228e+00 -4.6795e+00  1e+01  2e-01  4e-13\n 4: -2.0876e+00 -4.2039e+00  1e+01  1e-01  3e-13\n 5: -1.8017e+00 -3.4722e+00  6e+00  5e-02  2e-13\n 6: -1.5822e+00 -3.0108e+00  3e+00  2e-02  2e-13\n 7: -1.6689e+00 -2.3824e+00  1e+00  5e-03  2e-13\n 8: -1.7780e+00 -2.2618e+00  5e-01  7e-04  3e-13\n 9: -1.8370e+00 -2.2139e+00  4e-01  4e-04  2e-13\n10: -1.9376e+00 -2.1154e+00  2e-01  2e-05  3e-13\n11: -1.9877e+00 -2.0816e+00  9e-02  5e-06  3e-13\n12: -2.0189e+00 -2.0661e+00  5e-02  4e-15  3e-13\n13: -2.0463e+00 -2.0580e+00  1e-02  2e-15  3e-13\n14: -2.0551e+00 -2.0559e+00  8e-04  1e-15  3e-13\n15: -2.0558e+00 -2.0558e+00  1e-05  2e-15  3e-13\n16: -2.0558e+00 -2.0558e+00  2e-07  2e-15  7e-13\nOptimal solution found.\nRecomputing classes...\nSelector differences: 7\nUpdating QP...\n\nIteration 4...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -3.0929e+01 -1.3040e+01  6e+03  8e+01  3e-12\n 1: -5.8554e+00 -9.9252e+00  2e+02  3e+00  4e-12\n 2: -2.9115e+00 -6.8248e+00  3e+01  3e-01  7e-13\n 3: -2.5300e+00 -4.7468e+00  1e+01  2e-01  4e-13\n 4: -2.0697e+00 -4.2594e+00  1e+01  1e-01  3e-13\n 5: -1.7464e+00 -3.4879e+00  7e+00  5e-02  3e-13\n 6: -1.5127e+00 -2.9897e+00  3e+00  2e-02  2e-13\n 7: -1.6222e+00 -2.3523e+00  1e+00  5e-03  2e-13\n 8: -1.6941e+00 -2.2769e+00  8e-01  3e-03  2e-13\n 9: -1.7569e+00 -2.2104e+00  6e-01  2e-03  2e-13\n10: -1.8344e+00 -2.1336e+00  3e-01  2e-04  3e-13\n11: -1.9111e+00 -2.0663e+00  2e-01  5e-15  3e-13\n12: -1.9783e+00 -2.0319e+00  5e-02  5e-15  3e-13\n13: -2.0034e+00 -2.0218e+00  2e-02  9e-16  3e-13\n14: -2.0163e+00 -2.0189e+00  3e-03  4e-15  3e-13\n15: -2.0182e+00 -2.0186e+00  4e-04  3e-15  3e-13\n16: -2.0186e+00 -2.0186e+00  8e-06  4e-16  3e-13\n17: -2.0186e+00 -2.0186e+00  1e-07  4e-15  8e-13\nOptimal solution found.\nRecomputing classes...\nSelector differences: 9\nUpdating QP...\n\nIteration 5...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -3.0165e+01 -1.2919e+01  5e+03  8e+01  3e-12\n 1: -5.9137e+00 -9.7845e+00  2e+02  3e+00  3e-12\n 2: -2.9147e+00 -6.7676e+00  3e+01  3e-01  6e-13\n 3: -2.5421e+00 -4.7173e+00  1e+01  2e-01  4e-13\n 4: -2.0792e+00 -4.1743e+00  1e+01  1e-01  3e-13\n 5: -1.7373e+00 -3.4519e+00  7e+00  6e-02  3e-13\n 6: -1.4819e+00 -2.9650e+00  3e+00  2e-02  2e-13\n 7: -1.5566e+00 -2.3266e+00  1e+00  4e-03  2e-13\n 8: -1.6978e+00 -2.1243e+00  5e-01  1e-03  2e-13\n 9: -1.7559e+00 -2.0952e+00  4e-01  7e-04  2e-13\n10: -1.8102e+00 -2.0493e+00  2e-01  6e-05  3e-13\n11: -1.9048e+00 -1.9926e+00  9e-02  1e-05  2e-13\n12: -1.9437e+00 -1.9716e+00  3e-02  3e-15  3e-13\n13: -1.9610e+00 -1.9672e+00  6e-03  1e-15  3e-13\n14: -1.9660e+00 -1.9662e+00  2e-04  3e-15  3e-13\n15: -1.9662e+00 -1.9662e+00  3e-06  2e-15  3e-13\n16: -1.9662e+00 -1.9662e+00  4e-08  1e-15  8e-13\nOptimal solution found.\nRecomputing classes...\nSelector differences: 3\nUpdating QP...\n\nIteration 6...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -1.9662e+00 -1.9662e+00  4e-08  1e-15  4e-03\n 1: -1.9662e+00 -1.9662e+00  1e-09  6e-16  4e-05\n 2: -1.9662e+00 -1.9662e+00  1e-11  1e-15  4e-07\n 3: -1.9662e+00 -1.9662e+00  1e-13  2e-14  4e-09\nOptimal solution found.\nRecomputing classes...\nSelector differences: 0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_y=np.sign(pred_y)\nfrom sklearn.metrics import balanced_accuracy_score\nprint(\"validation balance accuracy:\",balanced_accuracy_score(Y_val, pred_y))","execution_count":167,"outputs":[{"output_type":"stream","text":"validation balance accuracy: 0.6478260869565218\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvfile=\"/kaggle/input/3md3070-dlmi/testset/testset_data.csv\"\ntest_df=pd.read_csv(csvfile)  \ntest_svm=DLMI_data_svm(test_df,\"/kaggle/input/3md3070-dlmi/testset/\",train_data_transforms)","execution_count":168,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#uncomment this to execute pca version\n#MILSVM.fit(X_train_pca, Y_train) \n#pred_y=MILSVM.predict(X_val_pca)\n#pred_y=np.sign(pred_y)\n#from sklearn.metrics import balanced_accuracy_score\n#print(\"validation balance accuracy:\",balanced_accuracy_score(Y_val, pred_y))","execution_count":175,"outputs":[{"output_type":"stream","text":"Non-random start...\n\nIteration 1...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -5.4647e+01 -1.1412e+01  1e+04  1e+02  3e-08\n 1: -3.4462e+00 -1.1248e+01  3e+02  3e+00  3e-08\n 2: -2.2989e+00 -8.2476e+00  6e+01  6e-01  6e-09\n 3: -2.0890e+00 -5.9170e+00  3e+01  3e-01  3e-09\n 4: -1.9764e+00 -4.9210e+00  2e+01  2e-01  2e-09\n 5: -1.8348e+00 -4.0048e+00  1e+01  1e-01  1e-09\n 6: -1.7134e+00 -3.5073e+00  9e+00  6e-02  1e-09\n 7: -1.5966e+00 -3.1649e+00  8e+00  5e-02  1e-09\n 8: -1.4836e+00 -2.9891e+00  6e+00  4e-02  1e-09\n 9: -1.3689e+00 -2.8253e+00  5e+00  2e-02  9e-10\n10: -1.2546e+00 -2.6952e+00  4e+00  2e-02  9e-10\n11: -1.1711e+00 -2.4007e+00  3e+00  9e-03  8e-10\n12: -1.1094e+00 -2.1576e+00  1e+00  3e-03  9e-10\n13: -1.1076e+00 -1.9925e+00  1e+00  1e-03  8e-10\n14: -1.1970e+00 -1.6160e+00  4e-01  1e-04  9e-10\n15: -1.2208e+00 -1.6197e+00  4e-01  9e-05  9e-10\n16: -1.2674e+00 -1.5340e+00  3e-01  5e-05  8e-10\n17: -1.2772e+00 -1.5074e+00  2e-01  3e-05  8e-10\n18: -1.2921e+00 -1.5064e+00  2e-01  2e-05  8e-10\n19: -1.3487e+00 -1.4370e+00  9e-02  6e-06  8e-10\n20: -1.3554e+00 -1.4301e+00  7e-02  3e-06  8e-10\n21: -1.3664e+00 -1.4199e+00  5e-02  2e-07  1e-09\n22: -1.3827e+00 -1.4122e+00  3e-02  1e-07  9e-10\n23: -1.3934e+00 -1.4077e+00  1e-02  3e-08  9e-10\n24: -1.3971e+00 -1.4060e+00  9e-03  9e-09  8e-10\n25: -1.4008e+00 -1.4049e+00  4e-03  1e-15  9e-10\n26: -1.4033e+00 -1.4045e+00  1e-03  3e-16  9e-10\n27: -1.4037e+00 -1.4044e+00  7e-04  6e-16  1e-09\n28: -1.4043e+00 -1.4043e+00  3e-05  1e-15  1e-09\n29: -1.4043e+00 -1.4043e+00  4e-07  1e-15  1e-09\nOptimal solution found.\nRecomputing classes...\nSelector differences: 2143\nUpdating QP...\n\nIteration 2...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -4.7819e+01 -1.0959e+01  1e+04  1e+02  3e-08\n 1: -3.0582e+00 -1.0774e+01  2e+02  3e+00  3e-08\n 2: -2.0319e+00 -7.3100e+00  5e+01  5e-01  6e-09\n 3: -1.7144e+00 -4.5050e+00  2e+01  2e-01  3e-09\n 4: -1.3751e+00 -3.0216e+00  1e+01  1e-01  2e-09\n 5: -1.1515e+00 -2.2595e+00  9e+00  6e-02  1e-09\n 6: -9.4479e-01 -1.6773e+00  6e+00  4e-02  8e-10\n 7: -7.1924e-01 -1.5135e+00  4e+00  2e-02  7e-10\n 8: -5.5091e-01 -1.4444e+00  4e+00  1e-02  6e-10\n 9: -4.7731e-01 -1.1233e+00  2e+00  6e-03  5e-10\n10: -5.0617e-01 -9.0329e-01  6e-01  1e-03  5e-10\n11: -5.6242e-01 -8.2710e-01  3e-01  4e-04  5e-10\n12: -6.1273e-01 -8.0770e-01  2e-01  1e-04  5e-10\n13: -6.7072e-01 -7.7545e-01  1e-01  4e-05  6e-10\n14: -7.0766e-01 -7.5642e-01  5e-02  8e-06  7e-10\n15: -7.1769e-01 -7.5004e-01  3e-02  1e-06  7e-10\n16: -7.3983e-01 -7.4555e-01  6e-03  2e-07  7e-10\n17: -7.4421e-01 -7.4471e-01  5e-04  1e-09  7e-10\n18: -7.4466e-01 -7.4467e-01  7e-06  2e-11  8e-10\n19: -7.4467e-01 -7.4467e-01  9e-08  2e-13  7e-10\nOptimal solution found.\nRecomputing classes...\nSelector differences: 50\nUpdating QP...\n\nIteration 3...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -4.7343e+01 -1.0917e+01  1e+04  1e+02  3e-08\n 1: -3.0196e+00 -1.0730e+01  2e+02  3e+00  3e-08\n 2: -2.0175e+00 -7.1919e+00  5e+01  5e-01  7e-09\n 3: -1.6840e+00 -4.2310e+00  2e+01  2e-01  3e-09\n 4: -1.3154e+00 -2.8858e+00  1e+01  1e-01  2e-09\n 5: -1.0806e+00 -2.0847e+00  8e+00  6e-02  1e-09\n 6: -8.7547e-01 -1.6485e+00  6e+00  4e-02  8e-10\n 7: -6.1285e-01 -1.4284e+00  4e+00  2e-02  6e-10\n 8: -4.8870e-01 -1.2533e+00  3e+00  1e-02  5e-10\n 9: -4.0763e-01 -1.0127e+00  1e+00  3e-03  5e-10\n10: -4.8442e-01 -8.2426e-01  5e-01  1e-03  5e-10\n11: -5.4465e-01 -7.6087e-01  3e-01  4e-04  5e-10\n12: -5.7119e-01 -7.5350e-01  2e-01  2e-04  5e-10\n13: -6.2055e-01 -7.2267e-01  1e-01  1e-04  5e-10\n14: -6.5782e-01 -7.0469e-01  5e-02  1e-05  6e-10\n15: -6.8449e-01 -6.9508e-01  1e-02  1e-06  7e-10\n16: -6.9166e-01 -6.9359e-01  2e-03  1e-16  7e-10\n17: -6.9338e-01 -6.9342e-01  4e-05  3e-16  7e-10\n18: -6.9342e-01 -6.9342e-01  5e-07  7e-16  7e-10\nOptimal solution found.\nRecomputing classes...\nSelector differences: 17\nUpdating QP...\n\nIteration 4...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -4.7376e+01 -1.0917e+01  1e+04  1e+02  3e-08\n 1: -2.9923e+00 -1.0731e+01  2e+02  2e+00  3e-08\n 2: -2.0112e+00 -7.1239e+00  5e+01  5e-01  6e-09\n 3: -1.6872e+00 -4.2527e+00  2e+01  2e-01  3e-09\n 4: -1.3094e+00 -2.9000e+00  1e+01  1e-01  2e-09\n 5: -1.0548e+00 -2.0407e+00  8e+00  6e-02  1e-09\n 6: -8.7234e-01 -1.6830e+00  6e+00  4e-02  8e-10\n 7: -7.5502e-01 -1.4544e+00  5e+00  3e-02  7e-10\n 8: -4.7274e-01 -1.3426e+00  3e+00  1e-02  6e-10\n 9: -3.5361e-01 -1.1956e+00  2e+00  5e-03  5e-10\n10: -4.2060e-01 -8.7767e-01  7e-01  1e-03  5e-10\n11: -4.5827e-01 -8.4594e-01  5e-01  7e-04  5e-10\n12: -5.2148e-01 -7.7014e-01  3e-01  4e-04  4e-10\n13: -5.6787e-01 -7.4540e-01  2e-01  2e-04  5e-10\n14: -6.0284e-01 -7.2369e-01  1e-01  9e-05  5e-10\n15: -6.4548e-01 -6.9739e-01  5e-02  3e-16  6e-10\n16: -6.6279e-01 -6.9168e-01  3e-02  9e-17  6e-10\n17: -6.8171e-01 -6.8693e-01  5e-03  7e-16  6e-10\n18: -6.8588e-01 -6.8609e-01  2e-04  2e-15  7e-10\n19: -6.8606e-01 -6.8606e-01  4e-06  9e-16  7e-10\n20: -6.8606e-01 -6.8606e-01  6e-08  6e-16  7e-10\nOptimal solution found.\nRecomputing classes...\nSelector differences: 9\nUpdating QP...\n\nIteration 5...\nTraining SVM...\n     pcost       dcost       gap    pres   dres\n 0: -4.7765e+01 -1.0912e+01  1e+04  1e+02  3e-08\n 1: -3.0597e+00 -1.0727e+01  2e+02  3e+00  2e-08\n 2: -2.0377e+00 -7.2404e+00  5e+01  5e-01  5e-09\n 3: -1.7072e+00 -4.2999e+00  2e+01  2e-01  2e-09\n 4: -1.3475e+00 -2.9758e+00  1e+01  1e-01  1e-09\n 5: -1.0842e+00 -1.9924e+00  8e+00  6e-02  1e-09\n 6: -8.9615e-01 -1.6568e+00  6e+00  4e-02  7e-10\n 7: -6.6425e-01 -1.4399e+00  4e+00  2e-02  6e-10\n 8: -5.8511e-01 -1.2100e+00  3e+00  2e-02  5e-10\n 9: -4.8686e-01 -1.0422e+00  2e+00  7e-03  5e-10\n10: -4.7938e-01 -8.3163e-01  6e-01  2e-03  5e-10\n11: -5.2295e-01 -7.6606e-01  3e-01  7e-04  5e-10\n12: -5.7693e-01 -7.3991e-01  2e-01  9e-05  6e-10\n13: -6.2741e-01 -7.0379e-01  8e-02  5e-16  6e-10\n14: -6.4777e-01 -6.9667e-01  5e-02  1e-16  5e-10\n15: -6.7596e-01 -6.8842e-01  1e-02  1e-16  6e-10\n16: -6.8467e-01 -6.8630e-01  2e-03  1e-16  7e-10\n17: -6.8604e-01 -6.8607e-01  3e-05  3e-16  7e-10\n18: -6.8606e-01 -6.8606e-01  4e-07  7e-16  7e-10\nOptimal solution found.\nRecomputing classes...\nSelector differences: 0\nvalidation balance accuracy: 0.8130434782608695\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test,Y_test,P_test=extract_features(model,test_svm)","execution_count":169,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_pca = process_pca(pca,X_test,P_test)","execution_count":170,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n#test score :0.83116\n##sometimes you need to execute this cell twice for the csv file to be properly saved\nmyCsv = csv.writer(open('/kaggle/working/pred_svm_no_pca.csv', 'w'))\nmyCsv.writerow([\"ID\", \"Predicted\"])\npred_y_test=MILSVM.predict(X_test)\n#pred_y_test=MILSVM.predict(X_test_pca) uncomment this for pca\nfor i in range(len(pred_y_test)):\n    \n    myCsv.writerow([test_svm[i][1][\"name\"], int((np.sign(pred_y_test[i])+1)/2)])\n","execution_count":173,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ANN"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch\nimport torch.nn.functional as F\nclass ANN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.input= nn.Linear(2, 4)\n        self.hidden1= nn.Linear(4, 3)\n        self.sig=nn.Sigmoid()\n        self.output = nn.Linear(3, 1)\n        self.rel=nn.ReLU()\n        \n\n    def forward(self, Y):\n\n        X=self.rel(self.input(Y))\n      \n        X=self.rel(self.hidden1(X))\n\n        X=self.sig(self.output(X).view(-1,1))\n        return X\n","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\n\ndef train(model,train_data_loader,val_data_loader,epochs=50):\n    optimizer =torch.optim.Adam(model.parameters(), lr = 0.0005, weight_decay=10e-5)\n    scheduler= torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.9)\n\n    for epoch in range(1,epochs+1):\n        model.train()\n        \n  \n        for iter_num,(X, Y) in enumerate(train_data_loader):\n\n\n            optimizer.zero_grad()\n\n            pred = model(X)\n\n            criterion1=torch.nn.BCELoss()\n          \n            loss = criterion1(pred,Y.view(-1,1))\n\n            loss.backward()\n\n            temp=[]\n            for layer in model.parameters():\n                temp.append(layer)\n\n            print('Epoch: {}  | Training Loss: {:1.5f} '.format(epoch, loss))\n            optimizer.step()\n        scheduler.step()\n\n        model.eval()\n        with torch.no_grad():\n            total_pred=[]\n            total_truth=[]\n            for iter_num,(X_val, Y_val) in enumerate(val_data_loader):\n                pred_val = model(X_val)\n\n\n\n\n                predd=[int(score >= 0.5) for score in pred_val]\n                total_pred.extend(predd)\n                Y_truth=[int(i) for i in Y_val.detach().numpy()]\n                total_truth.extend(Y_truth)\n            #print( total_truth,total_pred)\n        \n            print('Epoch: {}  | Validation balanced accuracy : {:1.5f} '.format(epoch, float(balanced_accuracy_score(total_truth,total_pred))))\n    torch.save(model, 'ann_model_weights.pt')\n    return model","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset,TensorDataset\nX_train=df_train.iloc[:,-2:]\nY_train=df_train.iloc[:,1]\nX_train.iloc[:,0]=X_train.iloc[:,0].str[-4:]\nX_train.iloc[:,0]=pd.to_numeric(X_train.DOB)\nX_train = torch.FloatTensor(X_train.values)\nY_train = torch.FloatTensor(Y_train.values)\ntrain_data_loader = DataLoader(TensorDataset(X_train, Y_train), batch_size=32)\n\nX_val=df_val.iloc[:,-2:]\nY_val=df_val.iloc[:,1]\nX_val.iloc[:,0]=X_val.iloc[:,0].str[-4:]\nX_val.iloc[:,0]=pd.to_numeric(X_val.DOB)\n\n\n\nX_val = torch.FloatTensor(X_val.values)\nY_val = torch.FloatTensor(Y_val.values)\nval_data_loader = DataLoader(TensorDataset(X_val, Y_val), batch_size=32)\nmodel0 = ANN()\nmodel0=train(model0,train_data_loader,val_data_loader,epochs=5000)\n","execution_count":34,"outputs":[{"output_type":"stream","text":"Epoch: 1  | Training Loss: 3.78080 \nEpoch: 1  | Training Loss: 3.62793 \nEpoch: 1  | Training Loss: 2.60591 \nEpoch: 1  | Training Loss: 1.94699 \nEpoch: 1  | Training Loss: 0.00038 \nEpoch: 1  | Validation balanced accuracy : 0.50000 \nEpoch: 2  | Training Loss: 3.09245 \nEpoch: 2  | Training Loss: 2.96288 \nEpoch: 2  | Training Loss: 2.12083 \nEpoch: 2  | Training Loss: 1.57667 \nEpoch: 2  | Training Loss: 0.00180 \nEpoch: 2  | Validation balanced accuracy : 0.50000 \nEpoch: 3  | Training Loss: 2.46813 \nEpoch: 3  | Training Loss: 2.34354 \nEpoch: 3  | Training Loss: 1.66206 \nEpoch: 3  | Training Loss: 1.22317 \nEpoch: 3  | Training Loss: 0.00802 \nEpoch: 3  | Validation balanced accuracy : 0.50000 \nEpoch: 4  | Training Loss: 1.86886 \nEpoch: 4  | Training Loss: 1.74949 \nEpoch: 4  | Training Loss: 1.22644 \nEpoch: 4  | Training Loss: 0.89227 \nEpoch: 4  | Training Loss: 0.03398 \nEpoch: 4  | Validation balanced accuracy : 0.50000 \nEpoch: 5  | Training Loss: 1.31222 \nEpoch: 5  | Training Loss: 1.20508 \nEpoch: 5  | Training Loss: 0.84788 \nEpoch: 5  | Training Loss: 0.62714 \nEpoch: 5  | Training Loss: 0.12910 \nEpoch: 5  | Validation balanced accuracy : 0.50000 \nEpoch: 6  | Training Loss: 0.87480 \nEpoch: 6  | Training Loss: 0.80408 \nEpoch: 6  | Training Loss: 0.63246 \nEpoch: 6  | Training Loss: 0.53640 \nEpoch: 6  | Training Loss: 0.36478 \nEpoch: 6  | Validation balanced accuracy : 0.50000 \nEpoch: 7  | Training Loss: 0.68882 \nEpoch: 7  | Training Loss: 0.67047 \nEpoch: 7  | Training Loss: 0.63296 \nEpoch: 7  | Training Loss: 0.61943 \nEpoch: 7  | Training Loss: 0.59333 \nEpoch: 7  | Validation balanced accuracy : 0.50000 \nEpoch: 8  | Training Loss: 0.68559 \nEpoch: 8  | Training Loss: 0.67599 \nEpoch: 8  | Training Loss: 0.65743 \nEpoch: 8  | Training Loss: 0.63068 \nEpoch: 8  | Training Loss: 0.56287 \nEpoch: 8  | Validation balanced accuracy : 0.50000 \nEpoch: 9  | Training Loss: 0.68021 \nEpoch: 9  | Training Loss: 0.66931 \nEpoch: 9  | Training Loss: 0.61949 \nEpoch: 9  | Training Loss: 0.56461 \nEpoch: 9  | Training Loss: 0.39862 \nEpoch: 9  | Validation balanced accuracy : 0.50000 \nEpoch: 10  | Training Loss: 0.70212 \nEpoch: 10  | Training Loss: 0.70065 \nEpoch: 10  | Training Loss: 0.61235 \nEpoch: 10  | Training Loss: 0.53560 \nEpoch: 10  | Training Loss: 0.28236 \nEpoch: 10  | Validation balanced accuracy : 0.50000 \nEpoch: 11  | Training Loss: 0.75372 \nEpoch: 11  | Training Loss: 0.75124 \nEpoch: 11  | Training Loss: 0.62944 \nEpoch: 11  | Training Loss: 0.53623 \nEpoch: 11  | Training Loss: 0.24213 \nEpoch: 11  | Validation balanced accuracy : 0.50000 \nEpoch: 12  | Training Loss: 0.77676 \nEpoch: 12  | Training Loss: 0.76566 \nEpoch: 12  | Training Loss: 0.63188 \nEpoch: 12  | Training Loss: 0.53584 \nEpoch: 12  | Training Loss: 0.25390 \nEpoch: 12  | Validation balanced accuracy : 0.50000 \nEpoch: 13  | Training Loss: 0.75998 \nEpoch: 13  | Training Loss: 0.74359 \nEpoch: 13  | Training Loss: 0.62061 \nEpoch: 13  | Training Loss: 0.53475 \nEpoch: 13  | Training Loss: 0.29445 \nEpoch: 13  | Validation balanced accuracy : 0.50000 \nEpoch: 14  | Training Loss: 0.73059 \nEpoch: 14  | Training Loss: 0.71480 \nEpoch: 14  | Training Loss: 0.61172 \nEpoch: 14  | Training Loss: 0.53891 \nEpoch: 14  | Training Loss: 0.33620 \nEpoch: 14  | Validation balanced accuracy : 0.50000 \nEpoch: 15  | Training Loss: 0.71162 \nEpoch: 15  | Training Loss: 0.69878 \nEpoch: 15  | Training Loss: 0.60935 \nEpoch: 15  | Training Loss: 0.54305 \nEpoch: 15  | Training Loss: 0.35349 \nEpoch: 15  | Validation balanced accuracy : 0.50000 \nEpoch: 16  | Training Loss: 0.70707 \nEpoch: 16  | Training Loss: 0.69672 \nEpoch: 16  | Training Loss: 0.60927 \nEpoch: 16  | Training Loss: 0.54192 \nEpoch: 16  | Training Loss: 0.34340 \nEpoch: 16  | Validation balanced accuracy : 0.50000 \nEpoch: 17  | Training Loss: 0.71246 \nEpoch: 17  | Training Loss: 0.70357 \nEpoch: 17  | Training Loss: 0.61037 \nEpoch: 17  | Training Loss: 0.53855 \nEpoch: 17  | Training Loss: 0.32334 \nEpoch: 17  | Validation balanced accuracy : 0.50000 \nEpoch: 18  | Training Loss: 0.72147 \nEpoch: 18  | Training Loss: 0.71264 \nEpoch: 18  | Training Loss: 0.61230 \nEpoch: 18  | Training Loss: 0.53649 \nEpoch: 18  | Training Loss: 0.30969 \nEpoch: 18  | Validation balanced accuracy : 0.50000 \nEpoch: 19  | Training Loss: 0.72729 \nEpoch: 19  | Training Loss: 0.71747 \nEpoch: 19  | Training Loss: 0.61322 \nEpoch: 19  | Training Loss: 0.53601 \nEpoch: 19  | Training Loss: 0.30764 \nEpoch: 19  | Validation balanced accuracy : 0.50000 \nEpoch: 20  | Training Loss: 0.72714 \nEpoch: 20  | Training Loss: 0.71637 \nEpoch: 20  | Training Loss: 0.61256 \nEpoch: 20  | Training Loss: 0.53650 \nEpoch: 20  | Training Loss: 0.31367 \nEpoch: 20  | Validation balanced accuracy : 0.50000 \nEpoch: 21  | Training Loss: 0.72335 \nEpoch: 21  | Training Loss: 0.71238 \nEpoch: 21  | Training Loss: 0.61140 \nEpoch: 21  | Training Loss: 0.53740 \nEpoch: 21  | Training Loss: 0.32098 \nEpoch: 21  | Validation balanced accuracy : 0.50000 \nEpoch: 22  | Training Loss: 0.71976 \nEpoch: 22  | Training Loss: 0.70921 \nEpoch: 22  | Training Loss: 0.61066 \nEpoch: 22  | Training Loss: 0.53798 \nEpoch: 22  | Training Loss: 0.32443 \nEpoch: 22  | Validation balanced accuracy : 0.50000 \nEpoch: 23  | Training Loss: 0.71843 \nEpoch: 23  | Training Loss: 0.70845 \nEpoch: 23  | Training Loss: 0.61051 \nEpoch: 23  | Training Loss: 0.53790 \nEpoch: 23  | Training Loss: 0.32322 \nEpoch: 23  | Validation balanced accuracy : 0.50000 \nEpoch: 24  | Training Loss: 0.71920 \nEpoch: 24  | Training Loss: 0.70959 \nEpoch: 24  | Training Loss: 0.61073 \nEpoch: 24  | Training Loss: 0.53744 \nEpoch: 24  | Training Loss: 0.31993 \nEpoch: 24  | Validation balanced accuracy : 0.50000 \nEpoch: 25  | Training Loss: 0.72069 \nEpoch: 25  | Training Loss: 0.71116 \nEpoch: 25  | Training Loss: 0.61101 \nEpoch: 25  | Training Loss: 0.53705 \nEpoch: 25  | Training Loss: 0.31747 \nEpoch: 25  | Validation balanced accuracy : 0.50000 \nEpoch: 26  | Training Loss: 0.72159 \nEpoch: 26  | Training Loss: 0.71196 \nEpoch: 26  | Training Loss: 0.61107 \nEpoch: 26  | Training Loss: 0.53692 \nEpoch: 26  | Training Loss: 0.31702 \nEpoch: 26  | Validation balanced accuracy : 0.50000 \nEpoch: 27  | Training Loss: 0.72147 \nEpoch: 27  | Training Loss: 0.71175 \nEpoch: 27  | Training Loss: 0.61090 \nEpoch: 27  | Training Loss: 0.53700 \nEpoch: 27  | Training Loss: 0.31801 \nEpoch: 27  | Validation balanced accuracy : 0.50000 \nEpoch: 28  | Training Loss: 0.72075 \nEpoch: 28  | Training Loss: 0.71107 \nEpoch: 28  | Training Loss: 0.61065 \nEpoch: 28  | Training Loss: 0.53713 \nEpoch: 28  | Training Loss: 0.31914 \nEpoch: 28  | Validation balanced accuracy : 0.50000 \nEpoch: 29  | Training Loss: 0.72009 \nEpoch: 29  | Training Loss: 0.71055 \nEpoch: 29  | Training Loss: 0.61046 \nEpoch: 29  | Training Loss: 0.53718 \nEpoch: 29  | Training Loss: 0.31951 \nEpoch: 29  | Validation balanced accuracy : 0.50000 \nEpoch: 30  | Training Loss: 0.71983 \nEpoch: 30  | Training Loss: 0.71047 \nEpoch: 30  | Training Loss: 0.61038 \nEpoch: 30  | Training Loss: 0.53712 \nEpoch: 30  | Training Loss: 0.31911 \nEpoch: 30  | Validation balanced accuracy : 0.50000 \nEpoch: 31  | Training Loss: 0.71993 \nEpoch: 31  | Training Loss: 0.71069 \nEpoch: 31  | Training Loss: 0.61036 \nEpoch: 31  | Training Loss: 0.53701 \nEpoch: 31  | Training Loss: 0.31843 \nEpoch: 31  | Validation balanced accuracy : 0.50000 \nEpoch: 32  | Training Loss: 0.72010 \nEpoch: 32  | Training Loss: 0.71093 \nEpoch: 32  | Training Loss: 0.61033 \nEpoch: 32  | Training Loss: 0.53692 \nEpoch: 32  | Training Loss: 0.31798 \nEpoch: 32  | Validation balanced accuracy : 0.50000 \nEpoch: 33  | Training Loss: 0.72014 \nEpoch: 33  | Training Loss: 0.71101 \nEpoch: 33  | Training Loss: 0.61027 \nEpoch: 33  | Training Loss: 0.53688 \nEpoch: 33  | Training Loss: 0.31789 \nEpoch: 33  | Validation balanced accuracy : 0.50000 \nEpoch: 34  | Training Loss: 0.72000 \nEpoch: 34  | Training Loss: 0.71093 \nEpoch: 34  | Training Loss: 0.61016 \nEpoch: 34  | Training Loss: 0.53687 \nEpoch: 34  | Training Loss: 0.31799 \nEpoch: 34  | Validation balanced accuracy : 0.50000 \nEpoch: 35  | Training Loss: 0.71978 \nEpoch: 35  | Training Loss: 0.71079 \nEpoch: 35  | Training Loss: 0.61005 \nEpoch: 35  | Training Loss: 0.53686 \nEpoch: 35  | Training Loss: 0.31806 \nEpoch: 35  | Validation balanced accuracy : 0.50000 \nEpoch: 36  | Training Loss: 0.71960 \nEpoch: 36  | Training Loss: 0.71071 \nEpoch: 36  | Training Loss: 0.60996 \nEpoch: 36  | Training Loss: 0.53683 \nEpoch: 36  | Training Loss: 0.31797 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 36  | Validation balanced accuracy : 0.50000 \nEpoch: 37  | Training Loss: 0.71950 \nEpoch: 37  | Training Loss: 0.71070 \nEpoch: 37  | Training Loss: 0.60988 \nEpoch: 37  | Training Loss: 0.53678 \nEpoch: 37  | Training Loss: 0.31777 \nEpoch: 37  | Validation balanced accuracy : 0.50000 \nEpoch: 38  | Training Loss: 0.71945 \nEpoch: 38  | Training Loss: 0.71073 \nEpoch: 38  | Training Loss: 0.60981 \nEpoch: 38  | Training Loss: 0.53673 \nEpoch: 38  | Training Loss: 0.31755 \nEpoch: 38  | Validation balanced accuracy : 0.50000 \nEpoch: 39  | Training Loss: 0.71940 \nEpoch: 39  | Training Loss: 0.71075 \nEpoch: 39  | Training Loss: 0.60974 \nEpoch: 39  | Training Loss: 0.53669 \nEpoch: 39  | Training Loss: 0.31739 \nEpoch: 39  | Validation balanced accuracy : 0.50000 \nEpoch: 40  | Training Loss: 0.71931 \nEpoch: 40  | Training Loss: 0.71073 \nEpoch: 40  | Training Loss: 0.60966 \nEpoch: 40  | Training Loss: 0.53665 \nEpoch: 40  | Training Loss: 0.31729 \nEpoch: 40  | Validation balanced accuracy : 0.50000 \nEpoch: 41  | Training Loss: 0.71920 \nEpoch: 41  | Training Loss: 0.71069 \nEpoch: 41  | Training Loss: 0.60957 \nEpoch: 41  | Training Loss: 0.53662 \nEpoch: 41  | Training Loss: 0.31721 \nEpoch: 41  | Validation balanced accuracy : 0.50000 \nEpoch: 42  | Training Loss: 0.71908 \nEpoch: 42  | Training Loss: 0.71065 \nEpoch: 42  | Training Loss: 0.60949 \nEpoch: 42  | Training Loss: 0.53659 \nEpoch: 42  | Training Loss: 0.31711 \nEpoch: 42  | Validation balanced accuracy : 0.50000 \nEpoch: 43  | Training Loss: 0.71897 \nEpoch: 43  | Training Loss: 0.71062 \nEpoch: 43  | Training Loss: 0.60940 \nEpoch: 43  | Training Loss: 0.53655 \nEpoch: 43  | Training Loss: 0.31698 \nEpoch: 43  | Validation balanced accuracy : 0.50000 \nEpoch: 44  | Training Loss: 0.71888 \nEpoch: 44  | Training Loss: 0.71061 \nEpoch: 44  | Training Loss: 0.60933 \nEpoch: 44  | Training Loss: 0.53651 \nEpoch: 44  | Training Loss: 0.31684 \nEpoch: 44  | Validation balanced accuracy : 0.50000 \nEpoch: 45  | Training Loss: 0.71879 \nEpoch: 45  | Training Loss: 0.71059 \nEpoch: 45  | Training Loss: 0.60925 \nEpoch: 45  | Training Loss: 0.53647 \nEpoch: 45  | Training Loss: 0.31670 \nEpoch: 45  | Validation balanced accuracy : 0.50000 \nEpoch: 46  | Training Loss: 0.71870 \nEpoch: 46  | Training Loss: 0.71058 \nEpoch: 46  | Training Loss: 0.60917 \nEpoch: 46  | Training Loss: 0.53644 \nEpoch: 46  | Training Loss: 0.31657 \nEpoch: 46  | Validation balanced accuracy : 0.50000 \nEpoch: 47  | Training Loss: 0.71860 \nEpoch: 47  | Training Loss: 0.71055 \nEpoch: 47  | Training Loss: 0.60909 \nEpoch: 47  | Training Loss: 0.53640 \nEpoch: 47  | Training Loss: 0.31645 \nEpoch: 47  | Validation balanced accuracy : 0.50000 \nEpoch: 48  | Training Loss: 0.71850 \nEpoch: 48  | Training Loss: 0.71052 \nEpoch: 48  | Training Loss: 0.60901 \nEpoch: 48  | Training Loss: 0.53637 \nEpoch: 48  | Training Loss: 0.31633 \nEpoch: 48  | Validation balanced accuracy : 0.50000 \nEpoch: 49  | Training Loss: 0.71840 \nEpoch: 49  | Training Loss: 0.71050 \nEpoch: 49  | Training Loss: 0.60893 \nEpoch: 49  | Training Loss: 0.53633 \nEpoch: 49  | Training Loss: 0.31620 \nEpoch: 49  | Validation balanced accuracy : 0.50000 \nEpoch: 50  | Training Loss: 0.71831 \nEpoch: 50  | Training Loss: 0.71047 \nEpoch: 50  | Training Loss: 0.60885 \nEpoch: 50  | Training Loss: 0.53629 \nEpoch: 50  | Training Loss: 0.31607 \nEpoch: 50  | Validation balanced accuracy : 0.50000 \nEpoch: 51  | Training Loss: 0.71821 \nEpoch: 51  | Training Loss: 0.71045 \nEpoch: 51  | Training Loss: 0.60877 \nEpoch: 51  | Training Loss: 0.53626 \nEpoch: 51  | Training Loss: 0.31594 \nEpoch: 51  | Validation balanced accuracy : 0.50000 \nEpoch: 52  | Training Loss: 0.71812 \nEpoch: 52  | Training Loss: 0.71043 \nEpoch: 52  | Training Loss: 0.60870 \nEpoch: 52  | Training Loss: 0.53622 \nEpoch: 52  | Training Loss: 0.31581 \nEpoch: 52  | Validation balanced accuracy : 0.50000 \nEpoch: 53  | Training Loss: 0.71802 \nEpoch: 53  | Training Loss: 0.71040 \nEpoch: 53  | Training Loss: 0.60862 \nEpoch: 53  | Training Loss: 0.53618 \nEpoch: 53  | Training Loss: 0.31568 \nEpoch: 53  | Validation balanced accuracy : 0.50000 \nEpoch: 54  | Training Loss: 0.71793 \nEpoch: 54  | Training Loss: 0.71038 \nEpoch: 54  | Training Loss: 0.60854 \nEpoch: 54  | Training Loss: 0.53615 \nEpoch: 54  | Training Loss: 0.31556 \nEpoch: 54  | Validation balanced accuracy : 0.50000 \nEpoch: 55  | Training Loss: 0.71783 \nEpoch: 55  | Training Loss: 0.71035 \nEpoch: 55  | Training Loss: 0.60846 \nEpoch: 55  | Training Loss: 0.53611 \nEpoch: 55  | Training Loss: 0.31543 \nEpoch: 55  | Validation balanced accuracy : 0.50000 \nEpoch: 56  | Training Loss: 0.71773 \nEpoch: 56  | Training Loss: 0.71033 \nEpoch: 56  | Training Loss: 0.60839 \nEpoch: 56  | Training Loss: 0.53607 \nEpoch: 56  | Training Loss: 0.31530 \nEpoch: 56  | Validation balanced accuracy : 0.50000 \nEpoch: 57  | Training Loss: 0.71764 \nEpoch: 57  | Training Loss: 0.71030 \nEpoch: 57  | Training Loss: 0.60831 \nEpoch: 57  | Training Loss: 0.53604 \nEpoch: 57  | Training Loss: 0.31517 \nEpoch: 57  | Validation balanced accuracy : 0.50000 \nEpoch: 58  | Training Loss: 0.71754 \nEpoch: 58  | Training Loss: 0.71028 \nEpoch: 58  | Training Loss: 0.60823 \nEpoch: 58  | Training Loss: 0.53600 \nEpoch: 58  | Training Loss: 0.31504 \nEpoch: 58  | Validation balanced accuracy : 0.50000 \nEpoch: 59  | Training Loss: 0.71745 \nEpoch: 59  | Training Loss: 0.71025 \nEpoch: 59  | Training Loss: 0.60815 \nEpoch: 59  | Training Loss: 0.53597 \nEpoch: 59  | Training Loss: 0.31491 \nEpoch: 59  | Validation balanced accuracy : 0.50000 \nEpoch: 60  | Training Loss: 0.71736 \nEpoch: 60  | Training Loss: 0.71023 \nEpoch: 60  | Training Loss: 0.60808 \nEpoch: 60  | Training Loss: 0.53593 \nEpoch: 60  | Training Loss: 0.31478 \nEpoch: 60  | Validation balanced accuracy : 0.50000 \nEpoch: 61  | Training Loss: 0.71726 \nEpoch: 61  | Training Loss: 0.71020 \nEpoch: 61  | Training Loss: 0.60800 \nEpoch: 61  | Training Loss: 0.53589 \nEpoch: 61  | Training Loss: 0.31465 \nEpoch: 61  | Validation balanced accuracy : 0.50000 \nEpoch: 62  | Training Loss: 0.71717 \nEpoch: 62  | Training Loss: 0.71017 \nEpoch: 62  | Training Loss: 0.60793 \nEpoch: 62  | Training Loss: 0.53586 \nEpoch: 62  | Training Loss: 0.31453 \nEpoch: 62  | Validation balanced accuracy : 0.50000 \nEpoch: 63  | Training Loss: 0.71707 \nEpoch: 63  | Training Loss: 0.71015 \nEpoch: 63  | Training Loss: 0.60785 \nEpoch: 63  | Training Loss: 0.53582 \nEpoch: 63  | Training Loss: 0.31440 \nEpoch: 63  | Validation balanced accuracy : 0.50000 \nEpoch: 64  | Training Loss: 0.71698 \nEpoch: 64  | Training Loss: 0.71012 \nEpoch: 64  | Training Loss: 0.60777 \nEpoch: 64  | Training Loss: 0.53579 \nEpoch: 64  | Training Loss: 0.31427 \nEpoch: 64  | Validation balanced accuracy : 0.50000 \nEpoch: 65  | Training Loss: 0.71688 \nEpoch: 65  | Training Loss: 0.71010 \nEpoch: 65  | Training Loss: 0.60770 \nEpoch: 65  | Training Loss: 0.53575 \nEpoch: 65  | Training Loss: 0.31414 \nEpoch: 65  | Validation balanced accuracy : 0.50000 \nEpoch: 66  | Training Loss: 0.71679 \nEpoch: 66  | Training Loss: 0.71007 \nEpoch: 66  | Training Loss: 0.60762 \nEpoch: 66  | Training Loss: 0.53572 \nEpoch: 66  | Training Loss: 0.31401 \nEpoch: 66  | Validation balanced accuracy : 0.50000 \nEpoch: 67  | Training Loss: 0.71670 \nEpoch: 67  | Training Loss: 0.71004 \nEpoch: 67  | Training Loss: 0.60755 \nEpoch: 67  | Training Loss: 0.53568 \nEpoch: 67  | Training Loss: 0.31388 \nEpoch: 67  | Validation balanced accuracy : 0.50000 \nEpoch: 68  | Training Loss: 0.71660 \nEpoch: 68  | Training Loss: 0.71002 \nEpoch: 68  | Training Loss: 0.60747 \nEpoch: 68  | Training Loss: 0.53564 \nEpoch: 68  | Training Loss: 0.31375 \nEpoch: 68  | Validation balanced accuracy : 0.50000 \nEpoch: 69  | Training Loss: 0.71651 \nEpoch: 69  | Training Loss: 0.70999 \nEpoch: 69  | Training Loss: 0.60740 \nEpoch: 69  | Training Loss: 0.53561 \nEpoch: 69  | Training Loss: 0.31362 \nEpoch: 69  | Validation balanced accuracy : 0.50000 \nEpoch: 70  | Training Loss: 0.71642 \nEpoch: 70  | Training Loss: 0.70996 \nEpoch: 70  | Training Loss: 0.60732 \nEpoch: 70  | Training Loss: 0.53557 \nEpoch: 70  | Training Loss: 0.31349 \nEpoch: 70  | Validation balanced accuracy : 0.50000 \nEpoch: 71  | Training Loss: 0.71632 \nEpoch: 71  | Training Loss: 0.70994 \nEpoch: 71  | Training Loss: 0.60725 \nEpoch: 71  | Training Loss: 0.53554 \nEpoch: 71  | Training Loss: 0.31337 \nEpoch: 71  | Validation balanced accuracy : 0.50000 \nEpoch: 72  | Training Loss: 0.71623 \nEpoch: 72  | Training Loss: 0.70991 \nEpoch: 72  | Training Loss: 0.60717 \nEpoch: 72  | Training Loss: 0.53550 \nEpoch: 72  | Training Loss: 0.31324 \nEpoch: 72  | Validation balanced accuracy : 0.50000 \nEpoch: 73  | Training Loss: 0.71614 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 73  | Training Loss: 0.70988 \nEpoch: 73  | Training Loss: 0.60710 \nEpoch: 73  | Training Loss: 0.53547 \nEpoch: 73  | Training Loss: 0.31311 \nEpoch: 73  | Validation balanced accuracy : 0.50000 \nEpoch: 74  | Training Loss: 0.71605 \nEpoch: 74  | Training Loss: 0.70985 \nEpoch: 74  | Training Loss: 0.60702 \nEpoch: 74  | Training Loss: 0.53543 \nEpoch: 74  | Training Loss: 0.31298 \nEpoch: 74  | Validation balanced accuracy : 0.50000 \nEpoch: 75  | Training Loss: 0.71596 \nEpoch: 75  | Training Loss: 0.70983 \nEpoch: 75  | Training Loss: 0.60695 \nEpoch: 75  | Training Loss: 0.53540 \nEpoch: 75  | Training Loss: 0.31285 \nEpoch: 75  | Validation balanced accuracy : 0.50000 \nEpoch: 76  | Training Loss: 0.71586 \nEpoch: 76  | Training Loss: 0.70980 \nEpoch: 76  | Training Loss: 0.60688 \nEpoch: 76  | Training Loss: 0.53536 \nEpoch: 76  | Training Loss: 0.31273 \nEpoch: 76  | Validation balanced accuracy : 0.50000 \nEpoch: 77  | Training Loss: 0.71577 \nEpoch: 77  | Training Loss: 0.70977 \nEpoch: 77  | Training Loss: 0.60680 \nEpoch: 77  | Training Loss: 0.53533 \nEpoch: 77  | Training Loss: 0.31260 \nEpoch: 77  | Validation balanced accuracy : 0.50000 \nEpoch: 78  | Training Loss: 0.71568 \nEpoch: 78  | Training Loss: 0.70975 \nEpoch: 78  | Training Loss: 0.60673 \nEpoch: 78  | Training Loss: 0.53529 \nEpoch: 78  | Training Loss: 0.31247 \nEpoch: 78  | Validation balanced accuracy : 0.50000 \nEpoch: 79  | Training Loss: 0.71559 \nEpoch: 79  | Training Loss: 0.70972 \nEpoch: 79  | Training Loss: 0.60666 \nEpoch: 79  | Training Loss: 0.53526 \nEpoch: 79  | Training Loss: 0.31234 \nEpoch: 79  | Validation balanced accuracy : 0.50000 \nEpoch: 80  | Training Loss: 0.71550 \nEpoch: 80  | Training Loss: 0.70969 \nEpoch: 80  | Training Loss: 0.60658 \nEpoch: 80  | Training Loss: 0.53522 \nEpoch: 80  | Training Loss: 0.31221 \nEpoch: 80  | Validation balanced accuracy : 0.50000 \nEpoch: 81  | Training Loss: 0.71541 \nEpoch: 81  | Training Loss: 0.70966 \nEpoch: 81  | Training Loss: 0.60651 \nEpoch: 81  | Training Loss: 0.53519 \nEpoch: 81  | Training Loss: 0.31209 \nEpoch: 81  | Validation balanced accuracy : 0.50000 \nEpoch: 82  | Training Loss: 0.71531 \nEpoch: 82  | Training Loss: 0.70963 \nEpoch: 82  | Training Loss: 0.60644 \nEpoch: 82  | Training Loss: 0.53515 \nEpoch: 82  | Training Loss: 0.31196 \nEpoch: 82  | Validation balanced accuracy : 0.50000 \nEpoch: 83  | Training Loss: 0.71522 \nEpoch: 83  | Training Loss: 0.70960 \nEpoch: 83  | Training Loss: 0.60636 \nEpoch: 83  | Training Loss: 0.53512 \nEpoch: 83  | Training Loss: 0.31183 \nEpoch: 83  | Validation balanced accuracy : 0.50000 \nEpoch: 84  | Training Loss: 0.71513 \nEpoch: 84  | Training Loss: 0.70958 \nEpoch: 84  | Training Loss: 0.60629 \nEpoch: 84  | Training Loss: 0.53508 \nEpoch: 84  | Training Loss: 0.31171 \nEpoch: 84  | Validation balanced accuracy : 0.50000 \nEpoch: 85  | Training Loss: 0.71504 \nEpoch: 85  | Training Loss: 0.70955 \nEpoch: 85  | Training Loss: 0.60622 \nEpoch: 85  | Training Loss: 0.53505 \nEpoch: 85  | Training Loss: 0.31158 \nEpoch: 85  | Validation balanced accuracy : 0.50000 \nEpoch: 86  | Training Loss: 0.71495 \nEpoch: 86  | Training Loss: 0.70952 \nEpoch: 86  | Training Loss: 0.60615 \nEpoch: 86  | Training Loss: 0.53502 \nEpoch: 86  | Training Loss: 0.31145 \nEpoch: 86  | Validation balanced accuracy : 0.50000 \nEpoch: 87  | Training Loss: 0.71486 \nEpoch: 87  | Training Loss: 0.70949 \nEpoch: 87  | Training Loss: 0.60608 \nEpoch: 87  | Training Loss: 0.53498 \nEpoch: 87  | Training Loss: 0.31132 \nEpoch: 87  | Validation balanced accuracy : 0.50000 \nEpoch: 88  | Training Loss: 0.71477 \nEpoch: 88  | Training Loss: 0.70947 \nEpoch: 88  | Training Loss: 0.60600 \nEpoch: 88  | Training Loss: 0.53495 \nEpoch: 88  | Training Loss: 0.31120 \nEpoch: 88  | Validation balanced accuracy : 0.50000 \nEpoch: 89  | Training Loss: 0.71468 \nEpoch: 89  | Training Loss: 0.70944 \nEpoch: 89  | Training Loss: 0.60593 \nEpoch: 89  | Training Loss: 0.53491 \nEpoch: 89  | Training Loss: 0.31107 \nEpoch: 89  | Validation balanced accuracy : 0.50000 \nEpoch: 90  | Training Loss: 0.71459 \nEpoch: 90  | Training Loss: 0.70941 \nEpoch: 90  | Training Loss: 0.60586 \nEpoch: 90  | Training Loss: 0.53488 \nEpoch: 90  | Training Loss: 0.31095 \nEpoch: 90  | Validation balanced accuracy : 0.50000 \nEpoch: 91  | Training Loss: 0.71450 \nEpoch: 91  | Training Loss: 0.70938 \nEpoch: 91  | Training Loss: 0.60579 \nEpoch: 91  | Training Loss: 0.53484 \nEpoch: 91  | Training Loss: 0.31082 \nEpoch: 91  | Validation balanced accuracy : 0.50000 \nEpoch: 92  | Training Loss: 0.71441 \nEpoch: 92  | Training Loss: 0.70935 \nEpoch: 92  | Training Loss: 0.60572 \nEpoch: 92  | Training Loss: 0.53481 \nEpoch: 92  | Training Loss: 0.31069 \nEpoch: 92  | Validation balanced accuracy : 0.50000 \nEpoch: 93  | Training Loss: 0.71432 \nEpoch: 93  | Training Loss: 0.70932 \nEpoch: 93  | Training Loss: 0.60565 \nEpoch: 93  | Training Loss: 0.53478 \nEpoch: 93  | Training Loss: 0.31057 \nEpoch: 93  | Validation balanced accuracy : 0.50000 \nEpoch: 94  | Training Loss: 0.71424 \nEpoch: 94  | Training Loss: 0.70930 \nEpoch: 94  | Training Loss: 0.60557 \nEpoch: 94  | Training Loss: 0.53474 \nEpoch: 94  | Training Loss: 0.31044 \nEpoch: 94  | Validation balanced accuracy : 0.50000 \nEpoch: 95  | Training Loss: 0.71415 \nEpoch: 95  | Training Loss: 0.70927 \nEpoch: 95  | Training Loss: 0.60550 \nEpoch: 95  | Training Loss: 0.53471 \nEpoch: 95  | Training Loss: 0.31032 \nEpoch: 95  | Validation balanced accuracy : 0.50000 \nEpoch: 96  | Training Loss: 0.71406 \nEpoch: 96  | Training Loss: 0.70924 \nEpoch: 96  | Training Loss: 0.60543 \nEpoch: 96  | Training Loss: 0.53468 \nEpoch: 96  | Training Loss: 0.31019 \nEpoch: 96  | Validation balanced accuracy : 0.50000 \nEpoch: 97  | Training Loss: 0.71397 \nEpoch: 97  | Training Loss: 0.70921 \nEpoch: 97  | Training Loss: 0.60536 \nEpoch: 97  | Training Loss: 0.53464 \nEpoch: 97  | Training Loss: 0.31007 \nEpoch: 97  | Validation balanced accuracy : 0.50000 \nEpoch: 98  | Training Loss: 0.71388 \nEpoch: 98  | Training Loss: 0.70918 \nEpoch: 98  | Training Loss: 0.60529 \nEpoch: 98  | Training Loss: 0.53461 \nEpoch: 98  | Training Loss: 0.30994 \nEpoch: 98  | Validation balanced accuracy : 0.50000 \nEpoch: 99  | Training Loss: 0.71379 \nEpoch: 99  | Training Loss: 0.70915 \nEpoch: 99  | Training Loss: 0.60522 \nEpoch: 99  | Training Loss: 0.53457 \nEpoch: 99  | Training Loss: 0.30982 \nEpoch: 99  | Validation balanced accuracy : 0.50000 \nEpoch: 100  | Training Loss: 0.71371 \nEpoch: 100  | Training Loss: 0.70913 \nEpoch: 100  | Training Loss: 0.60515 \nEpoch: 100  | Training Loss: 0.53454 \nEpoch: 100  | Training Loss: 0.30969 \nEpoch: 100  | Validation balanced accuracy : 0.50000 \nEpoch: 101  | Training Loss: 0.71362 \nEpoch: 101  | Training Loss: 0.70910 \nEpoch: 101  | Training Loss: 0.60508 \nEpoch: 101  | Training Loss: 0.53451 \nEpoch: 101  | Training Loss: 0.30957 \nEpoch: 101  | Validation balanced accuracy : 0.50000 \nEpoch: 102  | Training Loss: 0.71353 \nEpoch: 102  | Training Loss: 0.70907 \nEpoch: 102  | Training Loss: 0.60501 \nEpoch: 102  | Training Loss: 0.53447 \nEpoch: 102  | Training Loss: 0.30945 \nEpoch: 102  | Validation balanced accuracy : 0.50000 \nEpoch: 103  | Training Loss: 0.71344 \nEpoch: 103  | Training Loss: 0.70904 \nEpoch: 103  | Training Loss: 0.60494 \nEpoch: 103  | Training Loss: 0.53444 \nEpoch: 103  | Training Loss: 0.30932 \nEpoch: 103  | Validation balanced accuracy : 0.50000 \nEpoch: 104  | Training Loss: 0.71335 \nEpoch: 104  | Training Loss: 0.70901 \nEpoch: 104  | Training Loss: 0.60487 \nEpoch: 104  | Training Loss: 0.53441 \nEpoch: 104  | Training Loss: 0.30920 \nEpoch: 104  | Validation balanced accuracy : 0.50000 \nEpoch: 105  | Training Loss: 0.71327 \nEpoch: 105  | Training Loss: 0.70898 \nEpoch: 105  | Training Loss: 0.60480 \nEpoch: 105  | Training Loss: 0.53437 \nEpoch: 105  | Training Loss: 0.30907 \nEpoch: 105  | Validation balanced accuracy : 0.50000 \nEpoch: 106  | Training Loss: 0.71318 \nEpoch: 106  | Training Loss: 0.70896 \nEpoch: 106  | Training Loss: 0.60473 \nEpoch: 106  | Training Loss: 0.53434 \nEpoch: 106  | Training Loss: 0.30895 \nEpoch: 106  | Validation balanced accuracy : 0.50000 \nEpoch: 107  | Training Loss: 0.71309 \nEpoch: 107  | Training Loss: 0.70893 \nEpoch: 107  | Training Loss: 0.60466 \nEpoch: 107  | Training Loss: 0.53431 \nEpoch: 107  | Training Loss: 0.30883 \nEpoch: 107  | Validation balanced accuracy : 0.50000 \nEpoch: 108  | Training Loss: 0.71301 \nEpoch: 108  | Training Loss: 0.70890 \nEpoch: 108  | Training Loss: 0.60459 \nEpoch: 108  | Training Loss: 0.53427 \nEpoch: 108  | Training Loss: 0.30870 \nEpoch: 108  | Validation balanced accuracy : 0.50000 \nEpoch: 109  | Training Loss: 0.71292 \nEpoch: 109  | Training Loss: 0.70887 \nEpoch: 109  | Training Loss: 0.60453 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 109  | Training Loss: 0.53424 \nEpoch: 109  | Training Loss: 0.30858 \nEpoch: 109  | Validation balanced accuracy : 0.50000 \nEpoch: 110  | Training Loss: 0.71283 \nEpoch: 110  | Training Loss: 0.70884 \nEpoch: 110  | Training Loss: 0.60446 \nEpoch: 110  | Training Loss: 0.53421 \nEpoch: 110  | Training Loss: 0.30846 \nEpoch: 110  | Validation balanced accuracy : 0.50000 \nEpoch: 111  | Training Loss: 0.71275 \nEpoch: 111  | Training Loss: 0.70881 \nEpoch: 111  | Training Loss: 0.60439 \nEpoch: 111  | Training Loss: 0.53417 \nEpoch: 111  | Training Loss: 0.30833 \nEpoch: 111  | Validation balanced accuracy : 0.50000 \nEpoch: 112  | Training Loss: 0.71266 \nEpoch: 112  | Training Loss: 0.70878 \nEpoch: 112  | Training Loss: 0.60432 \nEpoch: 112  | Training Loss: 0.53414 \nEpoch: 112  | Training Loss: 0.30821 \nEpoch: 112  | Validation balanced accuracy : 0.50000 \nEpoch: 113  | Training Loss: 0.71257 \nEpoch: 113  | Training Loss: 0.70875 \nEpoch: 113  | Training Loss: 0.60425 \nEpoch: 113  | Training Loss: 0.53411 \nEpoch: 113  | Training Loss: 0.30809 \nEpoch: 113  | Validation balanced accuracy : 0.50000 \nEpoch: 114  | Training Loss: 0.71249 \nEpoch: 114  | Training Loss: 0.70872 \nEpoch: 114  | Training Loss: 0.60418 \nEpoch: 114  | Training Loss: 0.53408 \nEpoch: 114  | Training Loss: 0.30797 \nEpoch: 114  | Validation balanced accuracy : 0.50000 \nEpoch: 115  | Training Loss: 0.71240 \nEpoch: 115  | Training Loss: 0.70870 \nEpoch: 115  | Training Loss: 0.60411 \nEpoch: 115  | Training Loss: 0.53404 \nEpoch: 115  | Training Loss: 0.30784 \nEpoch: 115  | Validation balanced accuracy : 0.50000 \nEpoch: 116  | Training Loss: 0.71232 \nEpoch: 116  | Training Loss: 0.70867 \nEpoch: 116  | Training Loss: 0.60405 \nEpoch: 116  | Training Loss: 0.53401 \nEpoch: 116  | Training Loss: 0.30772 \nEpoch: 116  | Validation balanced accuracy : 0.50000 \nEpoch: 117  | Training Loss: 0.71223 \nEpoch: 117  | Training Loss: 0.70864 \nEpoch: 117  | Training Loss: 0.60398 \nEpoch: 117  | Training Loss: 0.53398 \nEpoch: 117  | Training Loss: 0.30760 \nEpoch: 117  | Validation balanced accuracy : 0.50000 \nEpoch: 118  | Training Loss: 0.71215 \nEpoch: 118  | Training Loss: 0.70861 \nEpoch: 118  | Training Loss: 0.60391 \nEpoch: 118  | Training Loss: 0.53395 \nEpoch: 118  | Training Loss: 0.30748 \nEpoch: 118  | Validation balanced accuracy : 0.50000 \nEpoch: 119  | Training Loss: 0.71206 \nEpoch: 119  | Training Loss: 0.70858 \nEpoch: 119  | Training Loss: 0.60384 \nEpoch: 119  | Training Loss: 0.53391 \nEpoch: 119  | Training Loss: 0.30736 \nEpoch: 119  | Validation balanced accuracy : 0.50000 \nEpoch: 120  | Training Loss: 0.71198 \nEpoch: 120  | Training Loss: 0.70855 \nEpoch: 120  | Training Loss: 0.60377 \nEpoch: 120  | Training Loss: 0.53388 \nEpoch: 120  | Training Loss: 0.30724 \nEpoch: 120  | Validation balanced accuracy : 0.50000 \nEpoch: 121  | Training Loss: 0.71189 \nEpoch: 121  | Training Loss: 0.70852 \nEpoch: 121  | Training Loss: 0.60371 \nEpoch: 121  | Training Loss: 0.53385 \nEpoch: 121  | Training Loss: 0.30712 \nEpoch: 121  | Validation balanced accuracy : 0.50000 \nEpoch: 122  | Training Loss: 0.71181 \nEpoch: 122  | Training Loss: 0.70849 \nEpoch: 122  | Training Loss: 0.60364 \nEpoch: 122  | Training Loss: 0.53382 \nEpoch: 122  | Training Loss: 0.30700 \nEpoch: 122  | Validation balanced accuracy : 0.50000 \nEpoch: 123  | Training Loss: 0.71172 \nEpoch: 123  | Training Loss: 0.70847 \nEpoch: 123  | Training Loss: 0.60357 \nEpoch: 123  | Training Loss: 0.53378 \nEpoch: 123  | Training Loss: 0.30687 \nEpoch: 123  | Validation balanced accuracy : 0.50000 \nEpoch: 124  | Training Loss: 0.71164 \nEpoch: 124  | Training Loss: 0.70844 \nEpoch: 124  | Training Loss: 0.60350 \nEpoch: 124  | Training Loss: 0.53375 \nEpoch: 124  | Training Loss: 0.30675 \nEpoch: 124  | Validation balanced accuracy : 0.50000 \nEpoch: 125  | Training Loss: 0.71155 \nEpoch: 125  | Training Loss: 0.70841 \nEpoch: 125  | Training Loss: 0.60344 \nEpoch: 125  | Training Loss: 0.53372 \nEpoch: 125  | Training Loss: 0.30664 \nEpoch: 125  | Validation balanced accuracy : 0.50000 \nEpoch: 126  | Training Loss: 0.71147 \nEpoch: 126  | Training Loss: 0.70838 \nEpoch: 126  | Training Loss: 0.60337 \nEpoch: 126  | Training Loss: 0.53369 \nEpoch: 126  | Training Loss: 0.30651 \nEpoch: 126  | Validation balanced accuracy : 0.50000 \nEpoch: 127  | Training Loss: 0.71138 \nEpoch: 127  | Training Loss: 0.70835 \nEpoch: 127  | Training Loss: 0.60330 \nEpoch: 127  | Training Loss: 0.53365 \nEpoch: 127  | Training Loss: 0.30640 \nEpoch: 127  | Validation balanced accuracy : 0.50000 \nEpoch: 128  | Training Loss: 0.71130 \nEpoch: 128  | Training Loss: 0.70832 \nEpoch: 128  | Training Loss: 0.60323 \nEpoch: 128  | Training Loss: 0.53362 \nEpoch: 128  | Training Loss: 0.30627 \nEpoch: 128  | Validation balanced accuracy : 0.50000 \nEpoch: 129  | Training Loss: 0.71122 \nEpoch: 129  | Training Loss: 0.70829 \nEpoch: 129  | Training Loss: 0.60317 \nEpoch: 129  | Training Loss: 0.53359 \nEpoch: 129  | Training Loss: 0.30616 \nEpoch: 129  | Validation balanced accuracy : 0.50000 \nEpoch: 130  | Training Loss: 0.71113 \nEpoch: 130  | Training Loss: 0.70826 \nEpoch: 130  | Training Loss: 0.60310 \nEpoch: 130  | Training Loss: 0.53356 \nEpoch: 130  | Training Loss: 0.30603 \nEpoch: 130  | Validation balanced accuracy : 0.50000 \nEpoch: 131  | Training Loss: 0.71105 \nEpoch: 131  | Training Loss: 0.70823 \nEpoch: 131  | Training Loss: 0.60303 \nEpoch: 131  | Training Loss: 0.53352 \nEpoch: 131  | Training Loss: 0.30592 \nEpoch: 131  | Validation balanced accuracy : 0.50000 \nEpoch: 132  | Training Loss: 0.71096 \nEpoch: 132  | Training Loss: 0.70820 \nEpoch: 132  | Training Loss: 0.60297 \nEpoch: 132  | Training Loss: 0.53349 \nEpoch: 132  | Training Loss: 0.30580 \nEpoch: 132  | Validation balanced accuracy : 0.50000 \nEpoch: 133  | Training Loss: 0.71088 \nEpoch: 133  | Training Loss: 0.70817 \nEpoch: 133  | Training Loss: 0.60290 \nEpoch: 133  | Training Loss: 0.53346 \nEpoch: 133  | Training Loss: 0.30568 \nEpoch: 133  | Validation balanced accuracy : 0.50000 \nEpoch: 134  | Training Loss: 0.71080 \nEpoch: 134  | Training Loss: 0.70815 \nEpoch: 134  | Training Loss: 0.60284 \nEpoch: 134  | Training Loss: 0.53343 \nEpoch: 134  | Training Loss: 0.30556 \nEpoch: 134  | Validation balanced accuracy : 0.50000 \nEpoch: 135  | Training Loss: 0.71071 \nEpoch: 135  | Training Loss: 0.70812 \nEpoch: 135  | Training Loss: 0.60277 \nEpoch: 135  | Training Loss: 0.53340 \nEpoch: 135  | Training Loss: 0.30544 \nEpoch: 135  | Validation balanced accuracy : 0.50000 \nEpoch: 136  | Training Loss: 0.71063 \nEpoch: 136  | Training Loss: 0.70809 \nEpoch: 136  | Training Loss: 0.60270 \nEpoch: 136  | Training Loss: 0.53336 \nEpoch: 136  | Training Loss: 0.30532 \nEpoch: 136  | Validation balanced accuracy : 0.50000 \nEpoch: 137  | Training Loss: 0.71055 \nEpoch: 137  | Training Loss: 0.70806 \nEpoch: 137  | Training Loss: 0.60264 \nEpoch: 137  | Training Loss: 0.53333 \nEpoch: 137  | Training Loss: 0.30520 \nEpoch: 137  | Validation balanced accuracy : 0.50000 \nEpoch: 138  | Training Loss: 0.71046 \nEpoch: 138  | Training Loss: 0.70803 \nEpoch: 138  | Training Loss: 0.60257 \nEpoch: 138  | Training Loss: 0.53330 \nEpoch: 138  | Training Loss: 0.30508 \nEpoch: 138  | Validation balanced accuracy : 0.50000 \nEpoch: 139  | Training Loss: 0.71038 \nEpoch: 139  | Training Loss: 0.70800 \nEpoch: 139  | Training Loss: 0.60250 \nEpoch: 139  | Training Loss: 0.53327 \nEpoch: 139  | Training Loss: 0.30496 \nEpoch: 139  | Validation balanced accuracy : 0.50000 \nEpoch: 140  | Training Loss: 0.71030 \nEpoch: 140  | Training Loss: 0.70797 \nEpoch: 140  | Training Loss: 0.60244 \nEpoch: 140  | Training Loss: 0.53324 \nEpoch: 140  | Training Loss: 0.30485 \nEpoch: 140  | Validation balanced accuracy : 0.50000 \nEpoch: 141  | Training Loss: 0.71022 \nEpoch: 141  | Training Loss: 0.70794 \nEpoch: 141  | Training Loss: 0.60237 \nEpoch: 141  | Training Loss: 0.53321 \nEpoch: 141  | Training Loss: 0.30473 \nEpoch: 141  | Validation balanced accuracy : 0.50000 \nEpoch: 142  | Training Loss: 0.71013 \nEpoch: 142  | Training Loss: 0.70791 \nEpoch: 142  | Training Loss: 0.60231 \nEpoch: 142  | Training Loss: 0.53317 \nEpoch: 142  | Training Loss: 0.30461 \nEpoch: 142  | Validation balanced accuracy : 0.50000 \nEpoch: 143  | Training Loss: 0.71005 \nEpoch: 143  | Training Loss: 0.70789 \nEpoch: 143  | Training Loss: 0.60224 \nEpoch: 143  | Training Loss: 0.53314 \nEpoch: 143  | Training Loss: 0.30449 \nEpoch: 143  | Validation balanced accuracy : 0.50000 \nEpoch: 144  | Training Loss: 0.70997 \nEpoch: 144  | Training Loss: 0.70786 \nEpoch: 144  | Training Loss: 0.60218 \nEpoch: 144  | Training Loss: 0.53311 \nEpoch: 144  | Training Loss: 0.30438 \nEpoch: 144  | Validation balanced accuracy : 0.50000 \nEpoch: 145  | Training Loss: 0.70989 \nEpoch: 145  | Training Loss: 0.70783 \nEpoch: 145  | Training Loss: 0.60211 \nEpoch: 145  | Training Loss: 0.53308 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 145  | Training Loss: 0.30426 \nEpoch: 145  | Validation balanced accuracy : 0.50000 \nEpoch: 146  | Training Loss: 0.70981 \nEpoch: 146  | Training Loss: 0.70780 \nEpoch: 146  | Training Loss: 0.60205 \nEpoch: 146  | Training Loss: 0.53305 \nEpoch: 146  | Training Loss: 0.30414 \nEpoch: 146  | Validation balanced accuracy : 0.50000 \nEpoch: 147  | Training Loss: 0.70972 \nEpoch: 147  | Training Loss: 0.70777 \nEpoch: 147  | Training Loss: 0.60198 \nEpoch: 147  | Training Loss: 0.53302 \nEpoch: 147  | Training Loss: 0.30402 \nEpoch: 147  | Validation balanced accuracy : 0.50000 \nEpoch: 148  | Training Loss: 0.70964 \nEpoch: 148  | Training Loss: 0.70774 \nEpoch: 148  | Training Loss: 0.60192 \nEpoch: 148  | Training Loss: 0.53298 \nEpoch: 148  | Training Loss: 0.30391 \nEpoch: 148  | Validation balanced accuracy : 0.50000 \nEpoch: 149  | Training Loss: 0.70956 \nEpoch: 149  | Training Loss: 0.70771 \nEpoch: 149  | Training Loss: 0.60185 \nEpoch: 149  | Training Loss: 0.53295 \nEpoch: 149  | Training Loss: 0.30379 \nEpoch: 149  | Validation balanced accuracy : 0.50000 \nEpoch: 150  | Training Loss: 0.70948 \nEpoch: 150  | Training Loss: 0.70768 \nEpoch: 150  | Training Loss: 0.60179 \nEpoch: 150  | Training Loss: 0.53292 \nEpoch: 150  | Training Loss: 0.30367 \nEpoch: 150  | Validation balanced accuracy : 0.50000 \nEpoch: 151  | Training Loss: 0.70940 \nEpoch: 151  | Training Loss: 0.70765 \nEpoch: 151  | Training Loss: 0.60172 \nEpoch: 151  | Training Loss: 0.53289 \nEpoch: 151  | Training Loss: 0.30356 \nEpoch: 151  | Validation balanced accuracy : 0.50000 \nEpoch: 152  | Training Loss: 0.70932 \nEpoch: 152  | Training Loss: 0.70762 \nEpoch: 152  | Training Loss: 0.60166 \nEpoch: 152  | Training Loss: 0.53286 \nEpoch: 152  | Training Loss: 0.30344 \nEpoch: 152  | Validation balanced accuracy : 0.50000 \nEpoch: 153  | Training Loss: 0.70923 \nEpoch: 153  | Training Loss: 0.70759 \nEpoch: 153  | Training Loss: 0.60159 \nEpoch: 153  | Training Loss: 0.53283 \nEpoch: 153  | Training Loss: 0.30332 \nEpoch: 153  | Validation balanced accuracy : 0.50000 \nEpoch: 154  | Training Loss: 0.70915 \nEpoch: 154  | Training Loss: 0.70756 \nEpoch: 154  | Training Loss: 0.60153 \nEpoch: 154  | Training Loss: 0.53280 \nEpoch: 154  | Training Loss: 0.30321 \nEpoch: 154  | Validation balanced accuracy : 0.50000 \nEpoch: 155  | Training Loss: 0.70907 \nEpoch: 155  | Training Loss: 0.70753 \nEpoch: 155  | Training Loss: 0.60146 \nEpoch: 155  | Training Loss: 0.53277 \nEpoch: 155  | Training Loss: 0.30309 \nEpoch: 155  | Validation balanced accuracy : 0.50000 \nEpoch: 156  | Training Loss: 0.70899 \nEpoch: 156  | Training Loss: 0.70750 \nEpoch: 156  | Training Loss: 0.60140 \nEpoch: 156  | Training Loss: 0.53273 \nEpoch: 156  | Training Loss: 0.30298 \nEpoch: 156  | Validation balanced accuracy : 0.50000 \nEpoch: 157  | Training Loss: 0.70891 \nEpoch: 157  | Training Loss: 0.70748 \nEpoch: 157  | Training Loss: 0.60134 \nEpoch: 157  | Training Loss: 0.53270 \nEpoch: 157  | Training Loss: 0.30286 \nEpoch: 157  | Validation balanced accuracy : 0.50000 \nEpoch: 158  | Training Loss: 0.70883 \nEpoch: 158  | Training Loss: 0.70745 \nEpoch: 158  | Training Loss: 0.60127 \nEpoch: 158  | Training Loss: 0.53267 \nEpoch: 158  | Training Loss: 0.30275 \nEpoch: 158  | Validation balanced accuracy : 0.50000 \nEpoch: 159  | Training Loss: 0.70875 \nEpoch: 159  | Training Loss: 0.70742 \nEpoch: 159  | Training Loss: 0.60121 \nEpoch: 159  | Training Loss: 0.53264 \nEpoch: 159  | Training Loss: 0.30263 \nEpoch: 159  | Validation balanced accuracy : 0.50000 \nEpoch: 160  | Training Loss: 0.70867 \nEpoch: 160  | Training Loss: 0.70739 \nEpoch: 160  | Training Loss: 0.60114 \nEpoch: 160  | Training Loss: 0.53261 \nEpoch: 160  | Training Loss: 0.30251 \nEpoch: 160  | Validation balanced accuracy : 0.50000 \nEpoch: 161  | Training Loss: 0.70859 \nEpoch: 161  | Training Loss: 0.70736 \nEpoch: 161  | Training Loss: 0.60108 \nEpoch: 161  | Training Loss: 0.53258 \nEpoch: 161  | Training Loss: 0.30240 \nEpoch: 161  | Validation balanced accuracy : 0.50000 \nEpoch: 162  | Training Loss: 0.70851 \nEpoch: 162  | Training Loss: 0.70733 \nEpoch: 162  | Training Loss: 0.60101 \nEpoch: 162  | Training Loss: 0.53255 \nEpoch: 162  | Training Loss: 0.30228 \nEpoch: 162  | Validation balanced accuracy : 0.50000 \nEpoch: 163  | Training Loss: 0.70843 \nEpoch: 163  | Training Loss: 0.70730 \nEpoch: 163  | Training Loss: 0.60095 \nEpoch: 163  | Training Loss: 0.53252 \nEpoch: 163  | Training Loss: 0.30217 \nEpoch: 163  | Validation balanced accuracy : 0.50000 \nEpoch: 164  | Training Loss: 0.70835 \nEpoch: 164  | Training Loss: 0.70727 \nEpoch: 164  | Training Loss: 0.60089 \nEpoch: 164  | Training Loss: 0.53249 \nEpoch: 164  | Training Loss: 0.30205 \nEpoch: 164  | Validation balanced accuracy : 0.50000 \nEpoch: 165  | Training Loss: 0.70827 \nEpoch: 165  | Training Loss: 0.70724 \nEpoch: 165  | Training Loss: 0.60082 \nEpoch: 165  | Training Loss: 0.53246 \nEpoch: 165  | Training Loss: 0.30194 \nEpoch: 165  | Validation balanced accuracy : 0.50000 \nEpoch: 166  | Training Loss: 0.70819 \nEpoch: 166  | Training Loss: 0.70721 \nEpoch: 166  | Training Loss: 0.60076 \nEpoch: 166  | Training Loss: 0.53243 \nEpoch: 166  | Training Loss: 0.30182 \nEpoch: 166  | Validation balanced accuracy : 0.50000 \nEpoch: 167  | Training Loss: 0.70811 \nEpoch: 167  | Training Loss: 0.70718 \nEpoch: 167  | Training Loss: 0.60070 \nEpoch: 167  | Training Loss: 0.53239 \nEpoch: 167  | Training Loss: 0.30171 \nEpoch: 167  | Validation balanced accuracy : 0.50000 \nEpoch: 168  | Training Loss: 0.70803 \nEpoch: 168  | Training Loss: 0.70715 \nEpoch: 168  | Training Loss: 0.60063 \nEpoch: 168  | Training Loss: 0.53236 \nEpoch: 168  | Training Loss: 0.30160 \nEpoch: 168  | Validation balanced accuracy : 0.50000 \nEpoch: 169  | Training Loss: 0.70795 \nEpoch: 169  | Training Loss: 0.70712 \nEpoch: 169  | Training Loss: 0.60057 \nEpoch: 169  | Training Loss: 0.53233 \nEpoch: 169  | Training Loss: 0.30148 \nEpoch: 169  | Validation balanced accuracy : 0.50000 \nEpoch: 170  | Training Loss: 0.70787 \nEpoch: 170  | Training Loss: 0.70709 \nEpoch: 170  | Training Loss: 0.60051 \nEpoch: 170  | Training Loss: 0.53230 \nEpoch: 170  | Training Loss: 0.30137 \nEpoch: 170  | Validation balanced accuracy : 0.50000 \nEpoch: 171  | Training Loss: 0.70779 \nEpoch: 171  | Training Loss: 0.70706 \nEpoch: 171  | Training Loss: 0.60044 \nEpoch: 171  | Training Loss: 0.53227 \nEpoch: 171  | Training Loss: 0.30125 \nEpoch: 171  | Validation balanced accuracy : 0.50000 \nEpoch: 172  | Training Loss: 0.70771 \nEpoch: 172  | Training Loss: 0.70703 \nEpoch: 172  | Training Loss: 0.60038 \nEpoch: 172  | Training Loss: 0.53224 \nEpoch: 172  | Training Loss: 0.30114 \nEpoch: 172  | Validation balanced accuracy : 0.50000 \nEpoch: 173  | Training Loss: 0.70763 \nEpoch: 173  | Training Loss: 0.70700 \nEpoch: 173  | Training Loss: 0.60032 \nEpoch: 173  | Training Loss: 0.53221 \nEpoch: 173  | Training Loss: 0.30102 \nEpoch: 173  | Validation balanced accuracy : 0.50000 \nEpoch: 174  | Training Loss: 0.70755 \nEpoch: 174  | Training Loss: 0.70697 \nEpoch: 174  | Training Loss: 0.60025 \nEpoch: 174  | Training Loss: 0.53218 \nEpoch: 174  | Training Loss: 0.30091 \nEpoch: 174  | Validation balanced accuracy : 0.50000 \nEpoch: 175  | Training Loss: 0.70747 \nEpoch: 175  | Training Loss: 0.70695 \nEpoch: 175  | Training Loss: 0.60019 \nEpoch: 175  | Training Loss: 0.53215 \nEpoch: 175  | Training Loss: 0.30080 \nEpoch: 175  | Validation balanced accuracy : 0.50000 \nEpoch: 176  | Training Loss: 0.70739 \nEpoch: 176  | Training Loss: 0.70691 \nEpoch: 176  | Training Loss: 0.60013 \nEpoch: 176  | Training Loss: 0.53212 \nEpoch: 176  | Training Loss: 0.30069 \nEpoch: 176  | Validation balanced accuracy : 0.50000 \nEpoch: 177  | Training Loss: 0.70731 \nEpoch: 177  | Training Loss: 0.70688 \nEpoch: 177  | Training Loss: 0.60006 \nEpoch: 177  | Training Loss: 0.53209 \nEpoch: 177  | Training Loss: 0.30057 \nEpoch: 177  | Validation balanced accuracy : 0.50000 \nEpoch: 178  | Training Loss: 0.70723 \nEpoch: 178  | Training Loss: 0.70685 \nEpoch: 178  | Training Loss: 0.60000 \nEpoch: 178  | Training Loss: 0.53206 \nEpoch: 178  | Training Loss: 0.30046 \nEpoch: 178  | Validation balanced accuracy : 0.50000 \nEpoch: 179  | Training Loss: 0.70715 \nEpoch: 179  | Training Loss: 0.70682 \nEpoch: 179  | Training Loss: 0.59994 \nEpoch: 179  | Training Loss: 0.53203 \nEpoch: 179  | Training Loss: 0.30035 \nEpoch: 179  | Validation balanced accuracy : 0.50000 \nEpoch: 180  | Training Loss: 0.70707 \nEpoch: 180  | Training Loss: 0.70680 \nEpoch: 180  | Training Loss: 0.59988 \nEpoch: 180  | Training Loss: 0.53200 \nEpoch: 180  | Training Loss: 0.30023 \nEpoch: 180  | Validation balanced accuracy : 0.50000 \nEpoch: 181  | Training Loss: 0.70700 \nEpoch: 181  | Training Loss: 0.70677 \nEpoch: 181  | Training Loss: 0.59981 \nEpoch: 181  | Training Loss: 0.53197 \nEpoch: 181  | Training Loss: 0.30012 \nEpoch: 181  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 182  | Training Loss: 0.70692 \nEpoch: 182  | Training Loss: 0.70674 \nEpoch: 182  | Training Loss: 0.59975 \nEpoch: 182  | Training Loss: 0.53194 \nEpoch: 182  | Training Loss: 0.30000 \nEpoch: 182  | Validation balanced accuracy : 0.50000 \nEpoch: 183  | Training Loss: 0.70684 \nEpoch: 183  | Training Loss: 0.70671 \nEpoch: 183  | Training Loss: 0.59969 \nEpoch: 183  | Training Loss: 0.53191 \nEpoch: 183  | Training Loss: 0.29989 \nEpoch: 183  | Validation balanced accuracy : 0.50000 \nEpoch: 184  | Training Loss: 0.70676 \nEpoch: 184  | Training Loss: 0.70668 \nEpoch: 184  | Training Loss: 0.59963 \nEpoch: 184  | Training Loss: 0.53188 \nEpoch: 184  | Training Loss: 0.29978 \nEpoch: 184  | Validation balanced accuracy : 0.50000 \nEpoch: 185  | Training Loss: 0.70668 \nEpoch: 185  | Training Loss: 0.70665 \nEpoch: 185  | Training Loss: 0.59956 \nEpoch: 185  | Training Loss: 0.53184 \nEpoch: 185  | Training Loss: 0.29967 \nEpoch: 185  | Validation balanced accuracy : 0.50000 \nEpoch: 186  | Training Loss: 0.70660 \nEpoch: 186  | Training Loss: 0.70662 \nEpoch: 186  | Training Loss: 0.59950 \nEpoch: 186  | Training Loss: 0.53181 \nEpoch: 186  | Training Loss: 0.29955 \nEpoch: 186  | Validation balanced accuracy : 0.50000 \nEpoch: 187  | Training Loss: 0.70652 \nEpoch: 187  | Training Loss: 0.70659 \nEpoch: 187  | Training Loss: 0.59944 \nEpoch: 187  | Training Loss: 0.53178 \nEpoch: 187  | Training Loss: 0.29944 \nEpoch: 187  | Validation balanced accuracy : 0.50000 \nEpoch: 188  | Training Loss: 0.70644 \nEpoch: 188  | Training Loss: 0.70656 \nEpoch: 188  | Training Loss: 0.59937 \nEpoch: 188  | Training Loss: 0.53175 \nEpoch: 188  | Training Loss: 0.29933 \nEpoch: 188  | Validation balanced accuracy : 0.50000 \nEpoch: 189  | Training Loss: 0.70637 \nEpoch: 189  | Training Loss: 0.70653 \nEpoch: 189  | Training Loss: 0.59931 \nEpoch: 189  | Training Loss: 0.53172 \nEpoch: 189  | Training Loss: 0.29922 \nEpoch: 189  | Validation balanced accuracy : 0.50000 \nEpoch: 190  | Training Loss: 0.70629 \nEpoch: 190  | Training Loss: 0.70650 \nEpoch: 190  | Training Loss: 0.59925 \nEpoch: 190  | Training Loss: 0.53169 \nEpoch: 190  | Training Loss: 0.29910 \nEpoch: 190  | Validation balanced accuracy : 0.50000 \nEpoch: 191  | Training Loss: 0.70621 \nEpoch: 191  | Training Loss: 0.70647 \nEpoch: 191  | Training Loss: 0.59919 \nEpoch: 191  | Training Loss: 0.53166 \nEpoch: 191  | Training Loss: 0.29899 \nEpoch: 191  | Validation balanced accuracy : 0.50000 \nEpoch: 192  | Training Loss: 0.70613 \nEpoch: 192  | Training Loss: 0.70644 \nEpoch: 192  | Training Loss: 0.59913 \nEpoch: 192  | Training Loss: 0.53163 \nEpoch: 192  | Training Loss: 0.29888 \nEpoch: 192  | Validation balanced accuracy : 0.50000 \nEpoch: 193  | Training Loss: 0.70605 \nEpoch: 193  | Training Loss: 0.70641 \nEpoch: 193  | Training Loss: 0.59906 \nEpoch: 193  | Training Loss: 0.53160 \nEpoch: 193  | Training Loss: 0.29877 \nEpoch: 193  | Validation balanced accuracy : 0.50000 \nEpoch: 194  | Training Loss: 0.70598 \nEpoch: 194  | Training Loss: 0.70638 \nEpoch: 194  | Training Loss: 0.59900 \nEpoch: 194  | Training Loss: 0.53157 \nEpoch: 194  | Training Loss: 0.29866 \nEpoch: 194  | Validation balanced accuracy : 0.50000 \nEpoch: 195  | Training Loss: 0.70590 \nEpoch: 195  | Training Loss: 0.70635 \nEpoch: 195  | Training Loss: 0.59894 \nEpoch: 195  | Training Loss: 0.53154 \nEpoch: 195  | Training Loss: 0.29855 \nEpoch: 195  | Validation balanced accuracy : 0.50000 \nEpoch: 196  | Training Loss: 0.70582 \nEpoch: 196  | Training Loss: 0.70632 \nEpoch: 196  | Training Loss: 0.59888 \nEpoch: 196  | Training Loss: 0.53151 \nEpoch: 196  | Training Loss: 0.29843 \nEpoch: 196  | Validation balanced accuracy : 0.50000 \nEpoch: 197  | Training Loss: 0.70574 \nEpoch: 197  | Training Loss: 0.70629 \nEpoch: 197  | Training Loss: 0.59882 \nEpoch: 197  | Training Loss: 0.53148 \nEpoch: 197  | Training Loss: 0.29832 \nEpoch: 197  | Validation balanced accuracy : 0.50000 \nEpoch: 198  | Training Loss: 0.70566 \nEpoch: 198  | Training Loss: 0.70626 \nEpoch: 198  | Training Loss: 0.59876 \nEpoch: 198  | Training Loss: 0.53145 \nEpoch: 198  | Training Loss: 0.29821 \nEpoch: 198  | Validation balanced accuracy : 0.50000 \nEpoch: 199  | Training Loss: 0.70559 \nEpoch: 199  | Training Loss: 0.70623 \nEpoch: 199  | Training Loss: 0.59869 \nEpoch: 199  | Training Loss: 0.53142 \nEpoch: 199  | Training Loss: 0.29810 \nEpoch: 199  | Validation balanced accuracy : 0.50000 \nEpoch: 200  | Training Loss: 0.70551 \nEpoch: 200  | Training Loss: 0.70620 \nEpoch: 200  | Training Loss: 0.59863 \nEpoch: 200  | Training Loss: 0.53139 \nEpoch: 200  | Training Loss: 0.29799 \nEpoch: 200  | Validation balanced accuracy : 0.50000 \nEpoch: 201  | Training Loss: 0.70543 \nEpoch: 201  | Training Loss: 0.70617 \nEpoch: 201  | Training Loss: 0.59857 \nEpoch: 201  | Training Loss: 0.53136 \nEpoch: 201  | Training Loss: 0.29788 \nEpoch: 201  | Validation balanced accuracy : 0.50000 \nEpoch: 202  | Training Loss: 0.70535 \nEpoch: 202  | Training Loss: 0.70614 \nEpoch: 202  | Training Loss: 0.59851 \nEpoch: 202  | Training Loss: 0.53133 \nEpoch: 202  | Training Loss: 0.29777 \nEpoch: 202  | Validation balanced accuracy : 0.50000 \nEpoch: 203  | Training Loss: 0.70528 \nEpoch: 203  | Training Loss: 0.70611 \nEpoch: 203  | Training Loss: 0.59845 \nEpoch: 203  | Training Loss: 0.53130 \nEpoch: 203  | Training Loss: 0.29766 \nEpoch: 203  | Validation balanced accuracy : 0.50000 \nEpoch: 204  | Training Loss: 0.70520 \nEpoch: 204  | Training Loss: 0.70608 \nEpoch: 204  | Training Loss: 0.59838 \nEpoch: 204  | Training Loss: 0.53127 \nEpoch: 204  | Training Loss: 0.29755 \nEpoch: 204  | Validation balanced accuracy : 0.50000 \nEpoch: 205  | Training Loss: 0.70512 \nEpoch: 205  | Training Loss: 0.70605 \nEpoch: 205  | Training Loss: 0.59832 \nEpoch: 205  | Training Loss: 0.53124 \nEpoch: 205  | Training Loss: 0.29743 \nEpoch: 205  | Validation balanced accuracy : 0.50000 \nEpoch: 206  | Training Loss: 0.70504 \nEpoch: 206  | Training Loss: 0.70602 \nEpoch: 206  | Training Loss: 0.59826 \nEpoch: 206  | Training Loss: 0.53121 \nEpoch: 206  | Training Loss: 0.29732 \nEpoch: 206  | Validation balanced accuracy : 0.50000 \nEpoch: 207  | Training Loss: 0.70497 \nEpoch: 207  | Training Loss: 0.70599 \nEpoch: 207  | Training Loss: 0.59820 \nEpoch: 207  | Training Loss: 0.53118 \nEpoch: 207  | Training Loss: 0.29721 \nEpoch: 207  | Validation balanced accuracy : 0.50000 \nEpoch: 208  | Training Loss: 0.70489 \nEpoch: 208  | Training Loss: 0.70595 \nEpoch: 208  | Training Loss: 0.59814 \nEpoch: 208  | Training Loss: 0.53115 \nEpoch: 208  | Training Loss: 0.29710 \nEpoch: 208  | Validation balanced accuracy : 0.50000 \nEpoch: 209  | Training Loss: 0.70481 \nEpoch: 209  | Training Loss: 0.70592 \nEpoch: 209  | Training Loss: 0.59808 \nEpoch: 209  | Training Loss: 0.53112 \nEpoch: 209  | Training Loss: 0.29699 \nEpoch: 209  | Validation balanced accuracy : 0.50000 \nEpoch: 210  | Training Loss: 0.70473 \nEpoch: 210  | Training Loss: 0.70589 \nEpoch: 210  | Training Loss: 0.59802 \nEpoch: 210  | Training Loss: 0.53109 \nEpoch: 210  | Training Loss: 0.29688 \nEpoch: 210  | Validation balanced accuracy : 0.50000 \nEpoch: 211  | Training Loss: 0.70466 \nEpoch: 211  | Training Loss: 0.70586 \nEpoch: 211  | Training Loss: 0.59795 \nEpoch: 211  | Training Loss: 0.53106 \nEpoch: 211  | Training Loss: 0.29677 \nEpoch: 211  | Validation balanced accuracy : 0.50000 \nEpoch: 212  | Training Loss: 0.70458 \nEpoch: 212  | Training Loss: 0.70583 \nEpoch: 212  | Training Loss: 0.59789 \nEpoch: 212  | Training Loss: 0.53103 \nEpoch: 212  | Training Loss: 0.29666 \nEpoch: 212  | Validation balanced accuracy : 0.50000 \nEpoch: 213  | Training Loss: 0.70450 \nEpoch: 213  | Training Loss: 0.70580 \nEpoch: 213  | Training Loss: 0.59783 \nEpoch: 213  | Training Loss: 0.53100 \nEpoch: 213  | Training Loss: 0.29655 \nEpoch: 213  | Validation balanced accuracy : 0.50000 \nEpoch: 214  | Training Loss: 0.70443 \nEpoch: 214  | Training Loss: 0.70577 \nEpoch: 214  | Training Loss: 0.59777 \nEpoch: 214  | Training Loss: 0.53097 \nEpoch: 214  | Training Loss: 0.29644 \nEpoch: 214  | Validation balanced accuracy : 0.50000 \nEpoch: 215  | Training Loss: 0.70435 \nEpoch: 215  | Training Loss: 0.70574 \nEpoch: 215  | Training Loss: 0.59771 \nEpoch: 215  | Training Loss: 0.53094 \nEpoch: 215  | Training Loss: 0.29633 \nEpoch: 215  | Validation balanced accuracy : 0.50000 \nEpoch: 216  | Training Loss: 0.70427 \nEpoch: 216  | Training Loss: 0.70571 \nEpoch: 216  | Training Loss: 0.59765 \nEpoch: 216  | Training Loss: 0.53091 \nEpoch: 216  | Training Loss: 0.29622 \nEpoch: 216  | Validation balanced accuracy : 0.50000 \nEpoch: 217  | Training Loss: 0.70419 \nEpoch: 217  | Training Loss: 0.70568 \nEpoch: 217  | Training Loss: 0.59759 \nEpoch: 217  | Training Loss: 0.53088 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 217  | Training Loss: 0.29611 \nEpoch: 217  | Validation balanced accuracy : 0.50000 \nEpoch: 218  | Training Loss: 0.70412 \nEpoch: 218  | Training Loss: 0.70565 \nEpoch: 218  | Training Loss: 0.59753 \nEpoch: 218  | Training Loss: 0.53085 \nEpoch: 218  | Training Loss: 0.29600 \nEpoch: 218  | Validation balanced accuracy : 0.50000 \nEpoch: 219  | Training Loss: 0.70404 \nEpoch: 219  | Training Loss: 0.70562 \nEpoch: 219  | Training Loss: 0.59746 \nEpoch: 219  | Training Loss: 0.53082 \nEpoch: 219  | Training Loss: 0.29589 \nEpoch: 219  | Validation balanced accuracy : 0.50000 \nEpoch: 220  | Training Loss: 0.70396 \nEpoch: 220  | Training Loss: 0.70559 \nEpoch: 220  | Training Loss: 0.59740 \nEpoch: 220  | Training Loss: 0.53079 \nEpoch: 220  | Training Loss: 0.29578 \nEpoch: 220  | Validation balanced accuracy : 0.50000 \nEpoch: 221  | Training Loss: 0.70389 \nEpoch: 221  | Training Loss: 0.70556 \nEpoch: 221  | Training Loss: 0.59734 \nEpoch: 221  | Training Loss: 0.53076 \nEpoch: 221  | Training Loss: 0.29567 \nEpoch: 221  | Validation balanced accuracy : 0.50000 \nEpoch: 222  | Training Loss: 0.70381 \nEpoch: 222  | Training Loss: 0.70553 \nEpoch: 222  | Training Loss: 0.59728 \nEpoch: 222  | Training Loss: 0.53073 \nEpoch: 222  | Training Loss: 0.29556 \nEpoch: 222  | Validation balanced accuracy : 0.50000 \nEpoch: 223  | Training Loss: 0.70373 \nEpoch: 223  | Training Loss: 0.70550 \nEpoch: 223  | Training Loss: 0.59722 \nEpoch: 223  | Training Loss: 0.53070 \nEpoch: 223  | Training Loss: 0.29545 \nEpoch: 223  | Validation balanced accuracy : 0.50000 \nEpoch: 224  | Training Loss: 0.70366 \nEpoch: 224  | Training Loss: 0.70547 \nEpoch: 224  | Training Loss: 0.59716 \nEpoch: 224  | Training Loss: 0.53068 \nEpoch: 224  | Training Loss: 0.29534 \nEpoch: 224  | Validation balanced accuracy : 0.50000 \nEpoch: 225  | Training Loss: 0.70358 \nEpoch: 225  | Training Loss: 0.70543 \nEpoch: 225  | Training Loss: 0.59710 \nEpoch: 225  | Training Loss: 0.53065 \nEpoch: 225  | Training Loss: 0.29523 \nEpoch: 225  | Validation balanced accuracy : 0.50000 \nEpoch: 226  | Training Loss: 0.70350 \nEpoch: 226  | Training Loss: 0.70540 \nEpoch: 226  | Training Loss: 0.59704 \nEpoch: 226  | Training Loss: 0.53062 \nEpoch: 226  | Training Loss: 0.29512 \nEpoch: 226  | Validation balanced accuracy : 0.50000 \nEpoch: 227  | Training Loss: 0.70343 \nEpoch: 227  | Training Loss: 0.70537 \nEpoch: 227  | Training Loss: 0.59698 \nEpoch: 227  | Training Loss: 0.53059 \nEpoch: 227  | Training Loss: 0.29501 \nEpoch: 227  | Validation balanced accuracy : 0.50000 \nEpoch: 228  | Training Loss: 0.70335 \nEpoch: 228  | Training Loss: 0.70534 \nEpoch: 228  | Training Loss: 0.59692 \nEpoch: 228  | Training Loss: 0.53056 \nEpoch: 228  | Training Loss: 0.29490 \nEpoch: 228  | Validation balanced accuracy : 0.50000 \nEpoch: 229  | Training Loss: 0.70327 \nEpoch: 229  | Training Loss: 0.70531 \nEpoch: 229  | Training Loss: 0.59685 \nEpoch: 229  | Training Loss: 0.53053 \nEpoch: 229  | Training Loss: 0.29479 \nEpoch: 229  | Validation balanced accuracy : 0.50000 \nEpoch: 230  | Training Loss: 0.70320 \nEpoch: 230  | Training Loss: 0.70528 \nEpoch: 230  | Training Loss: 0.59679 \nEpoch: 230  | Training Loss: 0.53050 \nEpoch: 230  | Training Loss: 0.29468 \nEpoch: 230  | Validation balanced accuracy : 0.50000 \nEpoch: 231  | Training Loss: 0.70312 \nEpoch: 231  | Training Loss: 0.70525 \nEpoch: 231  | Training Loss: 0.59673 \nEpoch: 231  | Training Loss: 0.53047 \nEpoch: 231  | Training Loss: 0.29458 \nEpoch: 231  | Validation balanced accuracy : 0.50000 \nEpoch: 232  | Training Loss: 0.70304 \nEpoch: 232  | Training Loss: 0.70522 \nEpoch: 232  | Training Loss: 0.59667 \nEpoch: 232  | Training Loss: 0.53044 \nEpoch: 232  | Training Loss: 0.29447 \nEpoch: 232  | Validation balanced accuracy : 0.50000 \nEpoch: 233  | Training Loss: 0.70297 \nEpoch: 233  | Training Loss: 0.70519 \nEpoch: 233  | Training Loss: 0.59661 \nEpoch: 233  | Training Loss: 0.53041 \nEpoch: 233  | Training Loss: 0.29436 \nEpoch: 233  | Validation balanced accuracy : 0.50000 \nEpoch: 234  | Training Loss: 0.70289 \nEpoch: 234  | Training Loss: 0.70516 \nEpoch: 234  | Training Loss: 0.59655 \nEpoch: 234  | Training Loss: 0.53038 \nEpoch: 234  | Training Loss: 0.29425 \nEpoch: 234  | Validation balanced accuracy : 0.50000 \nEpoch: 235  | Training Loss: 0.70281 \nEpoch: 235  | Training Loss: 0.70513 \nEpoch: 235  | Training Loss: 0.59649 \nEpoch: 235  | Training Loss: 0.53035 \nEpoch: 235  | Training Loss: 0.29414 \nEpoch: 235  | Validation balanced accuracy : 0.50000 \nEpoch: 236  | Training Loss: 0.70274 \nEpoch: 236  | Training Loss: 0.70509 \nEpoch: 236  | Training Loss: 0.59643 \nEpoch: 236  | Training Loss: 0.53032 \nEpoch: 236  | Training Loss: 0.29403 \nEpoch: 236  | Validation balanced accuracy : 0.50000 \nEpoch: 237  | Training Loss: 0.70266 \nEpoch: 237  | Training Loss: 0.70506 \nEpoch: 237  | Training Loss: 0.59637 \nEpoch: 237  | Training Loss: 0.53029 \nEpoch: 237  | Training Loss: 0.29392 \nEpoch: 237  | Validation balanced accuracy : 0.50000 \nEpoch: 238  | Training Loss: 0.70258 \nEpoch: 238  | Training Loss: 0.70503 \nEpoch: 238  | Training Loss: 0.59631 \nEpoch: 238  | Training Loss: 0.53026 \nEpoch: 238  | Training Loss: 0.29381 \nEpoch: 238  | Validation balanced accuracy : 0.50000 \nEpoch: 239  | Training Loss: 0.70251 \nEpoch: 239  | Training Loss: 0.70500 \nEpoch: 239  | Training Loss: 0.59625 \nEpoch: 239  | Training Loss: 0.53023 \nEpoch: 239  | Training Loss: 0.29370 \nEpoch: 239  | Validation balanced accuracy : 0.50000 \nEpoch: 240  | Training Loss: 0.70243 \nEpoch: 240  | Training Loss: 0.70497 \nEpoch: 240  | Training Loss: 0.59619 \nEpoch: 240  | Training Loss: 0.53020 \nEpoch: 240  | Training Loss: 0.29359 \nEpoch: 240  | Validation balanced accuracy : 0.50000 \nEpoch: 241  | Training Loss: 0.70235 \nEpoch: 241  | Training Loss: 0.70494 \nEpoch: 241  | Training Loss: 0.59613 \nEpoch: 241  | Training Loss: 0.53017 \nEpoch: 241  | Training Loss: 0.29348 \nEpoch: 241  | Validation balanced accuracy : 0.50000 \nEpoch: 242  | Training Loss: 0.70228 \nEpoch: 242  | Training Loss: 0.70491 \nEpoch: 242  | Training Loss: 0.59606 \nEpoch: 242  | Training Loss: 0.53014 \nEpoch: 242  | Training Loss: 0.29338 \nEpoch: 242  | Validation balanced accuracy : 0.50000 \nEpoch: 243  | Training Loss: 0.70220 \nEpoch: 243  | Training Loss: 0.70487 \nEpoch: 243  | Training Loss: 0.59600 \nEpoch: 243  | Training Loss: 0.53011 \nEpoch: 243  | Training Loss: 0.29327 \nEpoch: 243  | Validation balanced accuracy : 0.50000 \nEpoch: 244  | Training Loss: 0.70212 \nEpoch: 244  | Training Loss: 0.70484 \nEpoch: 244  | Training Loss: 0.59594 \nEpoch: 244  | Training Loss: 0.53008 \nEpoch: 244  | Training Loss: 0.29316 \nEpoch: 244  | Validation balanced accuracy : 0.50000 \nEpoch: 245  | Training Loss: 0.70205 \nEpoch: 245  | Training Loss: 0.70481 \nEpoch: 245  | Training Loss: 0.59588 \nEpoch: 245  | Training Loss: 0.53005 \nEpoch: 245  | Training Loss: 0.29305 \nEpoch: 245  | Validation balanced accuracy : 0.50000 \nEpoch: 246  | Training Loss: 0.70197 \nEpoch: 246  | Training Loss: 0.70478 \nEpoch: 246  | Training Loss: 0.59582 \nEpoch: 246  | Training Loss: 0.53002 \nEpoch: 246  | Training Loss: 0.29294 \nEpoch: 246  | Validation balanced accuracy : 0.50000 \nEpoch: 247  | Training Loss: 0.70189 \nEpoch: 247  | Training Loss: 0.70475 \nEpoch: 247  | Training Loss: 0.59576 \nEpoch: 247  | Training Loss: 0.52999 \nEpoch: 247  | Training Loss: 0.29283 \nEpoch: 247  | Validation balanced accuracy : 0.50000 \nEpoch: 248  | Training Loss: 0.70182 \nEpoch: 248  | Training Loss: 0.70472 \nEpoch: 248  | Training Loss: 0.59570 \nEpoch: 248  | Training Loss: 0.52996 \nEpoch: 248  | Training Loss: 0.29272 \nEpoch: 248  | Validation balanced accuracy : 0.50000 \nEpoch: 249  | Training Loss: 0.70174 \nEpoch: 249  | Training Loss: 0.70468 \nEpoch: 249  | Training Loss: 0.59564 \nEpoch: 249  | Training Loss: 0.52993 \nEpoch: 249  | Training Loss: 0.29262 \nEpoch: 249  | Validation balanced accuracy : 0.50000 \nEpoch: 250  | Training Loss: 0.70166 \nEpoch: 250  | Training Loss: 0.70465 \nEpoch: 250  | Training Loss: 0.59558 \nEpoch: 250  | Training Loss: 0.52990 \nEpoch: 250  | Training Loss: 0.29251 \nEpoch: 250  | Validation balanced accuracy : 0.50000 \nEpoch: 251  | Training Loss: 0.70159 \nEpoch: 251  | Training Loss: 0.70462 \nEpoch: 251  | Training Loss: 0.59552 \nEpoch: 251  | Training Loss: 0.52987 \nEpoch: 251  | Training Loss: 0.29239 \nEpoch: 251  | Validation balanced accuracy : 0.50000 \nEpoch: 252  | Training Loss: 0.70151 \nEpoch: 252  | Training Loss: 0.70459 \nEpoch: 252  | Training Loss: 0.59546 \nEpoch: 252  | Training Loss: 0.52985 \nEpoch: 252  | Training Loss: 0.29229 \nEpoch: 252  | Validation balanced accuracy : 0.50000 \nEpoch: 253  | Training Loss: 0.70144 \nEpoch: 253  | Training Loss: 0.70456 \nEpoch: 253  | Training Loss: 0.59540 \nEpoch: 253  | Training Loss: 0.52982 \nEpoch: 253  | Training Loss: 0.29218 \nEpoch: 253  | Validation balanced accuracy : 0.50000 \nEpoch: 254  | Training Loss: 0.70136 \nEpoch: 254  | Training Loss: 0.70453 \nEpoch: 254  | Training Loss: 0.59534 \nEpoch: 254  | Training Loss: 0.52979 \nEpoch: 254  | Training Loss: 0.29207 \nEpoch: 254  | Validation balanced accuracy : 0.50000 \nEpoch: 255  | Training Loss: 0.70128 \nEpoch: 255  | Training Loss: 0.70449 \nEpoch: 255  | Training Loss: 0.59528 \nEpoch: 255  | Training Loss: 0.52976 \nEpoch: 255  | Training Loss: 0.29196 \nEpoch: 255  | Validation balanced accuracy : 0.50000 \nEpoch: 256  | Training Loss: 0.70121 \nEpoch: 256  | Training Loss: 0.70446 \nEpoch: 256  | Training Loss: 0.59522 \nEpoch: 256  | Training Loss: 0.52973 \nEpoch: 256  | Training Loss: 0.29185 \nEpoch: 256  | Validation balanced accuracy : 0.50000 \nEpoch: 257  | Training Loss: 0.70113 \nEpoch: 257  | Training Loss: 0.70443 \nEpoch: 257  | Training Loss: 0.59516 \nEpoch: 257  | Training Loss: 0.52970 \nEpoch: 257  | Training Loss: 0.29174 \nEpoch: 257  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 258  | Training Loss: 0.70105 \nEpoch: 258  | Training Loss: 0.70440 \nEpoch: 258  | Training Loss: 0.59509 \nEpoch: 258  | Training Loss: 0.52967 \nEpoch: 258  | Training Loss: 0.29164 \nEpoch: 258  | Validation balanced accuracy : 0.50000 \nEpoch: 259  | Training Loss: 0.70098 \nEpoch: 259  | Training Loss: 0.70437 \nEpoch: 259  | Training Loss: 0.59503 \nEpoch: 259  | Training Loss: 0.52964 \nEpoch: 259  | Training Loss: 0.29153 \nEpoch: 259  | Validation balanced accuracy : 0.50000 \nEpoch: 260  | Training Loss: 0.70090 \nEpoch: 260  | Training Loss: 0.70433 \nEpoch: 260  | Training Loss: 0.59497 \nEpoch: 260  | Training Loss: 0.52961 \nEpoch: 260  | Training Loss: 0.29142 \nEpoch: 260  | Validation balanced accuracy : 0.50000 \nEpoch: 261  | Training Loss: 0.70083 \nEpoch: 261  | Training Loss: 0.70430 \nEpoch: 261  | Training Loss: 0.59491 \nEpoch: 261  | Training Loss: 0.52958 \nEpoch: 261  | Training Loss: 0.29131 \nEpoch: 261  | Validation balanced accuracy : 0.50000 \nEpoch: 262  | Training Loss: 0.70075 \nEpoch: 262  | Training Loss: 0.70427 \nEpoch: 262  | Training Loss: 0.59485 \nEpoch: 262  | Training Loss: 0.52955 \nEpoch: 262  | Training Loss: 0.29120 \nEpoch: 262  | Validation balanced accuracy : 0.50000 \nEpoch: 263  | Training Loss: 0.70067 \nEpoch: 263  | Training Loss: 0.70424 \nEpoch: 263  | Training Loss: 0.59479 \nEpoch: 263  | Training Loss: 0.52952 \nEpoch: 263  | Training Loss: 0.29109 \nEpoch: 263  | Validation balanced accuracy : 0.50000 \nEpoch: 264  | Training Loss: 0.70059 \nEpoch: 264  | Training Loss: 0.70420 \nEpoch: 264  | Training Loss: 0.59473 \nEpoch: 264  | Training Loss: 0.52949 \nEpoch: 264  | Training Loss: 0.29099 \nEpoch: 264  | Validation balanced accuracy : 0.50000 \nEpoch: 265  | Training Loss: 0.70052 \nEpoch: 265  | Training Loss: 0.70417 \nEpoch: 265  | Training Loss: 0.59467 \nEpoch: 265  | Training Loss: 0.52946 \nEpoch: 265  | Training Loss: 0.29088 \nEpoch: 265  | Validation balanced accuracy : 0.50000 \nEpoch: 266  | Training Loss: 0.70044 \nEpoch: 266  | Training Loss: 0.70414 \nEpoch: 266  | Training Loss: 0.59461 \nEpoch: 266  | Training Loss: 0.52943 \nEpoch: 266  | Training Loss: 0.29077 \nEpoch: 266  | Validation balanced accuracy : 0.50000 \nEpoch: 267  | Training Loss: 0.70037 \nEpoch: 267  | Training Loss: 0.70411 \nEpoch: 267  | Training Loss: 0.59455 \nEpoch: 267  | Training Loss: 0.52940 \nEpoch: 267  | Training Loss: 0.29066 \nEpoch: 267  | Validation balanced accuracy : 0.50000 \nEpoch: 268  | Training Loss: 0.70029 \nEpoch: 268  | Training Loss: 0.70408 \nEpoch: 268  | Training Loss: 0.59449 \nEpoch: 268  | Training Loss: 0.52937 \nEpoch: 268  | Training Loss: 0.29055 \nEpoch: 268  | Validation balanced accuracy : 0.50000 \nEpoch: 269  | Training Loss: 0.70021 \nEpoch: 269  | Training Loss: 0.70404 \nEpoch: 269  | Training Loss: 0.59443 \nEpoch: 269  | Training Loss: 0.52934 \nEpoch: 269  | Training Loss: 0.29045 \nEpoch: 269  | Validation balanced accuracy : 0.50000 \nEpoch: 270  | Training Loss: 0.70014 \nEpoch: 270  | Training Loss: 0.70401 \nEpoch: 270  | Training Loss: 0.59437 \nEpoch: 270  | Training Loss: 0.52931 \nEpoch: 270  | Training Loss: 0.29034 \nEpoch: 270  | Validation balanced accuracy : 0.50000 \nEpoch: 271  | Training Loss: 0.70006 \nEpoch: 271  | Training Loss: 0.70398 \nEpoch: 271  | Training Loss: 0.59431 \nEpoch: 271  | Training Loss: 0.52928 \nEpoch: 271  | Training Loss: 0.29023 \nEpoch: 271  | Validation balanced accuracy : 0.50000 \nEpoch: 272  | Training Loss: 0.69998 \nEpoch: 272  | Training Loss: 0.70395 \nEpoch: 272  | Training Loss: 0.59425 \nEpoch: 272  | Training Loss: 0.52925 \nEpoch: 272  | Training Loss: 0.29012 \nEpoch: 272  | Validation balanced accuracy : 0.50000 \nEpoch: 273  | Training Loss: 0.69991 \nEpoch: 273  | Training Loss: 0.70391 \nEpoch: 273  | Training Loss: 0.59418 \nEpoch: 273  | Training Loss: 0.52922 \nEpoch: 273  | Training Loss: 0.29001 \nEpoch: 273  | Validation balanced accuracy : 0.50000 \nEpoch: 274  | Training Loss: 0.69983 \nEpoch: 274  | Training Loss: 0.70388 \nEpoch: 274  | Training Loss: 0.59412 \nEpoch: 274  | Training Loss: 0.52919 \nEpoch: 274  | Training Loss: 0.28990 \nEpoch: 274  | Validation balanced accuracy : 0.50000 \nEpoch: 275  | Training Loss: 0.69975 \nEpoch: 275  | Training Loss: 0.70385 \nEpoch: 275  | Training Loss: 0.59406 \nEpoch: 275  | Training Loss: 0.52916 \nEpoch: 275  | Training Loss: 0.28980 \nEpoch: 275  | Validation balanced accuracy : 0.50000 \nEpoch: 276  | Training Loss: 0.69968 \nEpoch: 276  | Training Loss: 0.70381 \nEpoch: 276  | Training Loss: 0.59400 \nEpoch: 276  | Training Loss: 0.52913 \nEpoch: 276  | Training Loss: 0.28969 \nEpoch: 276  | Validation balanced accuracy : 0.50000 \nEpoch: 277  | Training Loss: 0.69960 \nEpoch: 277  | Training Loss: 0.70378 \nEpoch: 277  | Training Loss: 0.59394 \nEpoch: 277  | Training Loss: 0.52910 \nEpoch: 277  | Training Loss: 0.28958 \nEpoch: 277  | Validation balanced accuracy : 0.50000 \nEpoch: 278  | Training Loss: 0.69952 \nEpoch: 278  | Training Loss: 0.70375 \nEpoch: 278  | Training Loss: 0.59388 \nEpoch: 278  | Training Loss: 0.52907 \nEpoch: 278  | Training Loss: 0.28947 \nEpoch: 278  | Validation balanced accuracy : 0.50000 \nEpoch: 279  | Training Loss: 0.69945 \nEpoch: 279  | Training Loss: 0.70372 \nEpoch: 279  | Training Loss: 0.59382 \nEpoch: 279  | Training Loss: 0.52904 \nEpoch: 279  | Training Loss: 0.28936 \nEpoch: 279  | Validation balanced accuracy : 0.50000 \nEpoch: 280  | Training Loss: 0.69937 \nEpoch: 280  | Training Loss: 0.70368 \nEpoch: 280  | Training Loss: 0.59376 \nEpoch: 280  | Training Loss: 0.52901 \nEpoch: 280  | Training Loss: 0.28925 \nEpoch: 280  | Validation balanced accuracy : 0.50000 \nEpoch: 281  | Training Loss: 0.69929 \nEpoch: 281  | Training Loss: 0.70365 \nEpoch: 281  | Training Loss: 0.59370 \nEpoch: 281  | Training Loss: 0.52898 \nEpoch: 281  | Training Loss: 0.28915 \nEpoch: 281  | Validation balanced accuracy : 0.50000 \nEpoch: 282  | Training Loss: 0.69922 \nEpoch: 282  | Training Loss: 0.70362 \nEpoch: 282  | Training Loss: 0.59364 \nEpoch: 282  | Training Loss: 0.52896 \nEpoch: 282  | Training Loss: 0.28904 \nEpoch: 282  | Validation balanced accuracy : 0.50000 \nEpoch: 283  | Training Loss: 0.69914 \nEpoch: 283  | Training Loss: 0.70358 \nEpoch: 283  | Training Loss: 0.59358 \nEpoch: 283  | Training Loss: 0.52893 \nEpoch: 283  | Training Loss: 0.28893 \nEpoch: 283  | Validation balanced accuracy : 0.50000 \nEpoch: 284  | Training Loss: 0.69906 \nEpoch: 284  | Training Loss: 0.70355 \nEpoch: 284  | Training Loss: 0.59352 \nEpoch: 284  | Training Loss: 0.52890 \nEpoch: 284  | Training Loss: 0.28882 \nEpoch: 284  | Validation balanced accuracy : 0.50000 \nEpoch: 285  | Training Loss: 0.69899 \nEpoch: 285  | Training Loss: 0.70352 \nEpoch: 285  | Training Loss: 0.59346 \nEpoch: 285  | Training Loss: 0.52887 \nEpoch: 285  | Training Loss: 0.28871 \nEpoch: 285  | Validation balanced accuracy : 0.50000 \nEpoch: 286  | Training Loss: 0.69891 \nEpoch: 286  | Training Loss: 0.70348 \nEpoch: 286  | Training Loss: 0.59339 \nEpoch: 286  | Training Loss: 0.52884 \nEpoch: 286  | Training Loss: 0.28860 \nEpoch: 286  | Validation balanced accuracy : 0.50000 \nEpoch: 287  | Training Loss: 0.69883 \nEpoch: 287  | Training Loss: 0.70345 \nEpoch: 287  | Training Loss: 0.59333 \nEpoch: 287  | Training Loss: 0.52881 \nEpoch: 287  | Training Loss: 0.28850 \nEpoch: 287  | Validation balanced accuracy : 0.50000 \nEpoch: 288  | Training Loss: 0.69876 \nEpoch: 288  | Training Loss: 0.70342 \nEpoch: 288  | Training Loss: 0.59327 \nEpoch: 288  | Training Loss: 0.52878 \nEpoch: 288  | Training Loss: 0.28839 \nEpoch: 288  | Validation balanced accuracy : 0.50000 \nEpoch: 289  | Training Loss: 0.69868 \nEpoch: 289  | Training Loss: 0.70338 \nEpoch: 289  | Training Loss: 0.59321 \nEpoch: 289  | Training Loss: 0.52875 \nEpoch: 289  | Training Loss: 0.28828 \nEpoch: 289  | Validation balanced accuracy : 0.50000 \nEpoch: 290  | Training Loss: 0.69860 \nEpoch: 290  | Training Loss: 0.70335 \nEpoch: 290  | Training Loss: 0.59315 \nEpoch: 290  | Training Loss: 0.52872 \nEpoch: 290  | Training Loss: 0.28817 \nEpoch: 290  | Validation balanced accuracy : 0.50000 \nEpoch: 291  | Training Loss: 0.69852 \nEpoch: 291  | Training Loss: 0.70331 \nEpoch: 291  | Training Loss: 0.59309 \nEpoch: 291  | Training Loss: 0.52869 \nEpoch: 291  | Training Loss: 0.28806 \nEpoch: 291  | Validation balanced accuracy : 0.50000 \nEpoch: 292  | Training Loss: 0.69845 \nEpoch: 292  | Training Loss: 0.70328 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 292  | Training Loss: 0.59303 \nEpoch: 292  | Training Loss: 0.52866 \nEpoch: 292  | Training Loss: 0.28795 \nEpoch: 292  | Validation balanced accuracy : 0.50000 \nEpoch: 293  | Training Loss: 0.69837 \nEpoch: 293  | Training Loss: 0.70325 \nEpoch: 293  | Training Loss: 0.59297 \nEpoch: 293  | Training Loss: 0.52863 \nEpoch: 293  | Training Loss: 0.28784 \nEpoch: 293  | Validation balanced accuracy : 0.50000 \nEpoch: 294  | Training Loss: 0.69829 \nEpoch: 294  | Training Loss: 0.70322 \nEpoch: 294  | Training Loss: 0.59291 \nEpoch: 294  | Training Loss: 0.52860 \nEpoch: 294  | Training Loss: 0.28774 \nEpoch: 294  | Validation balanced accuracy : 0.50000 \nEpoch: 295  | Training Loss: 0.69822 \nEpoch: 295  | Training Loss: 0.70318 \nEpoch: 295  | Training Loss: 0.59284 \nEpoch: 295  | Training Loss: 0.52857 \nEpoch: 295  | Training Loss: 0.28763 \nEpoch: 295  | Validation balanced accuracy : 0.50000 \nEpoch: 296  | Training Loss: 0.69814 \nEpoch: 296  | Training Loss: 0.70315 \nEpoch: 296  | Training Loss: 0.59278 \nEpoch: 296  | Training Loss: 0.52854 \nEpoch: 296  | Training Loss: 0.28752 \nEpoch: 296  | Validation balanced accuracy : 0.50000 \nEpoch: 297  | Training Loss: 0.69806 \nEpoch: 297  | Training Loss: 0.70311 \nEpoch: 297  | Training Loss: 0.59272 \nEpoch: 297  | Training Loss: 0.52851 \nEpoch: 297  | Training Loss: 0.28741 \nEpoch: 297  | Validation balanced accuracy : 0.50000 \nEpoch: 298  | Training Loss: 0.69799 \nEpoch: 298  | Training Loss: 0.70308 \nEpoch: 298  | Training Loss: 0.59266 \nEpoch: 298  | Training Loss: 0.52848 \nEpoch: 298  | Training Loss: 0.28730 \nEpoch: 298  | Validation balanced accuracy : 0.50000 \nEpoch: 299  | Training Loss: 0.69791 \nEpoch: 299  | Training Loss: 0.70304 \nEpoch: 299  | Training Loss: 0.59260 \nEpoch: 299  | Training Loss: 0.52845 \nEpoch: 299  | Training Loss: 0.28719 \nEpoch: 299  | Validation balanced accuracy : 0.50000 \nEpoch: 300  | Training Loss: 0.69783 \nEpoch: 300  | Training Loss: 0.70301 \nEpoch: 300  | Training Loss: 0.59254 \nEpoch: 300  | Training Loss: 0.52842 \nEpoch: 300  | Training Loss: 0.28709 \nEpoch: 300  | Validation balanced accuracy : 0.50000 \nEpoch: 301  | Training Loss: 0.69775 \nEpoch: 301  | Training Loss: 0.70281 \nEpoch: 301  | Training Loss: 0.59251 \nEpoch: 301  | Training Loss: 0.52827 \nEpoch: 301  | Training Loss: 0.28577 \nEpoch: 301  | Validation balanced accuracy : 0.50000 \nEpoch: 302  | Training Loss: 0.69763 \nEpoch: 302  | Training Loss: 0.70270 \nEpoch: 302  | Training Loss: 0.59242 \nEpoch: 302  | Training Loss: 0.52828 \nEpoch: 302  | Training Loss: 0.28596 \nEpoch: 302  | Validation balanced accuracy : 0.50000 \nEpoch: 303  | Training Loss: 0.69741 \nEpoch: 303  | Training Loss: 0.70252 \nEpoch: 303  | Training Loss: 0.59233 \nEpoch: 303  | Training Loss: 0.52829 \nEpoch: 303  | Training Loss: 0.28609 \nEpoch: 303  | Validation balanced accuracy : 0.50000 \nEpoch: 304  | Training Loss: 0.69725 \nEpoch: 304  | Training Loss: 0.70242 \nEpoch: 304  | Training Loss: 0.59226 \nEpoch: 304  | Training Loss: 0.52827 \nEpoch: 304  | Training Loss: 0.28601 \nEpoch: 304  | Validation balanced accuracy : 0.50000 \nEpoch: 305  | Training Loss: 0.69719 \nEpoch: 305  | Training Loss: 0.70241 \nEpoch: 305  | Training Loss: 0.59222 \nEpoch: 305  | Training Loss: 0.52823 \nEpoch: 305  | Training Loss: 0.28579 \nEpoch: 305  | Validation balanced accuracy : 0.50000 \nEpoch: 306  | Training Loss: 0.69719 \nEpoch: 306  | Training Loss: 0.70245 \nEpoch: 306  | Training Loss: 0.59218 \nEpoch: 306  | Training Loss: 0.52818 \nEpoch: 306  | Training Loss: 0.28558 \nEpoch: 306  | Validation balanced accuracy : 0.50000 \nEpoch: 307  | Training Loss: 0.69716 \nEpoch: 307  | Training Loss: 0.70246 \nEpoch: 307  | Training Loss: 0.59213 \nEpoch: 307  | Training Loss: 0.52815 \nEpoch: 307  | Training Loss: 0.28547 \nEpoch: 307  | Validation balanced accuracy : 0.50000 \nEpoch: 308  | Training Loss: 0.69709 \nEpoch: 308  | Training Loss: 0.70242 \nEpoch: 308  | Training Loss: 0.59207 \nEpoch: 308  | Training Loss: 0.52813 \nEpoch: 308  | Training Loss: 0.28543 \nEpoch: 308  | Validation balanced accuracy : 0.50000 \nEpoch: 309  | Training Loss: 0.69699 \nEpoch: 309  | Training Loss: 0.70236 \nEpoch: 309  | Training Loss: 0.59201 \nEpoch: 309  | Training Loss: 0.52811 \nEpoch: 309  | Training Loss: 0.28538 \nEpoch: 309  | Validation balanced accuracy : 0.50000 \nEpoch: 310  | Training Loss: 0.69690 \nEpoch: 310  | Training Loss: 0.70231 \nEpoch: 310  | Training Loss: 0.59195 \nEpoch: 310  | Training Loss: 0.52809 \nEpoch: 310  | Training Loss: 0.28529 \nEpoch: 310  | Validation balanced accuracy : 0.50000 \nEpoch: 311  | Training Loss: 0.69683 \nEpoch: 311  | Training Loss: 0.70228 \nEpoch: 311  | Training Loss: 0.59190 \nEpoch: 311  | Training Loss: 0.52806 \nEpoch: 311  | Training Loss: 0.28517 \nEpoch: 311  | Validation balanced accuracy : 0.50000 \nEpoch: 312  | Training Loss: 0.69677 \nEpoch: 312  | Training Loss: 0.70226 \nEpoch: 312  | Training Loss: 0.59185 \nEpoch: 312  | Training Loss: 0.52803 \nEpoch: 312  | Training Loss: 0.28506 \nEpoch: 312  | Validation balanced accuracy : 0.50000 \nEpoch: 313  | Training Loss: 0.69671 \nEpoch: 313  | Training Loss: 0.70224 \nEpoch: 313  | Training Loss: 0.59179 \nEpoch: 313  | Training Loss: 0.52800 \nEpoch: 313  | Training Loss: 0.28495 \nEpoch: 313  | Validation balanced accuracy : 0.50000 \nEpoch: 314  | Training Loss: 0.69664 \nEpoch: 314  | Training Loss: 0.70221 \nEpoch: 314  | Training Loss: 0.59174 \nEpoch: 314  | Training Loss: 0.52797 \nEpoch: 314  | Training Loss: 0.28486 \nEpoch: 314  | Validation balanced accuracy : 0.50000 \nEpoch: 315  | Training Loss: 0.69657 \nEpoch: 315  | Training Loss: 0.70217 \nEpoch: 315  | Training Loss: 0.59168 \nEpoch: 315  | Training Loss: 0.52794 \nEpoch: 315  | Training Loss: 0.28478 \nEpoch: 315  | Validation balanced accuracy : 0.50000 \nEpoch: 316  | Training Loss: 0.69650 \nEpoch: 316  | Training Loss: 0.70214 \nEpoch: 316  | Training Loss: 0.59162 \nEpoch: 316  | Training Loss: 0.52792 \nEpoch: 316  | Training Loss: 0.28468 \nEpoch: 316  | Validation balanced accuracy : 0.50000 \nEpoch: 317  | Training Loss: 0.69642 \nEpoch: 317  | Training Loss: 0.70210 \nEpoch: 317  | Training Loss: 0.59157 \nEpoch: 317  | Training Loss: 0.52789 \nEpoch: 317  | Training Loss: 0.28458 \nEpoch: 317  | Validation balanced accuracy : 0.50000 \nEpoch: 318  | Training Loss: 0.69636 \nEpoch: 318  | Training Loss: 0.70207 \nEpoch: 318  | Training Loss: 0.59151 \nEpoch: 318  | Training Loss: 0.52786 \nEpoch: 318  | Training Loss: 0.28448 \nEpoch: 318  | Validation balanced accuracy : 0.50000 \nEpoch: 319  | Training Loss: 0.69629 \nEpoch: 319  | Training Loss: 0.70205 \nEpoch: 319  | Training Loss: 0.59146 \nEpoch: 319  | Training Loss: 0.52784 \nEpoch: 319  | Training Loss: 0.28438 \nEpoch: 319  | Validation balanced accuracy : 0.50000 \nEpoch: 320  | Training Loss: 0.69622 \nEpoch: 320  | Training Loss: 0.70201 \nEpoch: 320  | Training Loss: 0.59140 \nEpoch: 320  | Training Loss: 0.52781 \nEpoch: 320  | Training Loss: 0.28429 \nEpoch: 320  | Validation balanced accuracy : 0.50000 \nEpoch: 321  | Training Loss: 0.69615 \nEpoch: 321  | Training Loss: 0.70198 \nEpoch: 321  | Training Loss: 0.59134 \nEpoch: 321  | Training Loss: 0.52778 \nEpoch: 321  | Training Loss: 0.28419 \nEpoch: 321  | Validation balanced accuracy : 0.50000 \nEpoch: 322  | Training Loss: 0.69608 \nEpoch: 322  | Training Loss: 0.70195 \nEpoch: 322  | Training Loss: 0.59129 \nEpoch: 322  | Training Loss: 0.52775 \nEpoch: 322  | Training Loss: 0.28409 \nEpoch: 322  | Validation balanced accuracy : 0.50000 \nEpoch: 323  | Training Loss: 0.69601 \nEpoch: 323  | Training Loss: 0.70192 \nEpoch: 323  | Training Loss: 0.59123 \nEpoch: 323  | Training Loss: 0.52773 \nEpoch: 323  | Training Loss: 0.28400 \nEpoch: 323  | Validation balanced accuracy : 0.50000 \nEpoch: 324  | Training Loss: 0.69593 \nEpoch: 324  | Training Loss: 0.70189 \nEpoch: 324  | Training Loss: 0.59118 \nEpoch: 324  | Training Loss: 0.52770 \nEpoch: 324  | Training Loss: 0.28390 \nEpoch: 324  | Validation balanced accuracy : 0.50000 \nEpoch: 325  | Training Loss: 0.69587 \nEpoch: 325  | Training Loss: 0.70186 \nEpoch: 325  | Training Loss: 0.59112 \nEpoch: 325  | Training Loss: 0.52767 \nEpoch: 325  | Training Loss: 0.28380 \nEpoch: 325  | Validation balanced accuracy : 0.50000 \nEpoch: 326  | Training Loss: 0.69580 \nEpoch: 326  | Training Loss: 0.70182 \nEpoch: 326  | Training Loss: 0.59107 \nEpoch: 326  | Training Loss: 0.52764 \nEpoch: 326  | Training Loss: 0.28370 \nEpoch: 326  | Validation balanced accuracy : 0.50000 \nEpoch: 327  | Training Loss: 0.69572 \nEpoch: 327  | Training Loss: 0.70179 \nEpoch: 327  | Training Loss: 0.59101 \nEpoch: 327  | Training Loss: 0.52762 \nEpoch: 327  | Training Loss: 0.28361 \nEpoch: 327  | Validation balanced accuracy : 0.50000 \nEpoch: 328  | Training Loss: 0.69565 \nEpoch: 328  | Training Loss: 0.70176 \nEpoch: 328  | Training Loss: 0.59095 \nEpoch: 328  | Training Loss: 0.52759 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 328  | Training Loss: 0.28351 \nEpoch: 328  | Validation balanced accuracy : 0.50000 \nEpoch: 329  | Training Loss: 0.69558 \nEpoch: 329  | Training Loss: 0.70173 \nEpoch: 329  | Training Loss: 0.59090 \nEpoch: 329  | Training Loss: 0.52756 \nEpoch: 329  | Training Loss: 0.28341 \nEpoch: 329  | Validation balanced accuracy : 0.50000 \nEpoch: 330  | Training Loss: 0.69551 \nEpoch: 330  | Training Loss: 0.70170 \nEpoch: 330  | Training Loss: 0.59084 \nEpoch: 330  | Training Loss: 0.52754 \nEpoch: 330  | Training Loss: 0.28331 \nEpoch: 330  | Validation balanced accuracy : 0.50000 \nEpoch: 331  | Training Loss: 0.69544 \nEpoch: 331  | Training Loss: 0.70166 \nEpoch: 331  | Training Loss: 0.59079 \nEpoch: 331  | Training Loss: 0.52751 \nEpoch: 331  | Training Loss: 0.28321 \nEpoch: 331  | Validation balanced accuracy : 0.50000 \nEpoch: 332  | Training Loss: 0.69537 \nEpoch: 332  | Training Loss: 0.70163 \nEpoch: 332  | Training Loss: 0.59073 \nEpoch: 332  | Training Loss: 0.52748 \nEpoch: 332  | Training Loss: 0.28312 \nEpoch: 332  | Validation balanced accuracy : 0.50000 \nEpoch: 333  | Training Loss: 0.69530 \nEpoch: 333  | Training Loss: 0.70160 \nEpoch: 333  | Training Loss: 0.59067 \nEpoch: 333  | Training Loss: 0.52745 \nEpoch: 333  | Training Loss: 0.28302 \nEpoch: 333  | Validation balanced accuracy : 0.50000 \nEpoch: 334  | Training Loss: 0.69523 \nEpoch: 334  | Training Loss: 0.70157 \nEpoch: 334  | Training Loss: 0.59062 \nEpoch: 334  | Training Loss: 0.52743 \nEpoch: 334  | Training Loss: 0.28292 \nEpoch: 334  | Validation balanced accuracy : 0.50000 \nEpoch: 335  | Training Loss: 0.69516 \nEpoch: 335  | Training Loss: 0.70153 \nEpoch: 335  | Training Loss: 0.59056 \nEpoch: 335  | Training Loss: 0.52740 \nEpoch: 335  | Training Loss: 0.28282 \nEpoch: 335  | Validation balanced accuracy : 0.50000 \nEpoch: 336  | Training Loss: 0.69509 \nEpoch: 336  | Training Loss: 0.70150 \nEpoch: 336  | Training Loss: 0.59050 \nEpoch: 336  | Training Loss: 0.52737 \nEpoch: 336  | Training Loss: 0.28272 \nEpoch: 336  | Validation balanced accuracy : 0.50000 \nEpoch: 337  | Training Loss: 0.69502 \nEpoch: 337  | Training Loss: 0.70147 \nEpoch: 337  | Training Loss: 0.59045 \nEpoch: 337  | Training Loss: 0.52734 \nEpoch: 337  | Training Loss: 0.28263 \nEpoch: 337  | Validation balanced accuracy : 0.50000 \nEpoch: 338  | Training Loss: 0.69494 \nEpoch: 338  | Training Loss: 0.70144 \nEpoch: 338  | Training Loss: 0.59039 \nEpoch: 338  | Training Loss: 0.52731 \nEpoch: 338  | Training Loss: 0.28253 \nEpoch: 338  | Validation balanced accuracy : 0.50000 \nEpoch: 339  | Training Loss: 0.69487 \nEpoch: 339  | Training Loss: 0.70141 \nEpoch: 339  | Training Loss: 0.59033 \nEpoch: 339  | Training Loss: 0.52729 \nEpoch: 339  | Training Loss: 0.28243 \nEpoch: 339  | Validation balanced accuracy : 0.50000 \nEpoch: 340  | Training Loss: 0.69480 \nEpoch: 340  | Training Loss: 0.70137 \nEpoch: 340  | Training Loss: 0.59028 \nEpoch: 340  | Training Loss: 0.52726 \nEpoch: 340  | Training Loss: 0.28233 \nEpoch: 340  | Validation balanced accuracy : 0.50000 \nEpoch: 341  | Training Loss: 0.69473 \nEpoch: 341  | Training Loss: 0.70134 \nEpoch: 341  | Training Loss: 0.59022 \nEpoch: 341  | Training Loss: 0.52723 \nEpoch: 341  | Training Loss: 0.28224 \nEpoch: 341  | Validation balanced accuracy : 0.50000 \nEpoch: 342  | Training Loss: 0.69466 \nEpoch: 342  | Training Loss: 0.70131 \nEpoch: 342  | Training Loss: 0.59016 \nEpoch: 342  | Training Loss: 0.52720 \nEpoch: 342  | Training Loss: 0.28214 \nEpoch: 342  | Validation balanced accuracy : 0.50000 \nEpoch: 343  | Training Loss: 0.69459 \nEpoch: 343  | Training Loss: 0.70128 \nEpoch: 343  | Training Loss: 0.59011 \nEpoch: 343  | Training Loss: 0.52718 \nEpoch: 343  | Training Loss: 0.28204 \nEpoch: 343  | Validation balanced accuracy : 0.50000 \nEpoch: 344  | Training Loss: 0.69451 \nEpoch: 344  | Training Loss: 0.70124 \nEpoch: 344  | Training Loss: 0.59005 \nEpoch: 344  | Training Loss: 0.52715 \nEpoch: 344  | Training Loss: 0.28194 \nEpoch: 344  | Validation balanced accuracy : 0.50000 \nEpoch: 345  | Training Loss: 0.69444 \nEpoch: 345  | Training Loss: 0.70121 \nEpoch: 345  | Training Loss: 0.58999 \nEpoch: 345  | Training Loss: 0.52712 \nEpoch: 345  | Training Loss: 0.28184 \nEpoch: 345  | Validation balanced accuracy : 0.50000 \nEpoch: 346  | Training Loss: 0.69437 \nEpoch: 346  | Training Loss: 0.70118 \nEpoch: 346  | Training Loss: 0.58994 \nEpoch: 346  | Training Loss: 0.52709 \nEpoch: 346  | Training Loss: 0.28174 \nEpoch: 346  | Validation balanced accuracy : 0.50000 \nEpoch: 347  | Training Loss: 0.69430 \nEpoch: 347  | Training Loss: 0.70114 \nEpoch: 347  | Training Loss: 0.58988 \nEpoch: 347  | Training Loss: 0.52707 \nEpoch: 347  | Training Loss: 0.28165 \nEpoch: 347  | Validation balanced accuracy : 0.50000 \nEpoch: 348  | Training Loss: 0.69423 \nEpoch: 348  | Training Loss: 0.70111 \nEpoch: 348  | Training Loss: 0.58982 \nEpoch: 348  | Training Loss: 0.52704 \nEpoch: 348  | Training Loss: 0.28155 \nEpoch: 348  | Validation balanced accuracy : 0.50000 \nEpoch: 349  | Training Loss: 0.69416 \nEpoch: 349  | Training Loss: 0.70108 \nEpoch: 349  | Training Loss: 0.58977 \nEpoch: 349  | Training Loss: 0.52701 \nEpoch: 349  | Training Loss: 0.28145 \nEpoch: 349  | Validation balanced accuracy : 0.50000 \nEpoch: 350  | Training Loss: 0.69408 \nEpoch: 350  | Training Loss: 0.70104 \nEpoch: 350  | Training Loss: 0.58971 \nEpoch: 350  | Training Loss: 0.52698 \nEpoch: 350  | Training Loss: 0.28135 \nEpoch: 350  | Validation balanced accuracy : 0.50000 \nEpoch: 351  | Training Loss: 0.69401 \nEpoch: 351  | Training Loss: 0.70101 \nEpoch: 351  | Training Loss: 0.58965 \nEpoch: 351  | Training Loss: 0.52695 \nEpoch: 351  | Training Loss: 0.28125 \nEpoch: 351  | Validation balanced accuracy : 0.50000 \nEpoch: 352  | Training Loss: 0.69394 \nEpoch: 352  | Training Loss: 0.70098 \nEpoch: 352  | Training Loss: 0.58960 \nEpoch: 352  | Training Loss: 0.52693 \nEpoch: 352  | Training Loss: 0.28115 \nEpoch: 352  | Validation balanced accuracy : 0.50000 \nEpoch: 353  | Training Loss: 0.69387 \nEpoch: 353  | Training Loss: 0.70094 \nEpoch: 353  | Training Loss: 0.58954 \nEpoch: 353  | Training Loss: 0.52690 \nEpoch: 353  | Training Loss: 0.28106 \nEpoch: 353  | Validation balanced accuracy : 0.50000 \nEpoch: 354  | Training Loss: 0.69379 \nEpoch: 354  | Training Loss: 0.70091 \nEpoch: 354  | Training Loss: 0.58948 \nEpoch: 354  | Training Loss: 0.52687 \nEpoch: 354  | Training Loss: 0.28096 \nEpoch: 354  | Validation balanced accuracy : 0.50000 \nEpoch: 355  | Training Loss: 0.69372 \nEpoch: 355  | Training Loss: 0.70088 \nEpoch: 355  | Training Loss: 0.58942 \nEpoch: 355  | Training Loss: 0.52684 \nEpoch: 355  | Training Loss: 0.28086 \nEpoch: 355  | Validation balanced accuracy : 0.50000 \nEpoch: 356  | Training Loss: 0.69365 \nEpoch: 356  | Training Loss: 0.70084 \nEpoch: 356  | Training Loss: 0.58937 \nEpoch: 356  | Training Loss: 0.52681 \nEpoch: 356  | Training Loss: 0.28076 \nEpoch: 356  | Validation balanced accuracy : 0.50000 \nEpoch: 357  | Training Loss: 0.69358 \nEpoch: 357  | Training Loss: 0.70081 \nEpoch: 357  | Training Loss: 0.58931 \nEpoch: 357  | Training Loss: 0.52679 \nEpoch: 357  | Training Loss: 0.28066 \nEpoch: 357  | Validation balanced accuracy : 0.50000 \nEpoch: 358  | Training Loss: 0.69350 \nEpoch: 358  | Training Loss: 0.70078 \nEpoch: 358  | Training Loss: 0.58925 \nEpoch: 358  | Training Loss: 0.52676 \nEpoch: 358  | Training Loss: 0.28056 \nEpoch: 358  | Validation balanced accuracy : 0.50000 \nEpoch: 359  | Training Loss: 0.69343 \nEpoch: 359  | Training Loss: 0.70074 \nEpoch: 359  | Training Loss: 0.58919 \nEpoch: 359  | Training Loss: 0.52673 \nEpoch: 359  | Training Loss: 0.28046 \nEpoch: 359  | Validation balanced accuracy : 0.50000 \nEpoch: 360  | Training Loss: 0.69336 \nEpoch: 360  | Training Loss: 0.70071 \nEpoch: 360  | Training Loss: 0.58914 \nEpoch: 360  | Training Loss: 0.52670 \nEpoch: 360  | Training Loss: 0.28036 \nEpoch: 360  | Validation balanced accuracy : 0.50000 \nEpoch: 361  | Training Loss: 0.69329 \nEpoch: 361  | Training Loss: 0.70067 \nEpoch: 361  | Training Loss: 0.58908 \nEpoch: 361  | Training Loss: 0.52667 \nEpoch: 361  | Training Loss: 0.28026 \nEpoch: 361  | Validation balanced accuracy : 0.50000 \nEpoch: 362  | Training Loss: 0.69321 \nEpoch: 362  | Training Loss: 0.70064 \nEpoch: 362  | Training Loss: 0.58902 \nEpoch: 362  | Training Loss: 0.52664 \nEpoch: 362  | Training Loss: 0.28016 \nEpoch: 362  | Validation balanced accuracy : 0.50000 \nEpoch: 363  | Training Loss: 0.69314 \nEpoch: 363  | Training Loss: 0.70061 \nEpoch: 363  | Training Loss: 0.58896 \nEpoch: 363  | Training Loss: 0.52662 \nEpoch: 363  | Training Loss: 0.28006 \nEpoch: 363  | Validation balanced accuracy : 0.50000 \nEpoch: 364  | Training Loss: 0.69307 \nEpoch: 364  | Training Loss: 0.70057 \nEpoch: 364  | Training Loss: 0.58890 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 364  | Training Loss: 0.52659 \nEpoch: 364  | Training Loss: 0.27997 \nEpoch: 364  | Validation balanced accuracy : 0.50000 \nEpoch: 365  | Training Loss: 0.69299 \nEpoch: 365  | Training Loss: 0.70054 \nEpoch: 365  | Training Loss: 0.58885 \nEpoch: 365  | Training Loss: 0.52656 \nEpoch: 365  | Training Loss: 0.27986 \nEpoch: 365  | Validation balanced accuracy : 0.50000 \nEpoch: 366  | Training Loss: 0.69292 \nEpoch: 366  | Training Loss: 0.70050 \nEpoch: 366  | Training Loss: 0.58879 \nEpoch: 366  | Training Loss: 0.52653 \nEpoch: 366  | Training Loss: 0.27976 \nEpoch: 366  | Validation balanced accuracy : 0.50000 \nEpoch: 367  | Training Loss: 0.69285 \nEpoch: 367  | Training Loss: 0.70047 \nEpoch: 367  | Training Loss: 0.58873 \nEpoch: 367  | Training Loss: 0.52650 \nEpoch: 367  | Training Loss: 0.27966 \nEpoch: 367  | Validation balanced accuracy : 0.50000 \nEpoch: 368  | Training Loss: 0.69278 \nEpoch: 368  | Training Loss: 0.70044 \nEpoch: 368  | Training Loss: 0.58867 \nEpoch: 368  | Training Loss: 0.52647 \nEpoch: 368  | Training Loss: 0.27957 \nEpoch: 368  | Validation balanced accuracy : 0.50000 \nEpoch: 369  | Training Loss: 0.69270 \nEpoch: 369  | Training Loss: 0.70040 \nEpoch: 369  | Training Loss: 0.58861 \nEpoch: 369  | Training Loss: 0.52645 \nEpoch: 369  | Training Loss: 0.27947 \nEpoch: 369  | Validation balanced accuracy : 0.50000 \nEpoch: 370  | Training Loss: 0.69263 \nEpoch: 370  | Training Loss: 0.70037 \nEpoch: 370  | Training Loss: 0.58856 \nEpoch: 370  | Training Loss: 0.52642 \nEpoch: 370  | Training Loss: 0.27937 \nEpoch: 370  | Validation balanced accuracy : 0.50000 \nEpoch: 371  | Training Loss: 0.69255 \nEpoch: 371  | Training Loss: 0.70033 \nEpoch: 371  | Training Loss: 0.58850 \nEpoch: 371  | Training Loss: 0.52639 \nEpoch: 371  | Training Loss: 0.27927 \nEpoch: 371  | Validation balanced accuracy : 0.50000 \nEpoch: 372  | Training Loss: 0.69248 \nEpoch: 372  | Training Loss: 0.70030 \nEpoch: 372  | Training Loss: 0.58844 \nEpoch: 372  | Training Loss: 0.52636 \nEpoch: 372  | Training Loss: 0.27917 \nEpoch: 372  | Validation balanced accuracy : 0.50000 \nEpoch: 373  | Training Loss: 0.69241 \nEpoch: 373  | Training Loss: 0.70026 \nEpoch: 373  | Training Loss: 0.58838 \nEpoch: 373  | Training Loss: 0.52633 \nEpoch: 373  | Training Loss: 0.27907 \nEpoch: 373  | Validation balanced accuracy : 0.50000 \nEpoch: 374  | Training Loss: 0.69233 \nEpoch: 374  | Training Loss: 0.70023 \nEpoch: 374  | Training Loss: 0.58832 \nEpoch: 374  | Training Loss: 0.52630 \nEpoch: 374  | Training Loss: 0.27897 \nEpoch: 374  | Validation balanced accuracy : 0.50000 \nEpoch: 375  | Training Loss: 0.69226 \nEpoch: 375  | Training Loss: 0.70019 \nEpoch: 375  | Training Loss: 0.58826 \nEpoch: 375  | Training Loss: 0.52627 \nEpoch: 375  | Training Loss: 0.27887 \nEpoch: 375  | Validation balanced accuracy : 0.50000 \nEpoch: 376  | Training Loss: 0.69218 \nEpoch: 376  | Training Loss: 0.70016 \nEpoch: 376  | Training Loss: 0.58820 \nEpoch: 376  | Training Loss: 0.52625 \nEpoch: 376  | Training Loss: 0.27877 \nEpoch: 376  | Validation balanced accuracy : 0.50000 \nEpoch: 377  | Training Loss: 0.69211 \nEpoch: 377  | Training Loss: 0.70012 \nEpoch: 377  | Training Loss: 0.58815 \nEpoch: 377  | Training Loss: 0.52622 \nEpoch: 377  | Training Loss: 0.27867 \nEpoch: 377  | Validation balanced accuracy : 0.50000 \nEpoch: 378  | Training Loss: 0.69204 \nEpoch: 378  | Training Loss: 0.70009 \nEpoch: 378  | Training Loss: 0.58809 \nEpoch: 378  | Training Loss: 0.52619 \nEpoch: 378  | Training Loss: 0.27856 \nEpoch: 378  | Validation balanced accuracy : 0.50000 \nEpoch: 379  | Training Loss: 0.69196 \nEpoch: 379  | Training Loss: 0.70005 \nEpoch: 379  | Training Loss: 0.58803 \nEpoch: 379  | Training Loss: 0.52616 \nEpoch: 379  | Training Loss: 0.27846 \nEpoch: 379  | Validation balanced accuracy : 0.50000 \nEpoch: 380  | Training Loss: 0.69189 \nEpoch: 380  | Training Loss: 0.70002 \nEpoch: 380  | Training Loss: 0.58797 \nEpoch: 380  | Training Loss: 0.52613 \nEpoch: 380  | Training Loss: 0.27836 \nEpoch: 380  | Validation balanced accuracy : 0.50000 \nEpoch: 381  | Training Loss: 0.69181 \nEpoch: 381  | Training Loss: 0.69998 \nEpoch: 381  | Training Loss: 0.58791 \nEpoch: 381  | Training Loss: 0.52610 \nEpoch: 381  | Training Loss: 0.27826 \nEpoch: 381  | Validation balanced accuracy : 0.50000 \nEpoch: 382  | Training Loss: 0.69174 \nEpoch: 382  | Training Loss: 0.69994 \nEpoch: 382  | Training Loss: 0.58785 \nEpoch: 382  | Training Loss: 0.52607 \nEpoch: 382  | Training Loss: 0.27816 \nEpoch: 382  | Validation balanced accuracy : 0.50000 \nEpoch: 383  | Training Loss: 0.69166 \nEpoch: 383  | Training Loss: 0.69991 \nEpoch: 383  | Training Loss: 0.58779 \nEpoch: 383  | Training Loss: 0.52604 \nEpoch: 383  | Training Loss: 0.27806 \nEpoch: 383  | Validation balanced accuracy : 0.50000 \nEpoch: 384  | Training Loss: 0.69159 \nEpoch: 384  | Training Loss: 0.69987 \nEpoch: 384  | Training Loss: 0.58773 \nEpoch: 384  | Training Loss: 0.52601 \nEpoch: 384  | Training Loss: 0.27796 \nEpoch: 384  | Validation balanced accuracy : 0.50000 \nEpoch: 385  | Training Loss: 0.69151 \nEpoch: 385  | Training Loss: 0.69984 \nEpoch: 385  | Training Loss: 0.58767 \nEpoch: 385  | Training Loss: 0.52599 \nEpoch: 385  | Training Loss: 0.27786 \nEpoch: 385  | Validation balanced accuracy : 0.50000 \nEpoch: 386  | Training Loss: 0.69144 \nEpoch: 386  | Training Loss: 0.69980 \nEpoch: 386  | Training Loss: 0.58762 \nEpoch: 386  | Training Loss: 0.52596 \nEpoch: 386  | Training Loss: 0.27776 \nEpoch: 386  | Validation balanced accuracy : 0.50000 \nEpoch: 387  | Training Loss: 0.69136 \nEpoch: 387  | Training Loss: 0.69977 \nEpoch: 387  | Training Loss: 0.58756 \nEpoch: 387  | Training Loss: 0.52593 \nEpoch: 387  | Training Loss: 0.27766 \nEpoch: 387  | Validation balanced accuracy : 0.50000 \nEpoch: 388  | Training Loss: 0.69129 \nEpoch: 388  | Training Loss: 0.69973 \nEpoch: 388  | Training Loss: 0.58750 \nEpoch: 388  | Training Loss: 0.52590 \nEpoch: 388  | Training Loss: 0.27756 \nEpoch: 388  | Validation balanced accuracy : 0.50000 \nEpoch: 389  | Training Loss: 0.69121 \nEpoch: 389  | Training Loss: 0.69969 \nEpoch: 389  | Training Loss: 0.58744 \nEpoch: 389  | Training Loss: 0.52587 \nEpoch: 389  | Training Loss: 0.27746 \nEpoch: 389  | Validation balanced accuracy : 0.50000 \nEpoch: 390  | Training Loss: 0.69114 \nEpoch: 390  | Training Loss: 0.69966 \nEpoch: 390  | Training Loss: 0.58738 \nEpoch: 390  | Training Loss: 0.52584 \nEpoch: 390  | Training Loss: 0.27735 \nEpoch: 390  | Validation balanced accuracy : 0.50000 \nEpoch: 391  | Training Loss: 0.69106 \nEpoch: 391  | Training Loss: 0.69962 \nEpoch: 391  | Training Loss: 0.58732 \nEpoch: 391  | Training Loss: 0.52581 \nEpoch: 391  | Training Loss: 0.27725 \nEpoch: 391  | Validation balanced accuracy : 0.50000 \nEpoch: 392  | Training Loss: 0.69099 \nEpoch: 392  | Training Loss: 0.69959 \nEpoch: 392  | Training Loss: 0.58726 \nEpoch: 392  | Training Loss: 0.52578 \nEpoch: 392  | Training Loss: 0.27715 \nEpoch: 392  | Validation balanced accuracy : 0.50000 \nEpoch: 393  | Training Loss: 0.69091 \nEpoch: 393  | Training Loss: 0.69955 \nEpoch: 393  | Training Loss: 0.58720 \nEpoch: 393  | Training Loss: 0.52575 \nEpoch: 393  | Training Loss: 0.27705 \nEpoch: 393  | Validation balanced accuracy : 0.50000 \nEpoch: 394  | Training Loss: 0.69083 \nEpoch: 394  | Training Loss: 0.69951 \nEpoch: 394  | Training Loss: 0.58714 \nEpoch: 394  | Training Loss: 0.52572 \nEpoch: 394  | Training Loss: 0.27695 \nEpoch: 394  | Validation balanced accuracy : 0.50000 \nEpoch: 395  | Training Loss: 0.69076 \nEpoch: 395  | Training Loss: 0.69948 \nEpoch: 395  | Training Loss: 0.58708 \nEpoch: 395  | Training Loss: 0.52569 \nEpoch: 395  | Training Loss: 0.27685 \nEpoch: 395  | Validation balanced accuracy : 0.50000 \nEpoch: 396  | Training Loss: 0.69068 \nEpoch: 396  | Training Loss: 0.69944 \nEpoch: 396  | Training Loss: 0.58702 \nEpoch: 396  | Training Loss: 0.52566 \nEpoch: 396  | Training Loss: 0.27674 \nEpoch: 396  | Validation balanced accuracy : 0.50000 \nEpoch: 397  | Training Loss: 0.69061 \nEpoch: 397  | Training Loss: 0.69940 \nEpoch: 397  | Training Loss: 0.58696 \nEpoch: 397  | Training Loss: 0.52563 \nEpoch: 397  | Training Loss: 0.27664 \nEpoch: 397  | Validation balanced accuracy : 0.50000 \nEpoch: 398  | Training Loss: 0.69053 \nEpoch: 398  | Training Loss: 0.69937 \nEpoch: 398  | Training Loss: 0.58690 \nEpoch: 398  | Training Loss: 0.52561 \nEpoch: 398  | Training Loss: 0.27654 \nEpoch: 398  | Validation balanced accuracy : 0.50000 \nEpoch: 399  | Training Loss: 0.69045 \nEpoch: 399  | Training Loss: 0.69933 \nEpoch: 399  | Training Loss: 0.58684 \nEpoch: 399  | Training Loss: 0.52558 \nEpoch: 399  | Training Loss: 0.27644 \nEpoch: 399  | Validation balanced accuracy : 0.50000 \nEpoch: 400  | Training Loss: 0.69038 \nEpoch: 400  | Training Loss: 0.69929 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 400  | Training Loss: 0.58678 \nEpoch: 400  | Training Loss: 0.52555 \nEpoch: 400  | Training Loss: 0.27634 \nEpoch: 400  | Validation balanced accuracy : 0.50000 \nEpoch: 401  | Training Loss: 0.69030 \nEpoch: 401  | Training Loss: 0.69925 \nEpoch: 401  | Training Loss: 0.58671 \nEpoch: 401  | Training Loss: 0.52552 \nEpoch: 401  | Training Loss: 0.27623 \nEpoch: 401  | Validation balanced accuracy : 0.50000 \nEpoch: 402  | Training Loss: 0.69022 \nEpoch: 402  | Training Loss: 0.69922 \nEpoch: 402  | Training Loss: 0.58665 \nEpoch: 402  | Training Loss: 0.52549 \nEpoch: 402  | Training Loss: 0.27613 \nEpoch: 402  | Validation balanced accuracy : 0.50000 \nEpoch: 403  | Training Loss: 0.69015 \nEpoch: 403  | Training Loss: 0.69918 \nEpoch: 403  | Training Loss: 0.58659 \nEpoch: 403  | Training Loss: 0.52546 \nEpoch: 403  | Training Loss: 0.27603 \nEpoch: 403  | Validation balanced accuracy : 0.50000 \nEpoch: 404  | Training Loss: 0.69007 \nEpoch: 404  | Training Loss: 0.69914 \nEpoch: 404  | Training Loss: 0.58653 \nEpoch: 404  | Training Loss: 0.52543 \nEpoch: 404  | Training Loss: 0.27593 \nEpoch: 404  | Validation balanced accuracy : 0.50000 \nEpoch: 405  | Training Loss: 0.68999 \nEpoch: 405  | Training Loss: 0.69911 \nEpoch: 405  | Training Loss: 0.58647 \nEpoch: 405  | Training Loss: 0.52540 \nEpoch: 405  | Training Loss: 0.27582 \nEpoch: 405  | Validation balanced accuracy : 0.50000 \nEpoch: 406  | Training Loss: 0.68992 \nEpoch: 406  | Training Loss: 0.69907 \nEpoch: 406  | Training Loss: 0.58641 \nEpoch: 406  | Training Loss: 0.52537 \nEpoch: 406  | Training Loss: 0.27572 \nEpoch: 406  | Validation balanced accuracy : 0.50000 \nEpoch: 407  | Training Loss: 0.68984 \nEpoch: 407  | Training Loss: 0.69903 \nEpoch: 407  | Training Loss: 0.58635 \nEpoch: 407  | Training Loss: 0.52534 \nEpoch: 407  | Training Loss: 0.27562 \nEpoch: 407  | Validation balanced accuracy : 0.50000 \nEpoch: 408  | Training Loss: 0.68976 \nEpoch: 408  | Training Loss: 0.69899 \nEpoch: 408  | Training Loss: 0.58629 \nEpoch: 408  | Training Loss: 0.52531 \nEpoch: 408  | Training Loss: 0.27552 \nEpoch: 408  | Validation balanced accuracy : 0.50000 \nEpoch: 409  | Training Loss: 0.68968 \nEpoch: 409  | Training Loss: 0.69896 \nEpoch: 409  | Training Loss: 0.58623 \nEpoch: 409  | Training Loss: 0.52528 \nEpoch: 409  | Training Loss: 0.27541 \nEpoch: 409  | Validation balanced accuracy : 0.50000 \nEpoch: 410  | Training Loss: 0.68961 \nEpoch: 410  | Training Loss: 0.69892 \nEpoch: 410  | Training Loss: 0.58617 \nEpoch: 410  | Training Loss: 0.52525 \nEpoch: 410  | Training Loss: 0.27531 \nEpoch: 410  | Validation balanced accuracy : 0.50000 \nEpoch: 411  | Training Loss: 0.68953 \nEpoch: 411  | Training Loss: 0.69888 \nEpoch: 411  | Training Loss: 0.58610 \nEpoch: 411  | Training Loss: 0.52522 \nEpoch: 411  | Training Loss: 0.27521 \nEpoch: 411  | Validation balanced accuracy : 0.50000 \nEpoch: 412  | Training Loss: 0.68945 \nEpoch: 412  | Training Loss: 0.69884 \nEpoch: 412  | Training Loss: 0.58604 \nEpoch: 412  | Training Loss: 0.52519 \nEpoch: 412  | Training Loss: 0.27510 \nEpoch: 412  | Validation balanced accuracy : 0.50000 \nEpoch: 413  | Training Loss: 0.68937 \nEpoch: 413  | Training Loss: 0.69880 \nEpoch: 413  | Training Loss: 0.58598 \nEpoch: 413  | Training Loss: 0.52516 \nEpoch: 413  | Training Loss: 0.27500 \nEpoch: 413  | Validation balanced accuracy : 0.50000 \nEpoch: 414  | Training Loss: 0.68929 \nEpoch: 414  | Training Loss: 0.69876 \nEpoch: 414  | Training Loss: 0.58592 \nEpoch: 414  | Training Loss: 0.52513 \nEpoch: 414  | Training Loss: 0.27490 \nEpoch: 414  | Validation balanced accuracy : 0.50000 \nEpoch: 415  | Training Loss: 0.68922 \nEpoch: 415  | Training Loss: 0.69873 \nEpoch: 415  | Training Loss: 0.58586 \nEpoch: 415  | Training Loss: 0.52510 \nEpoch: 415  | Training Loss: 0.27479 \nEpoch: 415  | Validation balanced accuracy : 0.50000 \nEpoch: 416  | Training Loss: 0.68914 \nEpoch: 416  | Training Loss: 0.69869 \nEpoch: 416  | Training Loss: 0.58580 \nEpoch: 416  | Training Loss: 0.52507 \nEpoch: 416  | Training Loss: 0.27469 \nEpoch: 416  | Validation balanced accuracy : 0.50000 \nEpoch: 417  | Training Loss: 0.68906 \nEpoch: 417  | Training Loss: 0.69865 \nEpoch: 417  | Training Loss: 0.58573 \nEpoch: 417  | Training Loss: 0.52504 \nEpoch: 417  | Training Loss: 0.27459 \nEpoch: 417  | Validation balanced accuracy : 0.50000 \nEpoch: 418  | Training Loss: 0.68898 \nEpoch: 418  | Training Loss: 0.69861 \nEpoch: 418  | Training Loss: 0.58567 \nEpoch: 418  | Training Loss: 0.52501 \nEpoch: 418  | Training Loss: 0.27448 \nEpoch: 418  | Validation balanced accuracy : 0.50000 \nEpoch: 419  | Training Loss: 0.68890 \nEpoch: 419  | Training Loss: 0.69857 \nEpoch: 419  | Training Loss: 0.58561 \nEpoch: 419  | Training Loss: 0.52497 \nEpoch: 419  | Training Loss: 0.27438 \nEpoch: 419  | Validation balanced accuracy : 0.50000 \nEpoch: 420  | Training Loss: 0.68882 \nEpoch: 420  | Training Loss: 0.69853 \nEpoch: 420  | Training Loss: 0.58555 \nEpoch: 420  | Training Loss: 0.52494 \nEpoch: 420  | Training Loss: 0.27427 \nEpoch: 420  | Validation balanced accuracy : 0.50000 \nEpoch: 421  | Training Loss: 0.68874 \nEpoch: 421  | Training Loss: 0.69849 \nEpoch: 421  | Training Loss: 0.58548 \nEpoch: 421  | Training Loss: 0.52491 \nEpoch: 421  | Training Loss: 0.27417 \nEpoch: 421  | Validation balanced accuracy : 0.50000 \nEpoch: 422  | Training Loss: 0.68867 \nEpoch: 422  | Training Loss: 0.69846 \nEpoch: 422  | Training Loss: 0.58542 \nEpoch: 422  | Training Loss: 0.52488 \nEpoch: 422  | Training Loss: 0.27406 \nEpoch: 422  | Validation balanced accuracy : 0.50000 \nEpoch: 423  | Training Loss: 0.68859 \nEpoch: 423  | Training Loss: 0.69842 \nEpoch: 423  | Training Loss: 0.58536 \nEpoch: 423  | Training Loss: 0.52485 \nEpoch: 423  | Training Loss: 0.27396 \nEpoch: 423  | Validation balanced accuracy : 0.50000 \nEpoch: 424  | Training Loss: 0.68851 \nEpoch: 424  | Training Loss: 0.69838 \nEpoch: 424  | Training Loss: 0.58530 \nEpoch: 424  | Training Loss: 0.52482 \nEpoch: 424  | Training Loss: 0.27386 \nEpoch: 424  | Validation balanced accuracy : 0.50000 \nEpoch: 425  | Training Loss: 0.68843 \nEpoch: 425  | Training Loss: 0.69834 \nEpoch: 425  | Training Loss: 0.58523 \nEpoch: 425  | Training Loss: 0.52479 \nEpoch: 425  | Training Loss: 0.27375 \nEpoch: 425  | Validation balanced accuracy : 0.50000 \nEpoch: 426  | Training Loss: 0.68835 \nEpoch: 426  | Training Loss: 0.69830 \nEpoch: 426  | Training Loss: 0.58517 \nEpoch: 426  | Training Loss: 0.52476 \nEpoch: 426  | Training Loss: 0.27365 \nEpoch: 426  | Validation balanced accuracy : 0.50000 \nEpoch: 427  | Training Loss: 0.68827 \nEpoch: 427  | Training Loss: 0.69826 \nEpoch: 427  | Training Loss: 0.58511 \nEpoch: 427  | Training Loss: 0.52473 \nEpoch: 427  | Training Loss: 0.27354 \nEpoch: 427  | Validation balanced accuracy : 0.50000 \nEpoch: 428  | Training Loss: 0.68819 \nEpoch: 428  | Training Loss: 0.69822 \nEpoch: 428  | Training Loss: 0.58505 \nEpoch: 428  | Training Loss: 0.52470 \nEpoch: 428  | Training Loss: 0.27344 \nEpoch: 428  | Validation balanced accuracy : 0.50000 \nEpoch: 429  | Training Loss: 0.68811 \nEpoch: 429  | Training Loss: 0.69818 \nEpoch: 429  | Training Loss: 0.58498 \nEpoch: 429  | Training Loss: 0.52467 \nEpoch: 429  | Training Loss: 0.27333 \nEpoch: 429  | Validation balanced accuracy : 0.50000 \nEpoch: 430  | Training Loss: 0.68803 \nEpoch: 430  | Training Loss: 0.69814 \nEpoch: 430  | Training Loss: 0.58492 \nEpoch: 430  | Training Loss: 0.52464 \nEpoch: 430  | Training Loss: 0.27323 \nEpoch: 430  | Validation balanced accuracy : 0.50000 \nEpoch: 431  | Training Loss: 0.68795 \nEpoch: 431  | Training Loss: 0.69810 \nEpoch: 431  | Training Loss: 0.58486 \nEpoch: 431  | Training Loss: 0.52461 \nEpoch: 431  | Training Loss: 0.27312 \nEpoch: 431  | Validation balanced accuracy : 0.50000 \nEpoch: 432  | Training Loss: 0.68787 \nEpoch: 432  | Training Loss: 0.69806 \nEpoch: 432  | Training Loss: 0.58479 \nEpoch: 432  | Training Loss: 0.52457 \nEpoch: 432  | Training Loss: 0.27301 \nEpoch: 432  | Validation balanced accuracy : 0.50000 \nEpoch: 433  | Training Loss: 0.68779 \nEpoch: 433  | Training Loss: 0.69802 \nEpoch: 433  | Training Loss: 0.58473 \nEpoch: 433  | Training Loss: 0.52454 \nEpoch: 433  | Training Loss: 0.27291 \nEpoch: 433  | Validation balanced accuracy : 0.50000 \nEpoch: 434  | Training Loss: 0.68771 \nEpoch: 434  | Training Loss: 0.69798 \nEpoch: 434  | Training Loss: 0.58466 \nEpoch: 434  | Training Loss: 0.52451 \nEpoch: 434  | Training Loss: 0.27281 \nEpoch: 434  | Validation balanced accuracy : 0.50000 \nEpoch: 435  | Training Loss: 0.68763 \nEpoch: 435  | Training Loss: 0.69794 \nEpoch: 435  | Training Loss: 0.58460 \nEpoch: 435  | Training Loss: 0.52448 \nEpoch: 435  | Training Loss: 0.27270 \nEpoch: 435  | Validation balanced accuracy : 0.50000 \nEpoch: 436  | Training Loss: 0.68754 \nEpoch: 436  | Training Loss: 0.69790 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 436  | Training Loss: 0.58454 \nEpoch: 436  | Training Loss: 0.52445 \nEpoch: 436  | Training Loss: 0.27259 \nEpoch: 436  | Validation balanced accuracy : 0.50000 \nEpoch: 437  | Training Loss: 0.68746 \nEpoch: 437  | Training Loss: 0.69786 \nEpoch: 437  | Training Loss: 0.58447 \nEpoch: 437  | Training Loss: 0.52442 \nEpoch: 437  | Training Loss: 0.27249 \nEpoch: 437  | Validation balanced accuracy : 0.50000 \nEpoch: 438  | Training Loss: 0.68738 \nEpoch: 438  | Training Loss: 0.69782 \nEpoch: 438  | Training Loss: 0.58441 \nEpoch: 438  | Training Loss: 0.52439 \nEpoch: 438  | Training Loss: 0.27238 \nEpoch: 438  | Validation balanced accuracy : 0.50000 \nEpoch: 439  | Training Loss: 0.68730 \nEpoch: 439  | Training Loss: 0.69778 \nEpoch: 439  | Training Loss: 0.58434 \nEpoch: 439  | Training Loss: 0.52436 \nEpoch: 439  | Training Loss: 0.27227 \nEpoch: 439  | Validation balanced accuracy : 0.50000 \nEpoch: 440  | Training Loss: 0.68722 \nEpoch: 440  | Training Loss: 0.69773 \nEpoch: 440  | Training Loss: 0.58428 \nEpoch: 440  | Training Loss: 0.52432 \nEpoch: 440  | Training Loss: 0.27217 \nEpoch: 440  | Validation balanced accuracy : 0.50000 \nEpoch: 441  | Training Loss: 0.68714 \nEpoch: 441  | Training Loss: 0.69769 \nEpoch: 441  | Training Loss: 0.58422 \nEpoch: 441  | Training Loss: 0.52429 \nEpoch: 441  | Training Loss: 0.27206 \nEpoch: 441  | Validation balanced accuracy : 0.50000 \nEpoch: 442  | Training Loss: 0.68706 \nEpoch: 442  | Training Loss: 0.69765 \nEpoch: 442  | Training Loss: 0.58415 \nEpoch: 442  | Training Loss: 0.52426 \nEpoch: 442  | Training Loss: 0.27195 \nEpoch: 442  | Validation balanced accuracy : 0.50000 \nEpoch: 443  | Training Loss: 0.68697 \nEpoch: 443  | Training Loss: 0.69761 \nEpoch: 443  | Training Loss: 0.58409 \nEpoch: 443  | Training Loss: 0.52423 \nEpoch: 443  | Training Loss: 0.27185 \nEpoch: 443  | Validation balanced accuracy : 0.50000 \nEpoch: 444  | Training Loss: 0.68689 \nEpoch: 444  | Training Loss: 0.69757 \nEpoch: 444  | Training Loss: 0.58402 \nEpoch: 444  | Training Loss: 0.52420 \nEpoch: 444  | Training Loss: 0.27174 \nEpoch: 444  | Validation balanced accuracy : 0.50000 \nEpoch: 445  | Training Loss: 0.68681 \nEpoch: 445  | Training Loss: 0.69753 \nEpoch: 445  | Training Loss: 0.58396 \nEpoch: 445  | Training Loss: 0.52417 \nEpoch: 445  | Training Loss: 0.27164 \nEpoch: 445  | Validation balanced accuracy : 0.50000 \nEpoch: 446  | Training Loss: 0.68673 \nEpoch: 446  | Training Loss: 0.69749 \nEpoch: 446  | Training Loss: 0.58389 \nEpoch: 446  | Training Loss: 0.52413 \nEpoch: 446  | Training Loss: 0.27153 \nEpoch: 446  | Validation balanced accuracy : 0.50000 \nEpoch: 447  | Training Loss: 0.68664 \nEpoch: 447  | Training Loss: 0.69745 \nEpoch: 447  | Training Loss: 0.58383 \nEpoch: 447  | Training Loss: 0.52410 \nEpoch: 447  | Training Loss: 0.27142 \nEpoch: 447  | Validation balanced accuracy : 0.50000 \nEpoch: 448  | Training Loss: 0.68656 \nEpoch: 448  | Training Loss: 0.69740 \nEpoch: 448  | Training Loss: 0.58376 \nEpoch: 448  | Training Loss: 0.52407 \nEpoch: 448  | Training Loss: 0.27131 \nEpoch: 448  | Validation balanced accuracy : 0.50000 \nEpoch: 449  | Training Loss: 0.68648 \nEpoch: 449  | Training Loss: 0.69736 \nEpoch: 449  | Training Loss: 0.58370 \nEpoch: 449  | Training Loss: 0.52404 \nEpoch: 449  | Training Loss: 0.27120 \nEpoch: 449  | Validation balanced accuracy : 0.50000 \nEpoch: 450  | Training Loss: 0.68640 \nEpoch: 450  | Training Loss: 0.69732 \nEpoch: 450  | Training Loss: 0.58363 \nEpoch: 450  | Training Loss: 0.52401 \nEpoch: 450  | Training Loss: 0.27110 \nEpoch: 450  | Validation balanced accuracy : 0.50000 \nEpoch: 451  | Training Loss: 0.68631 \nEpoch: 451  | Training Loss: 0.69728 \nEpoch: 451  | Training Loss: 0.58356 \nEpoch: 451  | Training Loss: 0.52397 \nEpoch: 451  | Training Loss: 0.27099 \nEpoch: 451  | Validation balanced accuracy : 0.50000 \nEpoch: 452  | Training Loss: 0.68623 \nEpoch: 452  | Training Loss: 0.69723 \nEpoch: 452  | Training Loss: 0.58350 \nEpoch: 452  | Training Loss: 0.52394 \nEpoch: 452  | Training Loss: 0.27088 \nEpoch: 452  | Validation balanced accuracy : 0.50000 \nEpoch: 453  | Training Loss: 0.68615 \nEpoch: 453  | Training Loss: 0.69719 \nEpoch: 453  | Training Loss: 0.58343 \nEpoch: 453  | Training Loss: 0.52391 \nEpoch: 453  | Training Loss: 0.27077 \nEpoch: 453  | Validation balanced accuracy : 0.50000 \nEpoch: 454  | Training Loss: 0.68606 \nEpoch: 454  | Training Loss: 0.69715 \nEpoch: 454  | Training Loss: 0.58337 \nEpoch: 454  | Training Loss: 0.52388 \nEpoch: 454  | Training Loss: 0.27067 \nEpoch: 454  | Validation balanced accuracy : 0.50000 \nEpoch: 455  | Training Loss: 0.68598 \nEpoch: 455  | Training Loss: 0.69711 \nEpoch: 455  | Training Loss: 0.58330 \nEpoch: 455  | Training Loss: 0.52384 \nEpoch: 455  | Training Loss: 0.27056 \nEpoch: 455  | Validation balanced accuracy : 0.50000 \nEpoch: 456  | Training Loss: 0.68589 \nEpoch: 456  | Training Loss: 0.69707 \nEpoch: 456  | Training Loss: 0.58323 \nEpoch: 456  | Training Loss: 0.52381 \nEpoch: 456  | Training Loss: 0.27045 \nEpoch: 456  | Validation balanced accuracy : 0.50000 \nEpoch: 457  | Training Loss: 0.68581 \nEpoch: 457  | Training Loss: 0.69702 \nEpoch: 457  | Training Loss: 0.58317 \nEpoch: 457  | Training Loss: 0.52378 \nEpoch: 457  | Training Loss: 0.27034 \nEpoch: 457  | Validation balanced accuracy : 0.50000 \nEpoch: 458  | Training Loss: 0.68573 \nEpoch: 458  | Training Loss: 0.69698 \nEpoch: 458  | Training Loss: 0.58310 \nEpoch: 458  | Training Loss: 0.52375 \nEpoch: 458  | Training Loss: 0.27023 \nEpoch: 458  | Validation balanced accuracy : 0.50000 \nEpoch: 459  | Training Loss: 0.68564 \nEpoch: 459  | Training Loss: 0.69694 \nEpoch: 459  | Training Loss: 0.58303 \nEpoch: 459  | Training Loss: 0.52371 \nEpoch: 459  | Training Loss: 0.27012 \nEpoch: 459  | Validation balanced accuracy : 0.50000 \nEpoch: 460  | Training Loss: 0.68556 \nEpoch: 460  | Training Loss: 0.69689 \nEpoch: 460  | Training Loss: 0.58297 \nEpoch: 460  | Training Loss: 0.52368 \nEpoch: 460  | Training Loss: 0.27002 \nEpoch: 460  | Validation balanced accuracy : 0.50000 \nEpoch: 461  | Training Loss: 0.68547 \nEpoch: 461  | Training Loss: 0.69685 \nEpoch: 461  | Training Loss: 0.58290 \nEpoch: 461  | Training Loss: 0.52365 \nEpoch: 461  | Training Loss: 0.26991 \nEpoch: 461  | Validation balanced accuracy : 0.50000 \nEpoch: 462  | Training Loss: 0.68539 \nEpoch: 462  | Training Loss: 0.69681 \nEpoch: 462  | Training Loss: 0.58283 \nEpoch: 462  | Training Loss: 0.52362 \nEpoch: 462  | Training Loss: 0.26980 \nEpoch: 462  | Validation balanced accuracy : 0.50000 \nEpoch: 463  | Training Loss: 0.68530 \nEpoch: 463  | Training Loss: 0.69676 \nEpoch: 463  | Training Loss: 0.58277 \nEpoch: 463  | Training Loss: 0.52358 \nEpoch: 463  | Training Loss: 0.26969 \nEpoch: 463  | Validation balanced accuracy : 0.50000 \nEpoch: 464  | Training Loss: 0.68522 \nEpoch: 464  | Training Loss: 0.69672 \nEpoch: 464  | Training Loss: 0.58270 \nEpoch: 464  | Training Loss: 0.52355 \nEpoch: 464  | Training Loss: 0.26958 \nEpoch: 464  | Validation balanced accuracy : 0.50000 \nEpoch: 465  | Training Loss: 0.68513 \nEpoch: 465  | Training Loss: 0.69667 \nEpoch: 465  | Training Loss: 0.58263 \nEpoch: 465  | Training Loss: 0.52352 \nEpoch: 465  | Training Loss: 0.26947 \nEpoch: 465  | Validation balanced accuracy : 0.50000 \nEpoch: 466  | Training Loss: 0.68505 \nEpoch: 466  | Training Loss: 0.69663 \nEpoch: 466  | Training Loss: 0.58256 \nEpoch: 466  | Training Loss: 0.52348 \nEpoch: 466  | Training Loss: 0.26936 \nEpoch: 466  | Validation balanced accuracy : 0.50000 \nEpoch: 467  | Training Loss: 0.68496 \nEpoch: 467  | Training Loss: 0.69659 \nEpoch: 467  | Training Loss: 0.58250 \nEpoch: 467  | Training Loss: 0.52345 \nEpoch: 467  | Training Loss: 0.26925 \nEpoch: 467  | Validation balanced accuracy : 0.50000 \nEpoch: 468  | Training Loss: 0.68487 \nEpoch: 468  | Training Loss: 0.69654 \nEpoch: 468  | Training Loss: 0.58243 \nEpoch: 468  | Training Loss: 0.52342 \nEpoch: 468  | Training Loss: 0.26914 \nEpoch: 468  | Validation balanced accuracy : 0.50000 \nEpoch: 469  | Training Loss: 0.68479 \nEpoch: 469  | Training Loss: 0.69650 \nEpoch: 469  | Training Loss: 0.58236 \nEpoch: 469  | Training Loss: 0.52338 \nEpoch: 469  | Training Loss: 0.26903 \nEpoch: 469  | Validation balanced accuracy : 0.50000 \nEpoch: 470  | Training Loss: 0.68470 \nEpoch: 470  | Training Loss: 0.69645 \nEpoch: 470  | Training Loss: 0.58229 \nEpoch: 470  | Training Loss: 0.52335 \nEpoch: 470  | Training Loss: 0.26892 \nEpoch: 470  | Validation balanced accuracy : 0.50000 \nEpoch: 471  | Training Loss: 0.68462 \nEpoch: 471  | Training Loss: 0.69641 \nEpoch: 471  | Training Loss: 0.58222 \nEpoch: 471  | Training Loss: 0.52332 \nEpoch: 471  | Training Loss: 0.26881 \nEpoch: 471  | Validation balanced accuracy : 0.50000 \nEpoch: 472  | Training Loss: 0.68453 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 472  | Training Loss: 0.69636 \nEpoch: 472  | Training Loss: 0.58216 \nEpoch: 472  | Training Loss: 0.52328 \nEpoch: 472  | Training Loss: 0.26870 \nEpoch: 472  | Validation balanced accuracy : 0.50000 \nEpoch: 473  | Training Loss: 0.68444 \nEpoch: 473  | Training Loss: 0.69632 \nEpoch: 473  | Training Loss: 0.58209 \nEpoch: 473  | Training Loss: 0.52325 \nEpoch: 473  | Training Loss: 0.26859 \nEpoch: 473  | Validation balanced accuracy : 0.50000 \nEpoch: 474  | Training Loss: 0.68435 \nEpoch: 474  | Training Loss: 0.69627 \nEpoch: 474  | Training Loss: 0.58202 \nEpoch: 474  | Training Loss: 0.52322 \nEpoch: 474  | Training Loss: 0.26848 \nEpoch: 474  | Validation balanced accuracy : 0.50000 \nEpoch: 475  | Training Loss: 0.68427 \nEpoch: 475  | Training Loss: 0.69623 \nEpoch: 475  | Training Loss: 0.58195 \nEpoch: 475  | Training Loss: 0.52318 \nEpoch: 475  | Training Loss: 0.26836 \nEpoch: 475  | Validation balanced accuracy : 0.50000 \nEpoch: 476  | Training Loss: 0.68418 \nEpoch: 476  | Training Loss: 0.69618 \nEpoch: 476  | Training Loss: 0.58188 \nEpoch: 476  | Training Loss: 0.52315 \nEpoch: 476  | Training Loss: 0.26825 \nEpoch: 476  | Validation balanced accuracy : 0.50000 \nEpoch: 477  | Training Loss: 0.68409 \nEpoch: 477  | Training Loss: 0.69614 \nEpoch: 477  | Training Loss: 0.58181 \nEpoch: 477  | Training Loss: 0.52312 \nEpoch: 477  | Training Loss: 0.26814 \nEpoch: 477  | Validation balanced accuracy : 0.50000 \nEpoch: 478  | Training Loss: 0.68401 \nEpoch: 478  | Training Loss: 0.69609 \nEpoch: 478  | Training Loss: 0.58174 \nEpoch: 478  | Training Loss: 0.52308 \nEpoch: 478  | Training Loss: 0.26803 \nEpoch: 478  | Validation balanced accuracy : 0.50000 \nEpoch: 479  | Training Loss: 0.68392 \nEpoch: 479  | Training Loss: 0.69605 \nEpoch: 479  | Training Loss: 0.58167 \nEpoch: 479  | Training Loss: 0.52305 \nEpoch: 479  | Training Loss: 0.26792 \nEpoch: 479  | Validation balanced accuracy : 0.50000 \nEpoch: 480  | Training Loss: 0.68383 \nEpoch: 480  | Training Loss: 0.69600 \nEpoch: 480  | Training Loss: 0.58160 \nEpoch: 480  | Training Loss: 0.52301 \nEpoch: 480  | Training Loss: 0.26781 \nEpoch: 480  | Validation balanced accuracy : 0.50000 \nEpoch: 481  | Training Loss: 0.68374 \nEpoch: 481  | Training Loss: 0.69595 \nEpoch: 481  | Training Loss: 0.58153 \nEpoch: 481  | Training Loss: 0.52298 \nEpoch: 481  | Training Loss: 0.26770 \nEpoch: 481  | Validation balanced accuracy : 0.50000 \nEpoch: 482  | Training Loss: 0.68365 \nEpoch: 482  | Training Loss: 0.69591 \nEpoch: 482  | Training Loss: 0.58146 \nEpoch: 482  | Training Loss: 0.52295 \nEpoch: 482  | Training Loss: 0.26758 \nEpoch: 482  | Validation balanced accuracy : 0.50000 \nEpoch: 483  | Training Loss: 0.68356 \nEpoch: 483  | Training Loss: 0.69586 \nEpoch: 483  | Training Loss: 0.58139 \nEpoch: 483  | Training Loss: 0.52291 \nEpoch: 483  | Training Loss: 0.26747 \nEpoch: 483  | Validation balanced accuracy : 0.50000 \nEpoch: 484  | Training Loss: 0.68347 \nEpoch: 484  | Training Loss: 0.69582 \nEpoch: 484  | Training Loss: 0.58132 \nEpoch: 484  | Training Loss: 0.52288 \nEpoch: 484  | Training Loss: 0.26736 \nEpoch: 484  | Validation balanced accuracy : 0.50000 \nEpoch: 485  | Training Loss: 0.68338 \nEpoch: 485  | Training Loss: 0.69577 \nEpoch: 485  | Training Loss: 0.58125 \nEpoch: 485  | Training Loss: 0.52284 \nEpoch: 485  | Training Loss: 0.26724 \nEpoch: 485  | Validation balanced accuracy : 0.50000 \nEpoch: 486  | Training Loss: 0.68330 \nEpoch: 486  | Training Loss: 0.69572 \nEpoch: 486  | Training Loss: 0.58118 \nEpoch: 486  | Training Loss: 0.52281 \nEpoch: 486  | Training Loss: 0.26713 \nEpoch: 486  | Validation balanced accuracy : 0.50000 \nEpoch: 487  | Training Loss: 0.68321 \nEpoch: 487  | Training Loss: 0.69568 \nEpoch: 487  | Training Loss: 0.58111 \nEpoch: 487  | Training Loss: 0.52277 \nEpoch: 487  | Training Loss: 0.26702 \nEpoch: 487  | Validation balanced accuracy : 0.50000 \nEpoch: 488  | Training Loss: 0.68312 \nEpoch: 488  | Training Loss: 0.69563 \nEpoch: 488  | Training Loss: 0.58104 \nEpoch: 488  | Training Loss: 0.52274 \nEpoch: 488  | Training Loss: 0.26691 \nEpoch: 488  | Validation balanced accuracy : 0.50000 \nEpoch: 489  | Training Loss: 0.68303 \nEpoch: 489  | Training Loss: 0.69558 \nEpoch: 489  | Training Loss: 0.58097 \nEpoch: 489  | Training Loss: 0.52270 \nEpoch: 489  | Training Loss: 0.26679 \nEpoch: 489  | Validation balanced accuracy : 0.50000 \nEpoch: 490  | Training Loss: 0.68294 \nEpoch: 490  | Training Loss: 0.69553 \nEpoch: 490  | Training Loss: 0.58090 \nEpoch: 490  | Training Loss: 0.52267 \nEpoch: 490  | Training Loss: 0.26668 \nEpoch: 490  | Validation balanced accuracy : 0.50000 \nEpoch: 491  | Training Loss: 0.68285 \nEpoch: 491  | Training Loss: 0.69549 \nEpoch: 491  | Training Loss: 0.58083 \nEpoch: 491  | Training Loss: 0.52263 \nEpoch: 491  | Training Loss: 0.26657 \nEpoch: 491  | Validation balanced accuracy : 0.50000 \nEpoch: 492  | Training Loss: 0.68276 \nEpoch: 492  | Training Loss: 0.69544 \nEpoch: 492  | Training Loss: 0.58076 \nEpoch: 492  | Training Loss: 0.52260 \nEpoch: 492  | Training Loss: 0.26645 \nEpoch: 492  | Validation balanced accuracy : 0.50000 \nEpoch: 493  | Training Loss: 0.68266 \nEpoch: 493  | Training Loss: 0.69539 \nEpoch: 493  | Training Loss: 0.58069 \nEpoch: 493  | Training Loss: 0.52256 \nEpoch: 493  | Training Loss: 0.26634 \nEpoch: 493  | Validation balanced accuracy : 0.50000 \nEpoch: 494  | Training Loss: 0.68257 \nEpoch: 494  | Training Loss: 0.69534 \nEpoch: 494  | Training Loss: 0.58061 \nEpoch: 494  | Training Loss: 0.52253 \nEpoch: 494  | Training Loss: 0.26623 \nEpoch: 494  | Validation balanced accuracy : 0.50000 \nEpoch: 495  | Training Loss: 0.68248 \nEpoch: 495  | Training Loss: 0.69530 \nEpoch: 495  | Training Loss: 0.58054 \nEpoch: 495  | Training Loss: 0.52249 \nEpoch: 495  | Training Loss: 0.26611 \nEpoch: 495  | Validation balanced accuracy : 0.50000 \nEpoch: 496  | Training Loss: 0.68239 \nEpoch: 496  | Training Loss: 0.69525 \nEpoch: 496  | Training Loss: 0.58047 \nEpoch: 496  | Training Loss: 0.52246 \nEpoch: 496  | Training Loss: 0.26600 \nEpoch: 496  | Validation balanced accuracy : 0.50000 \nEpoch: 497  | Training Loss: 0.68230 \nEpoch: 497  | Training Loss: 0.69520 \nEpoch: 497  | Training Loss: 0.58040 \nEpoch: 497  | Training Loss: 0.52242 \nEpoch: 497  | Training Loss: 0.26588 \nEpoch: 497  | Validation balanced accuracy : 0.50000 \nEpoch: 498  | Training Loss: 0.68221 \nEpoch: 498  | Training Loss: 0.69515 \nEpoch: 498  | Training Loss: 0.58033 \nEpoch: 498  | Training Loss: 0.52239 \nEpoch: 498  | Training Loss: 0.26577 \nEpoch: 498  | Validation balanced accuracy : 0.50000 \nEpoch: 499  | Training Loss: 0.68212 \nEpoch: 499  | Training Loss: 0.69510 \nEpoch: 499  | Training Loss: 0.58025 \nEpoch: 499  | Training Loss: 0.52235 \nEpoch: 499  | Training Loss: 0.26565 \nEpoch: 499  | Validation balanced accuracy : 0.50000 \nEpoch: 500  | Training Loss: 0.68202 \nEpoch: 500  | Training Loss: 0.69505 \nEpoch: 500  | Training Loss: 0.58018 \nEpoch: 500  | Training Loss: 0.52232 \nEpoch: 500  | Training Loss: 0.26554 \nEpoch: 500  | Validation balanced accuracy : 0.50000 \nEpoch: 501  | Training Loss: 0.68193 \nEpoch: 501  | Training Loss: 0.69500 \nEpoch: 501  | Training Loss: 0.58011 \nEpoch: 501  | Training Loss: 0.52228 \nEpoch: 501  | Training Loss: 0.26542 \nEpoch: 501  | Validation balanced accuracy : 0.50000 \nEpoch: 502  | Training Loss: 0.68184 \nEpoch: 502  | Training Loss: 0.69495 \nEpoch: 502  | Training Loss: 0.58004 \nEpoch: 502  | Training Loss: 0.52224 \nEpoch: 502  | Training Loss: 0.26531 \nEpoch: 502  | Validation balanced accuracy : 0.50000 \nEpoch: 503  | Training Loss: 0.68175 \nEpoch: 503  | Training Loss: 0.69491 \nEpoch: 503  | Training Loss: 0.57996 \nEpoch: 503  | Training Loss: 0.52221 \nEpoch: 503  | Training Loss: 0.26519 \nEpoch: 503  | Validation balanced accuracy : 0.50000 \nEpoch: 504  | Training Loss: 0.68165 \nEpoch: 504  | Training Loss: 0.69486 \nEpoch: 504  | Training Loss: 0.57989 \nEpoch: 504  | Training Loss: 0.52217 \nEpoch: 504  | Training Loss: 0.26508 \nEpoch: 504  | Validation balanced accuracy : 0.50000 \nEpoch: 505  | Training Loss: 0.68156 \nEpoch: 505  | Training Loss: 0.69481 \nEpoch: 505  | Training Loss: 0.57982 \nEpoch: 505  | Training Loss: 0.52214 \nEpoch: 505  | Training Loss: 0.26496 \nEpoch: 505  | Validation balanced accuracy : 0.50000 \nEpoch: 506  | Training Loss: 0.68147 \nEpoch: 506  | Training Loss: 0.69476 \nEpoch: 506  | Training Loss: 0.57974 \nEpoch: 506  | Training Loss: 0.52210 \nEpoch: 506  | Training Loss: 0.26485 \nEpoch: 506  | Validation balanced accuracy : 0.50000 \nEpoch: 507  | Training Loss: 0.68137 \nEpoch: 507  | Training Loss: 0.69471 \nEpoch: 507  | Training Loss: 0.57967 \nEpoch: 507  | Training Loss: 0.52206 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 507  | Training Loss: 0.26473 \nEpoch: 507  | Validation balanced accuracy : 0.50000 \nEpoch: 508  | Training Loss: 0.68128 \nEpoch: 508  | Training Loss: 0.69466 \nEpoch: 508  | Training Loss: 0.57959 \nEpoch: 508  | Training Loss: 0.52203 \nEpoch: 508  | Training Loss: 0.26461 \nEpoch: 508  | Validation balanced accuracy : 0.50000 \nEpoch: 509  | Training Loss: 0.68118 \nEpoch: 509  | Training Loss: 0.69461 \nEpoch: 509  | Training Loss: 0.57952 \nEpoch: 509  | Training Loss: 0.52199 \nEpoch: 509  | Training Loss: 0.26449 \nEpoch: 509  | Validation balanced accuracy : 0.50000 \nEpoch: 510  | Training Loss: 0.68109 \nEpoch: 510  | Training Loss: 0.69456 \nEpoch: 510  | Training Loss: 0.57945 \nEpoch: 510  | Training Loss: 0.52195 \nEpoch: 510  | Training Loss: 0.26438 \nEpoch: 510  | Validation balanced accuracy : 0.50000 \nEpoch: 511  | Training Loss: 0.68100 \nEpoch: 511  | Training Loss: 0.69451 \nEpoch: 511  | Training Loss: 0.57937 \nEpoch: 511  | Training Loss: 0.52192 \nEpoch: 511  | Training Loss: 0.26426 \nEpoch: 511  | Validation balanced accuracy : 0.50000 \nEpoch: 512  | Training Loss: 0.68090 \nEpoch: 512  | Training Loss: 0.69446 \nEpoch: 512  | Training Loss: 0.57930 \nEpoch: 512  | Training Loss: 0.52188 \nEpoch: 512  | Training Loss: 0.26415 \nEpoch: 512  | Validation balanced accuracy : 0.50000 \nEpoch: 513  | Training Loss: 0.68080 \nEpoch: 513  | Training Loss: 0.69440 \nEpoch: 513  | Training Loss: 0.57922 \nEpoch: 513  | Training Loss: 0.52184 \nEpoch: 513  | Training Loss: 0.26403 \nEpoch: 513  | Validation balanced accuracy : 0.50000 \nEpoch: 514  | Training Loss: 0.68071 \nEpoch: 514  | Training Loss: 0.69435 \nEpoch: 514  | Training Loss: 0.57915 \nEpoch: 514  | Training Loss: 0.52181 \nEpoch: 514  | Training Loss: 0.26391 \nEpoch: 514  | Validation balanced accuracy : 0.50000 \nEpoch: 515  | Training Loss: 0.68062 \nEpoch: 515  | Training Loss: 0.69430 \nEpoch: 515  | Training Loss: 0.57907 \nEpoch: 515  | Training Loss: 0.52177 \nEpoch: 515  | Training Loss: 0.26379 \nEpoch: 515  | Validation balanced accuracy : 0.50000 \nEpoch: 516  | Training Loss: 0.68052 \nEpoch: 516  | Training Loss: 0.69425 \nEpoch: 516  | Training Loss: 0.57900 \nEpoch: 516  | Training Loss: 0.52173 \nEpoch: 516  | Training Loss: 0.26367 \nEpoch: 516  | Validation balanced accuracy : 0.50000 \nEpoch: 517  | Training Loss: 0.68042 \nEpoch: 517  | Training Loss: 0.69420 \nEpoch: 517  | Training Loss: 0.57892 \nEpoch: 517  | Training Loss: 0.52170 \nEpoch: 517  | Training Loss: 0.26356 \nEpoch: 517  | Validation balanced accuracy : 0.50000 \nEpoch: 518  | Training Loss: 0.68033 \nEpoch: 518  | Training Loss: 0.69415 \nEpoch: 518  | Training Loss: 0.57884 \nEpoch: 518  | Training Loss: 0.52166 \nEpoch: 518  | Training Loss: 0.26344 \nEpoch: 518  | Validation balanced accuracy : 0.50000 \nEpoch: 519  | Training Loss: 0.68023 \nEpoch: 519  | Training Loss: 0.69410 \nEpoch: 519  | Training Loss: 0.57877 \nEpoch: 519  | Training Loss: 0.52162 \nEpoch: 519  | Training Loss: 0.26332 \nEpoch: 519  | Validation balanced accuracy : 0.50000 \nEpoch: 520  | Training Loss: 0.68013 \nEpoch: 520  | Training Loss: 0.69404 \nEpoch: 520  | Training Loss: 0.57869 \nEpoch: 520  | Training Loss: 0.52158 \nEpoch: 520  | Training Loss: 0.26320 \nEpoch: 520  | Validation balanced accuracy : 0.50000 \nEpoch: 521  | Training Loss: 0.68004 \nEpoch: 521  | Training Loss: 0.69399 \nEpoch: 521  | Training Loss: 0.57862 \nEpoch: 521  | Training Loss: 0.52155 \nEpoch: 521  | Training Loss: 0.26308 \nEpoch: 521  | Validation balanced accuracy : 0.50000 \nEpoch: 522  | Training Loss: 0.67994 \nEpoch: 522  | Training Loss: 0.69394 \nEpoch: 522  | Training Loss: 0.57854 \nEpoch: 522  | Training Loss: 0.52151 \nEpoch: 522  | Training Loss: 0.26296 \nEpoch: 522  | Validation balanced accuracy : 0.50000 \nEpoch: 523  | Training Loss: 0.67984 \nEpoch: 523  | Training Loss: 0.69389 \nEpoch: 523  | Training Loss: 0.57846 \nEpoch: 523  | Training Loss: 0.52147 \nEpoch: 523  | Training Loss: 0.26284 \nEpoch: 523  | Validation balanced accuracy : 0.50000 \nEpoch: 524  | Training Loss: 0.67974 \nEpoch: 524  | Training Loss: 0.69383 \nEpoch: 524  | Training Loss: 0.57838 \nEpoch: 524  | Training Loss: 0.52143 \nEpoch: 524  | Training Loss: 0.26272 \nEpoch: 524  | Validation balanced accuracy : 0.50000 \nEpoch: 525  | Training Loss: 0.67965 \nEpoch: 525  | Training Loss: 0.69378 \nEpoch: 525  | Training Loss: 0.57831 \nEpoch: 525  | Training Loss: 0.52140 \nEpoch: 525  | Training Loss: 0.26260 \nEpoch: 525  | Validation balanced accuracy : 0.50000 \nEpoch: 526  | Training Loss: 0.67955 \nEpoch: 526  | Training Loss: 0.69373 \nEpoch: 526  | Training Loss: 0.57823 \nEpoch: 526  | Training Loss: 0.52136 \nEpoch: 526  | Training Loss: 0.26248 \nEpoch: 526  | Validation balanced accuracy : 0.50000 \nEpoch: 527  | Training Loss: 0.67945 \nEpoch: 527  | Training Loss: 0.69367 \nEpoch: 527  | Training Loss: 0.57815 \nEpoch: 527  | Training Loss: 0.52132 \nEpoch: 527  | Training Loss: 0.26236 \nEpoch: 527  | Validation balanced accuracy : 0.50000 \nEpoch: 528  | Training Loss: 0.67935 \nEpoch: 528  | Training Loss: 0.69362 \nEpoch: 528  | Training Loss: 0.57807 \nEpoch: 528  | Training Loss: 0.52128 \nEpoch: 528  | Training Loss: 0.26225 \nEpoch: 528  | Validation balanced accuracy : 0.50000 \nEpoch: 529  | Training Loss: 0.67925 \nEpoch: 529  | Training Loss: 0.69357 \nEpoch: 529  | Training Loss: 0.57800 \nEpoch: 529  | Training Loss: 0.52124 \nEpoch: 529  | Training Loss: 0.26213 \nEpoch: 529  | Validation balanced accuracy : 0.50000 \nEpoch: 530  | Training Loss: 0.67915 \nEpoch: 530  | Training Loss: 0.69351 \nEpoch: 530  | Training Loss: 0.57792 \nEpoch: 530  | Training Loss: 0.52121 \nEpoch: 530  | Training Loss: 0.26200 \nEpoch: 530  | Validation balanced accuracy : 0.50000 \nEpoch: 531  | Training Loss: 0.67905 \nEpoch: 531  | Training Loss: 0.69346 \nEpoch: 531  | Training Loss: 0.57784 \nEpoch: 531  | Training Loss: 0.52117 \nEpoch: 531  | Training Loss: 0.26188 \nEpoch: 531  | Validation balanced accuracy : 0.50000 \nEpoch: 532  | Training Loss: 0.67895 \nEpoch: 532  | Training Loss: 0.69341 \nEpoch: 532  | Training Loss: 0.57776 \nEpoch: 532  | Training Loss: 0.52113 \nEpoch: 532  | Training Loss: 0.26176 \nEpoch: 532  | Validation balanced accuracy : 0.50000 \nEpoch: 533  | Training Loss: 0.67885 \nEpoch: 533  | Training Loss: 0.69335 \nEpoch: 533  | Training Loss: 0.57768 \nEpoch: 533  | Training Loss: 0.52109 \nEpoch: 533  | Training Loss: 0.26164 \nEpoch: 533  | Validation balanced accuracy : 0.50000 \nEpoch: 534  | Training Loss: 0.67875 \nEpoch: 534  | Training Loss: 0.69330 \nEpoch: 534  | Training Loss: 0.57760 \nEpoch: 534  | Training Loss: 0.52105 \nEpoch: 534  | Training Loss: 0.26152 \nEpoch: 534  | Validation balanced accuracy : 0.50000 \nEpoch: 535  | Training Loss: 0.67865 \nEpoch: 535  | Training Loss: 0.69324 \nEpoch: 535  | Training Loss: 0.57752 \nEpoch: 535  | Training Loss: 0.52101 \nEpoch: 535  | Training Loss: 0.26140 \nEpoch: 535  | Validation balanced accuracy : 0.50000 \nEpoch: 536  | Training Loss: 0.67855 \nEpoch: 536  | Training Loss: 0.69319 \nEpoch: 536  | Training Loss: 0.57744 \nEpoch: 536  | Training Loss: 0.52097 \nEpoch: 536  | Training Loss: 0.26128 \nEpoch: 536  | Validation balanced accuracy : 0.50000 \nEpoch: 537  | Training Loss: 0.67845 \nEpoch: 537  | Training Loss: 0.69313 \nEpoch: 537  | Training Loss: 0.57736 \nEpoch: 537  | Training Loss: 0.52093 \nEpoch: 537  | Training Loss: 0.26115 \nEpoch: 537  | Validation balanced accuracy : 0.50000 \nEpoch: 538  | Training Loss: 0.67835 \nEpoch: 538  | Training Loss: 0.69308 \nEpoch: 538  | Training Loss: 0.57729 \nEpoch: 538  | Training Loss: 0.52089 \nEpoch: 538  | Training Loss: 0.26103 \nEpoch: 538  | Validation balanced accuracy : 0.50000 \nEpoch: 539  | Training Loss: 0.67825 \nEpoch: 539  | Training Loss: 0.69302 \nEpoch: 539  | Training Loss: 0.57721 \nEpoch: 539  | Training Loss: 0.52085 \nEpoch: 539  | Training Loss: 0.26091 \nEpoch: 539  | Validation balanced accuracy : 0.50000 \nEpoch: 540  | Training Loss: 0.67814 \nEpoch: 540  | Training Loss: 0.69296 \nEpoch: 540  | Training Loss: 0.57712 \nEpoch: 540  | Training Loss: 0.52082 \nEpoch: 540  | Training Loss: 0.26079 \nEpoch: 540  | Validation balanced accuracy : 0.50000 \nEpoch: 541  | Training Loss: 0.67804 \nEpoch: 541  | Training Loss: 0.69291 \nEpoch: 541  | Training Loss: 0.57704 \nEpoch: 541  | Training Loss: 0.52078 \nEpoch: 541  | Training Loss: 0.26066 \nEpoch: 541  | Validation balanced accuracy : 0.50000 \nEpoch: 542  | Training Loss: 0.67794 \nEpoch: 542  | Training Loss: 0.69285 \nEpoch: 542  | Training Loss: 0.57696 \nEpoch: 542  | Training Loss: 0.52074 \nEpoch: 542  | Training Loss: 0.26054 \nEpoch: 542  | Validation balanced accuracy : 0.50000 \nEpoch: 543  | Training Loss: 0.67784 \nEpoch: 543  | Training Loss: 0.69280 \nEpoch: 543  | Training Loss: 0.57688 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 543  | Training Loss: 0.52070 \nEpoch: 543  | Training Loss: 0.26042 \nEpoch: 543  | Validation balanced accuracy : 0.50000 \nEpoch: 544  | Training Loss: 0.67773 \nEpoch: 544  | Training Loss: 0.69274 \nEpoch: 544  | Training Loss: 0.57680 \nEpoch: 544  | Training Loss: 0.52066 \nEpoch: 544  | Training Loss: 0.26029 \nEpoch: 544  | Validation balanced accuracy : 0.50000 \nEpoch: 545  | Training Loss: 0.67763 \nEpoch: 545  | Training Loss: 0.69268 \nEpoch: 545  | Training Loss: 0.57672 \nEpoch: 545  | Training Loss: 0.52062 \nEpoch: 545  | Training Loss: 0.26017 \nEpoch: 545  | Validation balanced accuracy : 0.50000 \nEpoch: 546  | Training Loss: 0.67753 \nEpoch: 546  | Training Loss: 0.69262 \nEpoch: 546  | Training Loss: 0.57664 \nEpoch: 546  | Training Loss: 0.52058 \nEpoch: 546  | Training Loss: 0.26005 \nEpoch: 546  | Validation balanced accuracy : 0.50000 \nEpoch: 547  | Training Loss: 0.67742 \nEpoch: 547  | Training Loss: 0.69257 \nEpoch: 547  | Training Loss: 0.57656 \nEpoch: 547  | Training Loss: 0.52054 \nEpoch: 547  | Training Loss: 0.25992 \nEpoch: 547  | Validation balanced accuracy : 0.50000 \nEpoch: 548  | Training Loss: 0.67732 \nEpoch: 548  | Training Loss: 0.69251 \nEpoch: 548  | Training Loss: 0.57648 \nEpoch: 548  | Training Loss: 0.52050 \nEpoch: 548  | Training Loss: 0.25980 \nEpoch: 548  | Validation balanced accuracy : 0.50000 \nEpoch: 549  | Training Loss: 0.67721 \nEpoch: 549  | Training Loss: 0.69245 \nEpoch: 549  | Training Loss: 0.57639 \nEpoch: 549  | Training Loss: 0.52046 \nEpoch: 549  | Training Loss: 0.25967 \nEpoch: 549  | Validation balanced accuracy : 0.50000 \nEpoch: 550  | Training Loss: 0.67711 \nEpoch: 550  | Training Loss: 0.69239 \nEpoch: 550  | Training Loss: 0.57631 \nEpoch: 550  | Training Loss: 0.52041 \nEpoch: 550  | Training Loss: 0.25955 \nEpoch: 550  | Validation balanced accuracy : 0.50000 \nEpoch: 551  | Training Loss: 0.67701 \nEpoch: 551  | Training Loss: 0.69234 \nEpoch: 551  | Training Loss: 0.57623 \nEpoch: 551  | Training Loss: 0.52037 \nEpoch: 551  | Training Loss: 0.25942 \nEpoch: 551  | Validation balanced accuracy : 0.50000 \nEpoch: 552  | Training Loss: 0.67690 \nEpoch: 552  | Training Loss: 0.69228 \nEpoch: 552  | Training Loss: 0.57614 \nEpoch: 552  | Training Loss: 0.52033 \nEpoch: 552  | Training Loss: 0.25930 \nEpoch: 552  | Validation balanced accuracy : 0.50000 \nEpoch: 553  | Training Loss: 0.67679 \nEpoch: 553  | Training Loss: 0.69222 \nEpoch: 553  | Training Loss: 0.57606 \nEpoch: 553  | Training Loss: 0.52029 \nEpoch: 553  | Training Loss: 0.25917 \nEpoch: 553  | Validation balanced accuracy : 0.50000 \nEpoch: 554  | Training Loss: 0.67669 \nEpoch: 554  | Training Loss: 0.69216 \nEpoch: 554  | Training Loss: 0.57598 \nEpoch: 554  | Training Loss: 0.52025 \nEpoch: 554  | Training Loss: 0.25905 \nEpoch: 554  | Validation balanced accuracy : 0.50000 \nEpoch: 555  | Training Loss: 0.67658 \nEpoch: 555  | Training Loss: 0.69210 \nEpoch: 555  | Training Loss: 0.57589 \nEpoch: 555  | Training Loss: 0.52021 \nEpoch: 555  | Training Loss: 0.25892 \nEpoch: 555  | Validation balanced accuracy : 0.50000 \nEpoch: 556  | Training Loss: 0.67647 \nEpoch: 556  | Training Loss: 0.69204 \nEpoch: 556  | Training Loss: 0.57581 \nEpoch: 556  | Training Loss: 0.52017 \nEpoch: 556  | Training Loss: 0.25879 \nEpoch: 556  | Validation balanced accuracy : 0.50000 \nEpoch: 557  | Training Loss: 0.67637 \nEpoch: 557  | Training Loss: 0.69198 \nEpoch: 557  | Training Loss: 0.57573 \nEpoch: 557  | Training Loss: 0.52013 \nEpoch: 557  | Training Loss: 0.25867 \nEpoch: 557  | Validation balanced accuracy : 0.50000 \nEpoch: 558  | Training Loss: 0.67626 \nEpoch: 558  | Training Loss: 0.69192 \nEpoch: 558  | Training Loss: 0.57564 \nEpoch: 558  | Training Loss: 0.52009 \nEpoch: 558  | Training Loss: 0.25854 \nEpoch: 558  | Validation balanced accuracy : 0.50000 \nEpoch: 559  | Training Loss: 0.67615 \nEpoch: 559  | Training Loss: 0.69186 \nEpoch: 559  | Training Loss: 0.57556 \nEpoch: 559  | Training Loss: 0.52004 \nEpoch: 559  | Training Loss: 0.25841 \nEpoch: 559  | Validation balanced accuracy : 0.50000 \nEpoch: 560  | Training Loss: 0.67605 \nEpoch: 560  | Training Loss: 0.69180 \nEpoch: 560  | Training Loss: 0.57547 \nEpoch: 560  | Training Loss: 0.52000 \nEpoch: 560  | Training Loss: 0.25829 \nEpoch: 560  | Validation balanced accuracy : 0.50000 \nEpoch: 561  | Training Loss: 0.67594 \nEpoch: 561  | Training Loss: 0.69174 \nEpoch: 561  | Training Loss: 0.57539 \nEpoch: 561  | Training Loss: 0.51996 \nEpoch: 561  | Training Loss: 0.25816 \nEpoch: 561  | Validation balanced accuracy : 0.50000 \nEpoch: 562  | Training Loss: 0.67583 \nEpoch: 562  | Training Loss: 0.69168 \nEpoch: 562  | Training Loss: 0.57530 \nEpoch: 562  | Training Loss: 0.51992 \nEpoch: 562  | Training Loss: 0.25803 \nEpoch: 562  | Validation balanced accuracy : 0.50000 \nEpoch: 563  | Training Loss: 0.67572 \nEpoch: 563  | Training Loss: 0.69162 \nEpoch: 563  | Training Loss: 0.57522 \nEpoch: 563  | Training Loss: 0.51988 \nEpoch: 563  | Training Loss: 0.25790 \nEpoch: 563  | Validation balanced accuracy : 0.50000 \nEpoch: 564  | Training Loss: 0.67561 \nEpoch: 564  | Training Loss: 0.69156 \nEpoch: 564  | Training Loss: 0.57513 \nEpoch: 564  | Training Loss: 0.51983 \nEpoch: 564  | Training Loss: 0.25778 \nEpoch: 564  | Validation balanced accuracy : 0.50000 \nEpoch: 565  | Training Loss: 0.67550 \nEpoch: 565  | Training Loss: 0.69150 \nEpoch: 565  | Training Loss: 0.57504 \nEpoch: 565  | Training Loss: 0.51979 \nEpoch: 565  | Training Loss: 0.25765 \nEpoch: 565  | Validation balanced accuracy : 0.50000 \nEpoch: 566  | Training Loss: 0.67539 \nEpoch: 566  | Training Loss: 0.69144 \nEpoch: 566  | Training Loss: 0.57496 \nEpoch: 566  | Training Loss: 0.51975 \nEpoch: 566  | Training Loss: 0.25752 \nEpoch: 566  | Validation balanced accuracy : 0.50000 \nEpoch: 567  | Training Loss: 0.67528 \nEpoch: 567  | Training Loss: 0.69138 \nEpoch: 567  | Training Loss: 0.57487 \nEpoch: 567  | Training Loss: 0.51971 \nEpoch: 567  | Training Loss: 0.25739 \nEpoch: 567  | Validation balanced accuracy : 0.50000 \nEpoch: 568  | Training Loss: 0.67517 \nEpoch: 568  | Training Loss: 0.69132 \nEpoch: 568  | Training Loss: 0.57478 \nEpoch: 568  | Training Loss: 0.51966 \nEpoch: 568  | Training Loss: 0.25726 \nEpoch: 568  | Validation balanced accuracy : 0.50000 \nEpoch: 569  | Training Loss: 0.67506 \nEpoch: 569  | Training Loss: 0.69125 \nEpoch: 569  | Training Loss: 0.57470 \nEpoch: 569  | Training Loss: 0.51962 \nEpoch: 569  | Training Loss: 0.25713 \nEpoch: 569  | Validation balanced accuracy : 0.50000 \nEpoch: 570  | Training Loss: 0.67495 \nEpoch: 570  | Training Loss: 0.69119 \nEpoch: 570  | Training Loss: 0.57461 \nEpoch: 570  | Training Loss: 0.51958 \nEpoch: 570  | Training Loss: 0.25700 \nEpoch: 570  | Validation balanced accuracy : 0.50000 \nEpoch: 571  | Training Loss: 0.67484 \nEpoch: 571  | Training Loss: 0.69113 \nEpoch: 571  | Training Loss: 0.57452 \nEpoch: 571  | Training Loss: 0.51953 \nEpoch: 571  | Training Loss: 0.25687 \nEpoch: 571  | Validation balanced accuracy : 0.50000 \nEpoch: 572  | Training Loss: 0.67473 \nEpoch: 572  | Training Loss: 0.69107 \nEpoch: 572  | Training Loss: 0.57443 \nEpoch: 572  | Training Loss: 0.51949 \nEpoch: 572  | Training Loss: 0.25674 \nEpoch: 572  | Validation balanced accuracy : 0.50000 \nEpoch: 573  | Training Loss: 0.67461 \nEpoch: 573  | Training Loss: 0.69100 \nEpoch: 573  | Training Loss: 0.57435 \nEpoch: 573  | Training Loss: 0.51945 \nEpoch: 573  | Training Loss: 0.25661 \nEpoch: 573  | Validation balanced accuracy : 0.50000 \nEpoch: 574  | Training Loss: 0.67450 \nEpoch: 574  | Training Loss: 0.69094 \nEpoch: 574  | Training Loss: 0.57426 \nEpoch: 574  | Training Loss: 0.51940 \nEpoch: 574  | Training Loss: 0.25648 \nEpoch: 574  | Validation balanced accuracy : 0.50000 \nEpoch: 575  | Training Loss: 0.67439 \nEpoch: 575  | Training Loss: 0.69088 \nEpoch: 575  | Training Loss: 0.57417 \nEpoch: 575  | Training Loss: 0.51936 \nEpoch: 575  | Training Loss: 0.25635 \nEpoch: 575  | Validation balanced accuracy : 0.50000 \nEpoch: 576  | Training Loss: 0.67428 \nEpoch: 576  | Training Loss: 0.69081 \nEpoch: 576  | Training Loss: 0.57408 \nEpoch: 576  | Training Loss: 0.51932 \nEpoch: 576  | Training Loss: 0.25622 \nEpoch: 576  | Validation balanced accuracy : 0.50000 \nEpoch: 577  | Training Loss: 0.67416 \nEpoch: 577  | Training Loss: 0.69075 \nEpoch: 577  | Training Loss: 0.57399 \nEpoch: 577  | Training Loss: 0.51927 \nEpoch: 577  | Training Loss: 0.25609 \nEpoch: 577  | Validation balanced accuracy : 0.50000 \nEpoch: 578  | Training Loss: 0.67405 \nEpoch: 578  | Training Loss: 0.69068 \nEpoch: 578  | Training Loss: 0.57390 \nEpoch: 578  | Training Loss: 0.51923 \nEpoch: 578  | Training Loss: 0.25596 \nEpoch: 578  | Validation balanced accuracy : 0.50000 \nEpoch: 579  | Training Loss: 0.67394 \nEpoch: 579  | Training Loss: 0.69062 \nEpoch: 579  | Training Loss: 0.57381 \nEpoch: 579  | Training Loss: 0.51918 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 579  | Training Loss: 0.25583 \nEpoch: 579  | Validation balanced accuracy : 0.50000 \nEpoch: 580  | Training Loss: 0.67382 \nEpoch: 580  | Training Loss: 0.69055 \nEpoch: 580  | Training Loss: 0.57372 \nEpoch: 580  | Training Loss: 0.51914 \nEpoch: 580  | Training Loss: 0.25570 \nEpoch: 580  | Validation balanced accuracy : 0.50000 \nEpoch: 581  | Training Loss: 0.67370 \nEpoch: 581  | Training Loss: 0.69049 \nEpoch: 581  | Training Loss: 0.57363 \nEpoch: 581  | Training Loss: 0.51909 \nEpoch: 581  | Training Loss: 0.25556 \nEpoch: 581  | Validation balanced accuracy : 0.50000 \nEpoch: 582  | Training Loss: 0.67359 \nEpoch: 582  | Training Loss: 0.69042 \nEpoch: 582  | Training Loss: 0.57354 \nEpoch: 582  | Training Loss: 0.51905 \nEpoch: 582  | Training Loss: 0.25543 \nEpoch: 582  | Validation balanced accuracy : 0.50000 \nEpoch: 583  | Training Loss: 0.67348 \nEpoch: 583  | Training Loss: 0.69036 \nEpoch: 583  | Training Loss: 0.57345 \nEpoch: 583  | Training Loss: 0.51901 \nEpoch: 583  | Training Loss: 0.25530 \nEpoch: 583  | Validation balanced accuracy : 0.50000 \nEpoch: 584  | Training Loss: 0.67336 \nEpoch: 584  | Training Loss: 0.69029 \nEpoch: 584  | Training Loss: 0.57336 \nEpoch: 584  | Training Loss: 0.51896 \nEpoch: 584  | Training Loss: 0.25516 \nEpoch: 584  | Validation balanced accuracy : 0.50000 \nEpoch: 585  | Training Loss: 0.67324 \nEpoch: 585  | Training Loss: 0.69023 \nEpoch: 585  | Training Loss: 0.57326 \nEpoch: 585  | Training Loss: 0.51892 \nEpoch: 585  | Training Loss: 0.25503 \nEpoch: 585  | Validation balanced accuracy : 0.50000 \nEpoch: 586  | Training Loss: 0.67313 \nEpoch: 586  | Training Loss: 0.69016 \nEpoch: 586  | Training Loss: 0.57317 \nEpoch: 586  | Training Loss: 0.51887 \nEpoch: 586  | Training Loss: 0.25490 \nEpoch: 586  | Validation balanced accuracy : 0.50000 \nEpoch: 587  | Training Loss: 0.67301 \nEpoch: 587  | Training Loss: 0.69009 \nEpoch: 587  | Training Loss: 0.57308 \nEpoch: 587  | Training Loss: 0.51882 \nEpoch: 587  | Training Loss: 0.25476 \nEpoch: 587  | Validation balanced accuracy : 0.50000 \nEpoch: 588  | Training Loss: 0.67289 \nEpoch: 588  | Training Loss: 0.69003 \nEpoch: 588  | Training Loss: 0.57299 \nEpoch: 588  | Training Loss: 0.51878 \nEpoch: 588  | Training Loss: 0.25463 \nEpoch: 588  | Validation balanced accuracy : 0.50000 \nEpoch: 589  | Training Loss: 0.67277 \nEpoch: 589  | Training Loss: 0.68996 \nEpoch: 589  | Training Loss: 0.57290 \nEpoch: 589  | Training Loss: 0.51873 \nEpoch: 589  | Training Loss: 0.25449 \nEpoch: 589  | Validation balanced accuracy : 0.50000 \nEpoch: 590  | Training Loss: 0.67266 \nEpoch: 590  | Training Loss: 0.68989 \nEpoch: 590  | Training Loss: 0.57280 \nEpoch: 590  | Training Loss: 0.51869 \nEpoch: 590  | Training Loss: 0.25436 \nEpoch: 590  | Validation balanced accuracy : 0.50000 \nEpoch: 591  | Training Loss: 0.67254 \nEpoch: 591  | Training Loss: 0.68982 \nEpoch: 591  | Training Loss: 0.57271 \nEpoch: 591  | Training Loss: 0.51864 \nEpoch: 591  | Training Loss: 0.25422 \nEpoch: 591  | Validation balanced accuracy : 0.50000 \nEpoch: 592  | Training Loss: 0.67242 \nEpoch: 592  | Training Loss: 0.68975 \nEpoch: 592  | Training Loss: 0.57262 \nEpoch: 592  | Training Loss: 0.51859 \nEpoch: 592  | Training Loss: 0.25409 \nEpoch: 592  | Validation balanced accuracy : 0.50000 \nEpoch: 593  | Training Loss: 0.67230 \nEpoch: 593  | Training Loss: 0.68969 \nEpoch: 593  | Training Loss: 0.57252 \nEpoch: 593  | Training Loss: 0.51855 \nEpoch: 593  | Training Loss: 0.25396 \nEpoch: 593  | Validation balanced accuracy : 0.50000 \nEpoch: 594  | Training Loss: 0.67218 \nEpoch: 594  | Training Loss: 0.68962 \nEpoch: 594  | Training Loss: 0.57243 \nEpoch: 594  | Training Loss: 0.51850 \nEpoch: 594  | Training Loss: 0.25382 \nEpoch: 594  | Validation balanced accuracy : 0.50000 \nEpoch: 595  | Training Loss: 0.67206 \nEpoch: 595  | Training Loss: 0.68955 \nEpoch: 595  | Training Loss: 0.57233 \nEpoch: 595  | Training Loss: 0.51845 \nEpoch: 595  | Training Loss: 0.25368 \nEpoch: 595  | Validation balanced accuracy : 0.50000 \nEpoch: 596  | Training Loss: 0.67194 \nEpoch: 596  | Training Loss: 0.68948 \nEpoch: 596  | Training Loss: 0.57224 \nEpoch: 596  | Training Loss: 0.51841 \nEpoch: 596  | Training Loss: 0.25355 \nEpoch: 596  | Validation balanced accuracy : 0.50000 \nEpoch: 597  | Training Loss: 0.67182 \nEpoch: 597  | Training Loss: 0.68941 \nEpoch: 597  | Training Loss: 0.57214 \nEpoch: 597  | Training Loss: 0.51836 \nEpoch: 597  | Training Loss: 0.25341 \nEpoch: 597  | Validation balanced accuracy : 0.50000 \nEpoch: 598  | Training Loss: 0.67169 \nEpoch: 598  | Training Loss: 0.68934 \nEpoch: 598  | Training Loss: 0.57205 \nEpoch: 598  | Training Loss: 0.51831 \nEpoch: 598  | Training Loss: 0.25327 \nEpoch: 598  | Validation balanced accuracy : 0.50000 \nEpoch: 599  | Training Loss: 0.67157 \nEpoch: 599  | Training Loss: 0.68927 \nEpoch: 599  | Training Loss: 0.57195 \nEpoch: 599  | Training Loss: 0.51827 \nEpoch: 599  | Training Loss: 0.25314 \nEpoch: 599  | Validation balanced accuracy : 0.50000 \nEpoch: 600  | Training Loss: 0.67145 \nEpoch: 600  | Training Loss: 0.68920 \nEpoch: 600  | Training Loss: 0.57186 \nEpoch: 600  | Training Loss: 0.51822 \nEpoch: 600  | Training Loss: 0.25300 \nEpoch: 600  | Validation balanced accuracy : 0.50000 \nEpoch: 601  | Training Loss: 0.67133 \nEpoch: 601  | Training Loss: 0.68904 \nEpoch: 601  | Training Loss: 0.57178 \nEpoch: 601  | Training Loss: 0.51809 \nEpoch: 601  | Training Loss: 0.25211 \nEpoch: 601  | Validation balanced accuracy : 0.50000 \nEpoch: 602  | Training Loss: 0.67119 \nEpoch: 602  | Training Loss: 0.68894 \nEpoch: 602  | Training Loss: 0.57168 \nEpoch: 602  | Training Loss: 0.51806 \nEpoch: 602  | Training Loss: 0.25213 \nEpoch: 602  | Validation balanced accuracy : 0.50000 \nEpoch: 603  | Training Loss: 0.67101 \nEpoch: 603  | Training Loss: 0.68880 \nEpoch: 603  | Training Loss: 0.57157 \nEpoch: 603  | Training Loss: 0.51804 \nEpoch: 603  | Training Loss: 0.25215 \nEpoch: 603  | Validation balanced accuracy : 0.50000 \nEpoch: 604  | Training Loss: 0.67083 \nEpoch: 604  | Training Loss: 0.68868 \nEpoch: 604  | Training Loss: 0.57147 \nEpoch: 604  | Training Loss: 0.51801 \nEpoch: 604  | Training Loss: 0.25208 \nEpoch: 604  | Validation balanced accuracy : 0.50000 \nEpoch: 605  | Training Loss: 0.67069 \nEpoch: 605  | Training Loss: 0.68860 \nEpoch: 605  | Training Loss: 0.57139 \nEpoch: 605  | Training Loss: 0.51797 \nEpoch: 605  | Training Loss: 0.25194 \nEpoch: 605  | Validation balanced accuracy : 0.50000 \nEpoch: 606  | Training Loss: 0.67060 \nEpoch: 606  | Training Loss: 0.68856 \nEpoch: 606  | Training Loss: 0.57130 \nEpoch: 606  | Training Loss: 0.51792 \nEpoch: 606  | Training Loss: 0.25176 \nEpoch: 606  | Validation balanced accuracy : 0.50000 \nEpoch: 607  | Training Loss: 0.67052 \nEpoch: 607  | Training Loss: 0.68852 \nEpoch: 607  | Training Loss: 0.57122 \nEpoch: 607  | Training Loss: 0.51787 \nEpoch: 607  | Training Loss: 0.25159 \nEpoch: 607  | Validation balanced accuracy : 0.50000 \nEpoch: 608  | Training Loss: 0.67043 \nEpoch: 608  | Training Loss: 0.68847 \nEpoch: 608  | Training Loss: 0.57114 \nEpoch: 608  | Training Loss: 0.51782 \nEpoch: 608  | Training Loss: 0.25146 \nEpoch: 608  | Validation balanced accuracy : 0.50000 \nEpoch: 609  | Training Loss: 0.67032 \nEpoch: 609  | Training Loss: 0.68841 \nEpoch: 609  | Training Loss: 0.57105 \nEpoch: 609  | Training Loss: 0.51778 \nEpoch: 609  | Training Loss: 0.25134 \nEpoch: 609  | Validation balanced accuracy : 0.50000 \nEpoch: 610  | Training Loss: 0.67020 \nEpoch: 610  | Training Loss: 0.68834 \nEpoch: 610  | Training Loss: 0.57096 \nEpoch: 610  | Training Loss: 0.51774 \nEpoch: 610  | Training Loss: 0.25124 \nEpoch: 610  | Validation balanced accuracy : 0.50000 \nEpoch: 611  | Training Loss: 0.67007 \nEpoch: 611  | Training Loss: 0.68826 \nEpoch: 611  | Training Loss: 0.57087 \nEpoch: 611  | Training Loss: 0.51769 \nEpoch: 611  | Training Loss: 0.25113 \nEpoch: 611  | Validation balanced accuracy : 0.50000 \nEpoch: 612  | Training Loss: 0.66995 \nEpoch: 612  | Training Loss: 0.68819 \nEpoch: 612  | Training Loss: 0.57077 \nEpoch: 612  | Training Loss: 0.51765 \nEpoch: 612  | Training Loss: 0.25101 \nEpoch: 612  | Validation balanced accuracy : 0.50000 \nEpoch: 613  | Training Loss: 0.66984 \nEpoch: 613  | Training Loss: 0.68812 \nEpoch: 613  | Training Loss: 0.57069 \nEpoch: 613  | Training Loss: 0.51761 \nEpoch: 613  | Training Loss: 0.25088 \nEpoch: 613  | Validation balanced accuracy : 0.50000 \nEpoch: 614  | Training Loss: 0.66973 \nEpoch: 614  | Training Loss: 0.68806 \nEpoch: 614  | Training Loss: 0.57060 \nEpoch: 614  | Training Loss: 0.51756 \nEpoch: 614  | Training Loss: 0.25074 \nEpoch: 614  | Validation balanced accuracy : 0.50000 \nEpoch: 615  | Training Loss: 0.66962 \nEpoch: 615  | Training Loss: 0.68800 \nEpoch: 615  | Training Loss: 0.57051 \nEpoch: 615  | Training Loss: 0.51751 \nEpoch: 615  | Training Loss: 0.25061 \nEpoch: 615  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 616  | Training Loss: 0.66950 \nEpoch: 616  | Training Loss: 0.68793 \nEpoch: 616  | Training Loss: 0.57042 \nEpoch: 616  | Training Loss: 0.51747 \nEpoch: 616  | Training Loss: 0.25049 \nEpoch: 616  | Validation balanced accuracy : 0.50000 \nEpoch: 617  | Training Loss: 0.66939 \nEpoch: 617  | Training Loss: 0.68787 \nEpoch: 617  | Training Loss: 0.57033 \nEpoch: 617  | Training Loss: 0.51743 \nEpoch: 617  | Training Loss: 0.25037 \nEpoch: 617  | Validation balanced accuracy : 0.50000 \nEpoch: 618  | Training Loss: 0.66927 \nEpoch: 618  | Training Loss: 0.68780 \nEpoch: 618  | Training Loss: 0.57023 \nEpoch: 618  | Training Loss: 0.51738 \nEpoch: 618  | Training Loss: 0.25024 \nEpoch: 618  | Validation balanced accuracy : 0.50000 \nEpoch: 619  | Training Loss: 0.66915 \nEpoch: 619  | Training Loss: 0.68773 \nEpoch: 619  | Training Loss: 0.57014 \nEpoch: 619  | Training Loss: 0.51734 \nEpoch: 619  | Training Loss: 0.25012 \nEpoch: 619  | Validation balanced accuracy : 0.50000 \nEpoch: 620  | Training Loss: 0.66904 \nEpoch: 620  | Training Loss: 0.68766 \nEpoch: 620  | Training Loss: 0.57005 \nEpoch: 620  | Training Loss: 0.51729 \nEpoch: 620  | Training Loss: 0.24999 \nEpoch: 620  | Validation balanced accuracy : 0.50000 \nEpoch: 621  | Training Loss: 0.66892 \nEpoch: 621  | Training Loss: 0.68760 \nEpoch: 621  | Training Loss: 0.56996 \nEpoch: 621  | Training Loss: 0.51724 \nEpoch: 621  | Training Loss: 0.24986 \nEpoch: 621  | Validation balanced accuracy : 0.50000 \nEpoch: 622  | Training Loss: 0.66881 \nEpoch: 622  | Training Loss: 0.68753 \nEpoch: 622  | Training Loss: 0.56987 \nEpoch: 622  | Training Loss: 0.51720 \nEpoch: 622  | Training Loss: 0.24973 \nEpoch: 622  | Validation balanced accuracy : 0.50000 \nEpoch: 623  | Training Loss: 0.66869 \nEpoch: 623  | Training Loss: 0.68746 \nEpoch: 623  | Training Loss: 0.56977 \nEpoch: 623  | Training Loss: 0.51715 \nEpoch: 623  | Training Loss: 0.24961 \nEpoch: 623  | Validation balanced accuracy : 0.50000 \nEpoch: 624  | Training Loss: 0.66857 \nEpoch: 624  | Training Loss: 0.68739 \nEpoch: 624  | Training Loss: 0.56968 \nEpoch: 624  | Training Loss: 0.51711 \nEpoch: 624  | Training Loss: 0.24948 \nEpoch: 624  | Validation balanced accuracy : 0.50000 \nEpoch: 625  | Training Loss: 0.66845 \nEpoch: 625  | Training Loss: 0.68732 \nEpoch: 625  | Training Loss: 0.56959 \nEpoch: 625  | Training Loss: 0.51706 \nEpoch: 625  | Training Loss: 0.24935 \nEpoch: 625  | Validation balanced accuracy : 0.50000 \nEpoch: 626  | Training Loss: 0.66833 \nEpoch: 626  | Training Loss: 0.68725 \nEpoch: 626  | Training Loss: 0.56949 \nEpoch: 626  | Training Loss: 0.51701 \nEpoch: 626  | Training Loss: 0.24922 \nEpoch: 626  | Validation balanced accuracy : 0.50000 \nEpoch: 627  | Training Loss: 0.66821 \nEpoch: 627  | Training Loss: 0.68718 \nEpoch: 627  | Training Loss: 0.56940 \nEpoch: 627  | Training Loss: 0.51697 \nEpoch: 627  | Training Loss: 0.24909 \nEpoch: 627  | Validation balanced accuracy : 0.50000 \nEpoch: 628  | Training Loss: 0.66809 \nEpoch: 628  | Training Loss: 0.68711 \nEpoch: 628  | Training Loss: 0.56930 \nEpoch: 628  | Training Loss: 0.51692 \nEpoch: 628  | Training Loss: 0.24896 \nEpoch: 628  | Validation balanced accuracy : 0.50000 \nEpoch: 629  | Training Loss: 0.66798 \nEpoch: 629  | Training Loss: 0.68704 \nEpoch: 629  | Training Loss: 0.56921 \nEpoch: 629  | Training Loss: 0.51687 \nEpoch: 629  | Training Loss: 0.24884 \nEpoch: 629  | Validation balanced accuracy : 0.50000 \nEpoch: 630  | Training Loss: 0.66785 \nEpoch: 630  | Training Loss: 0.68697 \nEpoch: 630  | Training Loss: 0.56912 \nEpoch: 630  | Training Loss: 0.51683 \nEpoch: 630  | Training Loss: 0.24871 \nEpoch: 630  | Validation balanced accuracy : 0.50000 \nEpoch: 631  | Training Loss: 0.66773 \nEpoch: 631  | Training Loss: 0.68690 \nEpoch: 631  | Training Loss: 0.56902 \nEpoch: 631  | Training Loss: 0.51678 \nEpoch: 631  | Training Loss: 0.24858 \nEpoch: 631  | Validation balanced accuracy : 0.50000 \nEpoch: 632  | Training Loss: 0.66761 \nEpoch: 632  | Training Loss: 0.68683 \nEpoch: 632  | Training Loss: 0.56893 \nEpoch: 632  | Training Loss: 0.51673 \nEpoch: 632  | Training Loss: 0.24845 \nEpoch: 632  | Validation balanced accuracy : 0.50000 \nEpoch: 633  | Training Loss: 0.66749 \nEpoch: 633  | Training Loss: 0.68676 \nEpoch: 633  | Training Loss: 0.56883 \nEpoch: 633  | Training Loss: 0.51668 \nEpoch: 633  | Training Loss: 0.24832 \nEpoch: 633  | Validation balanced accuracy : 0.50000 \nEpoch: 634  | Training Loss: 0.66737 \nEpoch: 634  | Training Loss: 0.68669 \nEpoch: 634  | Training Loss: 0.56873 \nEpoch: 634  | Training Loss: 0.51664 \nEpoch: 634  | Training Loss: 0.24819 \nEpoch: 634  | Validation balanced accuracy : 0.50000 \nEpoch: 635  | Training Loss: 0.66725 \nEpoch: 635  | Training Loss: 0.68662 \nEpoch: 635  | Training Loss: 0.56864 \nEpoch: 635  | Training Loss: 0.51659 \nEpoch: 635  | Training Loss: 0.24806 \nEpoch: 635  | Validation balanced accuracy : 0.50000 \nEpoch: 636  | Training Loss: 0.66712 \nEpoch: 636  | Training Loss: 0.68654 \nEpoch: 636  | Training Loss: 0.56854 \nEpoch: 636  | Training Loss: 0.51654 \nEpoch: 636  | Training Loss: 0.24792 \nEpoch: 636  | Validation balanced accuracy : 0.50000 \nEpoch: 637  | Training Loss: 0.66700 \nEpoch: 637  | Training Loss: 0.68647 \nEpoch: 637  | Training Loss: 0.56844 \nEpoch: 637  | Training Loss: 0.51649 \nEpoch: 637  | Training Loss: 0.24779 \nEpoch: 637  | Validation balanced accuracy : 0.50000 \nEpoch: 638  | Training Loss: 0.66688 \nEpoch: 638  | Training Loss: 0.68640 \nEpoch: 638  | Training Loss: 0.56835 \nEpoch: 638  | Training Loss: 0.51645 \nEpoch: 638  | Training Loss: 0.24766 \nEpoch: 638  | Validation balanced accuracy : 0.50000 \nEpoch: 639  | Training Loss: 0.66675 \nEpoch: 639  | Training Loss: 0.68633 \nEpoch: 639  | Training Loss: 0.56825 \nEpoch: 639  | Training Loss: 0.51640 \nEpoch: 639  | Training Loss: 0.24753 \nEpoch: 639  | Validation balanced accuracy : 0.50000 \nEpoch: 640  | Training Loss: 0.66663 \nEpoch: 640  | Training Loss: 0.68625 \nEpoch: 640  | Training Loss: 0.56815 \nEpoch: 640  | Training Loss: 0.51635 \nEpoch: 640  | Training Loss: 0.24740 \nEpoch: 640  | Validation balanced accuracy : 0.50000 \nEpoch: 641  | Training Loss: 0.66651 \nEpoch: 641  | Training Loss: 0.68618 \nEpoch: 641  | Training Loss: 0.56805 \nEpoch: 641  | Training Loss: 0.51630 \nEpoch: 641  | Training Loss: 0.24727 \nEpoch: 641  | Validation balanced accuracy : 0.50000 \nEpoch: 642  | Training Loss: 0.66638 \nEpoch: 642  | Training Loss: 0.68610 \nEpoch: 642  | Training Loss: 0.56795 \nEpoch: 642  | Training Loss: 0.51625 \nEpoch: 642  | Training Loss: 0.24713 \nEpoch: 642  | Validation balanced accuracy : 0.50000 \nEpoch: 643  | Training Loss: 0.66625 \nEpoch: 643  | Training Loss: 0.68603 \nEpoch: 643  | Training Loss: 0.56785 \nEpoch: 643  | Training Loss: 0.51620 \nEpoch: 643  | Training Loss: 0.24700 \nEpoch: 643  | Validation balanced accuracy : 0.50000 \nEpoch: 644  | Training Loss: 0.66613 \nEpoch: 644  | Training Loss: 0.68596 \nEpoch: 644  | Training Loss: 0.56775 \nEpoch: 644  | Training Loss: 0.51615 \nEpoch: 644  | Training Loss: 0.24687 \nEpoch: 644  | Validation balanced accuracy : 0.50000 \nEpoch: 645  | Training Loss: 0.66600 \nEpoch: 645  | Training Loss: 0.68588 \nEpoch: 645  | Training Loss: 0.56765 \nEpoch: 645  | Training Loss: 0.51610 \nEpoch: 645  | Training Loss: 0.24674 \nEpoch: 645  | Validation balanced accuracy : 0.50000 \nEpoch: 646  | Training Loss: 0.66588 \nEpoch: 646  | Training Loss: 0.68581 \nEpoch: 646  | Training Loss: 0.56755 \nEpoch: 646  | Training Loss: 0.51605 \nEpoch: 646  | Training Loss: 0.24660 \nEpoch: 646  | Validation balanced accuracy : 0.50000 \nEpoch: 647  | Training Loss: 0.66575 \nEpoch: 647  | Training Loss: 0.68573 \nEpoch: 647  | Training Loss: 0.56745 \nEpoch: 647  | Training Loss: 0.51600 \nEpoch: 647  | Training Loss: 0.24647 \nEpoch: 647  | Validation balanced accuracy : 0.50000 \nEpoch: 648  | Training Loss: 0.66562 \nEpoch: 648  | Training Loss: 0.68565 \nEpoch: 648  | Training Loss: 0.56735 \nEpoch: 648  | Training Loss: 0.51595 \nEpoch: 648  | Training Loss: 0.24633 \nEpoch: 648  | Validation balanced accuracy : 0.50000 \nEpoch: 649  | Training Loss: 0.66549 \nEpoch: 649  | Training Loss: 0.68558 \nEpoch: 649  | Training Loss: 0.56725 \nEpoch: 649  | Training Loss: 0.51590 \nEpoch: 649  | Training Loss: 0.24620 \nEpoch: 649  | Validation balanced accuracy : 0.50000 \nEpoch: 650  | Training Loss: 0.66536 \nEpoch: 650  | Training Loss: 0.68550 \nEpoch: 650  | Training Loss: 0.56715 \nEpoch: 650  | Training Loss: 0.51585 \nEpoch: 650  | Training Loss: 0.24607 \nEpoch: 650  | Validation balanced accuracy : 0.50000 \nEpoch: 651  | Training Loss: 0.66523 \nEpoch: 651  | Training Loss: 0.68542 \nEpoch: 651  | Training Loss: 0.56705 \nEpoch: 651  | Training Loss: 0.51580 \nEpoch: 651  | Training Loss: 0.24593 \nEpoch: 651  | Validation balanced accuracy : 0.50000 \nEpoch: 652  | Training Loss: 0.66511 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 652  | Training Loss: 0.68535 \nEpoch: 652  | Training Loss: 0.56695 \nEpoch: 652  | Training Loss: 0.51575 \nEpoch: 652  | Training Loss: 0.24580 \nEpoch: 652  | Validation balanced accuracy : 0.50000 \nEpoch: 653  | Training Loss: 0.66497 \nEpoch: 653  | Training Loss: 0.68527 \nEpoch: 653  | Training Loss: 0.56684 \nEpoch: 653  | Training Loss: 0.51570 \nEpoch: 653  | Training Loss: 0.24566 \nEpoch: 653  | Validation balanced accuracy : 0.50000 \nEpoch: 654  | Training Loss: 0.66484 \nEpoch: 654  | Training Loss: 0.68519 \nEpoch: 654  | Training Loss: 0.56674 \nEpoch: 654  | Training Loss: 0.51565 \nEpoch: 654  | Training Loss: 0.24552 \nEpoch: 654  | Validation balanced accuracy : 0.50000 \nEpoch: 655  | Training Loss: 0.66471 \nEpoch: 655  | Training Loss: 0.68511 \nEpoch: 655  | Training Loss: 0.56664 \nEpoch: 655  | Training Loss: 0.51560 \nEpoch: 655  | Training Loss: 0.24539 \nEpoch: 655  | Validation balanced accuracy : 0.50000 \nEpoch: 656  | Training Loss: 0.66458 \nEpoch: 656  | Training Loss: 0.68504 \nEpoch: 656  | Training Loss: 0.56654 \nEpoch: 656  | Training Loss: 0.51554 \nEpoch: 656  | Training Loss: 0.24525 \nEpoch: 656  | Validation balanced accuracy : 0.50000 \nEpoch: 657  | Training Loss: 0.66445 \nEpoch: 657  | Training Loss: 0.68496 \nEpoch: 657  | Training Loss: 0.56643 \nEpoch: 657  | Training Loss: 0.51549 \nEpoch: 657  | Training Loss: 0.24512 \nEpoch: 657  | Validation balanced accuracy : 0.50000 \nEpoch: 658  | Training Loss: 0.66432 \nEpoch: 658  | Training Loss: 0.68488 \nEpoch: 658  | Training Loss: 0.56633 \nEpoch: 658  | Training Loss: 0.51544 \nEpoch: 658  | Training Loss: 0.24498 \nEpoch: 658  | Validation balanced accuracy : 0.50000 \nEpoch: 659  | Training Loss: 0.66418 \nEpoch: 659  | Training Loss: 0.68480 \nEpoch: 659  | Training Loss: 0.56622 \nEpoch: 659  | Training Loss: 0.51539 \nEpoch: 659  | Training Loss: 0.24484 \nEpoch: 659  | Validation balanced accuracy : 0.50000 \nEpoch: 660  | Training Loss: 0.66405 \nEpoch: 660  | Training Loss: 0.68472 \nEpoch: 660  | Training Loss: 0.56612 \nEpoch: 660  | Training Loss: 0.51534 \nEpoch: 660  | Training Loss: 0.24470 \nEpoch: 660  | Validation balanced accuracy : 0.50000 \nEpoch: 661  | Training Loss: 0.66392 \nEpoch: 661  | Training Loss: 0.68464 \nEpoch: 661  | Training Loss: 0.56601 \nEpoch: 661  | Training Loss: 0.51528 \nEpoch: 661  | Training Loss: 0.24456 \nEpoch: 661  | Validation balanced accuracy : 0.50000 \nEpoch: 662  | Training Loss: 0.66378 \nEpoch: 662  | Training Loss: 0.68456 \nEpoch: 662  | Training Loss: 0.56591 \nEpoch: 662  | Training Loss: 0.51523 \nEpoch: 662  | Training Loss: 0.24443 \nEpoch: 662  | Validation balanced accuracy : 0.50000 \nEpoch: 663  | Training Loss: 0.66365 \nEpoch: 663  | Training Loss: 0.68448 \nEpoch: 663  | Training Loss: 0.56580 \nEpoch: 663  | Training Loss: 0.51518 \nEpoch: 663  | Training Loss: 0.24429 \nEpoch: 663  | Validation balanced accuracy : 0.50000 \nEpoch: 664  | Training Loss: 0.66351 \nEpoch: 664  | Training Loss: 0.68439 \nEpoch: 664  | Training Loss: 0.56569 \nEpoch: 664  | Training Loss: 0.51512 \nEpoch: 664  | Training Loss: 0.24415 \nEpoch: 664  | Validation balanced accuracy : 0.50000 \nEpoch: 665  | Training Loss: 0.66338 \nEpoch: 665  | Training Loss: 0.68431 \nEpoch: 665  | Training Loss: 0.56559 \nEpoch: 665  | Training Loss: 0.51507 \nEpoch: 665  | Training Loss: 0.24401 \nEpoch: 665  | Validation balanced accuracy : 0.50000 \nEpoch: 666  | Training Loss: 0.66324 \nEpoch: 666  | Training Loss: 0.68423 \nEpoch: 666  | Training Loss: 0.56548 \nEpoch: 666  | Training Loss: 0.51502 \nEpoch: 666  | Training Loss: 0.24387 \nEpoch: 666  | Validation balanced accuracy : 0.50000 \nEpoch: 667  | Training Loss: 0.66310 \nEpoch: 667  | Training Loss: 0.68415 \nEpoch: 667  | Training Loss: 0.56537 \nEpoch: 667  | Training Loss: 0.51496 \nEpoch: 667  | Training Loss: 0.24373 \nEpoch: 667  | Validation balanced accuracy : 0.50000 \nEpoch: 668  | Training Loss: 0.66297 \nEpoch: 668  | Training Loss: 0.68406 \nEpoch: 668  | Training Loss: 0.56526 \nEpoch: 668  | Training Loss: 0.51491 \nEpoch: 668  | Training Loss: 0.24359 \nEpoch: 668  | Validation balanced accuracy : 0.50000 \nEpoch: 669  | Training Loss: 0.66283 \nEpoch: 669  | Training Loss: 0.68398 \nEpoch: 669  | Training Loss: 0.56515 \nEpoch: 669  | Training Loss: 0.51486 \nEpoch: 669  | Training Loss: 0.24345 \nEpoch: 669  | Validation balanced accuracy : 0.50000 \nEpoch: 670  | Training Loss: 0.66269 \nEpoch: 670  | Training Loss: 0.68390 \nEpoch: 670  | Training Loss: 0.56504 \nEpoch: 670  | Training Loss: 0.51480 \nEpoch: 670  | Training Loss: 0.24331 \nEpoch: 670  | Validation balanced accuracy : 0.50000 \nEpoch: 671  | Training Loss: 0.66255 \nEpoch: 671  | Training Loss: 0.68381 \nEpoch: 671  | Training Loss: 0.56494 \nEpoch: 671  | Training Loss: 0.51475 \nEpoch: 671  | Training Loss: 0.24317 \nEpoch: 671  | Validation balanced accuracy : 0.50000 \nEpoch: 672  | Training Loss: 0.66241 \nEpoch: 672  | Training Loss: 0.68373 \nEpoch: 672  | Training Loss: 0.56483 \nEpoch: 672  | Training Loss: 0.51469 \nEpoch: 672  | Training Loss: 0.24303 \nEpoch: 672  | Validation balanced accuracy : 0.50000 \nEpoch: 673  | Training Loss: 0.66227 \nEpoch: 673  | Training Loss: 0.68364 \nEpoch: 673  | Training Loss: 0.56471 \nEpoch: 673  | Training Loss: 0.51464 \nEpoch: 673  | Training Loss: 0.24289 \nEpoch: 673  | Validation balanced accuracy : 0.50000 \nEpoch: 674  | Training Loss: 0.66213 \nEpoch: 674  | Training Loss: 0.68356 \nEpoch: 674  | Training Loss: 0.56460 \nEpoch: 674  | Training Loss: 0.51458 \nEpoch: 674  | Training Loss: 0.24275 \nEpoch: 674  | Validation balanced accuracy : 0.50000 \nEpoch: 675  | Training Loss: 0.66199 \nEpoch: 675  | Training Loss: 0.68347 \nEpoch: 675  | Training Loss: 0.56449 \nEpoch: 675  | Training Loss: 0.51453 \nEpoch: 675  | Training Loss: 0.24260 \nEpoch: 675  | Validation balanced accuracy : 0.50000 \nEpoch: 676  | Training Loss: 0.66185 \nEpoch: 676  | Training Loss: 0.68339 \nEpoch: 676  | Training Loss: 0.56438 \nEpoch: 676  | Training Loss: 0.51447 \nEpoch: 676  | Training Loss: 0.24246 \nEpoch: 676  | Validation balanced accuracy : 0.50000 \nEpoch: 677  | Training Loss: 0.66171 \nEpoch: 677  | Training Loss: 0.68330 \nEpoch: 677  | Training Loss: 0.56427 \nEpoch: 677  | Training Loss: 0.51441 \nEpoch: 677  | Training Loss: 0.24232 \nEpoch: 677  | Validation balanced accuracy : 0.50000 \nEpoch: 678  | Training Loss: 0.66157 \nEpoch: 678  | Training Loss: 0.68321 \nEpoch: 678  | Training Loss: 0.56416 \nEpoch: 678  | Training Loss: 0.51436 \nEpoch: 678  | Training Loss: 0.24218 \nEpoch: 678  | Validation balanced accuracy : 0.50000 \nEpoch: 679  | Training Loss: 0.66142 \nEpoch: 679  | Training Loss: 0.68313 \nEpoch: 679  | Training Loss: 0.56404 \nEpoch: 679  | Training Loss: 0.51430 \nEpoch: 679  | Training Loss: 0.24203 \nEpoch: 679  | Validation balanced accuracy : 0.50000 \nEpoch: 680  | Training Loss: 0.66128 \nEpoch: 680  | Training Loss: 0.68304 \nEpoch: 680  | Training Loss: 0.56393 \nEpoch: 680  | Training Loss: 0.51424 \nEpoch: 680  | Training Loss: 0.24189 \nEpoch: 680  | Validation balanced accuracy : 0.50000 \nEpoch: 681  | Training Loss: 0.66113 \nEpoch: 681  | Training Loss: 0.68295 \nEpoch: 681  | Training Loss: 0.56382 \nEpoch: 681  | Training Loss: 0.51419 \nEpoch: 681  | Training Loss: 0.24175 \nEpoch: 681  | Validation balanced accuracy : 0.50000 \nEpoch: 682  | Training Loss: 0.66099 \nEpoch: 682  | Training Loss: 0.68286 \nEpoch: 682  | Training Loss: 0.56370 \nEpoch: 682  | Training Loss: 0.51413 \nEpoch: 682  | Training Loss: 0.24160 \nEpoch: 682  | Validation balanced accuracy : 0.50000 \nEpoch: 683  | Training Loss: 0.66084 \nEpoch: 683  | Training Loss: 0.68277 \nEpoch: 683  | Training Loss: 0.56359 \nEpoch: 683  | Training Loss: 0.51407 \nEpoch: 683  | Training Loss: 0.24146 \nEpoch: 683  | Validation balanced accuracy : 0.50000 \nEpoch: 684  | Training Loss: 0.66070 \nEpoch: 684  | Training Loss: 0.68268 \nEpoch: 684  | Training Loss: 0.56347 \nEpoch: 684  | Training Loss: 0.51402 \nEpoch: 684  | Training Loss: 0.24131 \nEpoch: 684  | Validation balanced accuracy : 0.50000 \nEpoch: 685  | Training Loss: 0.66055 \nEpoch: 685  | Training Loss: 0.68259 \nEpoch: 685  | Training Loss: 0.56336 \nEpoch: 685  | Training Loss: 0.51396 \nEpoch: 685  | Training Loss: 0.24117 \nEpoch: 685  | Validation balanced accuracy : 0.50000 \nEpoch: 686  | Training Loss: 0.66041 \nEpoch: 686  | Training Loss: 0.68251 \nEpoch: 686  | Training Loss: 0.56324 \nEpoch: 686  | Training Loss: 0.51390 \nEpoch: 686  | Training Loss: 0.24102 \nEpoch: 686  | Validation balanced accuracy : 0.50000 \nEpoch: 687  | Training Loss: 0.66026 \nEpoch: 687  | Training Loss: 0.68242 \nEpoch: 687  | Training Loss: 0.56313 \nEpoch: 687  | Training Loss: 0.51384 \nEpoch: 687  | Training Loss: 0.24087 \nEpoch: 687  | Validation balanced accuracy : 0.50000 \nEpoch: 688  | Training Loss: 0.66011 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 688  | Training Loss: 0.68232 \nEpoch: 688  | Training Loss: 0.56301 \nEpoch: 688  | Training Loss: 0.51378 \nEpoch: 688  | Training Loss: 0.24073 \nEpoch: 688  | Validation balanced accuracy : 0.50000 \nEpoch: 689  | Training Loss: 0.65996 \nEpoch: 689  | Training Loss: 0.68223 \nEpoch: 689  | Training Loss: 0.56289 \nEpoch: 689  | Training Loss: 0.51372 \nEpoch: 689  | Training Loss: 0.24058 \nEpoch: 689  | Validation balanced accuracy : 0.50000 \nEpoch: 690  | Training Loss: 0.65981 \nEpoch: 690  | Training Loss: 0.68214 \nEpoch: 690  | Training Loss: 0.56278 \nEpoch: 690  | Training Loss: 0.51366 \nEpoch: 690  | Training Loss: 0.24044 \nEpoch: 690  | Validation balanced accuracy : 0.50000 \nEpoch: 691  | Training Loss: 0.65966 \nEpoch: 691  | Training Loss: 0.68205 \nEpoch: 691  | Training Loss: 0.56266 \nEpoch: 691  | Training Loss: 0.51361 \nEpoch: 691  | Training Loss: 0.24029 \nEpoch: 691  | Validation balanced accuracy : 0.50000 \nEpoch: 692  | Training Loss: 0.65951 \nEpoch: 692  | Training Loss: 0.68195 \nEpoch: 692  | Training Loss: 0.56254 \nEpoch: 692  | Training Loss: 0.51355 \nEpoch: 692  | Training Loss: 0.24014 \nEpoch: 692  | Validation balanced accuracy : 0.50000 \nEpoch: 693  | Training Loss: 0.65936 \nEpoch: 693  | Training Loss: 0.68186 \nEpoch: 693  | Training Loss: 0.56242 \nEpoch: 693  | Training Loss: 0.51349 \nEpoch: 693  | Training Loss: 0.23999 \nEpoch: 693  | Validation balanced accuracy : 0.50000 \nEpoch: 694  | Training Loss: 0.65921 \nEpoch: 694  | Training Loss: 0.68177 \nEpoch: 694  | Training Loss: 0.56230 \nEpoch: 694  | Training Loss: 0.51343 \nEpoch: 694  | Training Loss: 0.23984 \nEpoch: 694  | Validation balanced accuracy : 0.50000 \nEpoch: 695  | Training Loss: 0.65905 \nEpoch: 695  | Training Loss: 0.68167 \nEpoch: 695  | Training Loss: 0.56218 \nEpoch: 695  | Training Loss: 0.51337 \nEpoch: 695  | Training Loss: 0.23970 \nEpoch: 695  | Validation balanced accuracy : 0.50000 \nEpoch: 696  | Training Loss: 0.65890 \nEpoch: 696  | Training Loss: 0.68158 \nEpoch: 696  | Training Loss: 0.56206 \nEpoch: 696  | Training Loss: 0.51330 \nEpoch: 696  | Training Loss: 0.23955 \nEpoch: 696  | Validation balanced accuracy : 0.50000 \nEpoch: 697  | Training Loss: 0.65875 \nEpoch: 697  | Training Loss: 0.68148 \nEpoch: 697  | Training Loss: 0.56194 \nEpoch: 697  | Training Loss: 0.51324 \nEpoch: 697  | Training Loss: 0.23940 \nEpoch: 697  | Validation balanced accuracy : 0.50000 \nEpoch: 698  | Training Loss: 0.65859 \nEpoch: 698  | Training Loss: 0.68139 \nEpoch: 698  | Training Loss: 0.56182 \nEpoch: 698  | Training Loss: 0.51318 \nEpoch: 698  | Training Loss: 0.23925 \nEpoch: 698  | Validation balanced accuracy : 0.50000 \nEpoch: 699  | Training Loss: 0.65844 \nEpoch: 699  | Training Loss: 0.68129 \nEpoch: 699  | Training Loss: 0.56170 \nEpoch: 699  | Training Loss: 0.51312 \nEpoch: 699  | Training Loss: 0.23910 \nEpoch: 699  | Validation balanced accuracy : 0.50000 \nEpoch: 700  | Training Loss: 0.65828 \nEpoch: 700  | Training Loss: 0.68120 \nEpoch: 700  | Training Loss: 0.56157 \nEpoch: 700  | Training Loss: 0.51306 \nEpoch: 700  | Training Loss: 0.23895 \nEpoch: 700  | Validation balanced accuracy : 0.50000 \nEpoch: 701  | Training Loss: 0.65813 \nEpoch: 701  | Training Loss: 0.68110 \nEpoch: 701  | Training Loss: 0.56145 \nEpoch: 701  | Training Loss: 0.51300 \nEpoch: 701  | Training Loss: 0.23880 \nEpoch: 701  | Validation balanced accuracy : 0.50000 \nEpoch: 702  | Training Loss: 0.65797 \nEpoch: 702  | Training Loss: 0.68100 \nEpoch: 702  | Training Loss: 0.56133 \nEpoch: 702  | Training Loss: 0.51294 \nEpoch: 702  | Training Loss: 0.23865 \nEpoch: 702  | Validation balanced accuracy : 0.50000 \nEpoch: 703  | Training Loss: 0.65781 \nEpoch: 703  | Training Loss: 0.68090 \nEpoch: 703  | Training Loss: 0.56120 \nEpoch: 703  | Training Loss: 0.51287 \nEpoch: 703  | Training Loss: 0.23850 \nEpoch: 703  | Validation balanced accuracy : 0.50000 \nEpoch: 704  | Training Loss: 0.65765 \nEpoch: 704  | Training Loss: 0.68081 \nEpoch: 704  | Training Loss: 0.56108 \nEpoch: 704  | Training Loss: 0.51281 \nEpoch: 704  | Training Loss: 0.23834 \nEpoch: 704  | Validation balanced accuracy : 0.50000 \nEpoch: 705  | Training Loss: 0.65750 \nEpoch: 705  | Training Loss: 0.68071 \nEpoch: 705  | Training Loss: 0.56095 \nEpoch: 705  | Training Loss: 0.51275 \nEpoch: 705  | Training Loss: 0.23819 \nEpoch: 705  | Validation balanced accuracy : 0.50000 \nEpoch: 706  | Training Loss: 0.65734 \nEpoch: 706  | Training Loss: 0.68061 \nEpoch: 706  | Training Loss: 0.56083 \nEpoch: 706  | Training Loss: 0.51268 \nEpoch: 706  | Training Loss: 0.23804 \nEpoch: 706  | Validation balanced accuracy : 0.50000 \nEpoch: 707  | Training Loss: 0.65718 \nEpoch: 707  | Training Loss: 0.68051 \nEpoch: 707  | Training Loss: 0.56070 \nEpoch: 707  | Training Loss: 0.51262 \nEpoch: 707  | Training Loss: 0.23789 \nEpoch: 707  | Validation balanced accuracy : 0.50000 \nEpoch: 708  | Training Loss: 0.65702 \nEpoch: 708  | Training Loss: 0.68041 \nEpoch: 708  | Training Loss: 0.56057 \nEpoch: 708  | Training Loss: 0.51256 \nEpoch: 708  | Training Loss: 0.23774 \nEpoch: 708  | Validation balanced accuracy : 0.50000 \nEpoch: 709  | Training Loss: 0.65685 \nEpoch: 709  | Training Loss: 0.68031 \nEpoch: 709  | Training Loss: 0.56045 \nEpoch: 709  | Training Loss: 0.51249 \nEpoch: 709  | Training Loss: 0.23758 \nEpoch: 709  | Validation balanced accuracy : 0.50000 \nEpoch: 710  | Training Loss: 0.65669 \nEpoch: 710  | Training Loss: 0.68020 \nEpoch: 710  | Training Loss: 0.56032 \nEpoch: 710  | Training Loss: 0.51243 \nEpoch: 710  | Training Loss: 0.23743 \nEpoch: 710  | Validation balanced accuracy : 0.50000 \nEpoch: 711  | Training Loss: 0.65653 \nEpoch: 711  | Training Loss: 0.68010 \nEpoch: 711  | Training Loss: 0.56019 \nEpoch: 711  | Training Loss: 0.51236 \nEpoch: 711  | Training Loss: 0.23728 \nEpoch: 711  | Validation balanced accuracy : 0.50000 \nEpoch: 712  | Training Loss: 0.65637 \nEpoch: 712  | Training Loss: 0.68000 \nEpoch: 712  | Training Loss: 0.56006 \nEpoch: 712  | Training Loss: 0.51230 \nEpoch: 712  | Training Loss: 0.23712 \nEpoch: 712  | Validation balanced accuracy : 0.50000 \nEpoch: 713  | Training Loss: 0.65620 \nEpoch: 713  | Training Loss: 0.67990 \nEpoch: 713  | Training Loss: 0.55993 \nEpoch: 713  | Training Loss: 0.51223 \nEpoch: 713  | Training Loss: 0.23697 \nEpoch: 713  | Validation balanced accuracy : 0.50000 \nEpoch: 714  | Training Loss: 0.65604 \nEpoch: 714  | Training Loss: 0.67979 \nEpoch: 714  | Training Loss: 0.55980 \nEpoch: 714  | Training Loss: 0.51217 \nEpoch: 714  | Training Loss: 0.23681 \nEpoch: 714  | Validation balanced accuracy : 0.50000 \nEpoch: 715  | Training Loss: 0.65587 \nEpoch: 715  | Training Loss: 0.67969 \nEpoch: 715  | Training Loss: 0.55967 \nEpoch: 715  | Training Loss: 0.51210 \nEpoch: 715  | Training Loss: 0.23666 \nEpoch: 715  | Validation balanced accuracy : 0.50000 \nEpoch: 716  | Training Loss: 0.65570 \nEpoch: 716  | Training Loss: 0.67958 \nEpoch: 716  | Training Loss: 0.55954 \nEpoch: 716  | Training Loss: 0.51203 \nEpoch: 716  | Training Loss: 0.23650 \nEpoch: 716  | Validation balanced accuracy : 0.50000 \nEpoch: 717  | Training Loss: 0.65554 \nEpoch: 717  | Training Loss: 0.67948 \nEpoch: 717  | Training Loss: 0.55941 \nEpoch: 717  | Training Loss: 0.51197 \nEpoch: 717  | Training Loss: 0.23635 \nEpoch: 717  | Validation balanced accuracy : 0.50000 \nEpoch: 718  | Training Loss: 0.65537 \nEpoch: 718  | Training Loss: 0.67937 \nEpoch: 718  | Training Loss: 0.55928 \nEpoch: 718  | Training Loss: 0.51190 \nEpoch: 718  | Training Loss: 0.23619 \nEpoch: 718  | Validation balanced accuracy : 0.50000 \nEpoch: 719  | Training Loss: 0.65520 \nEpoch: 719  | Training Loss: 0.67927 \nEpoch: 719  | Training Loss: 0.55915 \nEpoch: 719  | Training Loss: 0.51183 \nEpoch: 719  | Training Loss: 0.23603 \nEpoch: 719  | Validation balanced accuracy : 0.50000 \nEpoch: 720  | Training Loss: 0.65503 \nEpoch: 720  | Training Loss: 0.67916 \nEpoch: 720  | Training Loss: 0.55901 \nEpoch: 720  | Training Loss: 0.51177 \nEpoch: 720  | Training Loss: 0.23587 \nEpoch: 720  | Validation balanced accuracy : 0.50000 \nEpoch: 721  | Training Loss: 0.65486 \nEpoch: 721  | Training Loss: 0.67905 \nEpoch: 721  | Training Loss: 0.55888 \nEpoch: 721  | Training Loss: 0.51170 \nEpoch: 721  | Training Loss: 0.23572 \nEpoch: 721  | Validation balanced accuracy : 0.50000 \nEpoch: 722  | Training Loss: 0.65469 \nEpoch: 722  | Training Loss: 0.67894 \nEpoch: 722  | Training Loss: 0.55875 \nEpoch: 722  | Training Loss: 0.51163 \nEpoch: 722  | Training Loss: 0.23556 \nEpoch: 722  | Validation balanced accuracy : 0.50000 \nEpoch: 723  | Training Loss: 0.65452 \nEpoch: 723  | Training Loss: 0.67884 \nEpoch: 723  | Training Loss: 0.55861 \nEpoch: 723  | Training Loss: 0.51156 \nEpoch: 723  | Training Loss: 0.23540 \nEpoch: 723  | Validation balanced accuracy : 0.50000 \nEpoch: 724  | Training Loss: 0.65435 \nEpoch: 724  | Training Loss: 0.67873 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 724  | Training Loss: 0.55847 \nEpoch: 724  | Training Loss: 0.51149 \nEpoch: 724  | Training Loss: 0.23524 \nEpoch: 724  | Validation balanced accuracy : 0.50000 \nEpoch: 725  | Training Loss: 0.65417 \nEpoch: 725  | Training Loss: 0.67862 \nEpoch: 725  | Training Loss: 0.55834 \nEpoch: 725  | Training Loss: 0.51142 \nEpoch: 725  | Training Loss: 0.23508 \nEpoch: 725  | Validation balanced accuracy : 0.50000 \nEpoch: 726  | Training Loss: 0.65400 \nEpoch: 726  | Training Loss: 0.67851 \nEpoch: 726  | Training Loss: 0.55820 \nEpoch: 726  | Training Loss: 0.51135 \nEpoch: 726  | Training Loss: 0.23493 \nEpoch: 726  | Validation balanced accuracy : 0.50000 \nEpoch: 727  | Training Loss: 0.65382 \nEpoch: 727  | Training Loss: 0.67840 \nEpoch: 727  | Training Loss: 0.55806 \nEpoch: 727  | Training Loss: 0.51129 \nEpoch: 727  | Training Loss: 0.23477 \nEpoch: 727  | Validation balanced accuracy : 0.50000 \nEpoch: 728  | Training Loss: 0.65365 \nEpoch: 728  | Training Loss: 0.67828 \nEpoch: 728  | Training Loss: 0.55793 \nEpoch: 728  | Training Loss: 0.51121 \nEpoch: 728  | Training Loss: 0.23461 \nEpoch: 728  | Validation balanced accuracy : 0.50000 \nEpoch: 729  | Training Loss: 0.65347 \nEpoch: 729  | Training Loss: 0.67817 \nEpoch: 729  | Training Loss: 0.55779 \nEpoch: 729  | Training Loss: 0.51114 \nEpoch: 729  | Training Loss: 0.23445 \nEpoch: 729  | Validation balanced accuracy : 0.50000 \nEpoch: 730  | Training Loss: 0.65330 \nEpoch: 730  | Training Loss: 0.67806 \nEpoch: 730  | Training Loss: 0.55765 \nEpoch: 730  | Training Loss: 0.51107 \nEpoch: 730  | Training Loss: 0.23429 \nEpoch: 730  | Validation balanced accuracy : 0.50000 \nEpoch: 731  | Training Loss: 0.65312 \nEpoch: 731  | Training Loss: 0.67795 \nEpoch: 731  | Training Loss: 0.55751 \nEpoch: 731  | Training Loss: 0.51100 \nEpoch: 731  | Training Loss: 0.23413 \nEpoch: 731  | Validation balanced accuracy : 0.50000 \nEpoch: 732  | Training Loss: 0.65294 \nEpoch: 732  | Training Loss: 0.67783 \nEpoch: 732  | Training Loss: 0.55737 \nEpoch: 732  | Training Loss: 0.51093 \nEpoch: 732  | Training Loss: 0.23396 \nEpoch: 732  | Validation balanced accuracy : 0.50000 \nEpoch: 733  | Training Loss: 0.65276 \nEpoch: 733  | Training Loss: 0.67772 \nEpoch: 733  | Training Loss: 0.55723 \nEpoch: 733  | Training Loss: 0.51086 \nEpoch: 733  | Training Loss: 0.23380 \nEpoch: 733  | Validation balanced accuracy : 0.50000 \nEpoch: 734  | Training Loss: 0.65258 \nEpoch: 734  | Training Loss: 0.67760 \nEpoch: 734  | Training Loss: 0.55709 \nEpoch: 734  | Training Loss: 0.51079 \nEpoch: 734  | Training Loss: 0.23364 \nEpoch: 734  | Validation balanced accuracy : 0.50000 \nEpoch: 735  | Training Loss: 0.65240 \nEpoch: 735  | Training Loss: 0.67749 \nEpoch: 735  | Training Loss: 0.55694 \nEpoch: 735  | Training Loss: 0.51071 \nEpoch: 735  | Training Loss: 0.23348 \nEpoch: 735  | Validation balanced accuracy : 0.50000 \nEpoch: 736  | Training Loss: 0.65222 \nEpoch: 736  | Training Loss: 0.67737 \nEpoch: 736  | Training Loss: 0.55680 \nEpoch: 736  | Training Loss: 0.51064 \nEpoch: 736  | Training Loss: 0.23331 \nEpoch: 736  | Validation balanced accuracy : 0.50000 \nEpoch: 737  | Training Loss: 0.65203 \nEpoch: 737  | Training Loss: 0.67725 \nEpoch: 737  | Training Loss: 0.55666 \nEpoch: 737  | Training Loss: 0.51057 \nEpoch: 737  | Training Loss: 0.23315 \nEpoch: 737  | Validation balanced accuracy : 0.50000 \nEpoch: 738  | Training Loss: 0.65185 \nEpoch: 738  | Training Loss: 0.67713 \nEpoch: 738  | Training Loss: 0.55651 \nEpoch: 738  | Training Loss: 0.51049 \nEpoch: 738  | Training Loss: 0.23299 \nEpoch: 738  | Validation balanced accuracy : 0.50000 \nEpoch: 739  | Training Loss: 0.65167 \nEpoch: 739  | Training Loss: 0.67702 \nEpoch: 739  | Training Loss: 0.55637 \nEpoch: 739  | Training Loss: 0.51042 \nEpoch: 739  | Training Loss: 0.23282 \nEpoch: 739  | Validation balanced accuracy : 0.50000 \nEpoch: 740  | Training Loss: 0.65148 \nEpoch: 740  | Training Loss: 0.67690 \nEpoch: 740  | Training Loss: 0.55622 \nEpoch: 740  | Training Loss: 0.51035 \nEpoch: 740  | Training Loss: 0.23266 \nEpoch: 740  | Validation balanced accuracy : 0.50000 \nEpoch: 741  | Training Loss: 0.65129 \nEpoch: 741  | Training Loss: 0.67678 \nEpoch: 741  | Training Loss: 0.55608 \nEpoch: 741  | Training Loss: 0.51027 \nEpoch: 741  | Training Loss: 0.23250 \nEpoch: 741  | Validation balanced accuracy : 0.50000 \nEpoch: 742  | Training Loss: 0.65111 \nEpoch: 742  | Training Loss: 0.67666 \nEpoch: 742  | Training Loss: 0.55593 \nEpoch: 742  | Training Loss: 0.51020 \nEpoch: 742  | Training Loss: 0.23233 \nEpoch: 742  | Validation balanced accuracy : 0.50000 \nEpoch: 743  | Training Loss: 0.65092 \nEpoch: 743  | Training Loss: 0.67654 \nEpoch: 743  | Training Loss: 0.55578 \nEpoch: 743  | Training Loss: 0.51012 \nEpoch: 743  | Training Loss: 0.23216 \nEpoch: 743  | Validation balanced accuracy : 0.50000 \nEpoch: 744  | Training Loss: 0.65073 \nEpoch: 744  | Training Loss: 0.67641 \nEpoch: 744  | Training Loss: 0.55563 \nEpoch: 744  | Training Loss: 0.51005 \nEpoch: 744  | Training Loss: 0.23200 \nEpoch: 744  | Validation balanced accuracy : 0.50000 \nEpoch: 745  | Training Loss: 0.65054 \nEpoch: 745  | Training Loss: 0.67629 \nEpoch: 745  | Training Loss: 0.55548 \nEpoch: 745  | Training Loss: 0.50997 \nEpoch: 745  | Training Loss: 0.23183 \nEpoch: 745  | Validation balanced accuracy : 0.50000 \nEpoch: 746  | Training Loss: 0.65035 \nEpoch: 746  | Training Loss: 0.67617 \nEpoch: 746  | Training Loss: 0.55533 \nEpoch: 746  | Training Loss: 0.50989 \nEpoch: 746  | Training Loss: 0.23167 \nEpoch: 746  | Validation balanced accuracy : 0.50000 \nEpoch: 747  | Training Loss: 0.65016 \nEpoch: 747  | Training Loss: 0.67604 \nEpoch: 747  | Training Loss: 0.55518 \nEpoch: 747  | Training Loss: 0.50982 \nEpoch: 747  | Training Loss: 0.23150 \nEpoch: 747  | Validation balanced accuracy : 0.50000 \nEpoch: 748  | Training Loss: 0.64996 \nEpoch: 748  | Training Loss: 0.67592 \nEpoch: 748  | Training Loss: 0.55503 \nEpoch: 748  | Training Loss: 0.50974 \nEpoch: 748  | Training Loss: 0.23133 \nEpoch: 748  | Validation balanced accuracy : 0.50000 \nEpoch: 749  | Training Loss: 0.64977 \nEpoch: 749  | Training Loss: 0.67579 \nEpoch: 749  | Training Loss: 0.55488 \nEpoch: 749  | Training Loss: 0.50966 \nEpoch: 749  | Training Loss: 0.23117 \nEpoch: 749  | Validation balanced accuracy : 0.50000 \nEpoch: 750  | Training Loss: 0.64958 \nEpoch: 750  | Training Loss: 0.67567 \nEpoch: 750  | Training Loss: 0.55473 \nEpoch: 750  | Training Loss: 0.50958 \nEpoch: 750  | Training Loss: 0.23100 \nEpoch: 750  | Validation balanced accuracy : 0.50000 \nEpoch: 751  | Training Loss: 0.64938 \nEpoch: 751  | Training Loss: 0.67554 \nEpoch: 751  | Training Loss: 0.55458 \nEpoch: 751  | Training Loss: 0.50950 \nEpoch: 751  | Training Loss: 0.23083 \nEpoch: 751  | Validation balanced accuracy : 0.50000 \nEpoch: 752  | Training Loss: 0.64918 \nEpoch: 752  | Training Loss: 0.67541 \nEpoch: 752  | Training Loss: 0.55442 \nEpoch: 752  | Training Loss: 0.50942 \nEpoch: 752  | Training Loss: 0.23066 \nEpoch: 752  | Validation balanced accuracy : 0.50000 \nEpoch: 753  | Training Loss: 0.64899 \nEpoch: 753  | Training Loss: 0.67529 \nEpoch: 753  | Training Loss: 0.55427 \nEpoch: 753  | Training Loss: 0.50934 \nEpoch: 753  | Training Loss: 0.23049 \nEpoch: 753  | Validation balanced accuracy : 0.50000 \nEpoch: 754  | Training Loss: 0.64879 \nEpoch: 754  | Training Loss: 0.67516 \nEpoch: 754  | Training Loss: 0.55411 \nEpoch: 754  | Training Loss: 0.50926 \nEpoch: 754  | Training Loss: 0.23032 \nEpoch: 754  | Validation balanced accuracy : 0.50000 \nEpoch: 755  | Training Loss: 0.64859 \nEpoch: 755  | Training Loss: 0.67503 \nEpoch: 755  | Training Loss: 0.55395 \nEpoch: 755  | Training Loss: 0.50918 \nEpoch: 755  | Training Loss: 0.23015 \nEpoch: 755  | Validation balanced accuracy : 0.50000 \nEpoch: 756  | Training Loss: 0.64839 \nEpoch: 756  | Training Loss: 0.67490 \nEpoch: 756  | Training Loss: 0.55380 \nEpoch: 756  | Training Loss: 0.50910 \nEpoch: 756  | Training Loss: 0.22998 \nEpoch: 756  | Validation balanced accuracy : 0.50000 \nEpoch: 757  | Training Loss: 0.64819 \nEpoch: 757  | Training Loss: 0.67476 \nEpoch: 757  | Training Loss: 0.55364 \nEpoch: 757  | Training Loss: 0.50902 \nEpoch: 757  | Training Loss: 0.22981 \nEpoch: 757  | Validation balanced accuracy : 0.50000 \nEpoch: 758  | Training Loss: 0.64799 \nEpoch: 758  | Training Loss: 0.67463 \nEpoch: 758  | Training Loss: 0.55348 \nEpoch: 758  | Training Loss: 0.50894 \nEpoch: 758  | Training Loss: 0.22964 \nEpoch: 758  | Validation balanced accuracy : 0.50000 \nEpoch: 759  | Training Loss: 0.64778 \nEpoch: 759  | Training Loss: 0.67450 \nEpoch: 759  | Training Loss: 0.55332 \nEpoch: 759  | Training Loss: 0.50886 \nEpoch: 759  | Training Loss: 0.22947 \nEpoch: 759  | Validation balanced accuracy : 0.50000 \nEpoch: 760  | Training Loss: 0.64758 \nEpoch: 760  | Training Loss: 0.67437 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 760  | Training Loss: 0.55316 \nEpoch: 760  | Training Loss: 0.50878 \nEpoch: 760  | Training Loss: 0.22930 \nEpoch: 760  | Validation balanced accuracy : 0.50000 \nEpoch: 761  | Training Loss: 0.64737 \nEpoch: 761  | Training Loss: 0.67423 \nEpoch: 761  | Training Loss: 0.55300 \nEpoch: 761  | Training Loss: 0.50869 \nEpoch: 761  | Training Loss: 0.22913 \nEpoch: 761  | Validation balanced accuracy : 0.50000 \nEpoch: 762  | Training Loss: 0.64717 \nEpoch: 762  | Training Loss: 0.67410 \nEpoch: 762  | Training Loss: 0.55284 \nEpoch: 762  | Training Loss: 0.50861 \nEpoch: 762  | Training Loss: 0.22896 \nEpoch: 762  | Validation balanced accuracy : 0.50000 \nEpoch: 763  | Training Loss: 0.64696 \nEpoch: 763  | Training Loss: 0.67396 \nEpoch: 763  | Training Loss: 0.55268 \nEpoch: 763  | Training Loss: 0.50853 \nEpoch: 763  | Training Loss: 0.22878 \nEpoch: 763  | Validation balanced accuracy : 0.50000 \nEpoch: 764  | Training Loss: 0.64675 \nEpoch: 764  | Training Loss: 0.67382 \nEpoch: 764  | Training Loss: 0.55251 \nEpoch: 764  | Training Loss: 0.50844 \nEpoch: 764  | Training Loss: 0.22861 \nEpoch: 764  | Validation balanced accuracy : 0.50000 \nEpoch: 765  | Training Loss: 0.64654 \nEpoch: 765  | Training Loss: 0.67368 \nEpoch: 765  | Training Loss: 0.55235 \nEpoch: 765  | Training Loss: 0.50836 \nEpoch: 765  | Training Loss: 0.22844 \nEpoch: 765  | Validation balanced accuracy : 0.50000 \nEpoch: 766  | Training Loss: 0.64633 \nEpoch: 766  | Training Loss: 0.67355 \nEpoch: 766  | Training Loss: 0.55218 \nEpoch: 766  | Training Loss: 0.50827 \nEpoch: 766  | Training Loss: 0.22826 \nEpoch: 766  | Validation balanced accuracy : 0.50000 \nEpoch: 767  | Training Loss: 0.64612 \nEpoch: 767  | Training Loss: 0.67341 \nEpoch: 767  | Training Loss: 0.55202 \nEpoch: 767  | Training Loss: 0.50819 \nEpoch: 767  | Training Loss: 0.22809 \nEpoch: 767  | Validation balanced accuracy : 0.50000 \nEpoch: 768  | Training Loss: 0.64591 \nEpoch: 768  | Training Loss: 0.67327 \nEpoch: 768  | Training Loss: 0.55185 \nEpoch: 768  | Training Loss: 0.50810 \nEpoch: 768  | Training Loss: 0.22792 \nEpoch: 768  | Validation balanced accuracy : 0.50000 \nEpoch: 769  | Training Loss: 0.64569 \nEpoch: 769  | Training Loss: 0.67312 \nEpoch: 769  | Training Loss: 0.55168 \nEpoch: 769  | Training Loss: 0.50801 \nEpoch: 769  | Training Loss: 0.22774 \nEpoch: 769  | Validation balanced accuracy : 0.50000 \nEpoch: 770  | Training Loss: 0.64548 \nEpoch: 770  | Training Loss: 0.67298 \nEpoch: 770  | Training Loss: 0.55152 \nEpoch: 770  | Training Loss: 0.50793 \nEpoch: 770  | Training Loss: 0.22757 \nEpoch: 770  | Validation balanced accuracy : 0.50000 \nEpoch: 771  | Training Loss: 0.64526 \nEpoch: 771  | Training Loss: 0.67284 \nEpoch: 771  | Training Loss: 0.55135 \nEpoch: 771  | Training Loss: 0.50784 \nEpoch: 771  | Training Loss: 0.22739 \nEpoch: 771  | Validation balanced accuracy : 0.50000 \nEpoch: 772  | Training Loss: 0.64504 \nEpoch: 772  | Training Loss: 0.67270 \nEpoch: 772  | Training Loss: 0.55118 \nEpoch: 772  | Training Loss: 0.50775 \nEpoch: 772  | Training Loss: 0.22721 \nEpoch: 772  | Validation balanced accuracy : 0.50000 \nEpoch: 773  | Training Loss: 0.64482 \nEpoch: 773  | Training Loss: 0.67255 \nEpoch: 773  | Training Loss: 0.55101 \nEpoch: 773  | Training Loss: 0.50766 \nEpoch: 773  | Training Loss: 0.22704 \nEpoch: 773  | Validation balanced accuracy : 0.50000 \nEpoch: 774  | Training Loss: 0.64460 \nEpoch: 774  | Training Loss: 0.67241 \nEpoch: 774  | Training Loss: 0.55083 \nEpoch: 774  | Training Loss: 0.50757 \nEpoch: 774  | Training Loss: 0.22686 \nEpoch: 774  | Validation balanced accuracy : 0.50000 \nEpoch: 775  | Training Loss: 0.64438 \nEpoch: 775  | Training Loss: 0.67226 \nEpoch: 775  | Training Loss: 0.55066 \nEpoch: 775  | Training Loss: 0.50748 \nEpoch: 775  | Training Loss: 0.22669 \nEpoch: 775  | Validation balanced accuracy : 0.50000 \nEpoch: 776  | Training Loss: 0.64416 \nEpoch: 776  | Training Loss: 0.67211 \nEpoch: 776  | Training Loss: 0.55049 \nEpoch: 776  | Training Loss: 0.50739 \nEpoch: 776  | Training Loss: 0.22651 \nEpoch: 776  | Validation balanced accuracy : 0.50000 \nEpoch: 777  | Training Loss: 0.64394 \nEpoch: 777  | Training Loss: 0.67196 \nEpoch: 777  | Training Loss: 0.55031 \nEpoch: 777  | Training Loss: 0.50730 \nEpoch: 777  | Training Loss: 0.22633 \nEpoch: 777  | Validation balanced accuracy : 0.50000 \nEpoch: 778  | Training Loss: 0.64371 \nEpoch: 778  | Training Loss: 0.67181 \nEpoch: 778  | Training Loss: 0.55014 \nEpoch: 778  | Training Loss: 0.50721 \nEpoch: 778  | Training Loss: 0.22615 \nEpoch: 778  | Validation balanced accuracy : 0.50000 \nEpoch: 779  | Training Loss: 0.64349 \nEpoch: 779  | Training Loss: 0.67166 \nEpoch: 779  | Training Loss: 0.54996 \nEpoch: 779  | Training Loss: 0.50712 \nEpoch: 779  | Training Loss: 0.22598 \nEpoch: 779  | Validation balanced accuracy : 0.50000 \nEpoch: 780  | Training Loss: 0.64326 \nEpoch: 780  | Training Loss: 0.67151 \nEpoch: 780  | Training Loss: 0.54978 \nEpoch: 780  | Training Loss: 0.50703 \nEpoch: 780  | Training Loss: 0.22580 \nEpoch: 780  | Validation balanced accuracy : 0.50000 \nEpoch: 781  | Training Loss: 0.64303 \nEpoch: 781  | Training Loss: 0.67136 \nEpoch: 781  | Training Loss: 0.54961 \nEpoch: 781  | Training Loss: 0.50693 \nEpoch: 781  | Training Loss: 0.22562 \nEpoch: 781  | Validation balanced accuracy : 0.50000 \nEpoch: 782  | Training Loss: 0.64280 \nEpoch: 782  | Training Loss: 0.67121 \nEpoch: 782  | Training Loss: 0.54943 \nEpoch: 782  | Training Loss: 0.50684 \nEpoch: 782  | Training Loss: 0.22544 \nEpoch: 782  | Validation balanced accuracy : 0.50000 \nEpoch: 783  | Training Loss: 0.64257 \nEpoch: 783  | Training Loss: 0.67105 \nEpoch: 783  | Training Loss: 0.54925 \nEpoch: 783  | Training Loss: 0.50675 \nEpoch: 783  | Training Loss: 0.22526 \nEpoch: 783  | Validation balanced accuracy : 0.50000 \nEpoch: 784  | Training Loss: 0.64234 \nEpoch: 784  | Training Loss: 0.67090 \nEpoch: 784  | Training Loss: 0.54907 \nEpoch: 784  | Training Loss: 0.50665 \nEpoch: 784  | Training Loss: 0.22508 \nEpoch: 784  | Validation balanced accuracy : 0.50000 \nEpoch: 785  | Training Loss: 0.64211 \nEpoch: 785  | Training Loss: 0.67074 \nEpoch: 785  | Training Loss: 0.54888 \nEpoch: 785  | Training Loss: 0.50656 \nEpoch: 785  | Training Loss: 0.22490 \nEpoch: 785  | Validation balanced accuracy : 0.50000 \nEpoch: 786  | Training Loss: 0.64187 \nEpoch: 786  | Training Loss: 0.67058 \nEpoch: 786  | Training Loss: 0.54870 \nEpoch: 786  | Training Loss: 0.50646 \nEpoch: 786  | Training Loss: 0.22472 \nEpoch: 786  | Validation balanced accuracy : 0.50000 \nEpoch: 787  | Training Loss: 0.64164 \nEpoch: 787  | Training Loss: 0.67042 \nEpoch: 787  | Training Loss: 0.54852 \nEpoch: 787  | Training Loss: 0.50637 \nEpoch: 787  | Training Loss: 0.22454 \nEpoch: 787  | Validation balanced accuracy : 0.50000 \nEpoch: 788  | Training Loss: 0.64140 \nEpoch: 788  | Training Loss: 0.67026 \nEpoch: 788  | Training Loss: 0.54833 \nEpoch: 788  | Training Loss: 0.50627 \nEpoch: 788  | Training Loss: 0.22436 \nEpoch: 788  | Validation balanced accuracy : 0.50000 \nEpoch: 789  | Training Loss: 0.64116 \nEpoch: 789  | Training Loss: 0.67010 \nEpoch: 789  | Training Loss: 0.54815 \nEpoch: 789  | Training Loss: 0.50617 \nEpoch: 789  | Training Loss: 0.22418 \nEpoch: 789  | Validation balanced accuracy : 0.50000 \nEpoch: 790  | Training Loss: 0.64092 \nEpoch: 790  | Training Loss: 0.66994 \nEpoch: 790  | Training Loss: 0.54796 \nEpoch: 790  | Training Loss: 0.50607 \nEpoch: 790  | Training Loss: 0.22399 \nEpoch: 790  | Validation balanced accuracy : 0.50000 \nEpoch: 791  | Training Loss: 0.64068 \nEpoch: 791  | Training Loss: 0.66978 \nEpoch: 791  | Training Loss: 0.54777 \nEpoch: 791  | Training Loss: 0.50597 \nEpoch: 791  | Training Loss: 0.22381 \nEpoch: 791  | Validation balanced accuracy : 0.50000 \nEpoch: 792  | Training Loss: 0.64044 \nEpoch: 792  | Training Loss: 0.66962 \nEpoch: 792  | Training Loss: 0.54758 \nEpoch: 792  | Training Loss: 0.50588 \nEpoch: 792  | Training Loss: 0.22363 \nEpoch: 792  | Validation balanced accuracy : 0.50000 \nEpoch: 793  | Training Loss: 0.64020 \nEpoch: 793  | Training Loss: 0.66945 \nEpoch: 793  | Training Loss: 0.54739 \nEpoch: 793  | Training Loss: 0.50578 \nEpoch: 793  | Training Loss: 0.22345 \nEpoch: 793  | Validation balanced accuracy : 0.50000 \nEpoch: 794  | Training Loss: 0.63995 \nEpoch: 794  | Training Loss: 0.66929 \nEpoch: 794  | Training Loss: 0.54720 \nEpoch: 794  | Training Loss: 0.50568 \nEpoch: 794  | Training Loss: 0.22326 \nEpoch: 794  | Validation balanced accuracy : 0.50000 \nEpoch: 795  | Training Loss: 0.63970 \nEpoch: 795  | Training Loss: 0.66912 \nEpoch: 795  | Training Loss: 0.54701 \nEpoch: 795  | Training Loss: 0.50558 \nEpoch: 795  | Training Loss: 0.22308 \nEpoch: 795  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 796  | Training Loss: 0.63946 \nEpoch: 796  | Training Loss: 0.66895 \nEpoch: 796  | Training Loss: 0.54682 \nEpoch: 796  | Training Loss: 0.50547 \nEpoch: 796  | Training Loss: 0.22290 \nEpoch: 796  | Validation balanced accuracy : 0.50000 \nEpoch: 797  | Training Loss: 0.63921 \nEpoch: 797  | Training Loss: 0.66878 \nEpoch: 797  | Training Loss: 0.54662 \nEpoch: 797  | Training Loss: 0.50537 \nEpoch: 797  | Training Loss: 0.22272 \nEpoch: 797  | Validation balanced accuracy : 0.50000 \nEpoch: 798  | Training Loss: 0.63896 \nEpoch: 798  | Training Loss: 0.66861 \nEpoch: 798  | Training Loss: 0.54643 \nEpoch: 798  | Training Loss: 0.50527 \nEpoch: 798  | Training Loss: 0.22253 \nEpoch: 798  | Validation balanced accuracy : 0.50000 \nEpoch: 799  | Training Loss: 0.63870 \nEpoch: 799  | Training Loss: 0.66844 \nEpoch: 799  | Training Loss: 0.54623 \nEpoch: 799  | Training Loss: 0.50517 \nEpoch: 799  | Training Loss: 0.22235 \nEpoch: 799  | Validation balanced accuracy : 0.50000 \nEpoch: 800  | Training Loss: 0.63845 \nEpoch: 800  | Training Loss: 0.66827 \nEpoch: 800  | Training Loss: 0.54603 \nEpoch: 800  | Training Loss: 0.50506 \nEpoch: 800  | Training Loss: 0.22216 \nEpoch: 800  | Validation balanced accuracy : 0.50000 \nEpoch: 801  | Training Loss: 0.63819 \nEpoch: 801  | Training Loss: 0.66809 \nEpoch: 801  | Training Loss: 0.54583 \nEpoch: 801  | Training Loss: 0.50496 \nEpoch: 801  | Training Loss: 0.22198 \nEpoch: 801  | Validation balanced accuracy : 0.50000 \nEpoch: 802  | Training Loss: 0.63794 \nEpoch: 802  | Training Loss: 0.66792 \nEpoch: 802  | Training Loss: 0.54563 \nEpoch: 802  | Training Loss: 0.50485 \nEpoch: 802  | Training Loss: 0.22179 \nEpoch: 802  | Validation balanced accuracy : 0.50000 \nEpoch: 803  | Training Loss: 0.63768 \nEpoch: 803  | Training Loss: 0.66774 \nEpoch: 803  | Training Loss: 0.54543 \nEpoch: 803  | Training Loss: 0.50475 \nEpoch: 803  | Training Loss: 0.22161 \nEpoch: 803  | Validation balanced accuracy : 0.50000 \nEpoch: 804  | Training Loss: 0.63742 \nEpoch: 804  | Training Loss: 0.66757 \nEpoch: 804  | Training Loss: 0.54523 \nEpoch: 804  | Training Loss: 0.50464 \nEpoch: 804  | Training Loss: 0.22142 \nEpoch: 804  | Validation balanced accuracy : 0.50000 \nEpoch: 805  | Training Loss: 0.63716 \nEpoch: 805  | Training Loss: 0.66739 \nEpoch: 805  | Training Loss: 0.54503 \nEpoch: 805  | Training Loss: 0.50453 \nEpoch: 805  | Training Loss: 0.22124 \nEpoch: 805  | Validation balanced accuracy : 0.50000 \nEpoch: 806  | Training Loss: 0.63689 \nEpoch: 806  | Training Loss: 0.66721 \nEpoch: 806  | Training Loss: 0.54483 \nEpoch: 806  | Training Loss: 0.50442 \nEpoch: 806  | Training Loss: 0.22105 \nEpoch: 806  | Validation balanced accuracy : 0.50000 \nEpoch: 807  | Training Loss: 0.63663 \nEpoch: 807  | Training Loss: 0.66703 \nEpoch: 807  | Training Loss: 0.54462 \nEpoch: 807  | Training Loss: 0.50431 \nEpoch: 807  | Training Loss: 0.22086 \nEpoch: 807  | Validation balanced accuracy : 0.50000 \nEpoch: 808  | Training Loss: 0.63636 \nEpoch: 808  | Training Loss: 0.66684 \nEpoch: 808  | Training Loss: 0.54441 \nEpoch: 808  | Training Loss: 0.50421 \nEpoch: 808  | Training Loss: 0.22068 \nEpoch: 808  | Validation balanced accuracy : 0.50000 \nEpoch: 809  | Training Loss: 0.63610 \nEpoch: 809  | Training Loss: 0.66666 \nEpoch: 809  | Training Loss: 0.54421 \nEpoch: 809  | Training Loss: 0.50410 \nEpoch: 809  | Training Loss: 0.22049 \nEpoch: 809  | Validation balanced accuracy : 0.50000 \nEpoch: 810  | Training Loss: 0.63583 \nEpoch: 810  | Training Loss: 0.66647 \nEpoch: 810  | Training Loss: 0.54400 \nEpoch: 810  | Training Loss: 0.50398 \nEpoch: 810  | Training Loss: 0.22030 \nEpoch: 810  | Validation balanced accuracy : 0.50000 \nEpoch: 811  | Training Loss: 0.63556 \nEpoch: 811  | Training Loss: 0.66629 \nEpoch: 811  | Training Loss: 0.54379 \nEpoch: 811  | Training Loss: 0.50387 \nEpoch: 811  | Training Loss: 0.22012 \nEpoch: 811  | Validation balanced accuracy : 0.50000 \nEpoch: 812  | Training Loss: 0.63528 \nEpoch: 812  | Training Loss: 0.66610 \nEpoch: 812  | Training Loss: 0.54358 \nEpoch: 812  | Training Loss: 0.50376 \nEpoch: 812  | Training Loss: 0.21993 \nEpoch: 812  | Validation balanced accuracy : 0.50000 \nEpoch: 813  | Training Loss: 0.63501 \nEpoch: 813  | Training Loss: 0.66591 \nEpoch: 813  | Training Loss: 0.54336 \nEpoch: 813  | Training Loss: 0.50365 \nEpoch: 813  | Training Loss: 0.21974 \nEpoch: 813  | Validation balanced accuracy : 0.50000 \nEpoch: 814  | Training Loss: 0.63473 \nEpoch: 814  | Training Loss: 0.66572 \nEpoch: 814  | Training Loss: 0.54315 \nEpoch: 814  | Training Loss: 0.50353 \nEpoch: 814  | Training Loss: 0.21955 \nEpoch: 814  | Validation balanced accuracy : 0.50000 \nEpoch: 815  | Training Loss: 0.63446 \nEpoch: 815  | Training Loss: 0.66553 \nEpoch: 815  | Training Loss: 0.54293 \nEpoch: 815  | Training Loss: 0.50342 \nEpoch: 815  | Training Loss: 0.21937 \nEpoch: 815  | Validation balanced accuracy : 0.50000 \nEpoch: 816  | Training Loss: 0.63418 \nEpoch: 816  | Training Loss: 0.66534 \nEpoch: 816  | Training Loss: 0.54272 \nEpoch: 816  | Training Loss: 0.50330 \nEpoch: 816  | Training Loss: 0.21918 \nEpoch: 816  | Validation balanced accuracy : 0.50000 \nEpoch: 817  | Training Loss: 0.63390 \nEpoch: 817  | Training Loss: 0.66514 \nEpoch: 817  | Training Loss: 0.54250 \nEpoch: 817  | Training Loss: 0.50319 \nEpoch: 817  | Training Loss: 0.21899 \nEpoch: 817  | Validation balanced accuracy : 0.50000 \nEpoch: 818  | Training Loss: 0.63361 \nEpoch: 818  | Training Loss: 0.66495 \nEpoch: 818  | Training Loss: 0.54228 \nEpoch: 818  | Training Loss: 0.50307 \nEpoch: 818  | Training Loss: 0.21880 \nEpoch: 818  | Validation balanced accuracy : 0.50000 \nEpoch: 819  | Training Loss: 0.63333 \nEpoch: 819  | Training Loss: 0.66475 \nEpoch: 819  | Training Loss: 0.54206 \nEpoch: 819  | Training Loss: 0.50295 \nEpoch: 819  | Training Loss: 0.21861 \nEpoch: 819  | Validation balanced accuracy : 0.50000 \nEpoch: 820  | Training Loss: 0.63304 \nEpoch: 820  | Training Loss: 0.66455 \nEpoch: 820  | Training Loss: 0.54184 \nEpoch: 820  | Training Loss: 0.50284 \nEpoch: 820  | Training Loss: 0.21843 \nEpoch: 820  | Validation balanced accuracy : 0.50000 \nEpoch: 821  | Training Loss: 0.63275 \nEpoch: 821  | Training Loss: 0.66435 \nEpoch: 821  | Training Loss: 0.54162 \nEpoch: 821  | Training Loss: 0.50272 \nEpoch: 821  | Training Loss: 0.21824 \nEpoch: 821  | Validation balanced accuracy : 0.50000 \nEpoch: 822  | Training Loss: 0.63246 \nEpoch: 822  | Training Loss: 0.66415 \nEpoch: 822  | Training Loss: 0.54139 \nEpoch: 822  | Training Loss: 0.50260 \nEpoch: 822  | Training Loss: 0.21805 \nEpoch: 822  | Validation balanced accuracy : 0.50000 \nEpoch: 823  | Training Loss: 0.63217 \nEpoch: 823  | Training Loss: 0.66395 \nEpoch: 823  | Training Loss: 0.54117 \nEpoch: 823  | Training Loss: 0.50248 \nEpoch: 823  | Training Loss: 0.21786 \nEpoch: 823  | Validation balanced accuracy : 0.50000 \nEpoch: 824  | Training Loss: 0.63188 \nEpoch: 824  | Training Loss: 0.66374 \nEpoch: 824  | Training Loss: 0.54094 \nEpoch: 824  | Training Loss: 0.50235 \nEpoch: 824  | Training Loss: 0.21767 \nEpoch: 824  | Validation balanced accuracy : 0.50000 \nEpoch: 825  | Training Loss: 0.63158 \nEpoch: 825  | Training Loss: 0.66353 \nEpoch: 825  | Training Loss: 0.54071 \nEpoch: 825  | Training Loss: 0.50223 \nEpoch: 825  | Training Loss: 0.21748 \nEpoch: 825  | Validation balanced accuracy : 0.50000 \nEpoch: 826  | Training Loss: 0.63129 \nEpoch: 826  | Training Loss: 0.66333 \nEpoch: 826  | Training Loss: 0.54049 \nEpoch: 826  | Training Loss: 0.50211 \nEpoch: 826  | Training Loss: 0.21729 \nEpoch: 826  | Validation balanced accuracy : 0.50000 \nEpoch: 827  | Training Loss: 0.63099 \nEpoch: 827  | Training Loss: 0.66312 \nEpoch: 827  | Training Loss: 0.54025 \nEpoch: 827  | Training Loss: 0.50198 \nEpoch: 827  | Training Loss: 0.21710 \nEpoch: 827  | Validation balanced accuracy : 0.50000 \nEpoch: 828  | Training Loss: 0.63068 \nEpoch: 828  | Training Loss: 0.66291 \nEpoch: 828  | Training Loss: 0.54002 \nEpoch: 828  | Training Loss: 0.50186 \nEpoch: 828  | Training Loss: 0.21691 \nEpoch: 828  | Validation balanced accuracy : 0.50000 \nEpoch: 829  | Training Loss: 0.63038 \nEpoch: 829  | Training Loss: 0.66269 \nEpoch: 829  | Training Loss: 0.53979 \nEpoch: 829  | Training Loss: 0.50173 \nEpoch: 829  | Training Loss: 0.21673 \nEpoch: 829  | Validation balanced accuracy : 0.50000 \nEpoch: 830  | Training Loss: 0.63007 \nEpoch: 830  | Training Loss: 0.66248 \nEpoch: 830  | Training Loss: 0.53955 \nEpoch: 830  | Training Loss: 0.50161 \nEpoch: 830  | Training Loss: 0.21654 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 830  | Validation balanced accuracy : 0.50000 \nEpoch: 831  | Training Loss: 0.62977 \nEpoch: 831  | Training Loss: 0.66226 \nEpoch: 831  | Training Loss: 0.53932 \nEpoch: 831  | Training Loss: 0.50148 \nEpoch: 831  | Training Loss: 0.21635 \nEpoch: 831  | Validation balanced accuracy : 0.50000 \nEpoch: 832  | Training Loss: 0.62946 \nEpoch: 832  | Training Loss: 0.66205 \nEpoch: 832  | Training Loss: 0.53908 \nEpoch: 832  | Training Loss: 0.50135 \nEpoch: 832  | Training Loss: 0.21616 \nEpoch: 832  | Validation balanced accuracy : 0.50000 \nEpoch: 833  | Training Loss: 0.62915 \nEpoch: 833  | Training Loss: 0.66183 \nEpoch: 833  | Training Loss: 0.53884 \nEpoch: 833  | Training Loss: 0.50122 \nEpoch: 833  | Training Loss: 0.21597 \nEpoch: 833  | Validation balanced accuracy : 0.50000 \nEpoch: 834  | Training Loss: 0.62883 \nEpoch: 834  | Training Loss: 0.66161 \nEpoch: 834  | Training Loss: 0.53860 \nEpoch: 834  | Training Loss: 0.50109 \nEpoch: 834  | Training Loss: 0.21578 \nEpoch: 834  | Validation balanced accuracy : 0.50000 \nEpoch: 835  | Training Loss: 0.62852 \nEpoch: 835  | Training Loss: 0.66139 \nEpoch: 835  | Training Loss: 0.53836 \nEpoch: 835  | Training Loss: 0.50096 \nEpoch: 835  | Training Loss: 0.21559 \nEpoch: 835  | Validation balanced accuracy : 0.50000 \nEpoch: 836  | Training Loss: 0.62820 \nEpoch: 836  | Training Loss: 0.66116 \nEpoch: 836  | Training Loss: 0.53812 \nEpoch: 836  | Training Loss: 0.50083 \nEpoch: 836  | Training Loss: 0.21540 \nEpoch: 836  | Validation balanced accuracy : 0.50000 \nEpoch: 837  | Training Loss: 0.62788 \nEpoch: 837  | Training Loss: 0.66094 \nEpoch: 837  | Training Loss: 0.53787 \nEpoch: 837  | Training Loss: 0.50070 \nEpoch: 837  | Training Loss: 0.21521 \nEpoch: 837  | Validation balanced accuracy : 0.50000 \nEpoch: 838  | Training Loss: 0.62756 \nEpoch: 838  | Training Loss: 0.66071 \nEpoch: 838  | Training Loss: 0.53762 \nEpoch: 838  | Training Loss: 0.50056 \nEpoch: 838  | Training Loss: 0.21502 \nEpoch: 838  | Validation balanced accuracy : 0.50000 \nEpoch: 839  | Training Loss: 0.62724 \nEpoch: 839  | Training Loss: 0.66048 \nEpoch: 839  | Training Loss: 0.53738 \nEpoch: 839  | Training Loss: 0.50043 \nEpoch: 839  | Training Loss: 0.21483 \nEpoch: 839  | Validation balanced accuracy : 0.50000 \nEpoch: 840  | Training Loss: 0.62691 \nEpoch: 840  | Training Loss: 0.66025 \nEpoch: 840  | Training Loss: 0.53713 \nEpoch: 840  | Training Loss: 0.50029 \nEpoch: 840  | Training Loss: 0.21465 \nEpoch: 840  | Validation balanced accuracy : 0.50000 \nEpoch: 841  | Training Loss: 0.62658 \nEpoch: 841  | Training Loss: 0.66002 \nEpoch: 841  | Training Loss: 0.53687 \nEpoch: 841  | Training Loss: 0.50016 \nEpoch: 841  | Training Loss: 0.21446 \nEpoch: 841  | Validation balanced accuracy : 0.50000 \nEpoch: 842  | Training Loss: 0.62625 \nEpoch: 842  | Training Loss: 0.65978 \nEpoch: 842  | Training Loss: 0.53662 \nEpoch: 842  | Training Loss: 0.50002 \nEpoch: 842  | Training Loss: 0.21427 \nEpoch: 842  | Validation balanced accuracy : 0.50000 \nEpoch: 843  | Training Loss: 0.62592 \nEpoch: 843  | Training Loss: 0.65955 \nEpoch: 843  | Training Loss: 0.53637 \nEpoch: 843  | Training Loss: 0.49988 \nEpoch: 843  | Training Loss: 0.21408 \nEpoch: 843  | Validation balanced accuracy : 0.50000 \nEpoch: 844  | Training Loss: 0.62558 \nEpoch: 844  | Training Loss: 0.65931 \nEpoch: 844  | Training Loss: 0.53611 \nEpoch: 844  | Training Loss: 0.49974 \nEpoch: 844  | Training Loss: 0.21389 \nEpoch: 844  | Validation balanced accuracy : 0.50000 \nEpoch: 845  | Training Loss: 0.62525 \nEpoch: 845  | Training Loss: 0.65907 \nEpoch: 845  | Training Loss: 0.53585 \nEpoch: 845  | Training Loss: 0.49960 \nEpoch: 845  | Training Loss: 0.21371 \nEpoch: 845  | Validation balanced accuracy : 0.50000 \nEpoch: 846  | Training Loss: 0.62491 \nEpoch: 846  | Training Loss: 0.65883 \nEpoch: 846  | Training Loss: 0.53560 \nEpoch: 846  | Training Loss: 0.49946 \nEpoch: 846  | Training Loss: 0.21352 \nEpoch: 846  | Validation balanced accuracy : 0.50000 \nEpoch: 847  | Training Loss: 0.62457 \nEpoch: 847  | Training Loss: 0.65858 \nEpoch: 847  | Training Loss: 0.53534 \nEpoch: 847  | Training Loss: 0.49932 \nEpoch: 847  | Training Loss: 0.21333 \nEpoch: 847  | Validation balanced accuracy : 0.50000 \nEpoch: 848  | Training Loss: 0.62422 \nEpoch: 848  | Training Loss: 0.65834 \nEpoch: 848  | Training Loss: 0.53507 \nEpoch: 848  | Training Loss: 0.49917 \nEpoch: 848  | Training Loss: 0.21314 \nEpoch: 848  | Validation balanced accuracy : 0.50000 \nEpoch: 849  | Training Loss: 0.62387 \nEpoch: 849  | Training Loss: 0.65809 \nEpoch: 849  | Training Loss: 0.53481 \nEpoch: 849  | Training Loss: 0.49903 \nEpoch: 849  | Training Loss: 0.21296 \nEpoch: 849  | Validation balanced accuracy : 0.50000 \nEpoch: 850  | Training Loss: 0.62353 \nEpoch: 850  | Training Loss: 0.65784 \nEpoch: 850  | Training Loss: 0.53454 \nEpoch: 850  | Training Loss: 0.49888 \nEpoch: 850  | Training Loss: 0.21277 \nEpoch: 850  | Validation balanced accuracy : 0.50000 \nEpoch: 851  | Training Loss: 0.62317 \nEpoch: 851  | Training Loss: 0.65759 \nEpoch: 851  | Training Loss: 0.53428 \nEpoch: 851  | Training Loss: 0.49873 \nEpoch: 851  | Training Loss: 0.21259 \nEpoch: 851  | Validation balanced accuracy : 0.50000 \nEpoch: 852  | Training Loss: 0.62282 \nEpoch: 852  | Training Loss: 0.65733 \nEpoch: 852  | Training Loss: 0.53401 \nEpoch: 852  | Training Loss: 0.49859 \nEpoch: 852  | Training Loss: 0.21240 \nEpoch: 852  | Validation balanced accuracy : 0.50000 \nEpoch: 853  | Training Loss: 0.62246 \nEpoch: 853  | Training Loss: 0.65708 \nEpoch: 853  | Training Loss: 0.53374 \nEpoch: 853  | Training Loss: 0.49844 \nEpoch: 853  | Training Loss: 0.21221 \nEpoch: 853  | Validation balanced accuracy : 0.50000 \nEpoch: 854  | Training Loss: 0.62211 \nEpoch: 854  | Training Loss: 0.65682 \nEpoch: 854  | Training Loss: 0.53346 \nEpoch: 854  | Training Loss: 0.49829 \nEpoch: 854  | Training Loss: 0.21203 \nEpoch: 854  | Validation balanced accuracy : 0.50000 \nEpoch: 855  | Training Loss: 0.62174 \nEpoch: 855  | Training Loss: 0.65656 \nEpoch: 855  | Training Loss: 0.53319 \nEpoch: 855  | Training Loss: 0.49814 \nEpoch: 855  | Training Loss: 0.21185 \nEpoch: 855  | Validation balanced accuracy : 0.50000 \nEpoch: 856  | Training Loss: 0.62138 \nEpoch: 856  | Training Loss: 0.65630 \nEpoch: 856  | Training Loss: 0.53291 \nEpoch: 856  | Training Loss: 0.49798 \nEpoch: 856  | Training Loss: 0.21166 \nEpoch: 856  | Validation balanced accuracy : 0.50000 \nEpoch: 857  | Training Loss: 0.62101 \nEpoch: 857  | Training Loss: 0.65604 \nEpoch: 857  | Training Loss: 0.53264 \nEpoch: 857  | Training Loss: 0.49783 \nEpoch: 857  | Training Loss: 0.21148 \nEpoch: 857  | Validation balanced accuracy : 0.50000 \nEpoch: 858  | Training Loss: 0.62065 \nEpoch: 858  | Training Loss: 0.65577 \nEpoch: 858  | Training Loss: 0.53236 \nEpoch: 858  | Training Loss: 0.49768 \nEpoch: 858  | Training Loss: 0.21130 \nEpoch: 858  | Validation balanced accuracy : 0.50000 \nEpoch: 859  | Training Loss: 0.62027 \nEpoch: 859  | Training Loss: 0.65550 \nEpoch: 859  | Training Loss: 0.53208 \nEpoch: 859  | Training Loss: 0.49752 \nEpoch: 859  | Training Loss: 0.21111 \nEpoch: 859  | Validation balanced accuracy : 0.50000 \nEpoch: 860  | Training Loss: 0.61990 \nEpoch: 860  | Training Loss: 0.65523 \nEpoch: 860  | Training Loss: 0.53179 \nEpoch: 860  | Training Loss: 0.49736 \nEpoch: 860  | Training Loss: 0.21093 \nEpoch: 860  | Validation balanced accuracy : 0.50000 \nEpoch: 861  | Training Loss: 0.61952 \nEpoch: 861  | Training Loss: 0.65496 \nEpoch: 861  | Training Loss: 0.53151 \nEpoch: 861  | Training Loss: 0.49720 \nEpoch: 861  | Training Loss: 0.21075 \nEpoch: 861  | Validation balanced accuracy : 0.50000 \nEpoch: 862  | Training Loss: 0.61914 \nEpoch: 862  | Training Loss: 0.65468 \nEpoch: 862  | Training Loss: 0.53122 \nEpoch: 862  | Training Loss: 0.49705 \nEpoch: 862  | Training Loss: 0.21057 \nEpoch: 862  | Validation balanced accuracy : 0.50000 \nEpoch: 863  | Training Loss: 0.61876 \nEpoch: 863  | Training Loss: 0.65441 \nEpoch: 863  | Training Loss: 0.53093 \nEpoch: 863  | Training Loss: 0.49688 \nEpoch: 863  | Training Loss: 0.21039 \nEpoch: 863  | Validation balanced accuracy : 0.50000 \nEpoch: 864  | Training Loss: 0.61838 \nEpoch: 864  | Training Loss: 0.65413 \nEpoch: 864  | Training Loss: 0.53064 \nEpoch: 864  | Training Loss: 0.49672 \nEpoch: 864  | Training Loss: 0.21021 \nEpoch: 864  | Validation balanced accuracy : 0.50000 \nEpoch: 865  | Training Loss: 0.61799 \nEpoch: 865  | Training Loss: 0.65384 \nEpoch: 865  | Training Loss: 0.53035 \nEpoch: 865  | Training Loss: 0.49656 \nEpoch: 865  | Training Loss: 0.21003 \nEpoch: 865  | Validation balanced accuracy : 0.50000 \nEpoch: 866  | Training Loss: 0.61760 \nEpoch: 866  | Training Loss: 0.65356 \nEpoch: 866  | Training Loss: 0.53006 \nEpoch: 866  | Training Loss: 0.49640 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 866  | Training Loss: 0.20986 \nEpoch: 866  | Validation balanced accuracy : 0.50000 \nEpoch: 867  | Training Loss: 0.61720 \nEpoch: 867  | Training Loss: 0.65327 \nEpoch: 867  | Training Loss: 0.52976 \nEpoch: 867  | Training Loss: 0.49623 \nEpoch: 867  | Training Loss: 0.20968 \nEpoch: 867  | Validation balanced accuracy : 0.50000 \nEpoch: 868  | Training Loss: 0.61681 \nEpoch: 868  | Training Loss: 0.65299 \nEpoch: 868  | Training Loss: 0.52947 \nEpoch: 868  | Training Loss: 0.49606 \nEpoch: 868  | Training Loss: 0.20950 \nEpoch: 868  | Validation balanced accuracy : 0.50000 \nEpoch: 869  | Training Loss: 0.61641 \nEpoch: 869  | Training Loss: 0.65270 \nEpoch: 869  | Training Loss: 0.52917 \nEpoch: 869  | Training Loss: 0.49590 \nEpoch: 869  | Training Loss: 0.20933 \nEpoch: 869  | Validation balanced accuracy : 0.50000 \nEpoch: 870  | Training Loss: 0.61601 \nEpoch: 870  | Training Loss: 0.65240 \nEpoch: 870  | Training Loss: 0.52886 \nEpoch: 870  | Training Loss: 0.49573 \nEpoch: 870  | Training Loss: 0.20915 \nEpoch: 870  | Validation balanced accuracy : 0.50000 \nEpoch: 871  | Training Loss: 0.61560 \nEpoch: 871  | Training Loss: 0.65211 \nEpoch: 871  | Training Loss: 0.52856 \nEpoch: 871  | Training Loss: 0.49556 \nEpoch: 871  | Training Loss: 0.20898 \nEpoch: 871  | Validation balanced accuracy : 0.50000 \nEpoch: 872  | Training Loss: 0.61519 \nEpoch: 872  | Training Loss: 0.65181 \nEpoch: 872  | Training Loss: 0.52826 \nEpoch: 872  | Training Loss: 0.49539 \nEpoch: 872  | Training Loss: 0.20881 \nEpoch: 872  | Validation balanced accuracy : 0.50000 \nEpoch: 873  | Training Loss: 0.61478 \nEpoch: 873  | Training Loss: 0.65151 \nEpoch: 873  | Training Loss: 0.52795 \nEpoch: 873  | Training Loss: 0.49521 \nEpoch: 873  | Training Loss: 0.20864 \nEpoch: 873  | Validation balanced accuracy : 0.50000 \nEpoch: 874  | Training Loss: 0.61437 \nEpoch: 874  | Training Loss: 0.65120 \nEpoch: 874  | Training Loss: 0.52764 \nEpoch: 874  | Training Loss: 0.49504 \nEpoch: 874  | Training Loss: 0.20847 \nEpoch: 874  | Validation balanced accuracy : 0.50000 \nEpoch: 875  | Training Loss: 0.61395 \nEpoch: 875  | Training Loss: 0.65090 \nEpoch: 875  | Training Loss: 0.52733 \nEpoch: 875  | Training Loss: 0.49486 \nEpoch: 875  | Training Loss: 0.20830 \nEpoch: 875  | Validation balanced accuracy : 0.50000 \nEpoch: 876  | Training Loss: 0.61353 \nEpoch: 876  | Training Loss: 0.65059 \nEpoch: 876  | Training Loss: 0.52702 \nEpoch: 876  | Training Loss: 0.49469 \nEpoch: 876  | Training Loss: 0.20813 \nEpoch: 876  | Validation balanced accuracy : 0.50000 \nEpoch: 877  | Training Loss: 0.61311 \nEpoch: 877  | Training Loss: 0.65028 \nEpoch: 877  | Training Loss: 0.52670 \nEpoch: 877  | Training Loss: 0.49451 \nEpoch: 877  | Training Loss: 0.20796 \nEpoch: 877  | Validation balanced accuracy : 0.50000 \nEpoch: 878  | Training Loss: 0.61269 \nEpoch: 878  | Training Loss: 0.64997 \nEpoch: 878  | Training Loss: 0.52638 \nEpoch: 878  | Training Loss: 0.49433 \nEpoch: 878  | Training Loss: 0.20780 \nEpoch: 878  | Validation balanced accuracy : 0.50000 \nEpoch: 879  | Training Loss: 0.61226 \nEpoch: 879  | Training Loss: 0.64965 \nEpoch: 879  | Training Loss: 0.52607 \nEpoch: 879  | Training Loss: 0.49415 \nEpoch: 879  | Training Loss: 0.20763 \nEpoch: 879  | Validation balanced accuracy : 0.50000 \nEpoch: 880  | Training Loss: 0.61182 \nEpoch: 880  | Training Loss: 0.64933 \nEpoch: 880  | Training Loss: 0.52574 \nEpoch: 880  | Training Loss: 0.49396 \nEpoch: 880  | Training Loss: 0.20747 \nEpoch: 880  | Validation balanced accuracy : 0.50000 \nEpoch: 881  | Training Loss: 0.61139 \nEpoch: 881  | Training Loss: 0.64901 \nEpoch: 881  | Training Loss: 0.52542 \nEpoch: 881  | Training Loss: 0.49378 \nEpoch: 881  | Training Loss: 0.20731 \nEpoch: 881  | Validation balanced accuracy : 0.50000 \nEpoch: 882  | Training Loss: 0.61095 \nEpoch: 882  | Training Loss: 0.64869 \nEpoch: 882  | Training Loss: 0.52510 \nEpoch: 882  | Training Loss: 0.49359 \nEpoch: 882  | Training Loss: 0.20715 \nEpoch: 882  | Validation balanced accuracy : 0.50000 \nEpoch: 883  | Training Loss: 0.61051 \nEpoch: 883  | Training Loss: 0.64836 \nEpoch: 883  | Training Loss: 0.52477 \nEpoch: 883  | Training Loss: 0.49341 \nEpoch: 883  | Training Loss: 0.20699 \nEpoch: 883  | Validation balanced accuracy : 0.50000 \nEpoch: 884  | Training Loss: 0.61006 \nEpoch: 884  | Training Loss: 0.64803 \nEpoch: 884  | Training Loss: 0.52444 \nEpoch: 884  | Training Loss: 0.49322 \nEpoch: 884  | Training Loss: 0.20683 \nEpoch: 884  | Validation balanced accuracy : 0.50000 \nEpoch: 885  | Training Loss: 0.60962 \nEpoch: 885  | Training Loss: 0.64770 \nEpoch: 885  | Training Loss: 0.52411 \nEpoch: 885  | Training Loss: 0.49303 \nEpoch: 885  | Training Loss: 0.20668 \nEpoch: 885  | Validation balanced accuracy : 0.50000 \nEpoch: 886  | Training Loss: 0.60916 \nEpoch: 886  | Training Loss: 0.64737 \nEpoch: 886  | Training Loss: 0.52378 \nEpoch: 886  | Training Loss: 0.49284 \nEpoch: 886  | Training Loss: 0.20652 \nEpoch: 886  | Validation balanced accuracy : 0.50000 \nEpoch: 887  | Training Loss: 0.60871 \nEpoch: 887  | Training Loss: 0.64703 \nEpoch: 887  | Training Loss: 0.52344 \nEpoch: 887  | Training Loss: 0.49265 \nEpoch: 887  | Training Loss: 0.20637 \nEpoch: 887  | Validation balanced accuracy : 0.50000 \nEpoch: 888  | Training Loss: 0.60825 \nEpoch: 888  | Training Loss: 0.64669 \nEpoch: 888  | Training Loss: 0.52310 \nEpoch: 888  | Training Loss: 0.49245 \nEpoch: 888  | Training Loss: 0.20622 \nEpoch: 888  | Validation balanced accuracy : 0.50000 \nEpoch: 889  | Training Loss: 0.60779 \nEpoch: 889  | Training Loss: 0.64635 \nEpoch: 889  | Training Loss: 0.52276 \nEpoch: 889  | Training Loss: 0.49226 \nEpoch: 889  | Training Loss: 0.20607 \nEpoch: 889  | Validation balanced accuracy : 0.50000 \nEpoch: 890  | Training Loss: 0.60732 \nEpoch: 890  | Training Loss: 0.64600 \nEpoch: 890  | Training Loss: 0.52242 \nEpoch: 890  | Training Loss: 0.49206 \nEpoch: 890  | Training Loss: 0.20592 \nEpoch: 890  | Validation balanced accuracy : 0.50000 \nEpoch: 891  | Training Loss: 0.60686 \nEpoch: 891  | Training Loss: 0.64565 \nEpoch: 891  | Training Loss: 0.52208 \nEpoch: 891  | Training Loss: 0.49186 \nEpoch: 891  | Training Loss: 0.20578 \nEpoch: 891  | Validation balanced accuracy : 0.50000 \nEpoch: 892  | Training Loss: 0.60639 \nEpoch: 892  | Training Loss: 0.64530 \nEpoch: 892  | Training Loss: 0.52173 \nEpoch: 892  | Training Loss: 0.49166 \nEpoch: 892  | Training Loss: 0.20563 \nEpoch: 892  | Validation balanced accuracy : 0.50000 \nEpoch: 893  | Training Loss: 0.60591 \nEpoch: 893  | Training Loss: 0.64495 \nEpoch: 893  | Training Loss: 0.52139 \nEpoch: 893  | Training Loss: 0.49146 \nEpoch: 893  | Training Loss: 0.20549 \nEpoch: 893  | Validation balanced accuracy : 0.50000 \nEpoch: 894  | Training Loss: 0.60543 \nEpoch: 894  | Training Loss: 0.64459 \nEpoch: 894  | Training Loss: 0.52104 \nEpoch: 894  | Training Loss: 0.49126 \nEpoch: 894  | Training Loss: 0.20535 \nEpoch: 894  | Validation balanced accuracy : 0.50000 \nEpoch: 895  | Training Loss: 0.60495 \nEpoch: 895  | Training Loss: 0.64423 \nEpoch: 895  | Training Loss: 0.52069 \nEpoch: 895  | Training Loss: 0.49105 \nEpoch: 895  | Training Loss: 0.20521 \nEpoch: 895  | Validation balanced accuracy : 0.50000 \nEpoch: 896  | Training Loss: 0.60447 \nEpoch: 896  | Training Loss: 0.64387 \nEpoch: 896  | Training Loss: 0.52033 \nEpoch: 896  | Training Loss: 0.49085 \nEpoch: 896  | Training Loss: 0.20508 \nEpoch: 896  | Validation balanced accuracy : 0.50000 \nEpoch: 897  | Training Loss: 0.60398 \nEpoch: 897  | Training Loss: 0.64350 \nEpoch: 897  | Training Loss: 0.51997 \nEpoch: 897  | Training Loss: 0.49064 \nEpoch: 897  | Training Loss: 0.20494 \nEpoch: 897  | Validation balanced accuracy : 0.50000 \nEpoch: 898  | Training Loss: 0.60348 \nEpoch: 898  | Training Loss: 0.64313 \nEpoch: 898  | Training Loss: 0.51962 \nEpoch: 898  | Training Loss: 0.49043 \nEpoch: 898  | Training Loss: 0.20481 \nEpoch: 898  | Validation balanced accuracy : 0.50000 \nEpoch: 899  | Training Loss: 0.60299 \nEpoch: 899  | Training Loss: 0.64276 \nEpoch: 899  | Training Loss: 0.51926 \nEpoch: 899  | Training Loss: 0.49022 \nEpoch: 899  | Training Loss: 0.20468 \nEpoch: 899  | Validation balanced accuracy : 0.50000 \nEpoch: 900  | Training Loss: 0.60249 \nEpoch: 900  | Training Loss: 0.64239 \nEpoch: 900  | Training Loss: 0.51889 \nEpoch: 900  | Training Loss: 0.49001 \nEpoch: 900  | Training Loss: 0.20456 \nEpoch: 900  | Validation balanced accuracy : 0.50000 \nEpoch: 901  | Training Loss: 0.60199 \nEpoch: 901  | Training Loss: 0.64201 \nEpoch: 901  | Training Loss: 0.51855 \nEpoch: 901  | Training Loss: 0.48977 \nEpoch: 901  | Training Loss: 0.20428 \nEpoch: 901  | Validation balanced accuracy : 0.50000 \nEpoch: 902  | Training Loss: 0.60153 \nEpoch: 902  | Training Loss: 0.64166 \nEpoch: 902  | Training Loss: 0.51822 \nEpoch: 902  | Training Loss: 0.48958 \nEpoch: 902  | Training Loss: 0.20418 \nEpoch: 902  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 903  | Training Loss: 0.60107 \nEpoch: 903  | Training Loss: 0.64131 \nEpoch: 903  | Training Loss: 0.51789 \nEpoch: 903  | Training Loss: 0.48938 \nEpoch: 903  | Training Loss: 0.20408 \nEpoch: 903  | Validation balanced accuracy : 0.50000 \nEpoch: 904  | Training Loss: 0.60060 \nEpoch: 904  | Training Loss: 0.64096 \nEpoch: 904  | Training Loss: 0.51755 \nEpoch: 904  | Training Loss: 0.48919 \nEpoch: 904  | Training Loss: 0.20399 \nEpoch: 904  | Validation balanced accuracy : 0.50000 \nEpoch: 905  | Training Loss: 0.60013 \nEpoch: 905  | Training Loss: 0.64061 \nEpoch: 905  | Training Loss: 0.51722 \nEpoch: 905  | Training Loss: 0.48900 \nEpoch: 905  | Training Loss: 0.20389 \nEpoch: 905  | Validation balanced accuracy : 0.50000 \nEpoch: 906  | Training Loss: 0.59966 \nEpoch: 906  | Training Loss: 0.64025 \nEpoch: 906  | Training Loss: 0.51688 \nEpoch: 906  | Training Loss: 0.48880 \nEpoch: 906  | Training Loss: 0.20380 \nEpoch: 906  | Validation balanced accuracy : 0.50000 \nEpoch: 907  | Training Loss: 0.59919 \nEpoch: 907  | Training Loss: 0.63990 \nEpoch: 907  | Training Loss: 0.51654 \nEpoch: 907  | Training Loss: 0.48860 \nEpoch: 907  | Training Loss: 0.20370 \nEpoch: 907  | Validation balanced accuracy : 0.50000 \nEpoch: 908  | Training Loss: 0.59871 \nEpoch: 908  | Training Loss: 0.63954 \nEpoch: 908  | Training Loss: 0.51620 \nEpoch: 908  | Training Loss: 0.48840 \nEpoch: 908  | Training Loss: 0.20360 \nEpoch: 908  | Validation balanced accuracy : 0.50000 \nEpoch: 909  | Training Loss: 0.59824 \nEpoch: 909  | Training Loss: 0.63918 \nEpoch: 909  | Training Loss: 0.51586 \nEpoch: 909  | Training Loss: 0.48819 \nEpoch: 909  | Training Loss: 0.20350 \nEpoch: 909  | Validation balanced accuracy : 0.50000 \nEpoch: 910  | Training Loss: 0.59776 \nEpoch: 910  | Training Loss: 0.63882 \nEpoch: 910  | Training Loss: 0.51552 \nEpoch: 910  | Training Loss: 0.48799 \nEpoch: 910  | Training Loss: 0.20341 \nEpoch: 910  | Validation balanced accuracy : 0.50000 \nEpoch: 911  | Training Loss: 0.59729 \nEpoch: 911  | Training Loss: 0.63846 \nEpoch: 911  | Training Loss: 0.51518 \nEpoch: 911  | Training Loss: 0.48778 \nEpoch: 911  | Training Loss: 0.20331 \nEpoch: 911  | Validation balanced accuracy : 0.50000 \nEpoch: 912  | Training Loss: 0.59681 \nEpoch: 912  | Training Loss: 0.63810 \nEpoch: 912  | Training Loss: 0.51483 \nEpoch: 912  | Training Loss: 0.48757 \nEpoch: 912  | Training Loss: 0.20322 \nEpoch: 912  | Validation balanced accuracy : 0.50000 \nEpoch: 913  | Training Loss: 0.59632 \nEpoch: 913  | Training Loss: 0.63773 \nEpoch: 913  | Training Loss: 0.51449 \nEpoch: 913  | Training Loss: 0.48736 \nEpoch: 913  | Training Loss: 0.20313 \nEpoch: 913  | Validation balanced accuracy : 0.50000 \nEpoch: 914  | Training Loss: 0.59584 \nEpoch: 914  | Training Loss: 0.63736 \nEpoch: 914  | Training Loss: 0.51414 \nEpoch: 914  | Training Loss: 0.48715 \nEpoch: 914  | Training Loss: 0.20305 \nEpoch: 914  | Validation balanced accuracy : 0.50000 \nEpoch: 915  | Training Loss: 0.59535 \nEpoch: 915  | Training Loss: 0.63699 \nEpoch: 915  | Training Loss: 0.51379 \nEpoch: 915  | Training Loss: 0.48694 \nEpoch: 915  | Training Loss: 0.20297 \nEpoch: 915  | Validation balanced accuracy : 0.50000 \nEpoch: 916  | Training Loss: 0.59485 \nEpoch: 916  | Training Loss: 0.63662 \nEpoch: 916  | Training Loss: 0.51344 \nEpoch: 916  | Training Loss: 0.48673 \nEpoch: 916  | Training Loss: 0.20289 \nEpoch: 916  | Validation balanced accuracy : 0.50000 \nEpoch: 917  | Training Loss: 0.59436 \nEpoch: 917  | Training Loss: 0.63624 \nEpoch: 917  | Training Loss: 0.51308 \nEpoch: 917  | Training Loss: 0.48651 \nEpoch: 917  | Training Loss: 0.20281 \nEpoch: 917  | Validation balanced accuracy : 0.50000 \nEpoch: 918  | Training Loss: 0.59386 \nEpoch: 918  | Training Loss: 0.63586 \nEpoch: 918  | Training Loss: 0.51273 \nEpoch: 918  | Training Loss: 0.48630 \nEpoch: 918  | Training Loss: 0.20274 \nEpoch: 918  | Validation balanced accuracy : 0.50000 \nEpoch: 919  | Training Loss: 0.59336 \nEpoch: 919  | Training Loss: 0.63548 \nEpoch: 919  | Training Loss: 0.51237 \nEpoch: 919  | Training Loss: 0.48608 \nEpoch: 919  | Training Loss: 0.20267 \nEpoch: 919  | Validation balanced accuracy : 0.50000 \nEpoch: 920  | Training Loss: 0.59285 \nEpoch: 920  | Training Loss: 0.63510 \nEpoch: 920  | Training Loss: 0.51201 \nEpoch: 920  | Training Loss: 0.48586 \nEpoch: 920  | Training Loss: 0.20260 \nEpoch: 920  | Validation balanced accuracy : 0.50000 \nEpoch: 921  | Training Loss: 0.59235 \nEpoch: 921  | Training Loss: 0.63471 \nEpoch: 921  | Training Loss: 0.51165 \nEpoch: 921  | Training Loss: 0.48564 \nEpoch: 921  | Training Loss: 0.20253 \nEpoch: 921  | Validation balanced accuracy : 0.50000 \nEpoch: 922  | Training Loss: 0.59184 \nEpoch: 922  | Training Loss: 0.63433 \nEpoch: 922  | Training Loss: 0.51129 \nEpoch: 922  | Training Loss: 0.48542 \nEpoch: 922  | Training Loss: 0.20247 \nEpoch: 922  | Validation balanced accuracy : 0.50000 \nEpoch: 923  | Training Loss: 0.59132 \nEpoch: 923  | Training Loss: 0.63393 \nEpoch: 923  | Training Loss: 0.51093 \nEpoch: 923  | Training Loss: 0.48519 \nEpoch: 923  | Training Loss: 0.20241 \nEpoch: 923  | Validation balanced accuracy : 0.50000 \nEpoch: 924  | Training Loss: 0.59081 \nEpoch: 924  | Training Loss: 0.63354 \nEpoch: 924  | Training Loss: 0.51057 \nEpoch: 924  | Training Loss: 0.48497 \nEpoch: 924  | Training Loss: 0.20235 \nEpoch: 924  | Validation balanced accuracy : 0.50000 \nEpoch: 925  | Training Loss: 0.59029 \nEpoch: 925  | Training Loss: 0.63315 \nEpoch: 925  | Training Loss: 0.51020 \nEpoch: 925  | Training Loss: 0.48474 \nEpoch: 925  | Training Loss: 0.20229 \nEpoch: 925  | Validation balanced accuracy : 0.50000 \nEpoch: 926  | Training Loss: 0.58977 \nEpoch: 926  | Training Loss: 0.63275 \nEpoch: 926  | Training Loss: 0.50984 \nEpoch: 926  | Training Loss: 0.48452 \nEpoch: 926  | Training Loss: 0.20224 \nEpoch: 926  | Validation balanced accuracy : 0.50000 \nEpoch: 927  | Training Loss: 0.58925 \nEpoch: 927  | Training Loss: 0.63235 \nEpoch: 927  | Training Loss: 0.50947 \nEpoch: 927  | Training Loss: 0.48429 \nEpoch: 927  | Training Loss: 0.20219 \nEpoch: 927  | Validation balanced accuracy : 0.50000 \nEpoch: 928  | Training Loss: 0.58872 \nEpoch: 928  | Training Loss: 0.63195 \nEpoch: 928  | Training Loss: 0.50910 \nEpoch: 928  | Training Loss: 0.48406 \nEpoch: 928  | Training Loss: 0.20215 \nEpoch: 928  | Validation balanced accuracy : 0.50000 \nEpoch: 929  | Training Loss: 0.58819 \nEpoch: 929  | Training Loss: 0.63154 \nEpoch: 929  | Training Loss: 0.50873 \nEpoch: 929  | Training Loss: 0.48383 \nEpoch: 929  | Training Loss: 0.20210 \nEpoch: 929  | Validation balanced accuracy : 0.50000 \nEpoch: 930  | Training Loss: 0.58766 \nEpoch: 930  | Training Loss: 0.63114 \nEpoch: 930  | Training Loss: 0.50836 \nEpoch: 930  | Training Loss: 0.48359 \nEpoch: 930  | Training Loss: 0.20206 \nEpoch: 930  | Validation balanced accuracy : 0.50000 \nEpoch: 931  | Training Loss: 0.58713 \nEpoch: 931  | Training Loss: 0.63073 \nEpoch: 931  | Training Loss: 0.50799 \nEpoch: 931  | Training Loss: 0.48336 \nEpoch: 931  | Training Loss: 0.20202 \nEpoch: 931  | Validation balanced accuracy : 0.50000 \nEpoch: 932  | Training Loss: 0.58659 \nEpoch: 932  | Training Loss: 0.63032 \nEpoch: 932  | Training Loss: 0.50761 \nEpoch: 932  | Training Loss: 0.48312 \nEpoch: 932  | Training Loss: 0.20199 \nEpoch: 932  | Validation balanced accuracy : 0.50000 \nEpoch: 933  | Training Loss: 0.58606 \nEpoch: 933  | Training Loss: 0.62990 \nEpoch: 933  | Training Loss: 0.50724 \nEpoch: 933  | Training Loss: 0.48289 \nEpoch: 933  | Training Loss: 0.20196 \nEpoch: 933  | Validation balanced accuracy : 0.50000 \nEpoch: 934  | Training Loss: 0.58552 \nEpoch: 934  | Training Loss: 0.62949 \nEpoch: 934  | Training Loss: 0.50686 \nEpoch: 934  | Training Loss: 0.48265 \nEpoch: 934  | Training Loss: 0.20193 \nEpoch: 934  | Validation balanced accuracy : 0.50000 \nEpoch: 935  | Training Loss: 0.58497 \nEpoch: 935  | Training Loss: 0.62907 \nEpoch: 935  | Training Loss: 0.50648 \nEpoch: 935  | Training Loss: 0.48241 \nEpoch: 935  | Training Loss: 0.20191 \nEpoch: 935  | Validation balanced accuracy : 0.50000 \nEpoch: 936  | Training Loss: 0.58443 \nEpoch: 936  | Training Loss: 0.62865 \nEpoch: 936  | Training Loss: 0.50611 \nEpoch: 936  | Training Loss: 0.48217 \nEpoch: 936  | Training Loss: 0.20189 \nEpoch: 936  | Validation balanced accuracy : 0.50000 \nEpoch: 937  | Training Loss: 0.58388 \nEpoch: 937  | Training Loss: 0.62823 \nEpoch: 937  | Training Loss: 0.50573 \nEpoch: 937  | Training Loss: 0.48192 \nEpoch: 937  | Training Loss: 0.20187 \nEpoch: 937  | Validation balanced accuracy : 0.50000 \nEpoch: 938  | Training Loss: 0.58333 \nEpoch: 938  | Training Loss: 0.62781 \nEpoch: 938  | Training Loss: 0.50534 \nEpoch: 938  | Training Loss: 0.48168 \nEpoch: 938  | Training Loss: 0.20185 \nEpoch: 938  | Validation balanced accuracy : 0.50000 \nEpoch: 939  | Training Loss: 0.58278 \nEpoch: 939  | Training Loss: 0.62738 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 939  | Training Loss: 0.50496 \nEpoch: 939  | Training Loss: 0.48143 \nEpoch: 939  | Training Loss: 0.20184 \nEpoch: 939  | Validation balanced accuracy : 0.50000 \nEpoch: 940  | Training Loss: 0.58222 \nEpoch: 940  | Training Loss: 0.62696 \nEpoch: 940  | Training Loss: 0.50458 \nEpoch: 940  | Training Loss: 0.48119 \nEpoch: 940  | Training Loss: 0.20183 \nEpoch: 940  | Validation balanced accuracy : 0.50000 \nEpoch: 941  | Training Loss: 0.58167 \nEpoch: 941  | Training Loss: 0.62653 \nEpoch: 941  | Training Loss: 0.50420 \nEpoch: 941  | Training Loss: 0.48094 \nEpoch: 941  | Training Loss: 0.20183 \nEpoch: 941  | Validation balanced accuracy : 0.50000 \nEpoch: 942  | Training Loss: 0.58111 \nEpoch: 942  | Training Loss: 0.62609 \nEpoch: 942  | Training Loss: 0.50381 \nEpoch: 942  | Training Loss: 0.48069 \nEpoch: 942  | Training Loss: 0.20183 \nEpoch: 942  | Validation balanced accuracy : 0.50000 \nEpoch: 943  | Training Loss: 0.58055 \nEpoch: 943  | Training Loss: 0.62566 \nEpoch: 943  | Training Loss: 0.50343 \nEpoch: 943  | Training Loss: 0.48044 \nEpoch: 943  | Training Loss: 0.20183 \nEpoch: 943  | Validation balanced accuracy : 0.50000 \nEpoch: 944  | Training Loss: 0.57998 \nEpoch: 944  | Training Loss: 0.62523 \nEpoch: 944  | Training Loss: 0.50304 \nEpoch: 944  | Training Loss: 0.48019 \nEpoch: 944  | Training Loss: 0.20183 \nEpoch: 944  | Validation balanced accuracy : 0.50000 \nEpoch: 945  | Training Loss: 0.57942 \nEpoch: 945  | Training Loss: 0.62479 \nEpoch: 945  | Training Loss: 0.50265 \nEpoch: 945  | Training Loss: 0.47993 \nEpoch: 945  | Training Loss: 0.20184 \nEpoch: 945  | Validation balanced accuracy : 0.50000 \nEpoch: 946  | Training Loss: 0.57885 \nEpoch: 946  | Training Loss: 0.62435 \nEpoch: 946  | Training Loss: 0.50226 \nEpoch: 946  | Training Loss: 0.47968 \nEpoch: 946  | Training Loss: 0.20185 \nEpoch: 946  | Validation balanced accuracy : 0.50000 \nEpoch: 947  | Training Loss: 0.57828 \nEpoch: 947  | Training Loss: 0.62391 \nEpoch: 947  | Training Loss: 0.50187 \nEpoch: 947  | Training Loss: 0.47942 \nEpoch: 947  | Training Loss: 0.20187 \nEpoch: 947  | Validation balanced accuracy : 0.50000 \nEpoch: 948  | Training Loss: 0.57771 \nEpoch: 948  | Training Loss: 0.62347 \nEpoch: 948  | Training Loss: 0.50148 \nEpoch: 948  | Training Loss: 0.47916 \nEpoch: 948  | Training Loss: 0.20189 \nEpoch: 948  | Validation balanced accuracy : 0.50000 \nEpoch: 949  | Training Loss: 0.57714 \nEpoch: 949  | Training Loss: 0.62302 \nEpoch: 949  | Training Loss: 0.50109 \nEpoch: 949  | Training Loss: 0.47890 \nEpoch: 949  | Training Loss: 0.20191 \nEpoch: 949  | Validation balanced accuracy : 0.50000 \nEpoch: 950  | Training Loss: 0.57656 \nEpoch: 950  | Training Loss: 0.62258 \nEpoch: 950  | Training Loss: 0.50070 \nEpoch: 950  | Training Loss: 0.47864 \nEpoch: 950  | Training Loss: 0.20193 \nEpoch: 950  | Validation balanced accuracy : 0.50000 \nEpoch: 951  | Training Loss: 0.57599 \nEpoch: 951  | Training Loss: 0.62213 \nEpoch: 951  | Training Loss: 0.50031 \nEpoch: 951  | Training Loss: 0.47838 \nEpoch: 951  | Training Loss: 0.20196 \nEpoch: 951  | Validation balanced accuracy : 0.50000 \nEpoch: 952  | Training Loss: 0.57541 \nEpoch: 952  | Training Loss: 0.62168 \nEpoch: 952  | Training Loss: 0.49992 \nEpoch: 952  | Training Loss: 0.47811 \nEpoch: 952  | Training Loss: 0.20199 \nEpoch: 952  | Validation balanced accuracy : 0.50000 \nEpoch: 953  | Training Loss: 0.57483 \nEpoch: 953  | Training Loss: 0.62123 \nEpoch: 953  | Training Loss: 0.49953 \nEpoch: 953  | Training Loss: 0.47785 \nEpoch: 953  | Training Loss: 0.20203 \nEpoch: 953  | Validation balanced accuracy : 0.50000 \nEpoch: 954  | Training Loss: 0.57425 \nEpoch: 954  | Training Loss: 0.62078 \nEpoch: 954  | Training Loss: 0.49913 \nEpoch: 954  | Training Loss: 0.47758 \nEpoch: 954  | Training Loss: 0.20207 \nEpoch: 954  | Validation balanced accuracy : 0.50000 \nEpoch: 955  | Training Loss: 0.57367 \nEpoch: 955  | Training Loss: 0.62033 \nEpoch: 955  | Training Loss: 0.49874 \nEpoch: 955  | Training Loss: 0.47731 \nEpoch: 955  | Training Loss: 0.20211 \nEpoch: 955  | Validation balanced accuracy : 0.50000 \nEpoch: 956  | Training Loss: 0.57309 \nEpoch: 956  | Training Loss: 0.61988 \nEpoch: 956  | Training Loss: 0.49835 \nEpoch: 956  | Training Loss: 0.47704 \nEpoch: 956  | Training Loss: 0.20215 \nEpoch: 956  | Validation balanced accuracy : 0.50000 \nEpoch: 957  | Training Loss: 0.57250 \nEpoch: 957  | Training Loss: 0.61942 \nEpoch: 957  | Training Loss: 0.49795 \nEpoch: 957  | Training Loss: 0.47677 \nEpoch: 957  | Training Loss: 0.20220 \nEpoch: 957  | Validation balanced accuracy : 0.50000 \nEpoch: 958  | Training Loss: 0.57192 \nEpoch: 958  | Training Loss: 0.61896 \nEpoch: 958  | Training Loss: 0.49756 \nEpoch: 958  | Training Loss: 0.47650 \nEpoch: 958  | Training Loss: 0.20225 \nEpoch: 958  | Validation balanced accuracy : 0.50000 \nEpoch: 959  | Training Loss: 0.57133 \nEpoch: 959  | Training Loss: 0.61851 \nEpoch: 959  | Training Loss: 0.49716 \nEpoch: 959  | Training Loss: 0.47623 \nEpoch: 959  | Training Loss: 0.20231 \nEpoch: 959  | Validation balanced accuracy : 0.50000 \nEpoch: 960  | Training Loss: 0.57074 \nEpoch: 960  | Training Loss: 0.61805 \nEpoch: 960  | Training Loss: 0.49677 \nEpoch: 960  | Training Loss: 0.47595 \nEpoch: 960  | Training Loss: 0.20237 \nEpoch: 960  | Validation balanced accuracy : 0.50000 \nEpoch: 961  | Training Loss: 0.57015 \nEpoch: 961  | Training Loss: 0.61759 \nEpoch: 961  | Training Loss: 0.49637 \nEpoch: 961  | Training Loss: 0.47568 \nEpoch: 961  | Training Loss: 0.20243 \nEpoch: 961  | Validation balanced accuracy : 0.50000 \nEpoch: 962  | Training Loss: 0.56956 \nEpoch: 962  | Training Loss: 0.61713 \nEpoch: 962  | Training Loss: 0.49597 \nEpoch: 962  | Training Loss: 0.47540 \nEpoch: 962  | Training Loss: 0.20249 \nEpoch: 962  | Validation balanced accuracy : 0.50000 \nEpoch: 963  | Training Loss: 0.56897 \nEpoch: 963  | Training Loss: 0.61666 \nEpoch: 963  | Training Loss: 0.49558 \nEpoch: 963  | Training Loss: 0.47512 \nEpoch: 963  | Training Loss: 0.20256 \nEpoch: 963  | Validation balanced accuracy : 0.50000 \nEpoch: 964  | Training Loss: 0.56838 \nEpoch: 964  | Training Loss: 0.61620 \nEpoch: 964  | Training Loss: 0.49518 \nEpoch: 964  | Training Loss: 0.47484 \nEpoch: 964  | Training Loss: 0.20263 \nEpoch: 964  | Validation balanced accuracy : 0.50000 \nEpoch: 965  | Training Loss: 0.56779 \nEpoch: 965  | Training Loss: 0.61574 \nEpoch: 965  | Training Loss: 0.49479 \nEpoch: 965  | Training Loss: 0.47456 \nEpoch: 965  | Training Loss: 0.20271 \nEpoch: 965  | Validation balanced accuracy : 0.50000 \nEpoch: 966  | Training Loss: 0.56720 \nEpoch: 966  | Training Loss: 0.61527 \nEpoch: 966  | Training Loss: 0.49439 \nEpoch: 966  | Training Loss: 0.47428 \nEpoch: 966  | Training Loss: 0.20278 \nEpoch: 966  | Validation balanced accuracy : 0.50000 \nEpoch: 967  | Training Loss: 0.56660 \nEpoch: 967  | Training Loss: 0.61481 \nEpoch: 967  | Training Loss: 0.49399 \nEpoch: 967  | Training Loss: 0.47399 \nEpoch: 967  | Training Loss: 0.20286 \nEpoch: 967  | Validation balanced accuracy : 0.50000 \nEpoch: 968  | Training Loss: 0.56601 \nEpoch: 968  | Training Loss: 0.61434 \nEpoch: 968  | Training Loss: 0.49360 \nEpoch: 968  | Training Loss: 0.47371 \nEpoch: 968  | Training Loss: 0.20295 \nEpoch: 968  | Validation balanced accuracy : 0.50000 \nEpoch: 969  | Training Loss: 0.56542 \nEpoch: 969  | Training Loss: 0.61387 \nEpoch: 969  | Training Loss: 0.49320 \nEpoch: 969  | Training Loss: 0.47342 \nEpoch: 969  | Training Loss: 0.20303 \nEpoch: 969  | Validation balanced accuracy : 0.50000 \nEpoch: 970  | Training Loss: 0.56482 \nEpoch: 970  | Training Loss: 0.61340 \nEpoch: 970  | Training Loss: 0.49281 \nEpoch: 970  | Training Loss: 0.47313 \nEpoch: 970  | Training Loss: 0.20312 \nEpoch: 970  | Validation balanced accuracy : 0.50000 \nEpoch: 971  | Training Loss: 0.56423 \nEpoch: 971  | Training Loss: 0.61294 \nEpoch: 971  | Training Loss: 0.49241 \nEpoch: 971  | Training Loss: 0.47284 \nEpoch: 971  | Training Loss: 0.20321 \nEpoch: 971  | Validation balanced accuracy : 0.50000 \nEpoch: 972  | Training Loss: 0.56363 \nEpoch: 972  | Training Loss: 0.61247 \nEpoch: 972  | Training Loss: 0.49202 \nEpoch: 972  | Training Loss: 0.47255 \nEpoch: 972  | Training Loss: 0.20331 \nEpoch: 972  | Validation balanced accuracy : 0.50000 \nEpoch: 973  | Training Loss: 0.56304 \nEpoch: 973  | Training Loss: 0.61200 \nEpoch: 973  | Training Loss: 0.49162 \nEpoch: 973  | Training Loss: 0.47226 \nEpoch: 973  | Training Loss: 0.20341 \nEpoch: 973  | Validation balanced accuracy : 0.50000 \nEpoch: 974  | Training Loss: 0.56244 \nEpoch: 974  | Training Loss: 0.61153 \nEpoch: 974  | Training Loss: 0.49123 \nEpoch: 974  | Training Loss: 0.47197 \nEpoch: 974  | Training Loss: 0.20351 \nEpoch: 974  | Validation balanced accuracy : 0.50000 \nEpoch: 975  | Training Loss: 0.56185 \nEpoch: 975  | Training Loss: 0.61106 \nEpoch: 975  | Training Loss: 0.49084 \nEpoch: 975  | Training Loss: 0.47168 \nEpoch: 975  | Training Loss: 0.20361 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 975  | Validation balanced accuracy : 0.50000 \nEpoch: 976  | Training Loss: 0.56125 \nEpoch: 976  | Training Loss: 0.61059 \nEpoch: 976  | Training Loss: 0.49044 \nEpoch: 976  | Training Loss: 0.47138 \nEpoch: 976  | Training Loss: 0.20371 \nEpoch: 976  | Validation balanced accuracy : 0.50000 \nEpoch: 977  | Training Loss: 0.56066 \nEpoch: 977  | Training Loss: 0.61012 \nEpoch: 977  | Training Loss: 0.49005 \nEpoch: 977  | Training Loss: 0.47108 \nEpoch: 977  | Training Loss: 0.20382 \nEpoch: 977  | Validation balanced accuracy : 0.50000 \nEpoch: 978  | Training Loss: 0.56006 \nEpoch: 978  | Training Loss: 0.60965 \nEpoch: 978  | Training Loss: 0.48966 \nEpoch: 978  | Training Loss: 0.47079 \nEpoch: 978  | Training Loss: 0.20393 \nEpoch: 978  | Validation balanced accuracy : 0.50000 \nEpoch: 979  | Training Loss: 0.55947 \nEpoch: 979  | Training Loss: 0.60917 \nEpoch: 979  | Training Loss: 0.48926 \nEpoch: 979  | Training Loss: 0.47049 \nEpoch: 979  | Training Loss: 0.20405 \nEpoch: 979  | Validation balanced accuracy : 0.50000 \nEpoch: 980  | Training Loss: 0.55887 \nEpoch: 980  | Training Loss: 0.60870 \nEpoch: 980  | Training Loss: 0.48887 \nEpoch: 980  | Training Loss: 0.47019 \nEpoch: 980  | Training Loss: 0.20416 \nEpoch: 980  | Validation balanced accuracy : 0.50000 \nEpoch: 981  | Training Loss: 0.55828 \nEpoch: 981  | Training Loss: 0.60823 \nEpoch: 981  | Training Loss: 0.48848 \nEpoch: 981  | Training Loss: 0.46989 \nEpoch: 981  | Training Loss: 0.20428 \nEpoch: 981  | Validation balanced accuracy : 0.50000 \nEpoch: 982  | Training Loss: 0.55769 \nEpoch: 982  | Training Loss: 0.60776 \nEpoch: 982  | Training Loss: 0.48809 \nEpoch: 982  | Training Loss: 0.46959 \nEpoch: 982  | Training Loss: 0.20440 \nEpoch: 982  | Validation balanced accuracy : 0.50000 \nEpoch: 983  | Training Loss: 0.55709 \nEpoch: 983  | Training Loss: 0.60729 \nEpoch: 983  | Training Loss: 0.48770 \nEpoch: 983  | Training Loss: 0.46928 \nEpoch: 983  | Training Loss: 0.20453 \nEpoch: 983  | Validation balanced accuracy : 0.50000 \nEpoch: 984  | Training Loss: 0.55650 \nEpoch: 984  | Training Loss: 0.60682 \nEpoch: 984  | Training Loss: 0.48732 \nEpoch: 984  | Training Loss: 0.46898 \nEpoch: 984  | Training Loss: 0.20465 \nEpoch: 984  | Validation balanced accuracy : 0.50000 \nEpoch: 985  | Training Loss: 0.55591 \nEpoch: 985  | Training Loss: 0.60635 \nEpoch: 985  | Training Loss: 0.48693 \nEpoch: 985  | Training Loss: 0.46867 \nEpoch: 985  | Training Loss: 0.20478 \nEpoch: 985  | Validation balanced accuracy : 0.50000 \nEpoch: 986  | Training Loss: 0.55532 \nEpoch: 986  | Training Loss: 0.60587 \nEpoch: 986  | Training Loss: 0.48654 \nEpoch: 986  | Training Loss: 0.46837 \nEpoch: 986  | Training Loss: 0.20491 \nEpoch: 986  | Validation balanced accuracy : 0.50000 \nEpoch: 987  | Training Loss: 0.55473 \nEpoch: 987  | Training Loss: 0.60540 \nEpoch: 987  | Training Loss: 0.48616 \nEpoch: 987  | Training Loss: 0.46806 \nEpoch: 987  | Training Loss: 0.20504 \nEpoch: 987  | Validation balanced accuracy : 0.50000 \nEpoch: 988  | Training Loss: 0.55414 \nEpoch: 988  | Training Loss: 0.60493 \nEpoch: 988  | Training Loss: 0.48577 \nEpoch: 988  | Training Loss: 0.46775 \nEpoch: 988  | Training Loss: 0.20517 \nEpoch: 988  | Validation balanced accuracy : 0.50000 \nEpoch: 989  | Training Loss: 0.55355 \nEpoch: 989  | Training Loss: 0.60446 \nEpoch: 989  | Training Loss: 0.48539 \nEpoch: 989  | Training Loss: 0.46744 \nEpoch: 989  | Training Loss: 0.20531 \nEpoch: 989  | Validation balanced accuracy : 0.50000 \nEpoch: 990  | Training Loss: 0.55296 \nEpoch: 990  | Training Loss: 0.60399 \nEpoch: 990  | Training Loss: 0.48500 \nEpoch: 990  | Training Loss: 0.46713 \nEpoch: 990  | Training Loss: 0.20545 \nEpoch: 990  | Validation balanced accuracy : 0.50000 \nEpoch: 991  | Training Loss: 0.55238 \nEpoch: 991  | Training Loss: 0.60352 \nEpoch: 991  | Training Loss: 0.48462 \nEpoch: 991  | Training Loss: 0.46682 \nEpoch: 991  | Training Loss: 0.20559 \nEpoch: 991  | Validation balanced accuracy : 0.50000 \nEpoch: 992  | Training Loss: 0.55179 \nEpoch: 992  | Training Loss: 0.60305 \nEpoch: 992  | Training Loss: 0.48424 \nEpoch: 992  | Training Loss: 0.46651 \nEpoch: 992  | Training Loss: 0.20573 \nEpoch: 992  | Validation balanced accuracy : 0.50000 \nEpoch: 993  | Training Loss: 0.55121 \nEpoch: 993  | Training Loss: 0.60258 \nEpoch: 993  | Training Loss: 0.48386 \nEpoch: 993  | Training Loss: 0.46619 \nEpoch: 993  | Training Loss: 0.20587 \nEpoch: 993  | Validation balanced accuracy : 0.50000 \nEpoch: 994  | Training Loss: 0.55063 \nEpoch: 994  | Training Loss: 0.60211 \nEpoch: 994  | Training Loss: 0.48348 \nEpoch: 994  | Training Loss: 0.46588 \nEpoch: 994  | Training Loss: 0.20602 \nEpoch: 994  | Validation balanced accuracy : 0.50000 \nEpoch: 995  | Training Loss: 0.55004 \nEpoch: 995  | Training Loss: 0.60164 \nEpoch: 995  | Training Loss: 0.48310 \nEpoch: 995  | Training Loss: 0.46556 \nEpoch: 995  | Training Loss: 0.20616 \nEpoch: 995  | Validation balanced accuracy : 0.50000 \nEpoch: 996  | Training Loss: 0.54946 \nEpoch: 996  | Training Loss: 0.60118 \nEpoch: 996  | Training Loss: 0.48272 \nEpoch: 996  | Training Loss: 0.46525 \nEpoch: 996  | Training Loss: 0.20631 \nEpoch: 996  | Validation balanced accuracy : 0.50000 \nEpoch: 997  | Training Loss: 0.54889 \nEpoch: 997  | Training Loss: 0.60071 \nEpoch: 997  | Training Loss: 0.48235 \nEpoch: 997  | Training Loss: 0.46493 \nEpoch: 997  | Training Loss: 0.20646 \nEpoch: 997  | Validation balanced accuracy : 0.50000 \nEpoch: 998  | Training Loss: 0.54831 \nEpoch: 998  | Training Loss: 0.60024 \nEpoch: 998  | Training Loss: 0.48197 \nEpoch: 998  | Training Loss: 0.46461 \nEpoch: 998  | Training Loss: 0.20661 \nEpoch: 998  | Validation balanced accuracy : 0.50000 \nEpoch: 999  | Training Loss: 0.54773 \nEpoch: 999  | Training Loss: 0.59978 \nEpoch: 999  | Training Loss: 0.48160 \nEpoch: 999  | Training Loss: 0.46429 \nEpoch: 999  | Training Loss: 0.20677 \nEpoch: 999  | Validation balanced accuracy : 0.50000 \nEpoch: 1000  | Training Loss: 0.54716 \nEpoch: 1000  | Training Loss: 0.59931 \nEpoch: 1000  | Training Loss: 0.48123 \nEpoch: 1000  | Training Loss: 0.46397 \nEpoch: 1000  | Training Loss: 0.20692 \nEpoch: 1000  | Validation balanced accuracy : 0.50000 \nEpoch: 1001  | Training Loss: 0.54658 \nEpoch: 1001  | Training Loss: 0.59884 \nEpoch: 1001  | Training Loss: 0.48085 \nEpoch: 1001  | Training Loss: 0.46365 \nEpoch: 1001  | Training Loss: 0.20707 \nEpoch: 1001  | Validation balanced accuracy : 0.50000 \nEpoch: 1002  | Training Loss: 0.54601 \nEpoch: 1002  | Training Loss: 0.59838 \nEpoch: 1002  | Training Loss: 0.48048 \nEpoch: 1002  | Training Loss: 0.46333 \nEpoch: 1002  | Training Loss: 0.20723 \nEpoch: 1002  | Validation balanced accuracy : 0.50000 \nEpoch: 1003  | Training Loss: 0.54544 \nEpoch: 1003  | Training Loss: 0.59792 \nEpoch: 1003  | Training Loss: 0.48012 \nEpoch: 1003  | Training Loss: 0.46301 \nEpoch: 1003  | Training Loss: 0.20739 \nEpoch: 1003  | Validation balanced accuracy : 0.50000 \nEpoch: 1004  | Training Loss: 0.54487 \nEpoch: 1004  | Training Loss: 0.59745 \nEpoch: 1004  | Training Loss: 0.47975 \nEpoch: 1004  | Training Loss: 0.46269 \nEpoch: 1004  | Training Loss: 0.20755 \nEpoch: 1004  | Validation balanced accuracy : 0.50000 \nEpoch: 1005  | Training Loss: 0.54431 \nEpoch: 1005  | Training Loss: 0.59699 \nEpoch: 1005  | Training Loss: 0.47938 \nEpoch: 1005  | Training Loss: 0.46236 \nEpoch: 1005  | Training Loss: 0.20771 \nEpoch: 1005  | Validation balanced accuracy : 0.50000 \nEpoch: 1006  | Training Loss: 0.54374 \nEpoch: 1006  | Training Loss: 0.59653 \nEpoch: 1006  | Training Loss: 0.47902 \nEpoch: 1006  | Training Loss: 0.46204 \nEpoch: 1006  | Training Loss: 0.20787 \nEpoch: 1006  | Validation balanced accuracy : 0.50000 \nEpoch: 1007  | Training Loss: 0.54318 \nEpoch: 1007  | Training Loss: 0.59607 \nEpoch: 1007  | Training Loss: 0.47865 \nEpoch: 1007  | Training Loss: 0.46171 \nEpoch: 1007  | Training Loss: 0.20803 \nEpoch: 1007  | Validation balanced accuracy : 0.50000 \nEpoch: 1008  | Training Loss: 0.54261 \nEpoch: 1008  | Training Loss: 0.59561 \nEpoch: 1008  | Training Loss: 0.47829 \nEpoch: 1008  | Training Loss: 0.46139 \nEpoch: 1008  | Training Loss: 0.20819 \nEpoch: 1008  | Validation balanced accuracy : 0.50000 \nEpoch: 1009  | Training Loss: 0.54205 \nEpoch: 1009  | Training Loss: 0.59515 \nEpoch: 1009  | Training Loss: 0.47793 \nEpoch: 1009  | Training Loss: 0.46106 \nEpoch: 1009  | Training Loss: 0.20836 \nEpoch: 1009  | Validation balanced accuracy : 0.50000 \nEpoch: 1010  | Training Loss: 0.54150 \nEpoch: 1010  | Training Loss: 0.59469 \nEpoch: 1010  | Training Loss: 0.47757 \nEpoch: 1010  | Training Loss: 0.46073 \nEpoch: 1010  | Training Loss: 0.20852 \nEpoch: 1010  | Validation balanced accuracy : 0.50000 \nEpoch: 1011  | Training Loss: 0.54094 \nEpoch: 1011  | Training Loss: 0.59423 \nEpoch: 1011  | Training Loss: 0.47721 \nEpoch: 1011  | Training Loss: 0.46041 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1011  | Training Loss: 0.20869 \nEpoch: 1011  | Validation balanced accuracy : 0.50000 \nEpoch: 1012  | Training Loss: 0.54038 \nEpoch: 1012  | Training Loss: 0.59378 \nEpoch: 1012  | Training Loss: 0.47685 \nEpoch: 1012  | Training Loss: 0.46008 \nEpoch: 1012  | Training Loss: 0.20885 \nEpoch: 1012  | Validation balanced accuracy : 0.50000 \nEpoch: 1013  | Training Loss: 0.53983 \nEpoch: 1013  | Training Loss: 0.59332 \nEpoch: 1013  | Training Loss: 0.47650 \nEpoch: 1013  | Training Loss: 0.45975 \nEpoch: 1013  | Training Loss: 0.20902 \nEpoch: 1013  | Validation balanced accuracy : 0.50000 \nEpoch: 1014  | Training Loss: 0.53928 \nEpoch: 1014  | Training Loss: 0.59286 \nEpoch: 1014  | Training Loss: 0.47614 \nEpoch: 1014  | Training Loss: 0.45942 \nEpoch: 1014  | Training Loss: 0.20919 \nEpoch: 1014  | Validation balanced accuracy : 0.50000 \nEpoch: 1015  | Training Loss: 0.53873 \nEpoch: 1015  | Training Loss: 0.59241 \nEpoch: 1015  | Training Loss: 0.47579 \nEpoch: 1015  | Training Loss: 0.45909 \nEpoch: 1015  | Training Loss: 0.20936 \nEpoch: 1015  | Validation balanced accuracy : 0.50000 \nEpoch: 1016  | Training Loss: 0.53818 \nEpoch: 1016  | Training Loss: 0.59196 \nEpoch: 1016  | Training Loss: 0.47544 \nEpoch: 1016  | Training Loss: 0.45876 \nEpoch: 1016  | Training Loss: 0.20953 \nEpoch: 1016  | Validation balanced accuracy : 0.50000 \nEpoch: 1017  | Training Loss: 0.53763 \nEpoch: 1017  | Training Loss: 0.59150 \nEpoch: 1017  | Training Loss: 0.47508 \nEpoch: 1017  | Training Loss: 0.45842 \nEpoch: 1017  | Training Loss: 0.20970 \nEpoch: 1017  | Validation balanced accuracy : 0.50000 \nEpoch: 1018  | Training Loss: 0.53709 \nEpoch: 1018  | Training Loss: 0.59105 \nEpoch: 1018  | Training Loss: 0.47474 \nEpoch: 1018  | Training Loss: 0.45809 \nEpoch: 1018  | Training Loss: 0.20987 \nEpoch: 1018  | Validation balanced accuracy : 0.50000 \nEpoch: 1019  | Training Loss: 0.53655 \nEpoch: 1019  | Training Loss: 0.59060 \nEpoch: 1019  | Training Loss: 0.47439 \nEpoch: 1019  | Training Loss: 0.45776 \nEpoch: 1019  | Training Loss: 0.21004 \nEpoch: 1019  | Validation balanced accuracy : 0.50000 \nEpoch: 1020  | Training Loss: 0.53600 \nEpoch: 1020  | Training Loss: 0.59015 \nEpoch: 1020  | Training Loss: 0.47404 \nEpoch: 1020  | Training Loss: 0.45743 \nEpoch: 1020  | Training Loss: 0.21021 \nEpoch: 1020  | Validation balanced accuracy : 0.50000 \nEpoch: 1021  | Training Loss: 0.53547 \nEpoch: 1021  | Training Loss: 0.58970 \nEpoch: 1021  | Training Loss: 0.47370 \nEpoch: 1021  | Training Loss: 0.45709 \nEpoch: 1021  | Training Loss: 0.21038 \nEpoch: 1021  | Validation balanced accuracy : 0.50000 \nEpoch: 1022  | Training Loss: 0.53493 \nEpoch: 1022  | Training Loss: 0.58925 \nEpoch: 1022  | Training Loss: 0.47335 \nEpoch: 1022  | Training Loss: 0.45676 \nEpoch: 1022  | Training Loss: 0.21056 \nEpoch: 1022  | Validation balanced accuracy : 0.50000 \nEpoch: 1023  | Training Loss: 0.53439 \nEpoch: 1023  | Training Loss: 0.58881 \nEpoch: 1023  | Training Loss: 0.47301 \nEpoch: 1023  | Training Loss: 0.45642 \nEpoch: 1023  | Training Loss: 0.21073 \nEpoch: 1023  | Validation balanced accuracy : 0.50000 \nEpoch: 1024  | Training Loss: 0.53386 \nEpoch: 1024  | Training Loss: 0.58836 \nEpoch: 1024  | Training Loss: 0.47267 \nEpoch: 1024  | Training Loss: 0.45609 \nEpoch: 1024  | Training Loss: 0.21090 \nEpoch: 1024  | Validation balanced accuracy : 0.50000 \nEpoch: 1025  | Training Loss: 0.53333 \nEpoch: 1025  | Training Loss: 0.58791 \nEpoch: 1025  | Training Loss: 0.47233 \nEpoch: 1025  | Training Loss: 0.45575 \nEpoch: 1025  | Training Loss: 0.21107 \nEpoch: 1025  | Validation balanced accuracy : 0.50000 \nEpoch: 1026  | Training Loss: 0.53280 \nEpoch: 1026  | Training Loss: 0.58747 \nEpoch: 1026  | Training Loss: 0.47199 \nEpoch: 1026  | Training Loss: 0.45541 \nEpoch: 1026  | Training Loss: 0.21125 \nEpoch: 1026  | Validation balanced accuracy : 0.50000 \nEpoch: 1027  | Training Loss: 0.53227 \nEpoch: 1027  | Training Loss: 0.58702 \nEpoch: 1027  | Training Loss: 0.47165 \nEpoch: 1027  | Training Loss: 0.45508 \nEpoch: 1027  | Training Loss: 0.21142 \nEpoch: 1027  | Validation balanced accuracy : 0.50000 \nEpoch: 1028  | Training Loss: 0.53174 \nEpoch: 1028  | Training Loss: 0.58658 \nEpoch: 1028  | Training Loss: 0.47132 \nEpoch: 1028  | Training Loss: 0.45474 \nEpoch: 1028  | Training Loss: 0.21160 \nEpoch: 1028  | Validation balanced accuracy : 0.50000 \nEpoch: 1029  | Training Loss: 0.53122 \nEpoch: 1029  | Training Loss: 0.58614 \nEpoch: 1029  | Training Loss: 0.47098 \nEpoch: 1029  | Training Loss: 0.45440 \nEpoch: 1029  | Training Loss: 0.21177 \nEpoch: 1029  | Validation balanced accuracy : 0.50000 \nEpoch: 1030  | Training Loss: 0.53070 \nEpoch: 1030  | Training Loss: 0.58570 \nEpoch: 1030  | Training Loss: 0.47065 \nEpoch: 1030  | Training Loss: 0.45407 \nEpoch: 1030  | Training Loss: 0.21195 \nEpoch: 1030  | Validation balanced accuracy : 0.50000 \nEpoch: 1031  | Training Loss: 0.53018 \nEpoch: 1031  | Training Loss: 0.58526 \nEpoch: 1031  | Training Loss: 0.47032 \nEpoch: 1031  | Training Loss: 0.45373 \nEpoch: 1031  | Training Loss: 0.21212 \nEpoch: 1031  | Validation balanced accuracy : 0.50000 \nEpoch: 1032  | Training Loss: 0.52966 \nEpoch: 1032  | Training Loss: 0.58482 \nEpoch: 1032  | Training Loss: 0.46999 \nEpoch: 1032  | Training Loss: 0.45339 \nEpoch: 1032  | Training Loss: 0.21230 \nEpoch: 1032  | Validation balanced accuracy : 0.50000 \nEpoch: 1033  | Training Loss: 0.52914 \nEpoch: 1033  | Training Loss: 0.58438 \nEpoch: 1033  | Training Loss: 0.46966 \nEpoch: 1033  | Training Loss: 0.45305 \nEpoch: 1033  | Training Loss: 0.21247 \nEpoch: 1033  | Validation balanced accuracy : 0.50000 \nEpoch: 1034  | Training Loss: 0.52863 \nEpoch: 1034  | Training Loss: 0.58394 \nEpoch: 1034  | Training Loss: 0.46933 \nEpoch: 1034  | Training Loss: 0.45271 \nEpoch: 1034  | Training Loss: 0.21265 \nEpoch: 1034  | Validation balanced accuracy : 0.50000 \nEpoch: 1035  | Training Loss: 0.52811 \nEpoch: 1035  | Training Loss: 0.58350 \nEpoch: 1035  | Training Loss: 0.46901 \nEpoch: 1035  | Training Loss: 0.45237 \nEpoch: 1035  | Training Loss: 0.21282 \nEpoch: 1035  | Validation balanced accuracy : 0.50000 \nEpoch: 1036  | Training Loss: 0.52760 \nEpoch: 1036  | Training Loss: 0.58307 \nEpoch: 1036  | Training Loss: 0.46868 \nEpoch: 1036  | Training Loss: 0.45203 \nEpoch: 1036  | Training Loss: 0.21300 \nEpoch: 1036  | Validation balanced accuracy : 0.50000 \nEpoch: 1037  | Training Loss: 0.52709 \nEpoch: 1037  | Training Loss: 0.58263 \nEpoch: 1037  | Training Loss: 0.46836 \nEpoch: 1037  | Training Loss: 0.45169 \nEpoch: 1037  | Training Loss: 0.21317 \nEpoch: 1037  | Validation balanced accuracy : 0.50000 \nEpoch: 1038  | Training Loss: 0.52658 \nEpoch: 1038  | Training Loss: 0.58220 \nEpoch: 1038  | Training Loss: 0.46803 \nEpoch: 1038  | Training Loss: 0.45135 \nEpoch: 1038  | Training Loss: 0.21335 \nEpoch: 1038  | Validation balanced accuracy : 0.50000 \nEpoch: 1039  | Training Loss: 0.52608 \nEpoch: 1039  | Training Loss: 0.58176 \nEpoch: 1039  | Training Loss: 0.46771 \nEpoch: 1039  | Training Loss: 0.45101 \nEpoch: 1039  | Training Loss: 0.21352 \nEpoch: 1039  | Validation balanced accuracy : 0.50000 \nEpoch: 1040  | Training Loss: 0.52557 \nEpoch: 1040  | Training Loss: 0.58133 \nEpoch: 1040  | Training Loss: 0.46739 \nEpoch: 1040  | Training Loss: 0.45067 \nEpoch: 1040  | Training Loss: 0.21370 \nEpoch: 1040  | Validation balanced accuracy : 0.50000 \nEpoch: 1041  | Training Loss: 0.52507 \nEpoch: 1041  | Training Loss: 0.58090 \nEpoch: 1041  | Training Loss: 0.46708 \nEpoch: 1041  | Training Loss: 0.45033 \nEpoch: 1041  | Training Loss: 0.21387 \nEpoch: 1041  | Validation balanced accuracy : 0.50000 \nEpoch: 1042  | Training Loss: 0.52457 \nEpoch: 1042  | Training Loss: 0.58047 \nEpoch: 1042  | Training Loss: 0.46676 \nEpoch: 1042  | Training Loss: 0.44998 \nEpoch: 1042  | Training Loss: 0.21405 \nEpoch: 1042  | Validation balanced accuracy : 0.50000 \nEpoch: 1043  | Training Loss: 0.52407 \nEpoch: 1043  | Training Loss: 0.58004 \nEpoch: 1043  | Training Loss: 0.46644 \nEpoch: 1043  | Training Loss: 0.44964 \nEpoch: 1043  | Training Loss: 0.21422 \nEpoch: 1043  | Validation balanced accuracy : 0.50000 \nEpoch: 1044  | Training Loss: 0.52357 \nEpoch: 1044  | Training Loss: 0.57961 \nEpoch: 1044  | Training Loss: 0.46613 \nEpoch: 1044  | Training Loss: 0.44930 \nEpoch: 1044  | Training Loss: 0.21440 \nEpoch: 1044  | Validation balanced accuracy : 0.50000 \nEpoch: 1045  | Training Loss: 0.52307 \nEpoch: 1045  | Training Loss: 0.57918 \nEpoch: 1045  | Training Loss: 0.46581 \nEpoch: 1045  | Training Loss: 0.44896 \nEpoch: 1045  | Training Loss: 0.21457 \nEpoch: 1045  | Validation balanced accuracy : 0.50000 \nEpoch: 1046  | Training Loss: 0.52258 \nEpoch: 1046  | Training Loss: 0.57875 \nEpoch: 1046  | Training Loss: 0.46550 \nEpoch: 1046  | Training Loss: 0.44862 \nEpoch: 1046  | Training Loss: 0.21475 \nEpoch: 1046  | Validation balanced accuracy : 0.50000 \nEpoch: 1047  | Training Loss: 0.52209 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1047  | Training Loss: 0.57833 \nEpoch: 1047  | Training Loss: 0.46519 \nEpoch: 1047  | Training Loss: 0.44827 \nEpoch: 1047  | Training Loss: 0.21492 \nEpoch: 1047  | Validation balanced accuracy : 0.50000 \nEpoch: 1048  | Training Loss: 0.52159 \nEpoch: 1048  | Training Loss: 0.57790 \nEpoch: 1048  | Training Loss: 0.46488 \nEpoch: 1048  | Training Loss: 0.44793 \nEpoch: 1048  | Training Loss: 0.21510 \nEpoch: 1048  | Validation balanced accuracy : 0.50000 \nEpoch: 1049  | Training Loss: 0.52111 \nEpoch: 1049  | Training Loss: 0.57747 \nEpoch: 1049  | Training Loss: 0.46457 \nEpoch: 1049  | Training Loss: 0.44759 \nEpoch: 1049  | Training Loss: 0.21527 \nEpoch: 1049  | Validation balanced accuracy : 0.50000 \nEpoch: 1050  | Training Loss: 0.52062 \nEpoch: 1050  | Training Loss: 0.57705 \nEpoch: 1050  | Training Loss: 0.46427 \nEpoch: 1050  | Training Loss: 0.44725 \nEpoch: 1050  | Training Loss: 0.21545 \nEpoch: 1050  | Validation balanced accuracy : 0.50000 \nEpoch: 1051  | Training Loss: 0.52013 \nEpoch: 1051  | Training Loss: 0.57663 \nEpoch: 1051  | Training Loss: 0.46396 \nEpoch: 1051  | Training Loss: 0.44690 \nEpoch: 1051  | Training Loss: 0.21562 \nEpoch: 1051  | Validation balanced accuracy : 0.50000 \nEpoch: 1052  | Training Loss: 0.51965 \nEpoch: 1052  | Training Loss: 0.57620 \nEpoch: 1052  | Training Loss: 0.46366 \nEpoch: 1052  | Training Loss: 0.44656 \nEpoch: 1052  | Training Loss: 0.21580 \nEpoch: 1052  | Validation balanced accuracy : 0.50000 \nEpoch: 1053  | Training Loss: 0.51916 \nEpoch: 1053  | Training Loss: 0.57578 \nEpoch: 1053  | Training Loss: 0.46335 \nEpoch: 1053  | Training Loss: 0.44621 \nEpoch: 1053  | Training Loss: 0.21597 \nEpoch: 1053  | Validation balanced accuracy : 0.50000 \nEpoch: 1054  | Training Loss: 0.51868 \nEpoch: 1054  | Training Loss: 0.57536 \nEpoch: 1054  | Training Loss: 0.46305 \nEpoch: 1054  | Training Loss: 0.44587 \nEpoch: 1054  | Training Loss: 0.21614 \nEpoch: 1054  | Validation balanced accuracy : 0.50000 \nEpoch: 1055  | Training Loss: 0.51820 \nEpoch: 1055  | Training Loss: 0.57494 \nEpoch: 1055  | Training Loss: 0.46275 \nEpoch: 1055  | Training Loss: 0.44553 \nEpoch: 1055  | Training Loss: 0.21632 \nEpoch: 1055  | Validation balanced accuracy : 0.50000 \nEpoch: 1056  | Training Loss: 0.51772 \nEpoch: 1056  | Training Loss: 0.57452 \nEpoch: 1056  | Training Loss: 0.46245 \nEpoch: 1056  | Training Loss: 0.44518 \nEpoch: 1056  | Training Loss: 0.21649 \nEpoch: 1056  | Validation balanced accuracy : 0.50000 \nEpoch: 1057  | Training Loss: 0.51725 \nEpoch: 1057  | Training Loss: 0.57410 \nEpoch: 1057  | Training Loss: 0.46215 \nEpoch: 1057  | Training Loss: 0.44484 \nEpoch: 1057  | Training Loss: 0.21666 \nEpoch: 1057  | Validation balanced accuracy : 0.50000 \nEpoch: 1058  | Training Loss: 0.51677 \nEpoch: 1058  | Training Loss: 0.57368 \nEpoch: 1058  | Training Loss: 0.46185 \nEpoch: 1058  | Training Loss: 0.44450 \nEpoch: 1058  | Training Loss: 0.21683 \nEpoch: 1058  | Validation balanced accuracy : 0.50000 \nEpoch: 1059  | Training Loss: 0.51630 \nEpoch: 1059  | Training Loss: 0.57326 \nEpoch: 1059  | Training Loss: 0.46156 \nEpoch: 1059  | Training Loss: 0.44415 \nEpoch: 1059  | Training Loss: 0.21701 \nEpoch: 1059  | Validation balanced accuracy : 0.50000 \nEpoch: 1060  | Training Loss: 0.51583 \nEpoch: 1060  | Training Loss: 0.57284 \nEpoch: 1060  | Training Loss: 0.46126 \nEpoch: 1060  | Training Loss: 0.44381 \nEpoch: 1060  | Training Loss: 0.21718 \nEpoch: 1060  | Validation balanced accuracy : 0.50000 \nEpoch: 1061  | Training Loss: 0.51535 \nEpoch: 1061  | Training Loss: 0.57243 \nEpoch: 1061  | Training Loss: 0.46097 \nEpoch: 1061  | Training Loss: 0.44346 \nEpoch: 1061  | Training Loss: 0.21735 \nEpoch: 1061  | Validation balanced accuracy : 0.50000 \nEpoch: 1062  | Training Loss: 0.51488 \nEpoch: 1062  | Training Loss: 0.57201 \nEpoch: 1062  | Training Loss: 0.46067 \nEpoch: 1062  | Training Loss: 0.44312 \nEpoch: 1062  | Training Loss: 0.21752 \nEpoch: 1062  | Validation balanced accuracy : 0.50000 \nEpoch: 1063  | Training Loss: 0.51442 \nEpoch: 1063  | Training Loss: 0.57160 \nEpoch: 1063  | Training Loss: 0.46038 \nEpoch: 1063  | Training Loss: 0.44277 \nEpoch: 1063  | Training Loss: 0.21769 \nEpoch: 1063  | Validation balanced accuracy : 0.50000 \nEpoch: 1064  | Training Loss: 0.51395 \nEpoch: 1064  | Training Loss: 0.57118 \nEpoch: 1064  | Training Loss: 0.46009 \nEpoch: 1064  | Training Loss: 0.44243 \nEpoch: 1064  | Training Loss: 0.21786 \nEpoch: 1064  | Validation balanced accuracy : 0.50000 \nEpoch: 1065  | Training Loss: 0.51349 \nEpoch: 1065  | Training Loss: 0.57077 \nEpoch: 1065  | Training Loss: 0.45980 \nEpoch: 1065  | Training Loss: 0.44209 \nEpoch: 1065  | Training Loss: 0.21803 \nEpoch: 1065  | Validation balanced accuracy : 0.50000 \nEpoch: 1066  | Training Loss: 0.51302 \nEpoch: 1066  | Training Loss: 0.57035 \nEpoch: 1066  | Training Loss: 0.45951 \nEpoch: 1066  | Training Loss: 0.44174 \nEpoch: 1066  | Training Loss: 0.21820 \nEpoch: 1066  | Validation balanced accuracy : 0.50000 \nEpoch: 1067  | Training Loss: 0.51256 \nEpoch: 1067  | Training Loss: 0.56994 \nEpoch: 1067  | Training Loss: 0.45923 \nEpoch: 1067  | Training Loss: 0.44140 \nEpoch: 1067  | Training Loss: 0.21837 \nEpoch: 1067  | Validation balanced accuracy : 0.50000 \nEpoch: 1068  | Training Loss: 0.51210 \nEpoch: 1068  | Training Loss: 0.56953 \nEpoch: 1068  | Training Loss: 0.45894 \nEpoch: 1068  | Training Loss: 0.44105 \nEpoch: 1068  | Training Loss: 0.21854 \nEpoch: 1068  | Validation balanced accuracy : 0.50000 \nEpoch: 1069  | Training Loss: 0.51164 \nEpoch: 1069  | Training Loss: 0.56912 \nEpoch: 1069  | Training Loss: 0.45865 \nEpoch: 1069  | Training Loss: 0.44071 \nEpoch: 1069  | Training Loss: 0.21871 \nEpoch: 1069  | Validation balanced accuracy : 0.50000 \nEpoch: 1070  | Training Loss: 0.51118 \nEpoch: 1070  | Training Loss: 0.56871 \nEpoch: 1070  | Training Loss: 0.45837 \nEpoch: 1070  | Training Loss: 0.44036 \nEpoch: 1070  | Training Loss: 0.21888 \nEpoch: 1070  | Validation balanced accuracy : 0.50000 \nEpoch: 1071  | Training Loss: 0.51072 \nEpoch: 1071  | Training Loss: 0.56830 \nEpoch: 1071  | Training Loss: 0.45809 \nEpoch: 1071  | Training Loss: 0.44002 \nEpoch: 1071  | Training Loss: 0.21905 \nEpoch: 1071  | Validation balanced accuracy : 0.50000 \nEpoch: 1072  | Training Loss: 0.51027 \nEpoch: 1072  | Training Loss: 0.56789 \nEpoch: 1072  | Training Loss: 0.45780 \nEpoch: 1072  | Training Loss: 0.43967 \nEpoch: 1072  | Training Loss: 0.21922 \nEpoch: 1072  | Validation balanced accuracy : 0.50000 \nEpoch: 1073  | Training Loss: 0.50981 \nEpoch: 1073  | Training Loss: 0.56748 \nEpoch: 1073  | Training Loss: 0.45752 \nEpoch: 1073  | Training Loss: 0.43933 \nEpoch: 1073  | Training Loss: 0.21939 \nEpoch: 1073  | Validation balanced accuracy : 0.50000 \nEpoch: 1074  | Training Loss: 0.50936 \nEpoch: 1074  | Training Loss: 0.56707 \nEpoch: 1074  | Training Loss: 0.45724 \nEpoch: 1074  | Training Loss: 0.43899 \nEpoch: 1074  | Training Loss: 0.21955 \nEpoch: 1074  | Validation balanced accuracy : 0.50000 \nEpoch: 1075  | Training Loss: 0.50891 \nEpoch: 1075  | Training Loss: 0.56667 \nEpoch: 1075  | Training Loss: 0.45696 \nEpoch: 1075  | Training Loss: 0.43864 \nEpoch: 1075  | Training Loss: 0.21972 \nEpoch: 1075  | Validation balanced accuracy : 0.50000 \nEpoch: 1076  | Training Loss: 0.50846 \nEpoch: 1076  | Training Loss: 0.56626 \nEpoch: 1076  | Training Loss: 0.45669 \nEpoch: 1076  | Training Loss: 0.43830 \nEpoch: 1076  | Training Loss: 0.21989 \nEpoch: 1076  | Validation balanced accuracy : 0.50000 \nEpoch: 1077  | Training Loss: 0.50801 \nEpoch: 1077  | Training Loss: 0.56585 \nEpoch: 1077  | Training Loss: 0.45641 \nEpoch: 1077  | Training Loss: 0.43795 \nEpoch: 1077  | Training Loss: 0.22005 \nEpoch: 1077  | Validation balanced accuracy : 0.50000 \nEpoch: 1078  | Training Loss: 0.50756 \nEpoch: 1078  | Training Loss: 0.56545 \nEpoch: 1078  | Training Loss: 0.45613 \nEpoch: 1078  | Training Loss: 0.43761 \nEpoch: 1078  | Training Loss: 0.22022 \nEpoch: 1078  | Validation balanced accuracy : 0.50000 \nEpoch: 1079  | Training Loss: 0.50711 \nEpoch: 1079  | Training Loss: 0.56504 \nEpoch: 1079  | Training Loss: 0.45586 \nEpoch: 1079  | Training Loss: 0.43726 \nEpoch: 1079  | Training Loss: 0.22038 \nEpoch: 1079  | Validation balanced accuracy : 0.50000 \nEpoch: 1080  | Training Loss: 0.50667 \nEpoch: 1080  | Training Loss: 0.56464 \nEpoch: 1080  | Training Loss: 0.45558 \nEpoch: 1080  | Training Loss: 0.43692 \nEpoch: 1080  | Training Loss: 0.22055 \nEpoch: 1080  | Validation balanced accuracy : 0.50000 \nEpoch: 1081  | Training Loss: 0.50623 \nEpoch: 1081  | Training Loss: 0.56423 \nEpoch: 1081  | Training Loss: 0.45531 \nEpoch: 1081  | Training Loss: 0.43658 \nEpoch: 1081  | Training Loss: 0.22071 \nEpoch: 1081  | Validation balanced accuracy : 0.50000 \nEpoch: 1082  | Training Loss: 0.50578 \nEpoch: 1082  | Training Loss: 0.56383 \nEpoch: 1082  | Training Loss: 0.45504 \nEpoch: 1082  | Training Loss: 0.43623 \nEpoch: 1082  | Training Loss: 0.22088 \nEpoch: 1082  | Validation balanced accuracy : 0.50000 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1083  | Training Loss: 0.50534 \nEpoch: 1083  | Training Loss: 0.56343 \nEpoch: 1083  | Training Loss: 0.45477 \nEpoch: 1083  | Training Loss: 0.43589 \nEpoch: 1083  | Training Loss: 0.22104 \nEpoch: 1083  | Validation balanced accuracy : 0.50000 \nEpoch: 1084  | Training Loss: 0.50490 \nEpoch: 1084  | Training Loss: 0.56303 \nEpoch: 1084  | Training Loss: 0.45450 \nEpoch: 1084  | Training Loss: 0.43554 \nEpoch: 1084  | Training Loss: 0.22121 \nEpoch: 1084  | Validation balanced accuracy : 0.50000 \nEpoch: 1085  | Training Loss: 0.50446 \nEpoch: 1085  | Training Loss: 0.56262 \nEpoch: 1085  | Training Loss: 0.45423 \nEpoch: 1085  | Training Loss: 0.43520 \nEpoch: 1085  | Training Loss: 0.22137 \nEpoch: 1085  | Validation balanced accuracy : 0.50000 \nEpoch: 1086  | Training Loss: 0.50402 \nEpoch: 1086  | Training Loss: 0.56222 \nEpoch: 1086  | Training Loss: 0.45396 \nEpoch: 1086  | Training Loss: 0.43486 \nEpoch: 1086  | Training Loss: 0.22153 \nEpoch: 1086  | Validation balanced accuracy : 0.50000 \nEpoch: 1087  | Training Loss: 0.50359 \nEpoch: 1087  | Training Loss: 0.56182 \nEpoch: 1087  | Training Loss: 0.45369 \nEpoch: 1087  | Training Loss: 0.43451 \nEpoch: 1087  | Training Loss: 0.22169 \nEpoch: 1087  | Validation balanced accuracy : 0.50000 \nEpoch: 1088  | Training Loss: 0.50315 \nEpoch: 1088  | Training Loss: 0.56142 \nEpoch: 1088  | Training Loss: 0.45342 \nEpoch: 1088  | Training Loss: 0.43417 \nEpoch: 1088  | Training Loss: 0.22186 \nEpoch: 1088  | Validation balanced accuracy : 0.50000 \nEpoch: 1089  | Training Loss: 0.50271 \nEpoch: 1089  | Training Loss: 0.56102 \nEpoch: 1089  | Training Loss: 0.45316 \nEpoch: 1089  | Training Loss: 0.43383 \nEpoch: 1089  | Training Loss: 0.22202 \nEpoch: 1089  | Validation balanced accuracy : 0.50000 \nEpoch: 1090  | Training Loss: 0.50228 \nEpoch: 1090  | Training Loss: 0.56062 \nEpoch: 1090  | Training Loss: 0.45289 \nEpoch: 1090  | Training Loss: 0.43348 \nEpoch: 1090  | Training Loss: 0.22218 \nEpoch: 1090  | Validation balanced accuracy : 0.50000 \nEpoch: 1091  | Training Loss: 0.50185 \nEpoch: 1091  | Training Loss: 0.56023 \nEpoch: 1091  | Training Loss: 0.45263 \nEpoch: 1091  | Training Loss: 0.43314 \nEpoch: 1091  | Training Loss: 0.22234 \nEpoch: 1091  | Validation balanced accuracy : 0.50000 \nEpoch: 1092  | Training Loss: 0.50142 \nEpoch: 1092  | Training Loss: 0.55983 \nEpoch: 1092  | Training Loss: 0.45236 \nEpoch: 1092  | Training Loss: 0.43280 \nEpoch: 1092  | Training Loss: 0.22250 \nEpoch: 1092  | Validation balanced accuracy : 0.50000 \nEpoch: 1093  | Training Loss: 0.50099 \nEpoch: 1093  | Training Loss: 0.55943 \nEpoch: 1093  | Training Loss: 0.45210 \nEpoch: 1093  | Training Loss: 0.43245 \nEpoch: 1093  | Training Loss: 0.22266 \nEpoch: 1093  | Validation balanced accuracy : 0.50000 \nEpoch: 1094  | Training Loss: 0.50056 \nEpoch: 1094  | Training Loss: 0.55904 \nEpoch: 1094  | Training Loss: 0.45184 \nEpoch: 1094  | Training Loss: 0.43211 \nEpoch: 1094  | Training Loss: 0.22282 \nEpoch: 1094  | Validation balanced accuracy : 0.50000 \nEpoch: 1095  | Training Loss: 0.50013 \nEpoch: 1095  | Training Loss: 0.55864 \nEpoch: 1095  | Training Loss: 0.45158 \nEpoch: 1095  | Training Loss: 0.43177 \nEpoch: 1095  | Training Loss: 0.22298 \nEpoch: 1095  | Validation balanced accuracy : 0.50000 \nEpoch: 1096  | Training Loss: 0.49970 \nEpoch: 1096  | Training Loss: 0.55824 \nEpoch: 1096  | Training Loss: 0.45132 \nEpoch: 1096  | Training Loss: 0.43142 \nEpoch: 1096  | Training Loss: 0.22313 \nEpoch: 1096  | Validation balanced accuracy : 0.50000 \nEpoch: 1097  | Training Loss: 0.49928 \nEpoch: 1097  | Training Loss: 0.55785 \nEpoch: 1097  | Training Loss: 0.45106 \nEpoch: 1097  | Training Loss: 0.43108 \nEpoch: 1097  | Training Loss: 0.22329 \nEpoch: 1097  | Validation balanced accuracy : 0.50000 \nEpoch: 1098  | Training Loss: 0.49885 \nEpoch: 1098  | Training Loss: 0.55745 \nEpoch: 1098  | Training Loss: 0.45080 \nEpoch: 1098  | Training Loss: 0.43074 \nEpoch: 1098  | Training Loss: 0.22345 \nEpoch: 1098  | Validation balanced accuracy : 0.50000 \nEpoch: 1099  | Training Loss: 0.49843 \nEpoch: 1099  | Training Loss: 0.55706 \nEpoch: 1099  | Training Loss: 0.45055 \nEpoch: 1099  | Training Loss: 0.43040 \nEpoch: 1099  | Training Loss: 0.22361 \nEpoch: 1099  | Validation balanced accuracy : 0.50000 \nEpoch: 1100  | Training Loss: 0.49800 \nEpoch: 1100  | Training Loss: 0.55667 \nEpoch: 1100  | Training Loss: 0.45029 \nEpoch: 1100  | Training Loss: 0.43005 \nEpoch: 1100  | Training Loss: 0.22376 \nEpoch: 1100  | Validation balanced accuracy : 0.50000 \nEpoch: 1101  | Training Loss: 0.49758 \nEpoch: 1101  | Training Loss: 0.55627 \nEpoch: 1101  | Training Loss: 0.45003 \nEpoch: 1101  | Training Loss: 0.42971 \nEpoch: 1101  | Training Loss: 0.22392 \nEpoch: 1101  | Validation balanced accuracy : 0.50000 \nEpoch: 1102  | Training Loss: 0.49716 \nEpoch: 1102  | Training Loss: 0.55588 \nEpoch: 1102  | Training Loss: 0.44978 \nEpoch: 1102  | Training Loss: 0.42937 \nEpoch: 1102  | Training Loss: 0.22407 \nEpoch: 1102  | Validation balanced accuracy : 0.50000 \nEpoch: 1103  | Training Loss: 0.49674 \nEpoch: 1103  | Training Loss: 0.55549 \nEpoch: 1103  | Training Loss: 0.44952 \nEpoch: 1103  | Training Loss: 0.42903 \nEpoch: 1103  | Training Loss: 0.22423 \nEpoch: 1103  | Validation balanced accuracy : 0.50000 \nEpoch: 1104  | Training Loss: 0.49632 \nEpoch: 1104  | Training Loss: 0.55510 \nEpoch: 1104  | Training Loss: 0.44927 \nEpoch: 1104  | Training Loss: 0.42869 \nEpoch: 1104  | Training Loss: 0.22438 \nEpoch: 1104  | Validation balanced accuracy : 0.50000 \nEpoch: 1105  | Training Loss: 0.49590 \nEpoch: 1105  | Training Loss: 0.55471 \nEpoch: 1105  | Training Loss: 0.44902 \nEpoch: 1105  | Training Loss: 0.42835 \nEpoch: 1105  | Training Loss: 0.22454 \nEpoch: 1105  | Validation balanced accuracy : 0.50000 \nEpoch: 1106  | Training Loss: 0.49549 \nEpoch: 1106  | Training Loss: 0.55432 \nEpoch: 1106  | Training Loss: 0.44877 \nEpoch: 1106  | Training Loss: 0.42800 \nEpoch: 1106  | Training Loss: 0.22469 \nEpoch: 1106  | Validation balanced accuracy : 0.50000 \nEpoch: 1107  | Training Loss: 0.49507 \nEpoch: 1107  | Training Loss: 0.55393 \nEpoch: 1107  | Training Loss: 0.44852 \nEpoch: 1107  | Training Loss: 0.42766 \nEpoch: 1107  | Training Loss: 0.22485 \nEpoch: 1107  | Validation balanced accuracy : 0.50000 \nEpoch: 1108  | Training Loss: 0.49466 \nEpoch: 1108  | Training Loss: 0.55354 \nEpoch: 1108  | Training Loss: 0.44827 \nEpoch: 1108  | Training Loss: 0.42732 \nEpoch: 1108  | Training Loss: 0.22500 \nEpoch: 1108  | Validation balanced accuracy : 0.50000 \nEpoch: 1109  | Training Loss: 0.49424 \nEpoch: 1109  | Training Loss: 0.55315 \nEpoch: 1109  | Training Loss: 0.44802 \nEpoch: 1109  | Training Loss: 0.42698 \nEpoch: 1109  | Training Loss: 0.22515 \nEpoch: 1109  | Validation balanced accuracy : 0.50000 \nEpoch: 1110  | Training Loss: 0.49383 \nEpoch: 1110  | Training Loss: 0.55276 \nEpoch: 1110  | Training Loss: 0.44777 \nEpoch: 1110  | Training Loss: 0.42664 \nEpoch: 1110  | Training Loss: 0.22530 \nEpoch: 1110  | Validation balanced accuracy : 0.50000 \nEpoch: 1111  | Training Loss: 0.49342 \nEpoch: 1111  | Training Loss: 0.55238 \nEpoch: 1111  | Training Loss: 0.44752 \nEpoch: 1111  | Training Loss: 0.42630 \nEpoch: 1111  | Training Loss: 0.22546 \nEpoch: 1111  | Validation balanced accuracy : 0.50000 \nEpoch: 1112  | Training Loss: 0.49301 \nEpoch: 1112  | Training Loss: 0.55199 \nEpoch: 1112  | Training Loss: 0.44727 \nEpoch: 1112  | Training Loss: 0.42596 \nEpoch: 1112  | Training Loss: 0.22561 \nEpoch: 1112  | Validation balanced accuracy : 0.50000 \nEpoch: 1113  | Training Loss: 0.49260 \nEpoch: 1113  | Training Loss: 0.55160 \nEpoch: 1113  | Training Loss: 0.44703 \nEpoch: 1113  | Training Loss: 0.42562 \nEpoch: 1113  | Training Loss: 0.22576 \nEpoch: 1113  | Validation balanced accuracy : 0.50000 \nEpoch: 1114  | Training Loss: 0.49219 \nEpoch: 1114  | Training Loss: 0.55122 \nEpoch: 1114  | Training Loss: 0.44678 \nEpoch: 1114  | Training Loss: 0.42528 \nEpoch: 1114  | Training Loss: 0.22591 \nEpoch: 1114  | Validation balanced accuracy : 0.50000 \nEpoch: 1115  | Training Loss: 0.49178 \nEpoch: 1115  | Training Loss: 0.55083 \nEpoch: 1115  | Training Loss: 0.44654 \nEpoch: 1115  | Training Loss: 0.42494 \nEpoch: 1115  | Training Loss: 0.22606 \nEpoch: 1115  | Validation balanced accuracy : 0.50000 \nEpoch: 1116  | Training Loss: 0.49137 \nEpoch: 1116  | Training Loss: 0.55044 \nEpoch: 1116  | Training Loss: 0.44629 \nEpoch: 1116  | Training Loss: 0.42460 \nEpoch: 1116  | Training Loss: 0.22621 \nEpoch: 1116  | Validation balanced accuracy : 0.50000 \nEpoch: 1117  | Training Loss: 0.49096 \nEpoch: 1117  | Training Loss: 0.55006 \nEpoch: 1117  | Training Loss: 0.44605 \nEpoch: 1117  | Training Loss: 0.42426 \nEpoch: 1117  | Training Loss: 0.22636 \nEpoch: 1117  | Validation balanced accuracy : 0.50000 \nEpoch: 1118  | Training Loss: 0.49056 \nEpoch: 1118  | Training Loss: 0.54968 \nEpoch: 1118  | Training Loss: 0.44581 \nEpoch: 1118  | Training Loss: 0.42392 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1118  | Training Loss: 0.22650 \nEpoch: 1118  | Validation balanced accuracy : 0.50000 \nEpoch: 1119  | Training Loss: 0.49015 \nEpoch: 1119  | Training Loss: 0.54929 \nEpoch: 1119  | Training Loss: 0.44556 \nEpoch: 1119  | Training Loss: 0.42358 \nEpoch: 1119  | Training Loss: 0.22665 \nEpoch: 1119  | Validation balanced accuracy : 0.50000 \nEpoch: 1120  | Training Loss: 0.48975 \nEpoch: 1120  | Training Loss: 0.54891 \nEpoch: 1120  | Training Loss: 0.44532 \nEpoch: 1120  | Training Loss: 0.42324 \nEpoch: 1120  | Training Loss: 0.22680 \nEpoch: 1120  | Validation balanced accuracy : 0.50000 \nEpoch: 1121  | Training Loss: 0.48935 \nEpoch: 1121  | Training Loss: 0.54853 \nEpoch: 1121  | Training Loss: 0.44508 \nEpoch: 1121  | Training Loss: 0.42290 \nEpoch: 1121  | Training Loss: 0.22695 \nEpoch: 1121  | Validation balanced accuracy : 0.50000 \nEpoch: 1122  | Training Loss: 0.48894 \nEpoch: 1122  | Training Loss: 0.54814 \nEpoch: 1122  | Training Loss: 0.44484 \nEpoch: 1122  | Training Loss: 0.42257 \nEpoch: 1122  | Training Loss: 0.22709 \nEpoch: 1122  | Validation balanced accuracy : 0.50000 \nEpoch: 1123  | Training Loss: 0.48854 \nEpoch: 1123  | Training Loss: 0.54776 \nEpoch: 1123  | Training Loss: 0.44460 \nEpoch: 1123  | Training Loss: 0.42223 \nEpoch: 1123  | Training Loss: 0.22724 \nEpoch: 1123  | Validation balanced accuracy : 0.50000 \nEpoch: 1124  | Training Loss: 0.48814 \nEpoch: 1124  | Training Loss: 0.54738 \nEpoch: 1124  | Training Loss: 0.44436 \nEpoch: 1124  | Training Loss: 0.42189 \nEpoch: 1124  | Training Loss: 0.22739 \nEpoch: 1124  | Validation balanced accuracy : 0.50000 \nEpoch: 1125  | Training Loss: 0.48774 \nEpoch: 1125  | Training Loss: 0.54700 \nEpoch: 1125  | Training Loss: 0.44413 \nEpoch: 1125  | Training Loss: 0.42155 \nEpoch: 1125  | Training Loss: 0.22753 \nEpoch: 1125  | Validation balanced accuracy : 0.50000 \nEpoch: 1126  | Training Loss: 0.48734 \nEpoch: 1126  | Training Loss: 0.54662 \nEpoch: 1126  | Training Loss: 0.44389 \nEpoch: 1126  | Training Loss: 0.42121 \nEpoch: 1126  | Training Loss: 0.22768 \nEpoch: 1126  | Validation balanced accuracy : 0.50000 \nEpoch: 1127  | Training Loss: 0.48695 \nEpoch: 1127  | Training Loss: 0.54624 \nEpoch: 1127  | Training Loss: 0.44365 \nEpoch: 1127  | Training Loss: 0.42088 \nEpoch: 1127  | Training Loss: 0.22782 \nEpoch: 1127  | Validation balanced accuracy : 0.50000 \nEpoch: 1128  | Training Loss: 0.48655 \nEpoch: 1128  | Training Loss: 0.54586 \nEpoch: 1128  | Training Loss: 0.44342 \nEpoch: 1128  | Training Loss: 0.42054 \nEpoch: 1128  | Training Loss: 0.22796 \nEpoch: 1128  | Validation balanced accuracy : 0.50000 \nEpoch: 1129  | Training Loss: 0.48615 \nEpoch: 1129  | Training Loss: 0.54549 \nEpoch: 1129  | Training Loss: 0.44318 \nEpoch: 1129  | Training Loss: 0.42020 \nEpoch: 1129  | Training Loss: 0.22811 \nEpoch: 1129  | Validation balanced accuracy : 0.50000 \nEpoch: 1130  | Training Loss: 0.48576 \nEpoch: 1130  | Training Loss: 0.54511 \nEpoch: 1130  | Training Loss: 0.44295 \nEpoch: 1130  | Training Loss: 0.41987 \nEpoch: 1130  | Training Loss: 0.22825 \nEpoch: 1130  | Validation balanced accuracy : 0.50000 \nEpoch: 1131  | Training Loss: 0.48536 \nEpoch: 1131  | Training Loss: 0.54473 \nEpoch: 1131  | Training Loss: 0.44271 \nEpoch: 1131  | Training Loss: 0.41953 \nEpoch: 1131  | Training Loss: 0.22839 \nEpoch: 1131  | Validation balanced accuracy : 0.50000 \nEpoch: 1132  | Training Loss: 0.48497 \nEpoch: 1132  | Training Loss: 0.54435 \nEpoch: 1132  | Training Loss: 0.44248 \nEpoch: 1132  | Training Loss: 0.41919 \nEpoch: 1132  | Training Loss: 0.22854 \nEpoch: 1132  | Validation balanced accuracy : 0.50000 \nEpoch: 1133  | Training Loss: 0.48458 \nEpoch: 1133  | Training Loss: 0.54398 \nEpoch: 1133  | Training Loss: 0.44225 \nEpoch: 1133  | Training Loss: 0.41886 \nEpoch: 1133  | Training Loss: 0.22868 \nEpoch: 1133  | Validation balanced accuracy : 0.50000 \nEpoch: 1134  | Training Loss: 0.48418 \nEpoch: 1134  | Training Loss: 0.54360 \nEpoch: 1134  | Training Loss: 0.44201 \nEpoch: 1134  | Training Loss: 0.41852 \nEpoch: 1134  | Training Loss: 0.22882 \nEpoch: 1134  | Validation balanced accuracy : 0.50000 \nEpoch: 1135  | Training Loss: 0.48379 \nEpoch: 1135  | Training Loss: 0.54322 \nEpoch: 1135  | Training Loss: 0.44178 \nEpoch: 1135  | Training Loss: 0.41818 \nEpoch: 1135  | Training Loss: 0.22896 \nEpoch: 1135  | Validation balanced accuracy : 0.50000 \nEpoch: 1136  | Training Loss: 0.48340 \nEpoch: 1136  | Training Loss: 0.54285 \nEpoch: 1136  | Training Loss: 0.44155 \nEpoch: 1136  | Training Loss: 0.41785 \nEpoch: 1136  | Training Loss: 0.22910 \nEpoch: 1136  | Validation balanced accuracy : 0.50000 \nEpoch: 1137  | Training Loss: 0.48301 \nEpoch: 1137  | Training Loss: 0.54248 \nEpoch: 1137  | Training Loss: 0.44132 \nEpoch: 1137  | Training Loss: 0.41751 \nEpoch: 1137  | Training Loss: 0.22924 \nEpoch: 1137  | Validation balanced accuracy : 0.50000 \nEpoch: 1138  | Training Loss: 0.48262 \nEpoch: 1138  | Training Loss: 0.54210 \nEpoch: 1138  | Training Loss: 0.44109 \nEpoch: 1138  | Training Loss: 0.41718 \nEpoch: 1138  | Training Loss: 0.22938 \nEpoch: 1138  | Validation balanced accuracy : 0.50000 \nEpoch: 1139  | Training Loss: 0.48224 \nEpoch: 1139  | Training Loss: 0.54173 \nEpoch: 1139  | Training Loss: 0.44086 \nEpoch: 1139  | Training Loss: 0.41684 \nEpoch: 1139  | Training Loss: 0.22952 \nEpoch: 1139  | Validation balanced accuracy : 0.50000 \nEpoch: 1140  | Training Loss: 0.48185 \nEpoch: 1140  | Training Loss: 0.54136 \nEpoch: 1140  | Training Loss: 0.44063 \nEpoch: 1140  | Training Loss: 0.41651 \nEpoch: 1140  | Training Loss: 0.22966 \nEpoch: 1140  | Validation balanced accuracy : 0.50000 \nEpoch: 1141  | Training Loss: 0.48146 \nEpoch: 1141  | Training Loss: 0.54098 \nEpoch: 1141  | Training Loss: 0.44040 \nEpoch: 1141  | Training Loss: 0.41618 \nEpoch: 1141  | Training Loss: 0.22979 \nEpoch: 1141  | Validation balanced accuracy : 0.50000 \nEpoch: 1142  | Training Loss: 0.48108 \nEpoch: 1142  | Training Loss: 0.54061 \nEpoch: 1142  | Training Loss: 0.44018 \nEpoch: 1142  | Training Loss: 0.41584 \nEpoch: 1142  | Training Loss: 0.22993 \nEpoch: 1142  | Validation balanced accuracy : 0.50000 \nEpoch: 1143  | Training Loss: 0.48069 \nEpoch: 1143  | Training Loss: 0.54024 \nEpoch: 1143  | Training Loss: 0.43995 \nEpoch: 1143  | Training Loss: 0.41551 \nEpoch: 1143  | Training Loss: 0.23007 \nEpoch: 1143  | Validation balanced accuracy : 0.50000 \nEpoch: 1144  | Training Loss: 0.48031 \nEpoch: 1144  | Training Loss: 0.53987 \nEpoch: 1144  | Training Loss: 0.43972 \nEpoch: 1144  | Training Loss: 0.41518 \nEpoch: 1144  | Training Loss: 0.23020 \nEpoch: 1144  | Validation balanced accuracy : 0.50000 \nEpoch: 1145  | Training Loss: 0.47992 \nEpoch: 1145  | Training Loss: 0.53950 \nEpoch: 1145  | Training Loss: 0.43950 \nEpoch: 1145  | Training Loss: 0.41484 \nEpoch: 1145  | Training Loss: 0.23034 \nEpoch: 1145  | Validation balanced accuracy : 0.50000 \nEpoch: 1146  | Training Loss: 0.47954 \nEpoch: 1146  | Training Loss: 0.53913 \nEpoch: 1146  | Training Loss: 0.43927 \nEpoch: 1146  | Training Loss: 0.41451 \nEpoch: 1146  | Training Loss: 0.23048 \nEpoch: 1146  | Validation balanced accuracy : 0.50000 \nEpoch: 1147  | Training Loss: 0.47916 \nEpoch: 1147  | Training Loss: 0.53876 \nEpoch: 1147  | Training Loss: 0.43905 \nEpoch: 1147  | Training Loss: 0.41418 \nEpoch: 1147  | Training Loss: 0.23061 \nEpoch: 1147  | Validation balanced accuracy : 0.50000 \nEpoch: 1148  | Training Loss: 0.47878 \nEpoch: 1148  | Training Loss: 0.53839 \nEpoch: 1148  | Training Loss: 0.43882 \nEpoch: 1148  | Training Loss: 0.41384 \nEpoch: 1148  | Training Loss: 0.23075 \nEpoch: 1148  | Validation balanced accuracy : 0.50000 \nEpoch: 1149  | Training Loss: 0.47840 \nEpoch: 1149  | Training Loss: 0.53802 \nEpoch: 1149  | Training Loss: 0.43860 \nEpoch: 1149  | Training Loss: 0.41351 \nEpoch: 1149  | Training Loss: 0.23088 \nEpoch: 1149  | Validation balanced accuracy : 0.50000 \nEpoch: 1150  | Training Loss: 0.47802 \nEpoch: 1150  | Training Loss: 0.53766 \nEpoch: 1150  | Training Loss: 0.43838 \nEpoch: 1150  | Training Loss: 0.41318 \nEpoch: 1150  | Training Loss: 0.23101 \nEpoch: 1150  | Validation balanced accuracy : 0.50000 \nEpoch: 1151  | Training Loss: 0.47764 \nEpoch: 1151  | Training Loss: 0.53729 \nEpoch: 1151  | Training Loss: 0.43816 \nEpoch: 1151  | Training Loss: 0.41285 \nEpoch: 1151  | Training Loss: 0.23115 \nEpoch: 1151  | Validation balanced accuracy : 0.50000 \nEpoch: 1152  | Training Loss: 0.47726 \nEpoch: 1152  | Training Loss: 0.53692 \nEpoch: 1152  | Training Loss: 0.43793 \nEpoch: 1152  | Training Loss: 0.41252 \nEpoch: 1152  | Training Loss: 0.23128 \nEpoch: 1152  | Validation balanced accuracy : 0.50000 \nEpoch: 1153  | Training Loss: 0.47688 \nEpoch: 1153  | Training Loss: 0.53656 \nEpoch: 1153  | Training Loss: 0.43771 \nEpoch: 1153  | Training Loss: 0.41219 \nEpoch: 1153  | Training Loss: 0.23141 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1153  | Validation balanced accuracy : 0.50000 \nEpoch: 1154  | Training Loss: 0.47651 \nEpoch: 1154  | Training Loss: 0.53619 \nEpoch: 1154  | Training Loss: 0.43749 \nEpoch: 1154  | Training Loss: 0.41186 \nEpoch: 1154  | Training Loss: 0.23155 \nEpoch: 1154  | Validation balanced accuracy : 0.50000 \nEpoch: 1155  | Training Loss: 0.47613 \nEpoch: 1155  | Training Loss: 0.53582 \nEpoch: 1155  | Training Loss: 0.43727 \nEpoch: 1155  | Training Loss: 0.41153 \nEpoch: 1155  | Training Loss: 0.23168 \nEpoch: 1155  | Validation balanced accuracy : 0.50000 \nEpoch: 1156  | Training Loss: 0.47575 \nEpoch: 1156  | Training Loss: 0.53546 \nEpoch: 1156  | Training Loss: 0.43705 \nEpoch: 1156  | Training Loss: 0.41120 \nEpoch: 1156  | Training Loss: 0.23181 \nEpoch: 1156  | Validation balanced accuracy : 0.50000 \nEpoch: 1157  | Training Loss: 0.47538 \nEpoch: 1157  | Training Loss: 0.53510 \nEpoch: 1157  | Training Loss: 0.43683 \nEpoch: 1157  | Training Loss: 0.41087 \nEpoch: 1157  | Training Loss: 0.23194 \nEpoch: 1157  | Validation balanced accuracy : 0.50000 \nEpoch: 1158  | Training Loss: 0.47501 \nEpoch: 1158  | Training Loss: 0.53473 \nEpoch: 1158  | Training Loss: 0.43661 \nEpoch: 1158  | Training Loss: 0.41054 \nEpoch: 1158  | Training Loss: 0.23207 \nEpoch: 1158  | Validation balanced accuracy : 0.50000 \nEpoch: 1159  | Training Loss: 0.47463 \nEpoch: 1159  | Training Loss: 0.53437 \nEpoch: 1159  | Training Loss: 0.43640 \nEpoch: 1159  | Training Loss: 0.41021 \nEpoch: 1159  | Training Loss: 0.23220 \nEpoch: 1159  | Validation balanced accuracy : 0.50000 \nEpoch: 1160  | Training Loss: 0.47426 \nEpoch: 1160  | Training Loss: 0.53401 \nEpoch: 1160  | Training Loss: 0.43618 \nEpoch: 1160  | Training Loss: 0.40988 \nEpoch: 1160  | Training Loss: 0.23233 \nEpoch: 1160  | Validation balanced accuracy : 0.50000 \nEpoch: 1161  | Training Loss: 0.47389 \nEpoch: 1161  | Training Loss: 0.53365 \nEpoch: 1161  | Training Loss: 0.43596 \nEpoch: 1161  | Training Loss: 0.40955 \nEpoch: 1161  | Training Loss: 0.23246 \nEpoch: 1161  | Validation balanced accuracy : 0.50000 \nEpoch: 1162  | Training Loss: 0.47352 \nEpoch: 1162  | Training Loss: 0.53328 \nEpoch: 1162  | Training Loss: 0.43574 \nEpoch: 1162  | Training Loss: 0.40922 \nEpoch: 1162  | Training Loss: 0.23259 \nEpoch: 1162  | Validation balanced accuracy : 0.50000 \nEpoch: 1163  | Training Loss: 0.47315 \nEpoch: 1163  | Training Loss: 0.53292 \nEpoch: 1163  | Training Loss: 0.43553 \nEpoch: 1163  | Training Loss: 0.40889 \nEpoch: 1163  | Training Loss: 0.23271 \nEpoch: 1163  | Validation balanced accuracy : 0.50000 \nEpoch: 1164  | Training Loss: 0.47278 \nEpoch: 1164  | Training Loss: 0.53256 \nEpoch: 1164  | Training Loss: 0.43531 \nEpoch: 1164  | Training Loss: 0.40856 \nEpoch: 1164  | Training Loss: 0.23284 \nEpoch: 1164  | Validation balanced accuracy : 0.50000 \nEpoch: 1165  | Training Loss: 0.47241 \nEpoch: 1165  | Training Loss: 0.53220 \nEpoch: 1165  | Training Loss: 0.43510 \nEpoch: 1165  | Training Loss: 0.40824 \nEpoch: 1165  | Training Loss: 0.23297 \nEpoch: 1165  | Validation balanced accuracy : 0.50000 \nEpoch: 1166  | Training Loss: 0.47204 \nEpoch: 1166  | Training Loss: 0.53184 \nEpoch: 1166  | Training Loss: 0.43488 \nEpoch: 1166  | Training Loss: 0.40791 \nEpoch: 1166  | Training Loss: 0.23310 \nEpoch: 1166  | Validation balanced accuracy : 0.50000 \nEpoch: 1167  | Training Loss: 0.47167 \nEpoch: 1167  | Training Loss: 0.53149 \nEpoch: 1167  | Training Loss: 0.43467 \nEpoch: 1167  | Training Loss: 0.40758 \nEpoch: 1167  | Training Loss: 0.23322 \nEpoch: 1167  | Validation balanced accuracy : 0.50000 \nEpoch: 1168  | Training Loss: 0.47131 \nEpoch: 1168  | Training Loss: 0.53113 \nEpoch: 1168  | Training Loss: 0.43445 \nEpoch: 1168  | Training Loss: 0.40726 \nEpoch: 1168  | Training Loss: 0.23335 \nEpoch: 1168  | Validation balanced accuracy : 0.50000 \nEpoch: 1169  | Training Loss: 0.47094 \nEpoch: 1169  | Training Loss: 0.53077 \nEpoch: 1169  | Training Loss: 0.43424 \nEpoch: 1169  | Training Loss: 0.40693 \nEpoch: 1169  | Training Loss: 0.23347 \nEpoch: 1169  | Validation balanced accuracy : 0.50000 \nEpoch: 1170  | Training Loss: 0.47057 \nEpoch: 1170  | Training Loss: 0.53041 \nEpoch: 1170  | Training Loss: 0.43403 \nEpoch: 1170  | Training Loss: 0.40660 \nEpoch: 1170  | Training Loss: 0.23360 \nEpoch: 1170  | Validation balanced accuracy : 0.50000 \nEpoch: 1171  | Training Loss: 0.47021 \nEpoch: 1171  | Training Loss: 0.53006 \nEpoch: 1171  | Training Loss: 0.43382 \nEpoch: 1171  | Training Loss: 0.40628 \nEpoch: 1171  | Training Loss: 0.23372 \nEpoch: 1171  | Validation balanced accuracy : 0.50000 \nEpoch: 1172  | Training Loss: 0.46984 \nEpoch: 1172  | Training Loss: 0.52970 \nEpoch: 1172  | Training Loss: 0.43360 \nEpoch: 1172  | Training Loss: 0.40595 \nEpoch: 1172  | Training Loss: 0.23385 \nEpoch: 1172  | Validation balanced accuracy : 0.50000 \nEpoch: 1173  | Training Loss: 0.46948 \nEpoch: 1173  | Training Loss: 0.52935 \nEpoch: 1173  | Training Loss: 0.43339 \nEpoch: 1173  | Training Loss: 0.40563 \nEpoch: 1173  | Training Loss: 0.23397 \nEpoch: 1173  | Validation balanced accuracy : 0.50000 \nEpoch: 1174  | Training Loss: 0.46912 \nEpoch: 1174  | Training Loss: 0.52899 \nEpoch: 1174  | Training Loss: 0.43318 \nEpoch: 1174  | Training Loss: 0.40530 \nEpoch: 1174  | Training Loss: 0.23409 \nEpoch: 1174  | Validation balanced accuracy : 0.50000 \nEpoch: 1175  | Training Loss: 0.46876 \nEpoch: 1175  | Training Loss: 0.52864 \nEpoch: 1175  | Training Loss: 0.43297 \nEpoch: 1175  | Training Loss: 0.40498 \nEpoch: 1175  | Training Loss: 0.23422 \nEpoch: 1175  | Validation balanced accuracy : 0.50000 \nEpoch: 1176  | Training Loss: 0.46839 \nEpoch: 1176  | Training Loss: 0.52828 \nEpoch: 1176  | Training Loss: 0.43276 \nEpoch: 1176  | Training Loss: 0.40465 \nEpoch: 1176  | Training Loss: 0.23434 \nEpoch: 1176  | Validation balanced accuracy : 0.50000 \nEpoch: 1177  | Training Loss: 0.46803 \nEpoch: 1177  | Training Loss: 0.52793 \nEpoch: 1177  | Training Loss: 0.43255 \nEpoch: 1177  | Training Loss: 0.40433 \nEpoch: 1177  | Training Loss: 0.23446 \nEpoch: 1177  | Validation balanced accuracy : 0.50000 \nEpoch: 1178  | Training Loss: 0.46767 \nEpoch: 1178  | Training Loss: 0.52758 \nEpoch: 1178  | Training Loss: 0.43234 \nEpoch: 1178  | Training Loss: 0.40401 \nEpoch: 1178  | Training Loss: 0.23458 \nEpoch: 1178  | Validation balanced accuracy : 0.50000 \nEpoch: 1179  | Training Loss: 0.46731 \nEpoch: 1179  | Training Loss: 0.52723 \nEpoch: 1179  | Training Loss: 0.43213 \nEpoch: 1179  | Training Loss: 0.40368 \nEpoch: 1179  | Training Loss: 0.23470 \nEpoch: 1179  | Validation balanced accuracy : 0.50000 \nEpoch: 1180  | Training Loss: 0.46696 \nEpoch: 1180  | Training Loss: 0.52687 \nEpoch: 1180  | Training Loss: 0.43193 \nEpoch: 1180  | Training Loss: 0.40336 \nEpoch: 1180  | Training Loss: 0.23483 \nEpoch: 1180  | Validation balanced accuracy : 0.50000 \nEpoch: 1181  | Training Loss: 0.46660 \nEpoch: 1181  | Training Loss: 0.52652 \nEpoch: 1181  | Training Loss: 0.43172 \nEpoch: 1181  | Training Loss: 0.40304 \nEpoch: 1181  | Training Loss: 0.23495 \nEpoch: 1181  | Validation balanced accuracy : 0.50000 \nEpoch: 1182  | Training Loss: 0.46624 \nEpoch: 1182  | Training Loss: 0.52617 \nEpoch: 1182  | Training Loss: 0.43151 \nEpoch: 1182  | Training Loss: 0.40272 \nEpoch: 1182  | Training Loss: 0.23507 \nEpoch: 1182  | Validation balanced accuracy : 0.50000 \nEpoch: 1183  | Training Loss: 0.46588 \nEpoch: 1183  | Training Loss: 0.52582 \nEpoch: 1183  | Training Loss: 0.43130 \nEpoch: 1183  | Training Loss: 0.40239 \nEpoch: 1183  | Training Loss: 0.23518 \nEpoch: 1183  | Validation balanced accuracy : 0.50000 \nEpoch: 1184  | Training Loss: 0.46553 \nEpoch: 1184  | Training Loss: 0.52548 \nEpoch: 1184  | Training Loss: 0.43110 \nEpoch: 1184  | Training Loss: 0.40207 \nEpoch: 1184  | Training Loss: 0.23530 \nEpoch: 1184  | Validation balanced accuracy : 0.50000 \nEpoch: 1185  | Training Loss: 0.46517 \nEpoch: 1185  | Training Loss: 0.52513 \nEpoch: 1185  | Training Loss: 0.43089 \nEpoch: 1185  | Training Loss: 0.40175 \nEpoch: 1185  | Training Loss: 0.23542 \nEpoch: 1185  | Validation balanced accuracy : 0.50000 \nEpoch: 1186  | Training Loss: 0.46482 \nEpoch: 1186  | Training Loss: 0.52478 \nEpoch: 1186  | Training Loss: 0.43068 \nEpoch: 1186  | Training Loss: 0.40143 \nEpoch: 1186  | Training Loss: 0.23554 \nEpoch: 1186  | Validation balanced accuracy : 0.50000 \nEpoch: 1187  | Training Loss: 0.46446 \nEpoch: 1187  | Training Loss: 0.52443 \nEpoch: 1187  | Training Loss: 0.43048 \nEpoch: 1187  | Training Loss: 0.40111 \nEpoch: 1187  | Training Loss: 0.23566 \nEpoch: 1187  | Validation balanced accuracy : 0.50000 \nEpoch: 1188  | Training Loss: 0.46411 \nEpoch: 1188  | Training Loss: 0.52408 \nEpoch: 1188  | Training Loss: 0.43027 \nEpoch: 1188  | Training Loss: 0.40079 \nEpoch: 1188  | Training Loss: 0.23577 \nEpoch: 1188  | Validation balanced accuracy : 0.50000 \nEpoch: 1189  | Training Loss: 0.46375 \nEpoch: 1189  | Training Loss: 0.52374 \nEpoch: 1189  | Training Loss: 0.43007 \nEpoch: 1189  | Training Loss: 0.40047 \nEpoch: 1189  | Training Loss: 0.23589 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1189  | Validation balanced accuracy : 0.50000 \nEpoch: 1190  | Training Loss: 0.46340 \nEpoch: 1190  | Training Loss: 0.52339 \nEpoch: 1190  | Training Loss: 0.42987 \nEpoch: 1190  | Training Loss: 0.40015 \nEpoch: 1190  | Training Loss: 0.23601 \nEpoch: 1190  | Validation balanced accuracy : 0.50000 \nEpoch: 1191  | Training Loss: 0.46305 \nEpoch: 1191  | Training Loss: 0.52305 \nEpoch: 1191  | Training Loss: 0.42966 \nEpoch: 1191  | Training Loss: 0.39983 \nEpoch: 1191  | Training Loss: 0.23612 \nEpoch: 1191  | Validation balanced accuracy : 0.50000 \nEpoch: 1192  | Training Loss: 0.46270 \nEpoch: 1192  | Training Loss: 0.52270 \nEpoch: 1192  | Training Loss: 0.42946 \nEpoch: 1192  | Training Loss: 0.39951 \nEpoch: 1192  | Training Loss: 0.23624 \nEpoch: 1192  | Validation balanced accuracy : 0.50000 \nEpoch: 1193  | Training Loss: 0.46235 \nEpoch: 1193  | Training Loss: 0.52236 \nEpoch: 1193  | Training Loss: 0.42925 \nEpoch: 1193  | Training Loss: 0.39920 \nEpoch: 1193  | Training Loss: 0.23635 \nEpoch: 1193  | Validation balanced accuracy : 0.50000 \nEpoch: 1194  | Training Loss: 0.46200 \nEpoch: 1194  | Training Loss: 0.52202 \nEpoch: 1194  | Training Loss: 0.42905 \nEpoch: 1194  | Training Loss: 0.39888 \nEpoch: 1194  | Training Loss: 0.23647 \nEpoch: 1194  | Validation balanced accuracy : 0.50000 \nEpoch: 1195  | Training Loss: 0.46165 \nEpoch: 1195  | Training Loss: 0.52167 \nEpoch: 1195  | Training Loss: 0.42885 \nEpoch: 1195  | Training Loss: 0.39856 \nEpoch: 1195  | Training Loss: 0.23658 \nEpoch: 1195  | Validation balanced accuracy : 0.50000 \nEpoch: 1196  | Training Loss: 0.46130 \nEpoch: 1196  | Training Loss: 0.52133 \nEpoch: 1196  | Training Loss: 0.42865 \nEpoch: 1196  | Training Loss: 0.39824 \nEpoch: 1196  | Training Loss: 0.23670 \nEpoch: 1196  | Validation balanced accuracy : 0.50000 \nEpoch: 1197  | Training Loss: 0.46095 \nEpoch: 1197  | Training Loss: 0.52099 \nEpoch: 1197  | Training Loss: 0.42845 \nEpoch: 1197  | Training Loss: 0.39793 \nEpoch: 1197  | Training Loss: 0.23681 \nEpoch: 1197  | Validation balanced accuracy : 0.50000 \nEpoch: 1198  | Training Loss: 0.46061 \nEpoch: 1198  | Training Loss: 0.52065 \nEpoch: 1198  | Training Loss: 0.42825 \nEpoch: 1198  | Training Loss: 0.39761 \nEpoch: 1198  | Training Loss: 0.23692 \nEpoch: 1198  | Validation balanced accuracy : 0.50000 \nEpoch: 1199  | Training Loss: 0.46026 \nEpoch: 1199  | Training Loss: 0.52031 \nEpoch: 1199  | Training Loss: 0.42804 \nEpoch: 1199  | Training Loss: 0.39729 \nEpoch: 1199  | Training Loss: 0.23704 \nEpoch: 1199  | Validation balanced accuracy : 0.50000 \nEpoch: 1200  | Training Loss: 0.45991 \nEpoch: 1200  | Training Loss: 0.51997 \nEpoch: 1200  | Training Loss: 0.42784 \nEpoch: 1200  | Training Loss: 0.39698 \nEpoch: 1200  | Training Loss: 0.23715 \nEpoch: 1200  | Validation balanced accuracy : 0.50000 \nEpoch: 1201  | Training Loss: 0.45957 \nEpoch: 1201  | Training Loss: 0.51963 \nEpoch: 1201  | Training Loss: 0.42766 \nEpoch: 1201  | Training Loss: 0.39666 \nEpoch: 1201  | Training Loss: 0.23709 \nEpoch: 1201  | Validation balanced accuracy : 0.50000 \nEpoch: 1202  | Training Loss: 0.45925 \nEpoch: 1202  | Training Loss: 0.51932 \nEpoch: 1202  | Training Loss: 0.42748 \nEpoch: 1202  | Training Loss: 0.39637 \nEpoch: 1202  | Training Loss: 0.23720 \nEpoch: 1202  | Validation balanced accuracy : 0.50000 \nEpoch: 1203  | Training Loss: 0.45894 \nEpoch: 1203  | Training Loss: 0.51901 \nEpoch: 1203  | Training Loss: 0.42730 \nEpoch: 1203  | Training Loss: 0.39609 \nEpoch: 1203  | Training Loss: 0.23731 \nEpoch: 1203  | Validation balanced accuracy : 0.50000 \nEpoch: 1204  | Training Loss: 0.45862 \nEpoch: 1204  | Training Loss: 0.51870 \nEpoch: 1204  | Training Loss: 0.42712 \nEpoch: 1204  | Training Loss: 0.39581 \nEpoch: 1204  | Training Loss: 0.23742 \nEpoch: 1204  | Validation balanced accuracy : 0.50000 \nEpoch: 1205  | Training Loss: 0.45831 \nEpoch: 1205  | Training Loss: 0.51840 \nEpoch: 1205  | Training Loss: 0.42694 \nEpoch: 1205  | Training Loss: 0.39553 \nEpoch: 1205  | Training Loss: 0.23753 \nEpoch: 1205  | Validation balanced accuracy : 0.50000 \nEpoch: 1206  | Training Loss: 0.45799 \nEpoch: 1206  | Training Loss: 0.51809 \nEpoch: 1206  | Training Loss: 0.42676 \nEpoch: 1206  | Training Loss: 0.39525 \nEpoch: 1206  | Training Loss: 0.23763 \nEpoch: 1206  | Validation balanced accuracy : 0.50000 \nEpoch: 1207  | Training Loss: 0.45768 \nEpoch: 1207  | Training Loss: 0.51779 \nEpoch: 1207  | Training Loss: 0.42658 \nEpoch: 1207  | Training Loss: 0.39497 \nEpoch: 1207  | Training Loss: 0.23773 \nEpoch: 1207  | Validation balanced accuracy : 0.50000 \nEpoch: 1208  | Training Loss: 0.45737 \nEpoch: 1208  | Training Loss: 0.51748 \nEpoch: 1208  | Training Loss: 0.42640 \nEpoch: 1208  | Training Loss: 0.39468 \nEpoch: 1208  | Training Loss: 0.23783 \nEpoch: 1208  | Validation balanced accuracy : 0.50000 \nEpoch: 1209  | Training Loss: 0.45706 \nEpoch: 1209  | Training Loss: 0.51718 \nEpoch: 1209  | Training Loss: 0.42622 \nEpoch: 1209  | Training Loss: 0.39440 \nEpoch: 1209  | Training Loss: 0.23792 \nEpoch: 1209  | Validation balanced accuracy : 0.50000 \nEpoch: 1210  | Training Loss: 0.45676 \nEpoch: 1210  | Training Loss: 0.51688 \nEpoch: 1210  | Training Loss: 0.42604 \nEpoch: 1210  | Training Loss: 0.39412 \nEpoch: 1210  | Training Loss: 0.23802 \nEpoch: 1210  | Validation balanced accuracy : 0.50000 \nEpoch: 1211  | Training Loss: 0.45645 \nEpoch: 1211  | Training Loss: 0.51658 \nEpoch: 1211  | Training Loss: 0.42587 \nEpoch: 1211  | Training Loss: 0.39384 \nEpoch: 1211  | Training Loss: 0.23811 \nEpoch: 1211  | Validation balanced accuracy : 0.50000 \nEpoch: 1212  | Training Loss: 0.45615 \nEpoch: 1212  | Training Loss: 0.51628 \nEpoch: 1212  | Training Loss: 0.42569 \nEpoch: 1212  | Training Loss: 0.39356 \nEpoch: 1212  | Training Loss: 0.23821 \nEpoch: 1212  | Validation balanced accuracy : 0.50000 \nEpoch: 1213  | Training Loss: 0.45584 \nEpoch: 1213  | Training Loss: 0.51598 \nEpoch: 1213  | Training Loss: 0.42551 \nEpoch: 1213  | Training Loss: 0.39327 \nEpoch: 1213  | Training Loss: 0.23830 \nEpoch: 1213  | Validation balanced accuracy : 0.50000 \nEpoch: 1214  | Training Loss: 0.45554 \nEpoch: 1214  | Training Loss: 0.51568 \nEpoch: 1214  | Training Loss: 0.42534 \nEpoch: 1214  | Training Loss: 0.39299 \nEpoch: 1214  | Training Loss: 0.23840 \nEpoch: 1214  | Validation balanced accuracy : 0.50000 \nEpoch: 1215  | Training Loss: 0.45523 \nEpoch: 1215  | Training Loss: 0.51538 \nEpoch: 1215  | Training Loss: 0.42516 \nEpoch: 1215  | Training Loss: 0.39271 \nEpoch: 1215  | Training Loss: 0.23849 \nEpoch: 1215  | Validation balanced accuracy : 0.50000 \nEpoch: 1216  | Training Loss: 0.45493 \nEpoch: 1216  | Training Loss: 0.51508 \nEpoch: 1216  | Training Loss: 0.42498 \nEpoch: 1216  | Training Loss: 0.39243 \nEpoch: 1216  | Training Loss: 0.23858 \nEpoch: 1216  | Validation balanced accuracy : 0.50000 \nEpoch: 1217  | Training Loss: 0.45463 \nEpoch: 1217  | Training Loss: 0.51479 \nEpoch: 1217  | Training Loss: 0.42481 \nEpoch: 1217  | Training Loss: 0.39215 \nEpoch: 1217  | Training Loss: 0.23868 \nEpoch: 1217  | Validation balanced accuracy : 0.50000 \nEpoch: 1218  | Training Loss: 0.45432 \nEpoch: 1218  | Training Loss: 0.51449 \nEpoch: 1218  | Training Loss: 0.42463 \nEpoch: 1218  | Training Loss: 0.39187 \nEpoch: 1218  | Training Loss: 0.23877 \nEpoch: 1218  | Validation balanced accuracy : 0.50000 \nEpoch: 1219  | Training Loss: 0.45402 \nEpoch: 1219  | Training Loss: 0.51419 \nEpoch: 1219  | Training Loss: 0.42446 \nEpoch: 1219  | Training Loss: 0.39159 \nEpoch: 1219  | Training Loss: 0.23886 \nEpoch: 1219  | Validation balanced accuracy : 0.50000 \nEpoch: 1220  | Training Loss: 0.45372 \nEpoch: 1220  | Training Loss: 0.51389 \nEpoch: 1220  | Training Loss: 0.42428 \nEpoch: 1220  | Training Loss: 0.39131 \nEpoch: 1220  | Training Loss: 0.23896 \nEpoch: 1220  | Validation balanced accuracy : 0.50000 \nEpoch: 1221  | Training Loss: 0.45342 \nEpoch: 1221  | Training Loss: 0.51360 \nEpoch: 1221  | Training Loss: 0.42411 \nEpoch: 1221  | Training Loss: 0.39104 \nEpoch: 1221  | Training Loss: 0.23905 \nEpoch: 1221  | Validation balanced accuracy : 0.50000 \nEpoch: 1222  | Training Loss: 0.45312 \nEpoch: 1222  | Training Loss: 0.51330 \nEpoch: 1222  | Training Loss: 0.42393 \nEpoch: 1222  | Training Loss: 0.39076 \nEpoch: 1222  | Training Loss: 0.23914 \nEpoch: 1222  | Validation balanced accuracy : 0.50000 \nEpoch: 1223  | Training Loss: 0.45282 \nEpoch: 1223  | Training Loss: 0.51301 \nEpoch: 1223  | Training Loss: 0.42376 \nEpoch: 1223  | Training Loss: 0.39048 \nEpoch: 1223  | Training Loss: 0.23923 \nEpoch: 1223  | Validation balanced accuracy : 0.50000 \nEpoch: 1224  | Training Loss: 0.45252 \nEpoch: 1224  | Training Loss: 0.51271 \nEpoch: 1224  | Training Loss: 0.42358 \nEpoch: 1224  | Training Loss: 0.39020 \nEpoch: 1224  | Training Loss: 0.23933 \nEpoch: 1224  | Validation balanced accuracy : 0.50000 \nEpoch: 1225  | Training Loss: 0.45222 \nEpoch: 1225  | Training Loss: 0.51242 \nEpoch: 1225  | Training Loss: 0.42341 \nEpoch: 1225  | Training Loss: 0.38992 \nEpoch: 1225  | Training Loss: 0.23942 \nEpoch: 1225  | Validation balanced accuracy : 0.50000 \nEpoch: 1226  | Training Loss: 0.45192 \nEpoch: 1226  | Training Loss: 0.51212 \nEpoch: 1226  | Training Loss: 0.42323 \nEpoch: 1226  | Training Loss: 0.38964 \nEpoch: 1226  | Training Loss: 0.23951 \nEpoch: 1226  | Validation balanced accuracy : 0.50000 \nEpoch: 1227  | Training Loss: 0.45162 \nEpoch: 1227  | Training Loss: 0.51183 \nEpoch: 1227  | Training Loss: 0.42306 \nEpoch: 1227  | Training Loss: 0.38937 \nEpoch: 1227  | Training Loss: 0.23960 \nEpoch: 1227  | Validation balanced accuracy : 0.50000 \nEpoch: 1228  | Training Loss: 0.45132 \nEpoch: 1228  | Training Loss: 0.51154 \nEpoch: 1228  | Training Loss: 0.42289 \nEpoch: 1228  | Training Loss: 0.38909 \nEpoch: 1228  | Training Loss: 0.23969 \nEpoch: 1228  | Validation balanced accuracy : 0.50000 \nEpoch: 1229  | Training Loss: 0.45102 \nEpoch: 1229  | Training Loss: 0.51124 \nEpoch: 1229  | Training Loss: 0.42271 \nEpoch: 1229  | Training Loss: 0.38881 \nEpoch: 1229  | Training Loss: 0.23978 \nEpoch: 1229  | Validation balanced accuracy : 0.50000 \nEpoch: 1230  | Training Loss: 0.45072 \nEpoch: 1230  | Training Loss: 0.51095 \nEpoch: 1230  | Training Loss: 0.42254 \nEpoch: 1230  | Training Loss: 0.38854 \nEpoch: 1230  | Training Loss: 0.23987 \nEpoch: 1230  | Validation balanced accuracy : 0.50000 \nEpoch: 1231  | Training Loss: 0.45042 \nEpoch: 1231  | Training Loss: 0.51066 \nEpoch: 1231  | Training Loss: 0.42237 \nEpoch: 1231  | Training Loss: 0.38826 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1231  | Training Loss: 0.23996 \nEpoch: 1231  | Validation balanced accuracy : 0.50000 \nEpoch: 1232  | Training Loss: 0.45013 \nEpoch: 1232  | Training Loss: 0.51037 \nEpoch: 1232  | Training Loss: 0.42220 \nEpoch: 1232  | Training Loss: 0.38799 \nEpoch: 1232  | Training Loss: 0.24005 \nEpoch: 1232  | Validation balanced accuracy : 0.50000 \nEpoch: 1233  | Training Loss: 0.44983 \nEpoch: 1233  | Training Loss: 0.51008 \nEpoch: 1233  | Training Loss: 0.42202 \nEpoch: 1233  | Training Loss: 0.38771 \nEpoch: 1233  | Training Loss: 0.24014 \nEpoch: 1233  | Validation balanced accuracy : 0.50000 \nEpoch: 1234  | Training Loss: 0.44953 \nEpoch: 1234  | Training Loss: 0.50979 \nEpoch: 1234  | Training Loss: 0.42185 \nEpoch: 1234  | Training Loss: 0.38743 \nEpoch: 1234  | Training Loss: 0.24023 \nEpoch: 1234  | Validation balanced accuracy : 0.50000 \nEpoch: 1235  | Training Loss: 0.44924 \nEpoch: 1235  | Training Loss: 0.50950 \nEpoch: 1235  | Training Loss: 0.42168 \nEpoch: 1235  | Training Loss: 0.38716 \nEpoch: 1235  | Training Loss: 0.24031 \nEpoch: 1235  | Validation balanced accuracy : 0.50000 \nEpoch: 1236  | Training Loss: 0.44894 \nEpoch: 1236  | Training Loss: 0.50921 \nEpoch: 1236  | Training Loss: 0.42151 \nEpoch: 1236  | Training Loss: 0.38688 \nEpoch: 1236  | Training Loss: 0.24040 \nEpoch: 1236  | Validation balanced accuracy : 0.50000 \nEpoch: 1237  | Training Loss: 0.44865 \nEpoch: 1237  | Training Loss: 0.50892 \nEpoch: 1237  | Training Loss: 0.42134 \nEpoch: 1237  | Training Loss: 0.38661 \nEpoch: 1237  | Training Loss: 0.24049 \nEpoch: 1237  | Validation balanced accuracy : 0.50000 \nEpoch: 1238  | Training Loss: 0.44835 \nEpoch: 1238  | Training Loss: 0.50863 \nEpoch: 1238  | Training Loss: 0.42117 \nEpoch: 1238  | Training Loss: 0.38634 \nEpoch: 1238  | Training Loss: 0.24058 \nEpoch: 1238  | Validation balanced accuracy : 0.50000 \nEpoch: 1239  | Training Loss: 0.44806 \nEpoch: 1239  | Training Loss: 0.50834 \nEpoch: 1239  | Training Loss: 0.42099 \nEpoch: 1239  | Training Loss: 0.38606 \nEpoch: 1239  | Training Loss: 0.24066 \nEpoch: 1239  | Validation balanced accuracy : 0.50000 \nEpoch: 1240  | Training Loss: 0.44777 \nEpoch: 1240  | Training Loss: 0.50805 \nEpoch: 1240  | Training Loss: 0.42082 \nEpoch: 1240  | Training Loss: 0.38579 \nEpoch: 1240  | Training Loss: 0.24075 \nEpoch: 1240  | Validation balanced accuracy : 0.50000 \nEpoch: 1241  | Training Loss: 0.44747 \nEpoch: 1241  | Training Loss: 0.50777 \nEpoch: 1241  | Training Loss: 0.42065 \nEpoch: 1241  | Training Loss: 0.38552 \nEpoch: 1241  | Training Loss: 0.24084 \nEpoch: 1241  | Validation balanced accuracy : 0.50000 \nEpoch: 1242  | Training Loss: 0.44718 \nEpoch: 1242  | Training Loss: 0.50748 \nEpoch: 1242  | Training Loss: 0.42048 \nEpoch: 1242  | Training Loss: 0.38524 \nEpoch: 1242  | Training Loss: 0.24092 \nEpoch: 1242  | Validation balanced accuracy : 0.50000 \nEpoch: 1243  | Training Loss: 0.44689 \nEpoch: 1243  | Training Loss: 0.50719 \nEpoch: 1243  | Training Loss: 0.42031 \nEpoch: 1243  | Training Loss: 0.38497 \nEpoch: 1243  | Training Loss: 0.24101 \nEpoch: 1243  | Validation balanced accuracy : 0.50000 \nEpoch: 1244  | Training Loss: 0.44659 \nEpoch: 1244  | Training Loss: 0.50691 \nEpoch: 1244  | Training Loss: 0.42014 \nEpoch: 1244  | Training Loss: 0.38470 \nEpoch: 1244  | Training Loss: 0.24110 \nEpoch: 1244  | Validation balanced accuracy : 0.50000 \nEpoch: 1245  | Training Loss: 0.44630 \nEpoch: 1245  | Training Loss: 0.50662 \nEpoch: 1245  | Training Loss: 0.41997 \nEpoch: 1245  | Training Loss: 0.38443 \nEpoch: 1245  | Training Loss: 0.24118 \nEpoch: 1245  | Validation balanced accuracy : 0.50000 \nEpoch: 1246  | Training Loss: 0.44601 \nEpoch: 1246  | Training Loss: 0.50634 \nEpoch: 1246  | Training Loss: 0.41980 \nEpoch: 1246  | Training Loss: 0.38415 \nEpoch: 1246  | Training Loss: 0.24127 \nEpoch: 1246  | Validation balanced accuracy : 0.50000 \nEpoch: 1247  | Training Loss: 0.44572 \nEpoch: 1247  | Training Loss: 0.50605 \nEpoch: 1247  | Training Loss: 0.41963 \nEpoch: 1247  | Training Loss: 0.38388 \nEpoch: 1247  | Training Loss: 0.24135 \nEpoch: 1247  | Validation balanced accuracy : 0.50000 \nEpoch: 1248  | Training Loss: 0.44543 \nEpoch: 1248  | Training Loss: 0.50577 \nEpoch: 1248  | Training Loss: 0.41946 \nEpoch: 1248  | Training Loss: 0.38361 \nEpoch: 1248  | Training Loss: 0.24143 \nEpoch: 1248  | Validation balanced accuracy : 0.50000 \nEpoch: 1249  | Training Loss: 0.44514 \nEpoch: 1249  | Training Loss: 0.50549 \nEpoch: 1249  | Training Loss: 0.41929 \nEpoch: 1249  | Training Loss: 0.38334 \nEpoch: 1249  | Training Loss: 0.24152 \nEpoch: 1249  | Validation balanced accuracy : 0.50000 \nEpoch: 1250  | Training Loss: 0.44485 \nEpoch: 1250  | Training Loss: 0.50520 \nEpoch: 1250  | Training Loss: 0.41913 \nEpoch: 1250  | Training Loss: 0.38307 \nEpoch: 1250  | Training Loss: 0.24160 \nEpoch: 1250  | Validation balanced accuracy : 0.50000 \nEpoch: 1251  | Training Loss: 0.44456 \nEpoch: 1251  | Training Loss: 0.50492 \nEpoch: 1251  | Training Loss: 0.41896 \nEpoch: 1251  | Training Loss: 0.38280 \nEpoch: 1251  | Training Loss: 0.24169 \nEpoch: 1251  | Validation balanced accuracy : 0.50000 \nEpoch: 1252  | Training Loss: 0.44427 \nEpoch: 1252  | Training Loss: 0.50464 \nEpoch: 1252  | Training Loss: 0.41879 \nEpoch: 1252  | Training Loss: 0.38253 \nEpoch: 1252  | Training Loss: 0.24177 \nEpoch: 1252  | Validation balanced accuracy : 0.50000 \nEpoch: 1253  | Training Loss: 0.44398 \nEpoch: 1253  | Training Loss: 0.50436 \nEpoch: 1253  | Training Loss: 0.41862 \nEpoch: 1253  | Training Loss: 0.38226 \nEpoch: 1253  | Training Loss: 0.24185 \nEpoch: 1253  | Validation balanced accuracy : 0.50000 \nEpoch: 1254  | Training Loss: 0.44370 \nEpoch: 1254  | Training Loss: 0.50408 \nEpoch: 1254  | Training Loss: 0.41845 \nEpoch: 1254  | Training Loss: 0.38199 \nEpoch: 1254  | Training Loss: 0.24193 \nEpoch: 1254  | Validation balanced accuracy : 0.50000 \nEpoch: 1255  | Training Loss: 0.44341 \nEpoch: 1255  | Training Loss: 0.50379 \nEpoch: 1255  | Training Loss: 0.41828 \nEpoch: 1255  | Training Loss: 0.38172 \nEpoch: 1255  | Training Loss: 0.24202 \nEpoch: 1255  | Validation balanced accuracy : 0.50000 \nEpoch: 1256  | Training Loss: 0.44312 \nEpoch: 1256  | Training Loss: 0.50351 \nEpoch: 1256  | Training Loss: 0.41812 \nEpoch: 1256  | Training Loss: 0.38145 \nEpoch: 1256  | Training Loss: 0.24210 \nEpoch: 1256  | Validation balanced accuracy : 0.50000 \nEpoch: 1257  | Training Loss: 0.44283 \nEpoch: 1257  | Training Loss: 0.50323 \nEpoch: 1257  | Training Loss: 0.41795 \nEpoch: 1257  | Training Loss: 0.38118 \nEpoch: 1257  | Training Loss: 0.24218 \nEpoch: 1257  | Validation balanced accuracy : 0.50000 \nEpoch: 1258  | Training Loss: 0.44255 \nEpoch: 1258  | Training Loss: 0.50296 \nEpoch: 1258  | Training Loss: 0.41778 \nEpoch: 1258  | Training Loss: 0.38092 \nEpoch: 1258  | Training Loss: 0.24226 \nEpoch: 1258  | Validation balanced accuracy : 0.50000 \nEpoch: 1259  | Training Loss: 0.44226 \nEpoch: 1259  | Training Loss: 0.50268 \nEpoch: 1259  | Training Loss: 0.41761 \nEpoch: 1259  | Training Loss: 0.38065 \nEpoch: 1259  | Training Loss: 0.24234 \nEpoch: 1259  | Validation balanced accuracy : 0.50000 \nEpoch: 1260  | Training Loss: 0.44198 \nEpoch: 1260  | Training Loss: 0.50240 \nEpoch: 1260  | Training Loss: 0.41745 \nEpoch: 1260  | Training Loss: 0.38038 \nEpoch: 1260  | Training Loss: 0.24242 \nEpoch: 1260  | Validation balanced accuracy : 0.50000 \nEpoch: 1261  | Training Loss: 0.44169 \nEpoch: 1261  | Training Loss: 0.50212 \nEpoch: 1261  | Training Loss: 0.41728 \nEpoch: 1261  | Training Loss: 0.38011 \nEpoch: 1261  | Training Loss: 0.24250 \nEpoch: 1261  | Validation balanced accuracy : 0.50000 \nEpoch: 1262  | Training Loss: 0.44141 \nEpoch: 1262  | Training Loss: 0.50184 \nEpoch: 1262  | Training Loss: 0.41711 \nEpoch: 1262  | Training Loss: 0.37985 \nEpoch: 1262  | Training Loss: 0.24258 \nEpoch: 1262  | Validation balanced accuracy : 0.50000 \nEpoch: 1263  | Training Loss: 0.44112 \nEpoch: 1263  | Training Loss: 0.50157 \nEpoch: 1263  | Training Loss: 0.41695 \nEpoch: 1263  | Training Loss: 0.37958 \nEpoch: 1263  | Training Loss: 0.24266 \nEpoch: 1263  | Validation balanced accuracy : 0.50000 \nEpoch: 1264  | Training Loss: 0.44084 \nEpoch: 1264  | Training Loss: 0.50129 \nEpoch: 1264  | Training Loss: 0.41678 \nEpoch: 1264  | Training Loss: 0.37931 \nEpoch: 1264  | Training Loss: 0.24274 \nEpoch: 1264  | Validation balanced accuracy : 0.50000 \nEpoch: 1265  | Training Loss: 0.44055 \nEpoch: 1265  | Training Loss: 0.50101 \nEpoch: 1265  | Training Loss: 0.41661 \nEpoch: 1265  | Training Loss: 0.37905 \nEpoch: 1265  | Training Loss: 0.24282 \nEpoch: 1265  | Validation balanced accuracy : 0.50000 \nEpoch: 1266  | Training Loss: 0.44027 \nEpoch: 1266  | Training Loss: 0.50074 \nEpoch: 1266  | Training Loss: 0.41645 \nEpoch: 1266  | Training Loss: 0.37878 \nEpoch: 1266  | Training Loss: 0.24290 \nEpoch: 1266  | Validation balanced accuracy : 0.50000 \nEpoch: 1267  | Training Loss: 0.43999 \nEpoch: 1267  | Training Loss: 0.50046 \nEpoch: 1267  | Training Loss: 0.41628 \nEpoch: 1267  | Training Loss: 0.37852 \nEpoch: 1267  | Training Loss: 0.24298 \nEpoch: 1267  | Validation balanced accuracy : 0.50000 \nEpoch: 1268  | Training Loss: 0.43971 \nEpoch: 1268  | Training Loss: 0.50019 \nEpoch: 1268  | Training Loss: 0.41612 \nEpoch: 1268  | Training Loss: 0.37825 \nEpoch: 1268  | Training Loss: 0.24306 \nEpoch: 1268  | Validation balanced accuracy : 0.50000 \nEpoch: 1269  | Training Loss: 0.43942 \nEpoch: 1269  | Training Loss: 0.49991 \nEpoch: 1269  | Training Loss: 0.41595 \nEpoch: 1269  | Training Loss: 0.37799 \nEpoch: 1269  | Training Loss: 0.24314 \nEpoch: 1269  | Validation balanced accuracy : 0.50000 \nEpoch: 1270  | Training Loss: 0.43914 \nEpoch: 1270  | Training Loss: 0.49964 \nEpoch: 1270  | Training Loss: 0.41578 \nEpoch: 1270  | Training Loss: 0.37772 \nEpoch: 1270  | Training Loss: 0.24321 \nEpoch: 1270  | Validation balanced accuracy : 0.50000 \nEpoch: 1271  | Training Loss: 0.43886 \nEpoch: 1271  | Training Loss: 0.49937 \nEpoch: 1271  | Training Loss: 0.41562 \nEpoch: 1271  | Training Loss: 0.37746 \nEpoch: 1271  | Training Loss: 0.24329 \nEpoch: 1271  | Validation balanced accuracy : 0.50000 \nEpoch: 1272  | Training Loss: 0.43858 \nEpoch: 1272  | Training Loss: 0.49909 \nEpoch: 1272  | Training Loss: 0.41545 \nEpoch: 1272  | Training Loss: 0.37719 \nEpoch: 1272  | Training Loss: 0.24337 \nEpoch: 1272  | Validation balanced accuracy : 0.50000 \nEpoch: 1273  | Training Loss: 0.43830 \nEpoch: 1273  | Training Loss: 0.49882 \nEpoch: 1273  | Training Loss: 0.41529 \nEpoch: 1273  | Training Loss: 0.37693 \nEpoch: 1273  | Training Loss: 0.24344 \nEpoch: 1273  | Validation balanced accuracy : 0.50000 \nEpoch: 1274  | Training Loss: 0.43802 \nEpoch: 1274  | Training Loss: 0.49855 \nEpoch: 1274  | Training Loss: 0.41512 \nEpoch: 1274  | Training Loss: 0.37667 \nEpoch: 1274  | Training Loss: 0.24352 \nEpoch: 1274  | Validation balanced accuracy : 0.50000 \nEpoch: 1275  | Training Loss: 0.43774 \nEpoch: 1275  | Training Loss: 0.49828 \nEpoch: 1275  | Training Loss: 0.41496 \nEpoch: 1275  | Training Loss: 0.37640 \nEpoch: 1275  | Training Loss: 0.24360 \nEpoch: 1275  | Validation balanced accuracy : 0.50000 \nEpoch: 1276  | Training Loss: 0.43746 \nEpoch: 1276  | Training Loss: 0.49801 \nEpoch: 1276  | Training Loss: 0.41480 \nEpoch: 1276  | Training Loss: 0.37614 \nEpoch: 1276  | Training Loss: 0.24367 \nEpoch: 1276  | Validation balanced accuracy : 0.50000 \nEpoch: 1277  | Training Loss: 0.43718 \nEpoch: 1277  | Training Loss: 0.49774 \nEpoch: 1277  | Training Loss: 0.41463 \nEpoch: 1277  | Training Loss: 0.37588 \nEpoch: 1277  | Training Loss: 0.24375 \nEpoch: 1277  | Validation balanced accuracy : 0.50000 \nEpoch: 1278  | Training Loss: 0.43690 \nEpoch: 1278  | Training Loss: 0.49747 \nEpoch: 1278  | Training Loss: 0.41447 \nEpoch: 1278  | Training Loss: 0.37562 \nEpoch: 1278  | Training Loss: 0.24382 \nEpoch: 1278  | Validation balanced accuracy : 0.50000 \nEpoch: 1279  | Training Loss: 0.43663 \nEpoch: 1279  | Training Loss: 0.49720 \nEpoch: 1279  | Training Loss: 0.41430 \nEpoch: 1279  | Training Loss: 0.37536 \nEpoch: 1279  | Training Loss: 0.24390 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1279  | Validation balanced accuracy : 0.50000 \nEpoch: 1280  | Training Loss: 0.43635 \nEpoch: 1280  | Training Loss: 0.49693 \nEpoch: 1280  | Training Loss: 0.41414 \nEpoch: 1280  | Training Loss: 0.37509 \nEpoch: 1280  | Training Loss: 0.24397 \nEpoch: 1280  | Validation balanced accuracy : 0.50000 \nEpoch: 1281  | Training Loss: 0.43607 \nEpoch: 1281  | Training Loss: 0.49666 \nEpoch: 1281  | Training Loss: 0.41398 \nEpoch: 1281  | Training Loss: 0.37483 \nEpoch: 1281  | Training Loss: 0.24405 \nEpoch: 1281  | Validation balanced accuracy : 0.50000 \nEpoch: 1282  | Training Loss: 0.43579 \nEpoch: 1282  | Training Loss: 0.49639 \nEpoch: 1282  | Training Loss: 0.41381 \nEpoch: 1282  | Training Loss: 0.37457 \nEpoch: 1282  | Training Loss: 0.24412 \nEpoch: 1282  | Validation balanced accuracy : 0.50000 \nEpoch: 1283  | Training Loss: 0.43552 \nEpoch: 1283  | Training Loss: 0.49613 \nEpoch: 1283  | Training Loss: 0.41365 \nEpoch: 1283  | Training Loss: 0.37431 \nEpoch: 1283  | Training Loss: 0.24419 \nEpoch: 1283  | Validation balanced accuracy : 0.50000 \nEpoch: 1284  | Training Loss: 0.43524 \nEpoch: 1284  | Training Loss: 0.49586 \nEpoch: 1284  | Training Loss: 0.41349 \nEpoch: 1284  | Training Loss: 0.37405 \nEpoch: 1284  | Training Loss: 0.24427 \nEpoch: 1284  | Validation balanced accuracy : 0.50000 \nEpoch: 1285  | Training Loss: 0.43497 \nEpoch: 1285  | Training Loss: 0.49559 \nEpoch: 1285  | Training Loss: 0.41332 \nEpoch: 1285  | Training Loss: 0.37379 \nEpoch: 1285  | Training Loss: 0.24434 \nEpoch: 1285  | Validation balanced accuracy : 0.50000 \nEpoch: 1286  | Training Loss: 0.43469 \nEpoch: 1286  | Training Loss: 0.49533 \nEpoch: 1286  | Training Loss: 0.41316 \nEpoch: 1286  | Training Loss: 0.37353 \nEpoch: 1286  | Training Loss: 0.24441 \nEpoch: 1286  | Validation balanced accuracy : 0.50000 \nEpoch: 1287  | Training Loss: 0.43442 \nEpoch: 1287  | Training Loss: 0.49506 \nEpoch: 1287  | Training Loss: 0.41300 \nEpoch: 1287  | Training Loss: 0.37327 \nEpoch: 1287  | Training Loss: 0.24449 \nEpoch: 1287  | Validation balanced accuracy : 0.50000 \nEpoch: 1288  | Training Loss: 0.43414 \nEpoch: 1288  | Training Loss: 0.49480 \nEpoch: 1288  | Training Loss: 0.41283 \nEpoch: 1288  | Training Loss: 0.37301 \nEpoch: 1288  | Training Loss: 0.24456 \nEpoch: 1288  | Validation balanced accuracy : 0.50000 \nEpoch: 1289  | Training Loss: 0.43387 \nEpoch: 1289  | Training Loss: 0.49453 \nEpoch: 1289  | Training Loss: 0.41267 \nEpoch: 1289  | Training Loss: 0.37276 \nEpoch: 1289  | Training Loss: 0.24463 \nEpoch: 1289  | Validation balanced accuracy : 0.50000 \nEpoch: 1290  | Training Loss: 0.43359 \nEpoch: 1290  | Training Loss: 0.49427 \nEpoch: 1290  | Training Loss: 0.41251 \nEpoch: 1290  | Training Loss: 0.37250 \nEpoch: 1290  | Training Loss: 0.24470 \nEpoch: 1290  | Validation balanced accuracy : 0.50000 \nEpoch: 1291  | Training Loss: 0.43332 \nEpoch: 1291  | Training Loss: 0.49400 \nEpoch: 1291  | Training Loss: 0.41235 \nEpoch: 1291  | Training Loss: 0.37224 \nEpoch: 1291  | Training Loss: 0.24477 \nEpoch: 1291  | Validation balanced accuracy : 0.50000 \nEpoch: 1292  | Training Loss: 0.43305 \nEpoch: 1292  | Training Loss: 0.49374 \nEpoch: 1292  | Training Loss: 0.41218 \nEpoch: 1292  | Training Loss: 0.37198 \nEpoch: 1292  | Training Loss: 0.24484 \nEpoch: 1292  | Validation balanced accuracy : 0.50000 \nEpoch: 1293  | Training Loss: 0.43277 \nEpoch: 1293  | Training Loss: 0.49348 \nEpoch: 1293  | Training Loss: 0.41202 \nEpoch: 1293  | Training Loss: 0.37173 \nEpoch: 1293  | Training Loss: 0.24491 \nEpoch: 1293  | Validation balanced accuracy : 0.50000 \nEpoch: 1294  | Training Loss: 0.43250 \nEpoch: 1294  | Training Loss: 0.49322 \nEpoch: 1294  | Training Loss: 0.41186 \nEpoch: 1294  | Training Loss: 0.37147 \nEpoch: 1294  | Training Loss: 0.24499 \nEpoch: 1294  | Validation balanced accuracy : 0.50000 \nEpoch: 1295  | Training Loss: 0.43223 \nEpoch: 1295  | Training Loss: 0.49295 \nEpoch: 1295  | Training Loss: 0.41170 \nEpoch: 1295  | Training Loss: 0.37121 \nEpoch: 1295  | Training Loss: 0.24506 \nEpoch: 1295  | Validation balanced accuracy : 0.50000 \nEpoch: 1296  | Training Loss: 0.43196 \nEpoch: 1296  | Training Loss: 0.49269 \nEpoch: 1296  | Training Loss: 0.41154 \nEpoch: 1296  | Training Loss: 0.37096 \nEpoch: 1296  | Training Loss: 0.24513 \nEpoch: 1296  | Validation balanced accuracy : 0.50000 \nEpoch: 1297  | Training Loss: 0.43169 \nEpoch: 1297  | Training Loss: 0.49243 \nEpoch: 1297  | Training Loss: 0.41138 \nEpoch: 1297  | Training Loss: 0.37070 \nEpoch: 1297  | Training Loss: 0.24519 \nEpoch: 1297  | Validation balanced accuracy : 0.50000 \nEpoch: 1298  | Training Loss: 0.43142 \nEpoch: 1298  | Training Loss: 0.49217 \nEpoch: 1298  | Training Loss: 0.41122 \nEpoch: 1298  | Training Loss: 0.37044 \nEpoch: 1298  | Training Loss: 0.24526 \nEpoch: 1298  | Validation balanced accuracy : 0.50000 \nEpoch: 1299  | Training Loss: 0.43115 \nEpoch: 1299  | Training Loss: 0.49191 \nEpoch: 1299  | Training Loss: 0.41105 \nEpoch: 1299  | Training Loss: 0.37019 \nEpoch: 1299  | Training Loss: 0.24533 \nEpoch: 1299  | Validation balanced accuracy : 0.50000 \nEpoch: 1300  | Training Loss: 0.43088 \nEpoch: 1300  | Training Loss: 0.49165 \nEpoch: 1300  | Training Loss: 0.41089 \nEpoch: 1300  | Training Loss: 0.36993 \nEpoch: 1300  | Training Loss: 0.24540 \nEpoch: 1300  | Validation balanced accuracy : 0.50000 \nEpoch: 1301  | Training Loss: 0.43061 \nEpoch: 1301  | Training Loss: 0.49139 \nEpoch: 1301  | Training Loss: 0.41073 \nEpoch: 1301  | Training Loss: 0.36968 \nEpoch: 1301  | Training Loss: 0.24547 \nEpoch: 1301  | Validation balanced accuracy : 0.50000 \nEpoch: 1302  | Training Loss: 0.43034 \nEpoch: 1302  | Training Loss: 0.49114 \nEpoch: 1302  | Training Loss: 0.41057 \nEpoch: 1302  | Training Loss: 0.36942 \nEpoch: 1302  | Training Loss: 0.24554 \nEpoch: 1302  | Validation balanced accuracy : 0.50000 \nEpoch: 1303  | Training Loss: 0.43007 \nEpoch: 1303  | Training Loss: 0.49088 \nEpoch: 1303  | Training Loss: 0.41041 \nEpoch: 1303  | Training Loss: 0.36917 \nEpoch: 1303  | Training Loss: 0.24560 \nEpoch: 1303  | Validation balanced accuracy : 0.50000 \nEpoch: 1304  | Training Loss: 0.42980 \nEpoch: 1304  | Training Loss: 0.49062 \nEpoch: 1304  | Training Loss: 0.41025 \nEpoch: 1304  | Training Loss: 0.36892 \nEpoch: 1304  | Training Loss: 0.24567 \nEpoch: 1304  | Validation balanced accuracy : 0.50000 \nEpoch: 1305  | Training Loss: 0.42953 \nEpoch: 1305  | Training Loss: 0.49036 \nEpoch: 1305  | Training Loss: 0.41009 \nEpoch: 1305  | Training Loss: 0.36866 \nEpoch: 1305  | Training Loss: 0.24574 \nEpoch: 1305  | Validation balanced accuracy : 0.50000 \nEpoch: 1306  | Training Loss: 0.42927 \nEpoch: 1306  | Training Loss: 0.49011 \nEpoch: 1306  | Training Loss: 0.40993 \nEpoch: 1306  | Training Loss: 0.36841 \nEpoch: 1306  | Training Loss: 0.24581 \nEpoch: 1306  | Validation balanced accuracy : 0.50000 \nEpoch: 1307  | Training Loss: 0.42900 \nEpoch: 1307  | Training Loss: 0.48985 \nEpoch: 1307  | Training Loss: 0.40977 \nEpoch: 1307  | Training Loss: 0.36816 \nEpoch: 1307  | Training Loss: 0.24587 \nEpoch: 1307  | Validation balanced accuracy : 0.50000 \nEpoch: 1308  | Training Loss: 0.42873 \nEpoch: 1308  | Training Loss: 0.48960 \nEpoch: 1308  | Training Loss: 0.40961 \nEpoch: 1308  | Training Loss: 0.36791 \nEpoch: 1308  | Training Loss: 0.24594 \nEpoch: 1308  | Validation balanced accuracy : 0.50000 \nEpoch: 1309  | Training Loss: 0.42847 \nEpoch: 1309  | Training Loss: 0.48934 \nEpoch: 1309  | Training Loss: 0.40945 \nEpoch: 1309  | Training Loss: 0.36765 \nEpoch: 1309  | Training Loss: 0.24600 \nEpoch: 1309  | Validation balanced accuracy : 0.50000 \nEpoch: 1310  | Training Loss: 0.42820 \nEpoch: 1310  | Training Loss: 0.48909 \nEpoch: 1310  | Training Loss: 0.40929 \nEpoch: 1310  | Training Loss: 0.36740 \nEpoch: 1310  | Training Loss: 0.24607 \nEpoch: 1310  | Validation balanced accuracy : 0.50000 \nEpoch: 1311  | Training Loss: 0.42794 \nEpoch: 1311  | Training Loss: 0.48883 \nEpoch: 1311  | Training Loss: 0.40913 \nEpoch: 1311  | Training Loss: 0.36715 \nEpoch: 1311  | Training Loss: 0.24613 \nEpoch: 1311  | Validation balanced accuracy : 0.50000 \nEpoch: 1312  | Training Loss: 0.42767 \nEpoch: 1312  | Training Loss: 0.48858 \nEpoch: 1312  | Training Loss: 0.40897 \nEpoch: 1312  | Training Loss: 0.36690 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1312  | Training Loss: 0.24620 \nEpoch: 1312  | Validation balanced accuracy : 0.50000 \nEpoch: 1313  | Training Loss: 0.42741 \nEpoch: 1313  | Training Loss: 0.48833 \nEpoch: 1313  | Training Loss: 0.40881 \nEpoch: 1313  | Training Loss: 0.36665 \nEpoch: 1313  | Training Loss: 0.24626 \nEpoch: 1313  | Validation balanced accuracy : 0.50000 \nEpoch: 1314  | Training Loss: 0.42714 \nEpoch: 1314  | Training Loss: 0.48807 \nEpoch: 1314  | Training Loss: 0.40866 \nEpoch: 1314  | Training Loss: 0.36640 \nEpoch: 1314  | Training Loss: 0.24633 \nEpoch: 1314  | Validation balanced accuracy : 0.50000 \nEpoch: 1315  | Training Loss: 0.42688 \nEpoch: 1315  | Training Loss: 0.48782 \nEpoch: 1315  | Training Loss: 0.40850 \nEpoch: 1315  | Training Loss: 0.36615 \nEpoch: 1315  | Training Loss: 0.24639 \nEpoch: 1315  | Validation balanced accuracy : 0.50000 \nEpoch: 1316  | Training Loss: 0.42661 \nEpoch: 1316  | Training Loss: 0.48757 \nEpoch: 1316  | Training Loss: 0.40834 \nEpoch: 1316  | Training Loss: 0.36590 \nEpoch: 1316  | Training Loss: 0.24646 \nEpoch: 1316  | Validation balanced accuracy : 0.50000 \nEpoch: 1317  | Training Loss: 0.42635 \nEpoch: 1317  | Training Loss: 0.48732 \nEpoch: 1317  | Training Loss: 0.40818 \nEpoch: 1317  | Training Loss: 0.36565 \nEpoch: 1317  | Training Loss: 0.24652 \nEpoch: 1317  | Validation balanced accuracy : 0.50000 \nEpoch: 1318  | Training Loss: 0.42609 \nEpoch: 1318  | Training Loss: 0.48707 \nEpoch: 1318  | Training Loss: 0.40802 \nEpoch: 1318  | Training Loss: 0.36540 \nEpoch: 1318  | Training Loss: 0.24658 \nEpoch: 1318  | Validation balanced accuracy : 0.50000 \nEpoch: 1319  | Training Loss: 0.42582 \nEpoch: 1319  | Training Loss: 0.48682 \nEpoch: 1319  | Training Loss: 0.40786 \nEpoch: 1319  | Training Loss: 0.36515 \nEpoch: 1319  | Training Loss: 0.24665 \nEpoch: 1319  | Validation balanced accuracy : 0.50000 \nEpoch: 1320  | Training Loss: 0.42556 \nEpoch: 1320  | Training Loss: 0.48657 \nEpoch: 1320  | Training Loss: 0.40770 \nEpoch: 1320  | Training Loss: 0.36490 \nEpoch: 1320  | Training Loss: 0.24671 \nEpoch: 1320  | Validation balanced accuracy : 0.50000 \nEpoch: 1321  | Training Loss: 0.42530 \nEpoch: 1321  | Training Loss: 0.48632 \nEpoch: 1321  | Training Loss: 0.40755 \nEpoch: 1321  | Training Loss: 0.36465 \nEpoch: 1321  | Training Loss: 0.24677 \nEpoch: 1321  | Validation balanced accuracy : 0.50000 \nEpoch: 1322  | Training Loss: 0.42504 \nEpoch: 1322  | Training Loss: 0.48607 \nEpoch: 1322  | Training Loss: 0.40739 \nEpoch: 1322  | Training Loss: 0.36441 \nEpoch: 1322  | Training Loss: 0.24683 \nEpoch: 1322  | Validation balanced accuracy : 0.50000 \nEpoch: 1323  | Training Loss: 0.42478 \nEpoch: 1323  | Training Loss: 0.48582 \nEpoch: 1323  | Training Loss: 0.40723 \nEpoch: 1323  | Training Loss: 0.36416 \nEpoch: 1323  | Training Loss: 0.24689 \nEpoch: 1323  | Validation balanced accuracy : 0.50000 \nEpoch: 1324  | Training Loss: 0.42452 \nEpoch: 1324  | Training Loss: 0.48557 \nEpoch: 1324  | Training Loss: 0.40707 \nEpoch: 1324  | Training Loss: 0.36391 \nEpoch: 1324  | Training Loss: 0.24695 \nEpoch: 1324  | Validation balanced accuracy : 0.50000 \nEpoch: 1325  | Training Loss: 0.42426 \nEpoch: 1325  | Training Loss: 0.48533 \nEpoch: 1325  | Training Loss: 0.40692 \nEpoch: 1325  | Training Loss: 0.36366 \nEpoch: 1325  | Training Loss: 0.24702 \nEpoch: 1325  | Validation balanced accuracy : 0.50000 \nEpoch: 1326  | Training Loss: 0.42400 \nEpoch: 1326  | Training Loss: 0.48508 \nEpoch: 1326  | Training Loss: 0.40676 \nEpoch: 1326  | Training Loss: 0.36342 \nEpoch: 1326  | Training Loss: 0.24708 \nEpoch: 1326  | Validation balanced accuracy : 0.50000 \nEpoch: 1327  | Training Loss: 0.42374 \nEpoch: 1327  | Training Loss: 0.48483 \nEpoch: 1327  | Training Loss: 0.40660 \nEpoch: 1327  | Training Loss: 0.36317 \nEpoch: 1327  | Training Loss: 0.24714 \nEpoch: 1327  | Validation balanced accuracy : 0.50000 \nEpoch: 1328  | Training Loss: 0.42348 \nEpoch: 1328  | Training Loss: 0.48459 \nEpoch: 1328  | Training Loss: 0.40644 \nEpoch: 1328  | Training Loss: 0.36293 \nEpoch: 1328  | Training Loss: 0.24720 \nEpoch: 1328  | Validation balanced accuracy : 0.50000 \nEpoch: 1329  | Training Loss: 0.42322 \nEpoch: 1329  | Training Loss: 0.48434 \nEpoch: 1329  | Training Loss: 0.40629 \nEpoch: 1329  | Training Loss: 0.36268 \nEpoch: 1329  | Training Loss: 0.24726 \nEpoch: 1329  | Validation balanced accuracy : 0.50000 \nEpoch: 1330  | Training Loss: 0.42296 \nEpoch: 1330  | Training Loss: 0.48410 \nEpoch: 1330  | Training Loss: 0.40613 \nEpoch: 1330  | Training Loss: 0.36244 \nEpoch: 1330  | Training Loss: 0.24732 \nEpoch: 1330  | Validation balanced accuracy : 0.50000 \nEpoch: 1331  | Training Loss: 0.42271 \nEpoch: 1331  | Training Loss: 0.48385 \nEpoch: 1331  | Training Loss: 0.40597 \nEpoch: 1331  | Training Loss: 0.36219 \nEpoch: 1331  | Training Loss: 0.24737 \nEpoch: 1331  | Validation balanced accuracy : 0.50000 \nEpoch: 1332  | Training Loss: 0.42245 \nEpoch: 1332  | Training Loss: 0.48361 \nEpoch: 1332  | Training Loss: 0.40582 \nEpoch: 1332  | Training Loss: 0.36195 \nEpoch: 1332  | Training Loss: 0.24743 \nEpoch: 1332  | Validation balanced accuracy : 0.50000 \nEpoch: 1333  | Training Loss: 0.42219 \nEpoch: 1333  | Training Loss: 0.48336 \nEpoch: 1333  | Training Loss: 0.40566 \nEpoch: 1333  | Training Loss: 0.36170 \nEpoch: 1333  | Training Loss: 0.24749 \nEpoch: 1333  | Validation balanced accuracy : 0.50000 \nEpoch: 1334  | Training Loss: 0.42193 \nEpoch: 1334  | Training Loss: 0.48312 \nEpoch: 1334  | Training Loss: 0.40550 \nEpoch: 1334  | Training Loss: 0.36146 \nEpoch: 1334  | Training Loss: 0.24755 \nEpoch: 1334  | Validation balanced accuracy : 0.50000 \nEpoch: 1335  | Training Loss: 0.42168 \nEpoch: 1335  | Training Loss: 0.48288 \nEpoch: 1335  | Training Loss: 0.40535 \nEpoch: 1335  | Training Loss: 0.36121 \nEpoch: 1335  | Training Loss: 0.24761 \nEpoch: 1335  | Validation balanced accuracy : 0.50000 \nEpoch: 1336  | Training Loss: 0.42142 \nEpoch: 1336  | Training Loss: 0.48264 \nEpoch: 1336  | Training Loss: 0.40519 \nEpoch: 1336  | Training Loss: 0.36097 \nEpoch: 1336  | Training Loss: 0.24767 \nEpoch: 1336  | Validation balanced accuracy : 0.50000 \nEpoch: 1337  | Training Loss: 0.42117 \nEpoch: 1337  | Training Loss: 0.48240 \nEpoch: 1337  | Training Loss: 0.40503 \nEpoch: 1337  | Training Loss: 0.36073 \nEpoch: 1337  | Training Loss: 0.24772 \nEpoch: 1337  | Validation balanced accuracy : 0.50000 \nEpoch: 1338  | Training Loss: 0.42091 \nEpoch: 1338  | Training Loss: 0.48215 \nEpoch: 1338  | Training Loss: 0.40488 \nEpoch: 1338  | Training Loss: 0.36049 \nEpoch: 1338  | Training Loss: 0.24778 \nEpoch: 1338  | Validation balanced accuracy : 0.50000 \nEpoch: 1339  | Training Loss: 0.42066 \nEpoch: 1339  | Training Loss: 0.48191 \nEpoch: 1339  | Training Loss: 0.40472 \nEpoch: 1339  | Training Loss: 0.36024 \nEpoch: 1339  | Training Loss: 0.24784 \nEpoch: 1339  | Validation balanced accuracy : 0.50000 \nEpoch: 1340  | Training Loss: 0.42040 \nEpoch: 1340  | Training Loss: 0.48167 \nEpoch: 1340  | Training Loss: 0.40457 \nEpoch: 1340  | Training Loss: 0.36000 \nEpoch: 1340  | Training Loss: 0.24789 \nEpoch: 1340  | Validation balanced accuracy : 0.50000 \nEpoch: 1341  | Training Loss: 0.42015 \nEpoch: 1341  | Training Loss: 0.48143 \nEpoch: 1341  | Training Loss: 0.40441 \nEpoch: 1341  | Training Loss: 0.35976 \nEpoch: 1341  | Training Loss: 0.24795 \nEpoch: 1341  | Validation balanced accuracy : 0.50000 \nEpoch: 1342  | Training Loss: 0.41989 \nEpoch: 1342  | Training Loss: 0.48119 \nEpoch: 1342  | Training Loss: 0.40426 \nEpoch: 1342  | Training Loss: 0.35952 \nEpoch: 1342  | Training Loss: 0.24800 \nEpoch: 1342  | Validation balanced accuracy : 0.50000 \nEpoch: 1343  | Training Loss: 0.41964 \nEpoch: 1343  | Training Loss: 0.48096 \nEpoch: 1343  | Training Loss: 0.40410 \nEpoch: 1343  | Training Loss: 0.35928 \nEpoch: 1343  | Training Loss: 0.24806 \nEpoch: 1343  | Validation balanced accuracy : 0.50000 \nEpoch: 1344  | Training Loss: 0.41939 \nEpoch: 1344  | Training Loss: 0.48072 \nEpoch: 1344  | Training Loss: 0.40394 \nEpoch: 1344  | Training Loss: 0.35904 \nEpoch: 1344  | Training Loss: 0.24812 \nEpoch: 1344  | Validation balanced accuracy : 0.50000 \nEpoch: 1345  | Training Loss: 0.41914 \nEpoch: 1345  | Training Loss: 0.48048 \nEpoch: 1345  | Training Loss: 0.40379 \nEpoch: 1345  | Training Loss: 0.35880 \nEpoch: 1345  | Training Loss: 0.24817 \nEpoch: 1345  | Validation balanced accuracy : 0.50000 \nEpoch: 1346  | Training Loss: 0.41888 \nEpoch: 1346  | Training Loss: 0.48024 \nEpoch: 1346  | Training Loss: 0.40363 \nEpoch: 1346  | Training Loss: 0.35856 \nEpoch: 1346  | Training Loss: 0.24823 \nEpoch: 1346  | Validation balanced accuracy : 0.50000 \nEpoch: 1347  | Training Loss: 0.41863 \nEpoch: 1347  | Training Loss: 0.48000 \nEpoch: 1347  | Training Loss: 0.40348 \nEpoch: 1347  | Training Loss: 0.35832 \nEpoch: 1347  | Training Loss: 0.24828 \nEpoch: 1347  | Validation balanced accuracy : 0.50000 \nEpoch: 1348  | Training Loss: 0.41838 \nEpoch: 1348  | Training Loss: 0.47977 \nEpoch: 1348  | Training Loss: 0.40332 \nEpoch: 1348  | Training Loss: 0.35808 \nEpoch: 1348  | Training Loss: 0.24833 \nEpoch: 1348  | Validation balanced accuracy : 0.50000 \nEpoch: 1349  | Training Loss: 0.41813 \nEpoch: 1349  | Training Loss: 0.47953 \nEpoch: 1349  | Training Loss: 0.40317 \nEpoch: 1349  | Training Loss: 0.35784 \nEpoch: 1349  | Training Loss: 0.24839 \nEpoch: 1349  | Validation balanced accuracy : 0.50000 \nEpoch: 1350  | Training Loss: 0.41788 \nEpoch: 1350  | Training Loss: 0.47930 \nEpoch: 1350  | Training Loss: 0.40302 \nEpoch: 1350  | Training Loss: 0.35760 \nEpoch: 1350  | Training Loss: 0.24844 \nEpoch: 1350  | Validation balanced accuracy : 0.50000 \nEpoch: 1351  | Training Loss: 0.41763 \nEpoch: 1351  | Training Loss: 0.47906 \nEpoch: 1351  | Training Loss: 0.40286 \nEpoch: 1351  | Training Loss: 0.35736 \nEpoch: 1351  | Training Loss: 0.24849 \nEpoch: 1351  | Validation balanced accuracy : 0.50000 \nEpoch: 1352  | Training Loss: 0.41738 \nEpoch: 1352  | Training Loss: 0.47883 \nEpoch: 1352  | Training Loss: 0.40271 \nEpoch: 1352  | Training Loss: 0.35712 \nEpoch: 1352  | Training Loss: 0.24855 \nEpoch: 1352  | Validation balanced accuracy : 0.50000 \nEpoch: 1353  | Training Loss: 0.41713 \nEpoch: 1353  | Training Loss: 0.47859 \nEpoch: 1353  | Training Loss: 0.40255 \nEpoch: 1353  | Training Loss: 0.35689 \nEpoch: 1353  | Training Loss: 0.24860 \nEpoch: 1353  | Validation balanced accuracy : 0.50000 \nEpoch: 1354  | Training Loss: 0.41688 \nEpoch: 1354  | Training Loss: 0.47836 \nEpoch: 1354  | Training Loss: 0.40240 \nEpoch: 1354  | Training Loss: 0.35665 \nEpoch: 1354  | Training Loss: 0.24865 \nEpoch: 1354  | Validation balanced accuracy : 0.50000 \nEpoch: 1355  | Training Loss: 0.41663 \nEpoch: 1355  | Training Loss: 0.47813 \nEpoch: 1355  | Training Loss: 0.40224 \nEpoch: 1355  | Training Loss: 0.35641 \nEpoch: 1355  | Training Loss: 0.24870 \nEpoch: 1355  | Validation balanced accuracy : 0.50000 \nEpoch: 1356  | Training Loss: 0.41638 \nEpoch: 1356  | Training Loss: 0.47789 \nEpoch: 1356  | Training Loss: 0.40209 \nEpoch: 1356  | Training Loss: 0.35617 \nEpoch: 1356  | Training Loss: 0.24875 \nEpoch: 1356  | Validation balanced accuracy : 0.50000 \nEpoch: 1357  | Training Loss: 0.41613 \nEpoch: 1357  | Training Loss: 0.47766 \nEpoch: 1357  | Training Loss: 0.40194 \nEpoch: 1357  | Training Loss: 0.35594 \nEpoch: 1357  | Training Loss: 0.24881 \nEpoch: 1357  | Validation balanced accuracy : 0.50000 \nEpoch: 1358  | Training Loss: 0.41589 \nEpoch: 1358  | Training Loss: 0.47743 \nEpoch: 1358  | Training Loss: 0.40178 \nEpoch: 1358  | Training Loss: 0.35570 \nEpoch: 1358  | Training Loss: 0.24886 \nEpoch: 1358  | Validation balanced accuracy : 0.50000 \nEpoch: 1359  | Training Loss: 0.41564 \nEpoch: 1359  | Training Loss: 0.47720 \nEpoch: 1359  | Training Loss: 0.40163 \nEpoch: 1359  | Training Loss: 0.35547 \nEpoch: 1359  | Training Loss: 0.24891 \nEpoch: 1359  | Validation balanced accuracy : 0.50000 \nEpoch: 1360  | Training Loss: 0.41539 \nEpoch: 1360  | Training Loss: 0.47697 \nEpoch: 1360  | Training Loss: 0.40148 \nEpoch: 1360  | Training Loss: 0.35523 \nEpoch: 1360  | Training Loss: 0.24896 \nEpoch: 1360  | Validation balanced accuracy : 0.50000 \nEpoch: 1361  | Training Loss: 0.41515 \nEpoch: 1361  | Training Loss: 0.47674 \nEpoch: 1361  | Training Loss: 0.40132 \nEpoch: 1361  | Training Loss: 0.35500 \nEpoch: 1361  | Training Loss: 0.24901 \nEpoch: 1361  | Validation balanced accuracy : 0.50000 \nEpoch: 1362  | Training Loss: 0.41490 \nEpoch: 1362  | Training Loss: 0.47651 \nEpoch: 1362  | Training Loss: 0.40117 \nEpoch: 1362  | Training Loss: 0.35476 \nEpoch: 1362  | Training Loss: 0.24906 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1362  | Validation balanced accuracy : 0.50000 \nEpoch: 1363  | Training Loss: 0.41465 \nEpoch: 1363  | Training Loss: 0.47628 \nEpoch: 1363  | Training Loss: 0.40102 \nEpoch: 1363  | Training Loss: 0.35453 \nEpoch: 1363  | Training Loss: 0.24911 \nEpoch: 1363  | Validation balanced accuracy : 0.50000 \nEpoch: 1364  | Training Loss: 0.41441 \nEpoch: 1364  | Training Loss: 0.47605 \nEpoch: 1364  | Training Loss: 0.40086 \nEpoch: 1364  | Training Loss: 0.35429 \nEpoch: 1364  | Training Loss: 0.24916 \nEpoch: 1364  | Validation balanced accuracy : 0.50000 \nEpoch: 1365  | Training Loss: 0.41416 \nEpoch: 1365  | Training Loss: 0.47582 \nEpoch: 1365  | Training Loss: 0.40071 \nEpoch: 1365  | Training Loss: 0.35406 \nEpoch: 1365  | Training Loss: 0.24921 \nEpoch: 1365  | Validation balanced accuracy : 0.50000 \nEpoch: 1366  | Training Loss: 0.41392 \nEpoch: 1366  | Training Loss: 0.47559 \nEpoch: 1366  | Training Loss: 0.40056 \nEpoch: 1366  | Training Loss: 0.35383 \nEpoch: 1366  | Training Loss: 0.24925 \nEpoch: 1366  | Validation balanced accuracy : 0.50000 \nEpoch: 1367  | Training Loss: 0.41368 \nEpoch: 1367  | Training Loss: 0.47536 \nEpoch: 1367  | Training Loss: 0.40040 \nEpoch: 1367  | Training Loss: 0.35359 \nEpoch: 1367  | Training Loss: 0.24930 \nEpoch: 1367  | Validation balanced accuracy : 0.50000 \nEpoch: 1368  | Training Loss: 0.41343 \nEpoch: 1368  | Training Loss: 0.47513 \nEpoch: 1368  | Training Loss: 0.40025 \nEpoch: 1368  | Training Loss: 0.35336 \nEpoch: 1368  | Training Loss: 0.24935 \nEpoch: 1368  | Validation balanced accuracy : 0.50000 \nEpoch: 1369  | Training Loss: 0.41319 \nEpoch: 1369  | Training Loss: 0.47491 \nEpoch: 1369  | Training Loss: 0.40010 \nEpoch: 1369  | Training Loss: 0.35313 \nEpoch: 1369  | Training Loss: 0.24940 \nEpoch: 1369  | Validation balanced accuracy : 0.50000 \nEpoch: 1370  | Training Loss: 0.41294 \nEpoch: 1370  | Training Loss: 0.47468 \nEpoch: 1370  | Training Loss: 0.39995 \nEpoch: 1370  | Training Loss: 0.35290 \nEpoch: 1370  | Training Loss: 0.24945 \nEpoch: 1370  | Validation balanced accuracy : 0.50000 \nEpoch: 1371  | Training Loss: 0.41270 \nEpoch: 1371  | Training Loss: 0.47446 \nEpoch: 1371  | Training Loss: 0.39979 \nEpoch: 1371  | Training Loss: 0.35266 \nEpoch: 1371  | Training Loss: 0.24949 \nEpoch: 1371  | Validation balanced accuracy : 0.50000 \nEpoch: 1372  | Training Loss: 0.41246 \nEpoch: 1372  | Training Loss: 0.47423 \nEpoch: 1372  | Training Loss: 0.39964 \nEpoch: 1372  | Training Loss: 0.35243 \nEpoch: 1372  | Training Loss: 0.24954 \nEpoch: 1372  | Validation balanced accuracy : 0.50000 \nEpoch: 1373  | Training Loss: 0.41222 \nEpoch: 1373  | Training Loss: 0.47401 \nEpoch: 1373  | Training Loss: 0.39949 \nEpoch: 1373  | Training Loss: 0.35220 \nEpoch: 1373  | Training Loss: 0.24959 \nEpoch: 1373  | Validation balanced accuracy : 0.50000 \nEpoch: 1374  | Training Loss: 0.41198 \nEpoch: 1374  | Training Loss: 0.47378 \nEpoch: 1374  | Training Loss: 0.39934 \nEpoch: 1374  | Training Loss: 0.35197 \nEpoch: 1374  | Training Loss: 0.24963 \nEpoch: 1374  | Validation balanced accuracy : 0.50000 \nEpoch: 1375  | Training Loss: 0.41173 \nEpoch: 1375  | Training Loss: 0.47356 \nEpoch: 1375  | Training Loss: 0.39919 \nEpoch: 1375  | Training Loss: 0.35174 \nEpoch: 1375  | Training Loss: 0.24968 \nEpoch: 1375  | Validation balanced accuracy : 0.50000 \nEpoch: 1376  | Training Loss: 0.41149 \nEpoch: 1376  | Training Loss: 0.47333 \nEpoch: 1376  | Training Loss: 0.39903 \nEpoch: 1376  | Training Loss: 0.35151 \nEpoch: 1376  | Training Loss: 0.24972 \nEpoch: 1376  | Validation balanced accuracy : 0.50000 \nEpoch: 1377  | Training Loss: 0.41125 \nEpoch: 1377  | Training Loss: 0.47311 \nEpoch: 1377  | Training Loss: 0.39888 \nEpoch: 1377  | Training Loss: 0.35128 \nEpoch: 1377  | Training Loss: 0.24977 \nEpoch: 1377  | Validation balanced accuracy : 0.50000 \nEpoch: 1378  | Training Loss: 0.41101 \nEpoch: 1378  | Training Loss: 0.47289 \nEpoch: 1378  | Training Loss: 0.39873 \nEpoch: 1378  | Training Loss: 0.35105 \nEpoch: 1378  | Training Loss: 0.24981 \nEpoch: 1378  | Validation balanced accuracy : 0.50000 \nEpoch: 1379  | Training Loss: 0.41077 \nEpoch: 1379  | Training Loss: 0.47266 \nEpoch: 1379  | Training Loss: 0.39858 \nEpoch: 1379  | Training Loss: 0.35082 \nEpoch: 1379  | Training Loss: 0.24986 \nEpoch: 1379  | Validation balanced accuracy : 0.50000 \nEpoch: 1380  | Training Loss: 0.41053 \nEpoch: 1380  | Training Loss: 0.47244 \nEpoch: 1380  | Training Loss: 0.39843 \nEpoch: 1380  | Training Loss: 0.35059 \nEpoch: 1380  | Training Loss: 0.24990 \nEpoch: 1380  | Validation balanced accuracy : 0.50000 \nEpoch: 1381  | Training Loss: 0.41029 \nEpoch: 1381  | Training Loss: 0.47222 \nEpoch: 1381  | Training Loss: 0.39828 \nEpoch: 1381  | Training Loss: 0.35036 \nEpoch: 1381  | Training Loss: 0.24995 \nEpoch: 1381  | Validation balanced accuracy : 0.50000 \nEpoch: 1382  | Training Loss: 0.41006 \nEpoch: 1382  | Training Loss: 0.47200 \nEpoch: 1382  | Training Loss: 0.39813 \nEpoch: 1382  | Training Loss: 0.35014 \nEpoch: 1382  | Training Loss: 0.24999 \nEpoch: 1382  | Validation balanced accuracy : 0.50000 \nEpoch: 1383  | Training Loss: 0.40982 \nEpoch: 1383  | Training Loss: 0.47178 \nEpoch: 1383  | Training Loss: 0.39798 \nEpoch: 1383  | Training Loss: 0.34991 \nEpoch: 1383  | Training Loss: 0.25004 \nEpoch: 1383  | Validation balanced accuracy : 0.50000 \nEpoch: 1384  | Training Loss: 0.40958 \nEpoch: 1384  | Training Loss: 0.47156 \nEpoch: 1384  | Training Loss: 0.39783 \nEpoch: 1384  | Training Loss: 0.34968 \nEpoch: 1384  | Training Loss: 0.25008 \nEpoch: 1384  | Validation balanced accuracy : 0.50000 \nEpoch: 1385  | Training Loss: 0.40934 \nEpoch: 1385  | Training Loss: 0.47134 \nEpoch: 1385  | Training Loss: 0.39767 \nEpoch: 1385  | Training Loss: 0.34945 \nEpoch: 1385  | Training Loss: 0.25012 \nEpoch: 1385  | Validation balanced accuracy : 0.50000 \nEpoch: 1386  | Training Loss: 0.40910 \nEpoch: 1386  | Training Loss: 0.47112 \nEpoch: 1386  | Training Loss: 0.39752 \nEpoch: 1386  | Training Loss: 0.34923 \nEpoch: 1386  | Training Loss: 0.25016 \nEpoch: 1386  | Validation balanced accuracy : 0.50000 \nEpoch: 1387  | Training Loss: 0.40887 \nEpoch: 1387  | Training Loss: 0.47090 \nEpoch: 1387  | Training Loss: 0.39737 \nEpoch: 1387  | Training Loss: 0.34900 \nEpoch: 1387  | Training Loss: 0.25021 \nEpoch: 1387  | Validation balanced accuracy : 0.50000 \nEpoch: 1388  | Training Loss: 0.40863 \nEpoch: 1388  | Training Loss: 0.47068 \nEpoch: 1388  | Training Loss: 0.39722 \nEpoch: 1388  | Training Loss: 0.34877 \nEpoch: 1388  | Training Loss: 0.25025 \nEpoch: 1388  | Validation balanced accuracy : 0.50000 \nEpoch: 1389  | Training Loss: 0.40840 \nEpoch: 1389  | Training Loss: 0.47047 \nEpoch: 1389  | Training Loss: 0.39707 \nEpoch: 1389  | Training Loss: 0.34855 \nEpoch: 1389  | Training Loss: 0.25029 \nEpoch: 1389  | Validation balanced accuracy : 0.50000 \nEpoch: 1390  | Training Loss: 0.40816 \nEpoch: 1390  | Training Loss: 0.47025 \nEpoch: 1390  | Training Loss: 0.39692 \nEpoch: 1390  | Training Loss: 0.34832 \nEpoch: 1390  | Training Loss: 0.25033 \nEpoch: 1390  | Validation balanced accuracy : 0.50000 \nEpoch: 1391  | Training Loss: 0.40792 \nEpoch: 1391  | Training Loss: 0.47003 \nEpoch: 1391  | Training Loss: 0.39677 \nEpoch: 1391  | Training Loss: 0.34810 \nEpoch: 1391  | Training Loss: 0.25037 \nEpoch: 1391  | Validation balanced accuracy : 0.50000 \nEpoch: 1392  | Training Loss: 0.40769 \nEpoch: 1392  | Training Loss: 0.46981 \nEpoch: 1392  | Training Loss: 0.39662 \nEpoch: 1392  | Training Loss: 0.34787 \nEpoch: 1392  | Training Loss: 0.25042 \nEpoch: 1392  | Validation balanced accuracy : 0.50000 \nEpoch: 1393  | Training Loss: 0.40745 \nEpoch: 1393  | Training Loss: 0.46960 \nEpoch: 1393  | Training Loss: 0.39647 \nEpoch: 1393  | Training Loss: 0.34765 \nEpoch: 1393  | Training Loss: 0.25046 \nEpoch: 1393  | Validation balanced accuracy : 0.50000 \nEpoch: 1394  | Training Loss: 0.40722 \nEpoch: 1394  | Training Loss: 0.46938 \nEpoch: 1394  | Training Loss: 0.39632 \nEpoch: 1394  | Training Loss: 0.34742 \nEpoch: 1394  | Training Loss: 0.25050 \nEpoch: 1394  | Validation balanced accuracy : 0.50000 \nEpoch: 1395  | Training Loss: 0.40699 \nEpoch: 1395  | Training Loss: 0.46917 \nEpoch: 1395  | Training Loss: 0.39617 \nEpoch: 1395  | Training Loss: 0.34720 \nEpoch: 1395  | Training Loss: 0.25054 \nEpoch: 1395  | Validation balanced accuracy : 0.50000 \nEpoch: 1396  | Training Loss: 0.40675 \nEpoch: 1396  | Training Loss: 0.46895 \nEpoch: 1396  | Training Loss: 0.39602 \nEpoch: 1396  | Training Loss: 0.34697 \nEpoch: 1396  | Training Loss: 0.25058 \nEpoch: 1396  | Validation balanced accuracy : 0.50000 \nEpoch: 1397  | Training Loss: 0.40652 \nEpoch: 1397  | Training Loss: 0.46874 \nEpoch: 1397  | Training Loss: 0.39587 \nEpoch: 1397  | Training Loss: 0.34675 \nEpoch: 1397  | Training Loss: 0.25062 \nEpoch: 1397  | Validation balanced accuracy : 0.50000 \nEpoch: 1398  | Training Loss: 0.40629 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1398  | Training Loss: 0.46853 \nEpoch: 1398  | Training Loss: 0.39572 \nEpoch: 1398  | Training Loss: 0.34653 \nEpoch: 1398  | Training Loss: 0.25065 \nEpoch: 1398  | Validation balanced accuracy : 0.50000 \nEpoch: 1399  | Training Loss: 0.40605 \nEpoch: 1399  | Training Loss: 0.46831 \nEpoch: 1399  | Training Loss: 0.39558 \nEpoch: 1399  | Training Loss: 0.34631 \nEpoch: 1399  | Training Loss: 0.25069 \nEpoch: 1399  | Validation balanced accuracy : 0.50000 \nEpoch: 1400  | Training Loss: 0.40582 \nEpoch: 1400  | Training Loss: 0.46810 \nEpoch: 1400  | Training Loss: 0.39543 \nEpoch: 1400  | Training Loss: 0.34608 \nEpoch: 1400  | Training Loss: 0.25073 \nEpoch: 1400  | Validation balanced accuracy : 0.50000 \nEpoch: 1401  | Training Loss: 0.40559 \nEpoch: 1401  | Training Loss: 0.46789 \nEpoch: 1401  | Training Loss: 0.39528 \nEpoch: 1401  | Training Loss: 0.34586 \nEpoch: 1401  | Training Loss: 0.25077 \nEpoch: 1401  | Validation balanced accuracy : 0.50000 \nEpoch: 1402  | Training Loss: 0.40536 \nEpoch: 1402  | Training Loss: 0.46767 \nEpoch: 1402  | Training Loss: 0.39513 \nEpoch: 1402  | Training Loss: 0.34564 \nEpoch: 1402  | Training Loss: 0.25081 \nEpoch: 1402  | Validation balanced accuracy : 0.50000 \nEpoch: 1403  | Training Loss: 0.40513 \nEpoch: 1403  | Training Loss: 0.46746 \nEpoch: 1403  | Training Loss: 0.39498 \nEpoch: 1403  | Training Loss: 0.34542 \nEpoch: 1403  | Training Loss: 0.25085 \nEpoch: 1403  | Validation balanced accuracy : 0.50000 \nEpoch: 1404  | Training Loss: 0.40490 \nEpoch: 1404  | Training Loss: 0.46725 \nEpoch: 1404  | Training Loss: 0.39483 \nEpoch: 1404  | Training Loss: 0.34520 \nEpoch: 1404  | Training Loss: 0.25088 \nEpoch: 1404  | Validation balanced accuracy : 0.50000 \nEpoch: 1405  | Training Loss: 0.40467 \nEpoch: 1405  | Training Loss: 0.46704 \nEpoch: 1405  | Training Loss: 0.39468 \nEpoch: 1405  | Training Loss: 0.34498 \nEpoch: 1405  | Training Loss: 0.25092 \nEpoch: 1405  | Validation balanced accuracy : 0.50000 \nEpoch: 1406  | Training Loss: 0.40444 \nEpoch: 1406  | Training Loss: 0.46683 \nEpoch: 1406  | Training Loss: 0.39453 \nEpoch: 1406  | Training Loss: 0.34475 \nEpoch: 1406  | Training Loss: 0.25096 \nEpoch: 1406  | Validation balanced accuracy : 0.50000 \nEpoch: 1407  | Training Loss: 0.40421 \nEpoch: 1407  | Training Loss: 0.46662 \nEpoch: 1407  | Training Loss: 0.39439 \nEpoch: 1407  | Training Loss: 0.34453 \nEpoch: 1407  | Training Loss: 0.25099 \nEpoch: 1407  | Validation balanced accuracy : 0.50000 \nEpoch: 1408  | Training Loss: 0.40398 \nEpoch: 1408  | Training Loss: 0.46641 \nEpoch: 1408  | Training Loss: 0.39424 \nEpoch: 1408  | Training Loss: 0.34431 \nEpoch: 1408  | Training Loss: 0.25103 \nEpoch: 1408  | Validation balanced accuracy : 0.50000 \nEpoch: 1409  | Training Loss: 0.40375 \nEpoch: 1409  | Training Loss: 0.46620 \nEpoch: 1409  | Training Loss: 0.39409 \nEpoch: 1409  | Training Loss: 0.34409 \nEpoch: 1409  | Training Loss: 0.25107 \nEpoch: 1409  | Validation balanced accuracy : 0.50000 \nEpoch: 1410  | Training Loss: 0.40352 \nEpoch: 1410  | Training Loss: 0.46599 \nEpoch: 1410  | Training Loss: 0.39394 \nEpoch: 1410  | Training Loss: 0.34388 \nEpoch: 1410  | Training Loss: 0.25110 \nEpoch: 1410  | Validation balanced accuracy : 0.50000 \nEpoch: 1411  | Training Loss: 0.40329 \nEpoch: 1411  | Training Loss: 0.46578 \nEpoch: 1411  | Training Loss: 0.39379 \nEpoch: 1411  | Training Loss: 0.34366 \nEpoch: 1411  | Training Loss: 0.25114 \nEpoch: 1411  | Validation balanced accuracy : 0.50000 \nEpoch: 1412  | Training Loss: 0.40306 \nEpoch: 1412  | Training Loss: 0.46558 \nEpoch: 1412  | Training Loss: 0.39365 \nEpoch: 1412  | Training Loss: 0.34344 \nEpoch: 1412  | Training Loss: 0.25117 \nEpoch: 1412  | Validation balanced accuracy : 0.50000 \nEpoch: 1413  | Training Loss: 0.40284 \nEpoch: 1413  | Training Loss: 0.46537 \nEpoch: 1413  | Training Loss: 0.39350 \nEpoch: 1413  | Training Loss: 0.34322 \nEpoch: 1413  | Training Loss: 0.25121 \nEpoch: 1413  | Validation balanced accuracy : 0.50000 \nEpoch: 1414  | Training Loss: 0.40261 \nEpoch: 1414  | Training Loss: 0.46516 \nEpoch: 1414  | Training Loss: 0.39335 \nEpoch: 1414  | Training Loss: 0.34300 \nEpoch: 1414  | Training Loss: 0.25124 \nEpoch: 1414  | Validation balanced accuracy : 0.50000 \nEpoch: 1415  | Training Loss: 0.40238 \nEpoch: 1415  | Training Loss: 0.46496 \nEpoch: 1415  | Training Loss: 0.39320 \nEpoch: 1415  | Training Loss: 0.34278 \nEpoch: 1415  | Training Loss: 0.25128 \nEpoch: 1415  | Validation balanced accuracy : 0.50000 \nEpoch: 1416  | Training Loss: 0.40216 \nEpoch: 1416  | Training Loss: 0.46475 \nEpoch: 1416  | Training Loss: 0.39306 \nEpoch: 1416  | Training Loss: 0.34257 \nEpoch: 1416  | Training Loss: 0.25131 \nEpoch: 1416  | Validation balanced accuracy : 0.50000 \nEpoch: 1417  | Training Loss: 0.40193 \nEpoch: 1417  | Training Loss: 0.46454 \nEpoch: 1417  | Training Loss: 0.39291 \nEpoch: 1417  | Training Loss: 0.34235 \nEpoch: 1417  | Training Loss: 0.25134 \nEpoch: 1417  | Validation balanced accuracy : 0.50000 \nEpoch: 1418  | Training Loss: 0.40171 \nEpoch: 1418  | Training Loss: 0.46434 \nEpoch: 1418  | Training Loss: 0.39276 \nEpoch: 1418  | Training Loss: 0.34213 \nEpoch: 1418  | Training Loss: 0.25138 \nEpoch: 1418  | Validation balanced accuracy : 0.50000 \nEpoch: 1419  | Training Loss: 0.40148 \nEpoch: 1419  | Training Loss: 0.46413 \nEpoch: 1419  | Training Loss: 0.39261 \nEpoch: 1419  | Training Loss: 0.34192 \nEpoch: 1419  | Training Loss: 0.25141 \nEpoch: 1419  | Validation balanced accuracy : 0.50000 \nEpoch: 1420  | Training Loss: 0.40126 \nEpoch: 1420  | Training Loss: 0.46393 \nEpoch: 1420  | Training Loss: 0.39247 \nEpoch: 1420  | Training Loss: 0.34170 \nEpoch: 1420  | Training Loss: 0.25144 \nEpoch: 1420  | Validation balanced accuracy : 0.50000 \nEpoch: 1421  | Training Loss: 0.40103 \nEpoch: 1421  | Training Loss: 0.46373 \nEpoch: 1421  | Training Loss: 0.39232 \nEpoch: 1421  | Training Loss: 0.34148 \nEpoch: 1421  | Training Loss: 0.25148 \nEpoch: 1421  | Validation balanced accuracy : 0.50000 \nEpoch: 1422  | Training Loss: 0.40081 \nEpoch: 1422  | Training Loss: 0.46352 \nEpoch: 1422  | Training Loss: 0.39217 \nEpoch: 1422  | Training Loss: 0.34127 \nEpoch: 1422  | Training Loss: 0.25151 \nEpoch: 1422  | Validation balanced accuracy : 0.50000 \nEpoch: 1423  | Training Loss: 0.40058 \nEpoch: 1423  | Training Loss: 0.46332 \nEpoch: 1423  | Training Loss: 0.39203 \nEpoch: 1423  | Training Loss: 0.34105 \nEpoch: 1423  | Training Loss: 0.25154 \nEpoch: 1423  | Validation balanced accuracy : 0.50000 \nEpoch: 1424  | Training Loss: 0.40036 \nEpoch: 1424  | Training Loss: 0.46312 \nEpoch: 1424  | Training Loss: 0.39188 \nEpoch: 1424  | Training Loss: 0.34084 \nEpoch: 1424  | Training Loss: 0.25157 \nEpoch: 1424  | Validation balanced accuracy : 0.50000 \nEpoch: 1425  | Training Loss: 0.40014 \nEpoch: 1425  | Training Loss: 0.46291 \nEpoch: 1425  | Training Loss: 0.39174 \nEpoch: 1425  | Training Loss: 0.34063 \nEpoch: 1425  | Training Loss: 0.25160 \nEpoch: 1425  | Validation balanced accuracy : 0.50000 \nEpoch: 1426  | Training Loss: 0.39991 \nEpoch: 1426  | Training Loss: 0.46271 \nEpoch: 1426  | Training Loss: 0.39159 \nEpoch: 1426  | Training Loss: 0.34041 \nEpoch: 1426  | Training Loss: 0.25164 \nEpoch: 1426  | Validation balanced accuracy : 0.50000 \nEpoch: 1427  | Training Loss: 0.39969 \nEpoch: 1427  | Training Loss: 0.46251 \nEpoch: 1427  | Training Loss: 0.39144 \nEpoch: 1427  | Training Loss: 0.34020 \nEpoch: 1427  | Training Loss: 0.25167 \nEpoch: 1427  | Validation balanced accuracy : 0.50000 \nEpoch: 1428  | Training Loss: 0.39947 \nEpoch: 1428  | Training Loss: 0.46231 \nEpoch: 1428  | Training Loss: 0.39130 \nEpoch: 1428  | Training Loss: 0.33999 \nEpoch: 1428  | Training Loss: 0.25170 \nEpoch: 1428  | Validation balanced accuracy : 0.50000 \nEpoch: 1429  | Training Loss: 0.39925 \nEpoch: 1429  | Training Loss: 0.46211 \nEpoch: 1429  | Training Loss: 0.39115 \nEpoch: 1429  | Training Loss: 0.33977 \nEpoch: 1429  | Training Loss: 0.25173 \nEpoch: 1429  | Validation balanced accuracy : 0.50000 \nEpoch: 1430  | Training Loss: 0.39903 \nEpoch: 1430  | Training Loss: 0.46191 \nEpoch: 1430  | Training Loss: 0.39101 \nEpoch: 1430  | Training Loss: 0.33956 \nEpoch: 1430  | Training Loss: 0.25176 \nEpoch: 1430  | Validation balanced accuracy : 0.50000 \nEpoch: 1431  | Training Loss: 0.39881 \nEpoch: 1431  | Training Loss: 0.46171 \nEpoch: 1431  | Training Loss: 0.39086 \nEpoch: 1431  | Training Loss: 0.33935 \nEpoch: 1431  | Training Loss: 0.25179 \nEpoch: 1431  | Validation balanced accuracy : 0.50000 \nEpoch: 1432  | Training Loss: 0.39859 \nEpoch: 1432  | Training Loss: 0.46151 \nEpoch: 1432  | Training Loss: 0.39072 \nEpoch: 1432  | Training Loss: 0.33914 \nEpoch: 1432  | Training Loss: 0.25182 \nEpoch: 1432  | Validation balanced accuracy : 0.50000 \nEpoch: 1433  | Training Loss: 0.39837 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1433  | Training Loss: 0.46131 \nEpoch: 1433  | Training Loss: 0.39057 \nEpoch: 1433  | Training Loss: 0.33893 \nEpoch: 1433  | Training Loss: 0.25185 \nEpoch: 1433  | Validation balanced accuracy : 0.50000 \nEpoch: 1434  | Training Loss: 0.39815 \nEpoch: 1434  | Training Loss: 0.46111 \nEpoch: 1434  | Training Loss: 0.39043 \nEpoch: 1434  | Training Loss: 0.33872 \nEpoch: 1434  | Training Loss: 0.25188 \nEpoch: 1434  | Validation balanced accuracy : 0.50000 \nEpoch: 1435  | Training Loss: 0.39793 \nEpoch: 1435  | Training Loss: 0.46092 \nEpoch: 1435  | Training Loss: 0.39028 \nEpoch: 1435  | Training Loss: 0.33851 \nEpoch: 1435  | Training Loss: 0.25190 \nEpoch: 1435  | Validation balanced accuracy : 0.50000 \nEpoch: 1436  | Training Loss: 0.39771 \nEpoch: 1436  | Training Loss: 0.46072 \nEpoch: 1436  | Training Loss: 0.39014 \nEpoch: 1436  | Training Loss: 0.33830 \nEpoch: 1436  | Training Loss: 0.25193 \nEpoch: 1436  | Validation balanced accuracy : 0.55000 \nEpoch: 1437  | Training Loss: 0.39749 \nEpoch: 1437  | Training Loss: 0.46052 \nEpoch: 1437  | Training Loss: 0.38999 \nEpoch: 1437  | Training Loss: 0.33809 \nEpoch: 1437  | Training Loss: 0.25196 \nEpoch: 1437  | Validation balanced accuracy : 0.55000 \nEpoch: 1438  | Training Loss: 0.39727 \nEpoch: 1438  | Training Loss: 0.46033 \nEpoch: 1438  | Training Loss: 0.38985 \nEpoch: 1438  | Training Loss: 0.33788 \nEpoch: 1438  | Training Loss: 0.25199 \nEpoch: 1438  | Validation balanced accuracy : 0.55000 \nEpoch: 1439  | Training Loss: 0.39706 \nEpoch: 1439  | Training Loss: 0.46013 \nEpoch: 1439  | Training Loss: 0.38970 \nEpoch: 1439  | Training Loss: 0.33767 \nEpoch: 1439  | Training Loss: 0.25202 \nEpoch: 1439  | Validation balanced accuracy : 0.55000 \nEpoch: 1440  | Training Loss: 0.39684 \nEpoch: 1440  | Training Loss: 0.45994 \nEpoch: 1440  | Training Loss: 0.38956 \nEpoch: 1440  | Training Loss: 0.33746 \nEpoch: 1440  | Training Loss: 0.25205 \nEpoch: 1440  | Validation balanced accuracy : 0.55000 \nEpoch: 1441  | Training Loss: 0.39662 \nEpoch: 1441  | Training Loss: 0.45975 \nEpoch: 1441  | Training Loss: 0.38942 \nEpoch: 1441  | Training Loss: 0.33725 \nEpoch: 1441  | Training Loss: 0.25208 \nEpoch: 1441  | Validation balanced accuracy : 0.55000 \nEpoch: 1442  | Training Loss: 0.39641 \nEpoch: 1442  | Training Loss: 0.45955 \nEpoch: 1442  | Training Loss: 0.38927 \nEpoch: 1442  | Training Loss: 0.33705 \nEpoch: 1442  | Training Loss: 0.25210 \nEpoch: 1442  | Validation balanced accuracy : 0.55000 \nEpoch: 1443  | Training Loss: 0.39619 \nEpoch: 1443  | Training Loss: 0.45936 \nEpoch: 1443  | Training Loss: 0.38913 \nEpoch: 1443  | Training Loss: 0.33684 \nEpoch: 1443  | Training Loss: 0.25213 \nEpoch: 1443  | Validation balanced accuracy : 0.55000 \nEpoch: 1444  | Training Loss: 0.39598 \nEpoch: 1444  | Training Loss: 0.45917 \nEpoch: 1444  | Training Loss: 0.38899 \nEpoch: 1444  | Training Loss: 0.33663 \nEpoch: 1444  | Training Loss: 0.25216 \nEpoch: 1444  | Validation balanced accuracy : 0.60000 \nEpoch: 1445  | Training Loss: 0.39576 \nEpoch: 1445  | Training Loss: 0.45898 \nEpoch: 1445  | Training Loss: 0.38884 \nEpoch: 1445  | Training Loss: 0.33643 \nEpoch: 1445  | Training Loss: 0.25218 \nEpoch: 1445  | Validation balanced accuracy : 0.60000 \nEpoch: 1446  | Training Loss: 0.39555 \nEpoch: 1446  | Training Loss: 0.45879 \nEpoch: 1446  | Training Loss: 0.38870 \nEpoch: 1446  | Training Loss: 0.33622 \nEpoch: 1446  | Training Loss: 0.25221 \nEpoch: 1446  | Validation balanced accuracy : 0.60000 \nEpoch: 1447  | Training Loss: 0.39534 \nEpoch: 1447  | Training Loss: 0.45860 \nEpoch: 1447  | Training Loss: 0.38856 \nEpoch: 1447  | Training Loss: 0.33601 \nEpoch: 1447  | Training Loss: 0.25224 \nEpoch: 1447  | Validation balanced accuracy : 0.60000 \nEpoch: 1448  | Training Loss: 0.39513 \nEpoch: 1448  | Training Loss: 0.45842 \nEpoch: 1448  | Training Loss: 0.38841 \nEpoch: 1448  | Training Loss: 0.33581 \nEpoch: 1448  | Training Loss: 0.25226 \nEpoch: 1448  | Validation balanced accuracy : 0.60000 \nEpoch: 1449  | Training Loss: 0.39491 \nEpoch: 1449  | Training Loss: 0.45823 \nEpoch: 1449  | Training Loss: 0.38827 \nEpoch: 1449  | Training Loss: 0.33561 \nEpoch: 1449  | Training Loss: 0.25229 \nEpoch: 1449  | Validation balanced accuracy : 0.60000 \nEpoch: 1450  | Training Loss: 0.39470 \nEpoch: 1450  | Training Loss: 0.45804 \nEpoch: 1450  | Training Loss: 0.38813 \nEpoch: 1450  | Training Loss: 0.33540 \nEpoch: 1450  | Training Loss: 0.25232 \nEpoch: 1450  | Validation balanced accuracy : 0.60000 \nEpoch: 1451  | Training Loss: 0.39449 \nEpoch: 1451  | Training Loss: 0.45786 \nEpoch: 1451  | Training Loss: 0.38799 \nEpoch: 1451  | Training Loss: 0.33520 \nEpoch: 1451  | Training Loss: 0.25234 \nEpoch: 1451  | Validation balanced accuracy : 0.60000 \nEpoch: 1452  | Training Loss: 0.39428 \nEpoch: 1452  | Training Loss: 0.45767 \nEpoch: 1452  | Training Loss: 0.38785 \nEpoch: 1452  | Training Loss: 0.33500 \nEpoch: 1452  | Training Loss: 0.25237 \nEpoch: 1452  | Validation balanced accuracy : 0.65000 \nEpoch: 1453  | Training Loss: 0.39407 \nEpoch: 1453  | Training Loss: 0.45749 \nEpoch: 1453  | Training Loss: 0.38770 \nEpoch: 1453  | Training Loss: 0.33480 \nEpoch: 1453  | Training Loss: 0.25239 \nEpoch: 1453  | Validation balanced accuracy : 0.65000 \nEpoch: 1454  | Training Loss: 0.39386 \nEpoch: 1454  | Training Loss: 0.45730 \nEpoch: 1454  | Training Loss: 0.38756 \nEpoch: 1454  | Training Loss: 0.33460 \nEpoch: 1454  | Training Loss: 0.25242 \nEpoch: 1454  | Validation balanced accuracy : 0.65000 \nEpoch: 1455  | Training Loss: 0.39365 \nEpoch: 1455  | Training Loss: 0.45712 \nEpoch: 1455  | Training Loss: 0.38742 \nEpoch: 1455  | Training Loss: 0.33440 \nEpoch: 1455  | Training Loss: 0.25244 \nEpoch: 1455  | Validation balanced accuracy : 0.65000 \nEpoch: 1456  | Training Loss: 0.39344 \nEpoch: 1456  | Training Loss: 0.45694 \nEpoch: 1456  | Training Loss: 0.38728 \nEpoch: 1456  | Training Loss: 0.33421 \nEpoch: 1456  | Training Loss: 0.25247 \nEpoch: 1456  | Validation balanced accuracy : 0.65000 \nEpoch: 1457  | Training Loss: 0.39323 \nEpoch: 1457  | Training Loss: 0.45676 \nEpoch: 1457  | Training Loss: 0.38714 \nEpoch: 1457  | Training Loss: 0.33401 \nEpoch: 1457  | Training Loss: 0.25249 \nEpoch: 1457  | Validation balanced accuracy : 0.65000 \nEpoch: 1458  | Training Loss: 0.39302 \nEpoch: 1458  | Training Loss: 0.45658 \nEpoch: 1458  | Training Loss: 0.38700 \nEpoch: 1458  | Training Loss: 0.33381 \nEpoch: 1458  | Training Loss: 0.25251 \nEpoch: 1458  | Validation balanced accuracy : 0.65000 \nEpoch: 1459  | Training Loss: 0.39281 \nEpoch: 1459  | Training Loss: 0.45639 \nEpoch: 1459  | Training Loss: 0.38686 \nEpoch: 1459  | Training Loss: 0.33362 \nEpoch: 1459  | Training Loss: 0.25254 \nEpoch: 1459  | Validation balanced accuracy : 0.65000 \nEpoch: 1460  | Training Loss: 0.39261 \nEpoch: 1460  | Training Loss: 0.45621 \nEpoch: 1460  | Training Loss: 0.38672 \nEpoch: 1460  | Training Loss: 0.33343 \nEpoch: 1460  | Training Loss: 0.25256 \nEpoch: 1460  | Validation balanced accuracy : 0.65000 \nEpoch: 1461  | Training Loss: 0.39240 \nEpoch: 1461  | Training Loss: 0.45603 \nEpoch: 1461  | Training Loss: 0.38658 \nEpoch: 1461  | Training Loss: 0.33323 \nEpoch: 1461  | Training Loss: 0.25258 \nEpoch: 1461  | Validation balanced accuracy : 0.65000 \nEpoch: 1462  | Training Loss: 0.39219 \nEpoch: 1462  | Training Loss: 0.45585 \nEpoch: 1462  | Training Loss: 0.38644 \nEpoch: 1462  | Training Loss: 0.33304 \nEpoch: 1462  | Training Loss: 0.25260 \nEpoch: 1462  | Validation balanced accuracy : 0.65000 \nEpoch: 1463  | Training Loss: 0.39199 \nEpoch: 1463  | Training Loss: 0.45568 \nEpoch: 1463  | Training Loss: 0.38630 \nEpoch: 1463  | Training Loss: 0.33285 \nEpoch: 1463  | Training Loss: 0.25262 \nEpoch: 1463  | Validation balanced accuracy : 0.65000 \nEpoch: 1464  | Training Loss: 0.39179 \nEpoch: 1464  | Training Loss: 0.45550 \nEpoch: 1464  | Training Loss: 0.38616 \nEpoch: 1464  | Training Loss: 0.33266 \nEpoch: 1464  | Training Loss: 0.25264 \nEpoch: 1464  | Validation balanced accuracy : 0.65000 \nEpoch: 1465  | Training Loss: 0.39158 \nEpoch: 1465  | Training Loss: 0.45532 \nEpoch: 1465  | Training Loss: 0.38602 \nEpoch: 1465  | Training Loss: 0.33247 \nEpoch: 1465  | Training Loss: 0.25266 \nEpoch: 1465  | Validation balanced accuracy : 0.70000 \nEpoch: 1466  | Training Loss: 0.39138 \nEpoch: 1466  | Training Loss: 0.45514 \nEpoch: 1466  | Training Loss: 0.38588 \nEpoch: 1466  | Training Loss: 0.33228 \nEpoch: 1466  | Training Loss: 0.25268 \nEpoch: 1466  | Validation balanced accuracy : 0.70000 \nEpoch: 1467  | Training Loss: 0.39117 \nEpoch: 1467  | Training Loss: 0.45497 \nEpoch: 1467  | Training Loss: 0.38575 \nEpoch: 1467  | Training Loss: 0.33209 \nEpoch: 1467  | Training Loss: 0.25270 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1467  | Validation balanced accuracy : 0.70000 \nEpoch: 1468  | Training Loss: 0.39097 \nEpoch: 1468  | Training Loss: 0.45479 \nEpoch: 1468  | Training Loss: 0.38561 \nEpoch: 1468  | Training Loss: 0.33190 \nEpoch: 1468  | Training Loss: 0.25272 \nEpoch: 1468  | Validation balanced accuracy : 0.70000 \nEpoch: 1469  | Training Loss: 0.39077 \nEpoch: 1469  | Training Loss: 0.45461 \nEpoch: 1469  | Training Loss: 0.38547 \nEpoch: 1469  | Training Loss: 0.33171 \nEpoch: 1469  | Training Loss: 0.25274 \nEpoch: 1469  | Validation balanced accuracy : 0.70000 \nEpoch: 1470  | Training Loss: 0.39057 \nEpoch: 1470  | Training Loss: 0.45444 \nEpoch: 1470  | Training Loss: 0.38533 \nEpoch: 1470  | Training Loss: 0.33153 \nEpoch: 1470  | Training Loss: 0.25276 \nEpoch: 1470  | Validation balanced accuracy : 0.70000 \nEpoch: 1471  | Training Loss: 0.39036 \nEpoch: 1471  | Training Loss: 0.45426 \nEpoch: 1471  | Training Loss: 0.38519 \nEpoch: 1471  | Training Loss: 0.33134 \nEpoch: 1471  | Training Loss: 0.25278 \nEpoch: 1471  | Validation balanced accuracy : 0.70000 \nEpoch: 1472  | Training Loss: 0.39016 \nEpoch: 1472  | Training Loss: 0.45408 \nEpoch: 1472  | Training Loss: 0.38505 \nEpoch: 1472  | Training Loss: 0.33116 \nEpoch: 1472  | Training Loss: 0.25282 \nEpoch: 1472  | Validation balanced accuracy : 0.70000 \nEpoch: 1473  | Training Loss: 0.38995 \nEpoch: 1473  | Training Loss: 0.45390 \nEpoch: 1473  | Training Loss: 0.38492 \nEpoch: 1473  | Training Loss: 0.33098 \nEpoch: 1473  | Training Loss: 0.25286 \nEpoch: 1473  | Validation balanced accuracy : 0.70000 \nEpoch: 1474  | Training Loss: 0.38975 \nEpoch: 1474  | Training Loss: 0.45372 \nEpoch: 1474  | Training Loss: 0.38478 \nEpoch: 1474  | Training Loss: 0.33080 \nEpoch: 1474  | Training Loss: 0.25290 \nEpoch: 1474  | Validation balanced accuracy : 0.70000 \nEpoch: 1475  | Training Loss: 0.38954 \nEpoch: 1475  | Training Loss: 0.45354 \nEpoch: 1475  | Training Loss: 0.38464 \nEpoch: 1475  | Training Loss: 0.33062 \nEpoch: 1475  | Training Loss: 0.25293 \nEpoch: 1475  | Validation balanced accuracy : 0.70000 \nEpoch: 1476  | Training Loss: 0.38934 \nEpoch: 1476  | Training Loss: 0.45336 \nEpoch: 1476  | Training Loss: 0.38451 \nEpoch: 1476  | Training Loss: 0.33044 \nEpoch: 1476  | Training Loss: 0.25296 \nEpoch: 1476  | Validation balanced accuracy : 0.75000 \nEpoch: 1477  | Training Loss: 0.38915 \nEpoch: 1477  | Training Loss: 0.45318 \nEpoch: 1477  | Training Loss: 0.38437 \nEpoch: 1477  | Training Loss: 0.33026 \nEpoch: 1477  | Training Loss: 0.25298 \nEpoch: 1477  | Validation balanced accuracy : 0.75000 \nEpoch: 1478  | Training Loss: 0.38896 \nEpoch: 1478  | Training Loss: 0.45301 \nEpoch: 1478  | Training Loss: 0.38423 \nEpoch: 1478  | Training Loss: 0.33008 \nEpoch: 1478  | Training Loss: 0.25299 \nEpoch: 1478  | Validation balanced accuracy : 0.75000 \nEpoch: 1479  | Training Loss: 0.38877 \nEpoch: 1479  | Training Loss: 0.45285 \nEpoch: 1479  | Training Loss: 0.38410 \nEpoch: 1479  | Training Loss: 0.32989 \nEpoch: 1479  | Training Loss: 0.25299 \nEpoch: 1479  | Validation balanced accuracy : 0.75000 \nEpoch: 1480  | Training Loss: 0.38859 \nEpoch: 1480  | Training Loss: 0.45268 \nEpoch: 1480  | Training Loss: 0.38397 \nEpoch: 1480  | Training Loss: 0.32971 \nEpoch: 1480  | Training Loss: 0.25300 \nEpoch: 1480  | Validation balanced accuracy : 0.75000 \nEpoch: 1481  | Training Loss: 0.38840 \nEpoch: 1481  | Training Loss: 0.45251 \nEpoch: 1481  | Training Loss: 0.38383 \nEpoch: 1481  | Training Loss: 0.32953 \nEpoch: 1481  | Training Loss: 0.25300 \nEpoch: 1481  | Validation balanced accuracy : 0.75000 \nEpoch: 1482  | Training Loss: 0.38822 \nEpoch: 1482  | Training Loss: 0.45235 \nEpoch: 1482  | Training Loss: 0.38370 \nEpoch: 1482  | Training Loss: 0.32935 \nEpoch: 1482  | Training Loss: 0.25301 \nEpoch: 1482  | Validation balanced accuracy : 0.75000 \nEpoch: 1483  | Training Loss: 0.38804 \nEpoch: 1483  | Training Loss: 0.45218 \nEpoch: 1483  | Training Loss: 0.38356 \nEpoch: 1483  | Training Loss: 0.32917 \nEpoch: 1483  | Training Loss: 0.25302 \nEpoch: 1483  | Validation balanced accuracy : 0.75000 \nEpoch: 1484  | Training Loss: 0.38785 \nEpoch: 1484  | Training Loss: 0.45201 \nEpoch: 1484  | Training Loss: 0.38343 \nEpoch: 1484  | Training Loss: 0.32899 \nEpoch: 1484  | Training Loss: 0.25302 \nEpoch: 1484  | Validation balanced accuracy : 0.75000 \nEpoch: 1485  | Training Loss: 0.38767 \nEpoch: 1485  | Training Loss: 0.45184 \nEpoch: 1485  | Training Loss: 0.38329 \nEpoch: 1485  | Training Loss: 0.32881 \nEpoch: 1485  | Training Loss: 0.25303 \nEpoch: 1485  | Validation balanced accuracy : 0.75000 \nEpoch: 1486  | Training Loss: 0.38748 \nEpoch: 1486  | Training Loss: 0.45168 \nEpoch: 1486  | Training Loss: 0.38316 \nEpoch: 1486  | Training Loss: 0.32863 \nEpoch: 1486  | Training Loss: 0.25304 \nEpoch: 1486  | Validation balanced accuracy : 0.75000 \nEpoch: 1487  | Training Loss: 0.38730 \nEpoch: 1487  | Training Loss: 0.45151 \nEpoch: 1487  | Training Loss: 0.38303 \nEpoch: 1487  | Training Loss: 0.32845 \nEpoch: 1487  | Training Loss: 0.25305 \nEpoch: 1487  | Validation balanced accuracy : 0.75000 \nEpoch: 1488  | Training Loss: 0.38711 \nEpoch: 1488  | Training Loss: 0.45134 \nEpoch: 1488  | Training Loss: 0.38289 \nEpoch: 1488  | Training Loss: 0.32827 \nEpoch: 1488  | Training Loss: 0.25306 \nEpoch: 1488  | Validation balanced accuracy : 0.75000 \nEpoch: 1489  | Training Loss: 0.38693 \nEpoch: 1489  | Training Loss: 0.45118 \nEpoch: 1489  | Training Loss: 0.38276 \nEpoch: 1489  | Training Loss: 0.32809 \nEpoch: 1489  | Training Loss: 0.25307 \nEpoch: 1489  | Validation balanced accuracy : 0.75000 \nEpoch: 1490  | Training Loss: 0.38674 \nEpoch: 1490  | Training Loss: 0.45101 \nEpoch: 1490  | Training Loss: 0.38262 \nEpoch: 1490  | Training Loss: 0.32791 \nEpoch: 1490  | Training Loss: 0.25308 \nEpoch: 1490  | Validation balanced accuracy : 0.75000 \nEpoch: 1491  | Training Loss: 0.38655 \nEpoch: 1491  | Training Loss: 0.45084 \nEpoch: 1491  | Training Loss: 0.38249 \nEpoch: 1491  | Training Loss: 0.32773 \nEpoch: 1491  | Training Loss: 0.25310 \nEpoch: 1491  | Validation balanced accuracy : 0.75000 \nEpoch: 1492  | Training Loss: 0.38636 \nEpoch: 1492  | Training Loss: 0.45068 \nEpoch: 1492  | Training Loss: 0.38236 \nEpoch: 1492  | Training Loss: 0.32755 \nEpoch: 1492  | Training Loss: 0.25312 \nEpoch: 1492  | Validation balanced accuracy : 0.75000 \nEpoch: 1493  | Training Loss: 0.38617 \nEpoch: 1493  | Training Loss: 0.45051 \nEpoch: 1493  | Training Loss: 0.38222 \nEpoch: 1493  | Training Loss: 0.32737 \nEpoch: 1493  | Training Loss: 0.25314 \nEpoch: 1493  | Validation balanced accuracy : 0.72826 \nEpoch: 1494  | Training Loss: 0.38598 \nEpoch: 1494  | Training Loss: 0.45034 \nEpoch: 1494  | Training Loss: 0.38209 \nEpoch: 1494  | Training Loss: 0.32719 \nEpoch: 1494  | Training Loss: 0.25315 \nEpoch: 1494  | Validation balanced accuracy : 0.72826 \nEpoch: 1495  | Training Loss: 0.38580 \nEpoch: 1495  | Training Loss: 0.45018 \nEpoch: 1495  | Training Loss: 0.38195 \nEpoch: 1495  | Training Loss: 0.32701 \nEpoch: 1495  | Training Loss: 0.25316 \nEpoch: 1495  | Validation balanced accuracy : 0.72826 \nEpoch: 1496  | Training Loss: 0.38561 \nEpoch: 1496  | Training Loss: 0.45002 \nEpoch: 1496  | Training Loss: 0.38182 \nEpoch: 1496  | Training Loss: 0.32683 \nEpoch: 1496  | Training Loss: 0.25316 \nEpoch: 1496  | Validation balanced accuracy : 0.72826 \nEpoch: 1497  | Training Loss: 0.38543 \nEpoch: 1497  | Training Loss: 0.44986 \nEpoch: 1497  | Training Loss: 0.38169 \nEpoch: 1497  | Training Loss: 0.32665 \nEpoch: 1497  | Training Loss: 0.25317 \nEpoch: 1497  | Validation balanced accuracy : 0.72826 \nEpoch: 1498  | Training Loss: 0.38525 \nEpoch: 1498  | Training Loss: 0.44970 \nEpoch: 1498  | Training Loss: 0.38156 \nEpoch: 1498  | Training Loss: 0.32647 \nEpoch: 1498  | Training Loss: 0.25317 \nEpoch: 1498  | Validation balanced accuracy : 0.72826 \nEpoch: 1499  | Training Loss: 0.38507 \nEpoch: 1499  | Training Loss: 0.44954 \nEpoch: 1499  | Training Loss: 0.38142 \nEpoch: 1499  | Training Loss: 0.32629 \nEpoch: 1499  | Training Loss: 0.25318 \nEpoch: 1499  | Validation balanced accuracy : 0.72826 \nEpoch: 1500  | Training Loss: 0.38489 \nEpoch: 1500  | Training Loss: 0.44938 \nEpoch: 1500  | Training Loss: 0.38129 \nEpoch: 1500  | Training Loss: 0.32612 \nEpoch: 1500  | Training Loss: 0.25318 \nEpoch: 1500  | Validation balanced accuracy : 0.72826 \nEpoch: 1501  | Training Loss: 0.38471 \nEpoch: 1501  | Training Loss: 0.44921 \nEpoch: 1501  | Training Loss: 0.38117 \nEpoch: 1501  | Training Loss: 0.32594 \nEpoch: 1501  | Training Loss: 0.25295 \nEpoch: 1501  | Validation balanced accuracy : 0.72826 \nEpoch: 1502  | Training Loss: 0.38454 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1502  | Training Loss: 0.44906 \nEpoch: 1502  | Training Loss: 0.38105 \nEpoch: 1502  | Training Loss: 0.32578 \nEpoch: 1502  | Training Loss: 0.25297 \nEpoch: 1502  | Validation balanced accuracy : 0.72826 \nEpoch: 1503  | Training Loss: 0.38437 \nEpoch: 1503  | Training Loss: 0.44891 \nEpoch: 1503  | Training Loss: 0.38093 \nEpoch: 1503  | Training Loss: 0.32562 \nEpoch: 1503  | Training Loss: 0.25299 \nEpoch: 1503  | Validation balanced accuracy : 0.72826 \nEpoch: 1504  | Training Loss: 0.38419 \nEpoch: 1504  | Training Loss: 0.44876 \nEpoch: 1504  | Training Loss: 0.38080 \nEpoch: 1504  | Training Loss: 0.32546 \nEpoch: 1504  | Training Loss: 0.25302 \nEpoch: 1504  | Validation balanced accuracy : 0.72826 \nEpoch: 1505  | Training Loss: 0.38402 \nEpoch: 1505  | Training Loss: 0.44860 \nEpoch: 1505  | Training Loss: 0.38068 \nEpoch: 1505  | Training Loss: 0.32530 \nEpoch: 1505  | Training Loss: 0.25304 \nEpoch: 1505  | Validation balanced accuracy : 0.72826 \nEpoch: 1506  | Training Loss: 0.38384 \nEpoch: 1506  | Training Loss: 0.44845 \nEpoch: 1506  | Training Loss: 0.38056 \nEpoch: 1506  | Training Loss: 0.32514 \nEpoch: 1506  | Training Loss: 0.25305 \nEpoch: 1506  | Validation balanced accuracy : 0.72826 \nEpoch: 1507  | Training Loss: 0.38368 \nEpoch: 1507  | Training Loss: 0.44831 \nEpoch: 1507  | Training Loss: 0.38044 \nEpoch: 1507  | Training Loss: 0.32498 \nEpoch: 1507  | Training Loss: 0.25306 \nEpoch: 1507  | Validation balanced accuracy : 0.72826 \nEpoch: 1508  | Training Loss: 0.38351 \nEpoch: 1508  | Training Loss: 0.44816 \nEpoch: 1508  | Training Loss: 0.38033 \nEpoch: 1508  | Training Loss: 0.32482 \nEpoch: 1508  | Training Loss: 0.25308 \nEpoch: 1508  | Validation balanced accuracy : 0.72826 \nEpoch: 1509  | Training Loss: 0.38333 \nEpoch: 1509  | Training Loss: 0.44801 \nEpoch: 1509  | Training Loss: 0.38021 \nEpoch: 1509  | Training Loss: 0.32467 \nEpoch: 1509  | Training Loss: 0.25310 \nEpoch: 1509  | Validation balanced accuracy : 0.72826 \nEpoch: 1510  | Training Loss: 0.38316 \nEpoch: 1510  | Training Loss: 0.44786 \nEpoch: 1510  | Training Loss: 0.38009 \nEpoch: 1510  | Training Loss: 0.32451 \nEpoch: 1510  | Training Loss: 0.25314 \nEpoch: 1510  | Validation balanced accuracy : 0.77826 \nEpoch: 1511  | Training Loss: 0.38297 \nEpoch: 1511  | Training Loss: 0.44770 \nEpoch: 1511  | Training Loss: 0.37997 \nEpoch: 1511  | Training Loss: 0.32436 \nEpoch: 1511  | Training Loss: 0.25317 \nEpoch: 1511  | Validation balanced accuracy : 0.77826 \nEpoch: 1512  | Training Loss: 0.38279 \nEpoch: 1512  | Training Loss: 0.44755 \nEpoch: 1512  | Training Loss: 0.37986 \nEpoch: 1512  | Training Loss: 0.32420 \nEpoch: 1512  | Training Loss: 0.25320 \nEpoch: 1512  | Validation balanced accuracy : 0.77826 \nEpoch: 1513  | Training Loss: 0.38262 \nEpoch: 1513  | Training Loss: 0.44740 \nEpoch: 1513  | Training Loss: 0.37974 \nEpoch: 1513  | Training Loss: 0.32405 \nEpoch: 1513  | Training Loss: 0.25322 \nEpoch: 1513  | Validation balanced accuracy : 0.77826 \nEpoch: 1514  | Training Loss: 0.38245 \nEpoch: 1514  | Training Loss: 0.44726 \nEpoch: 1514  | Training Loss: 0.37962 \nEpoch: 1514  | Training Loss: 0.32389 \nEpoch: 1514  | Training Loss: 0.25323 \nEpoch: 1514  | Validation balanced accuracy : 0.77826 \nEpoch: 1515  | Training Loss: 0.38228 \nEpoch: 1515  | Training Loss: 0.44712 \nEpoch: 1515  | Training Loss: 0.37951 \nEpoch: 1515  | Training Loss: 0.32374 \nEpoch: 1515  | Training Loss: 0.25324 \nEpoch: 1515  | Validation balanced accuracy : 0.77826 \nEpoch: 1516  | Training Loss: 0.38212 \nEpoch: 1516  | Training Loss: 0.44698 \nEpoch: 1516  | Training Loss: 0.37939 \nEpoch: 1516  | Training Loss: 0.32358 \nEpoch: 1516  | Training Loss: 0.25323 \nEpoch: 1516  | Validation balanced accuracy : 0.77826 \nEpoch: 1517  | Training Loss: 0.38197 \nEpoch: 1517  | Training Loss: 0.44684 \nEpoch: 1517  | Training Loss: 0.37928 \nEpoch: 1517  | Training Loss: 0.32342 \nEpoch: 1517  | Training Loss: 0.25323 \nEpoch: 1517  | Validation balanced accuracy : 0.77826 \nEpoch: 1518  | Training Loss: 0.38181 \nEpoch: 1518  | Training Loss: 0.44671 \nEpoch: 1518  | Training Loss: 0.37916 \nEpoch: 1518  | Training Loss: 0.32327 \nEpoch: 1518  | Training Loss: 0.25322 \nEpoch: 1518  | Validation balanced accuracy : 0.75652 \nEpoch: 1519  | Training Loss: 0.38165 \nEpoch: 1519  | Training Loss: 0.44657 \nEpoch: 1519  | Training Loss: 0.37905 \nEpoch: 1519  | Training Loss: 0.32311 \nEpoch: 1519  | Training Loss: 0.25322 \nEpoch: 1519  | Validation balanced accuracy : 0.75652 \nEpoch: 1520  | Training Loss: 0.38150 \nEpoch: 1520  | Training Loss: 0.44644 \nEpoch: 1520  | Training Loss: 0.37894 \nEpoch: 1520  | Training Loss: 0.32295 \nEpoch: 1520  | Training Loss: 0.25322 \nEpoch: 1520  | Validation balanced accuracy : 0.75652 \nEpoch: 1521  | Training Loss: 0.38134 \nEpoch: 1521  | Training Loss: 0.44630 \nEpoch: 1521  | Training Loss: 0.37882 \nEpoch: 1521  | Training Loss: 0.32280 \nEpoch: 1521  | Training Loss: 0.25321 \nEpoch: 1521  | Validation balanced accuracy : 0.75652 \nEpoch: 1522  | Training Loss: 0.38118 \nEpoch: 1522  | Training Loss: 0.44616 \nEpoch: 1522  | Training Loss: 0.37871 \nEpoch: 1522  | Training Loss: 0.32264 \nEpoch: 1522  | Training Loss: 0.25322 \nEpoch: 1522  | Validation balanced accuracy : 0.75652 \nEpoch: 1523  | Training Loss: 0.38102 \nEpoch: 1523  | Training Loss: 0.44602 \nEpoch: 1523  | Training Loss: 0.37859 \nEpoch: 1523  | Training Loss: 0.32249 \nEpoch: 1523  | Training Loss: 0.25323 \nEpoch: 1523  | Validation balanced accuracy : 0.75652 \nEpoch: 1524  | Training Loss: 0.38085 \nEpoch: 1524  | Training Loss: 0.44588 \nEpoch: 1524  | Training Loss: 0.37848 \nEpoch: 1524  | Training Loss: 0.32233 \nEpoch: 1524  | Training Loss: 0.25325 \nEpoch: 1524  | Validation balanced accuracy : 0.75652 \nEpoch: 1525  | Training Loss: 0.38068 \nEpoch: 1525  | Training Loss: 0.44573 \nEpoch: 1525  | Training Loss: 0.37837 \nEpoch: 1525  | Training Loss: 0.32218 \nEpoch: 1525  | Training Loss: 0.25327 \nEpoch: 1525  | Validation balanced accuracy : 0.75652 \nEpoch: 1526  | Training Loss: 0.38052 \nEpoch: 1526  | Training Loss: 0.44559 \nEpoch: 1526  | Training Loss: 0.37826 \nEpoch: 1526  | Training Loss: 0.32203 \nEpoch: 1526  | Training Loss: 0.25328 \nEpoch: 1526  | Validation balanced accuracy : 0.75652 \nEpoch: 1527  | Training Loss: 0.38035 \nEpoch: 1527  | Training Loss: 0.44545 \nEpoch: 1527  | Training Loss: 0.37814 \nEpoch: 1527  | Training Loss: 0.32187 \nEpoch: 1527  | Training Loss: 0.25328 \nEpoch: 1527  | Validation balanced accuracy : 0.75652 \nEpoch: 1528  | Training Loss: 0.38019 \nEpoch: 1528  | Training Loss: 0.44532 \nEpoch: 1528  | Training Loss: 0.37803 \nEpoch: 1528  | Training Loss: 0.32172 \nEpoch: 1528  | Training Loss: 0.25328 \nEpoch: 1528  | Validation balanced accuracy : 0.75652 \nEpoch: 1529  | Training Loss: 0.38003 \nEpoch: 1529  | Training Loss: 0.44518 \nEpoch: 1529  | Training Loss: 0.37792 \nEpoch: 1529  | Training Loss: 0.32156 \nEpoch: 1529  | Training Loss: 0.25329 \nEpoch: 1529  | Validation balanced accuracy : 0.75652 \nEpoch: 1530  | Training Loss: 0.37987 \nEpoch: 1530  | Training Loss: 0.44504 \nEpoch: 1530  | Training Loss: 0.37781 \nEpoch: 1530  | Training Loss: 0.32141 \nEpoch: 1530  | Training Loss: 0.25330 \nEpoch: 1530  | Validation balanced accuracy : 0.75652 \nEpoch: 1531  | Training Loss: 0.37971 \nEpoch: 1531  | Training Loss: 0.44490 \nEpoch: 1531  | Training Loss: 0.37770 \nEpoch: 1531  | Training Loss: 0.32125 \nEpoch: 1531  | Training Loss: 0.25331 \nEpoch: 1531  | Validation balanced accuracy : 0.75652 \nEpoch: 1532  | Training Loss: 0.37954 \nEpoch: 1532  | Training Loss: 0.44476 \nEpoch: 1532  | Training Loss: 0.37759 \nEpoch: 1532  | Training Loss: 0.32110 \nEpoch: 1532  | Training Loss: 0.25332 \nEpoch: 1532  | Validation balanced accuracy : 0.75652 \nEpoch: 1533  | Training Loss: 0.37938 \nEpoch: 1533  | Training Loss: 0.44462 \nEpoch: 1533  | Training Loss: 0.37748 \nEpoch: 1533  | Training Loss: 0.32095 \nEpoch: 1533  | Training Loss: 0.25333 \nEpoch: 1533  | Validation balanced accuracy : 0.75652 \nEpoch: 1534  | Training Loss: 0.37921 \nEpoch: 1534  | Training Loss: 0.44448 \nEpoch: 1534  | Training Loss: 0.37737 \nEpoch: 1534  | Training Loss: 0.32079 \nEpoch: 1534  | Training Loss: 0.25333 \nEpoch: 1534  | Validation balanced accuracy : 0.75652 \nEpoch: 1535  | Training Loss: 0.37906 \nEpoch: 1535  | Training Loss: 0.44434 \nEpoch: 1535  | Training Loss: 0.37726 \nEpoch: 1535  | Training Loss: 0.32064 \nEpoch: 1535  | Training Loss: 0.25333 \nEpoch: 1535  | Validation balanced accuracy : 0.75652 \nEpoch: 1536  | Training Loss: 0.37890 \nEpoch: 1536  | Training Loss: 0.44421 \nEpoch: 1536  | Training Loss: 0.37715 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1536  | Training Loss: 0.32049 \nEpoch: 1536  | Training Loss: 0.25333 \nEpoch: 1536  | Validation balanced accuracy : 0.75652 \nEpoch: 1537  | Training Loss: 0.37875 \nEpoch: 1537  | Training Loss: 0.44408 \nEpoch: 1537  | Training Loss: 0.37704 \nEpoch: 1537  | Training Loss: 0.32033 \nEpoch: 1537  | Training Loss: 0.25332 \nEpoch: 1537  | Validation balanced accuracy : 0.75652 \nEpoch: 1538  | Training Loss: 0.37859 \nEpoch: 1538  | Training Loss: 0.44394 \nEpoch: 1538  | Training Loss: 0.37693 \nEpoch: 1538  | Training Loss: 0.32018 \nEpoch: 1538  | Training Loss: 0.25331 \nEpoch: 1538  | Validation balanced accuracy : 0.75652 \nEpoch: 1539  | Training Loss: 0.37844 \nEpoch: 1539  | Training Loss: 0.44381 \nEpoch: 1539  | Training Loss: 0.37682 \nEpoch: 1539  | Training Loss: 0.32002 \nEpoch: 1539  | Training Loss: 0.25331 \nEpoch: 1539  | Validation balanced accuracy : 0.75652 \nEpoch: 1540  | Training Loss: 0.37829 \nEpoch: 1540  | Training Loss: 0.44368 \nEpoch: 1540  | Training Loss: 0.37671 \nEpoch: 1540  | Training Loss: 0.31987 \nEpoch: 1540  | Training Loss: 0.25331 \nEpoch: 1540  | Validation balanced accuracy : 0.75652 \nEpoch: 1541  | Training Loss: 0.37812 \nEpoch: 1541  | Training Loss: 0.44354 \nEpoch: 1541  | Training Loss: 0.37660 \nEpoch: 1541  | Training Loss: 0.31972 \nEpoch: 1541  | Training Loss: 0.25333 \nEpoch: 1541  | Validation balanced accuracy : 0.75652 \nEpoch: 1542  | Training Loss: 0.37796 \nEpoch: 1542  | Training Loss: 0.44340 \nEpoch: 1542  | Training Loss: 0.37649 \nEpoch: 1542  | Training Loss: 0.31957 \nEpoch: 1542  | Training Loss: 0.25334 \nEpoch: 1542  | Validation balanced accuracy : 0.75652 \nEpoch: 1543  | Training Loss: 0.37779 \nEpoch: 1543  | Training Loss: 0.44326 \nEpoch: 1543  | Training Loss: 0.37638 \nEpoch: 1543  | Training Loss: 0.31941 \nEpoch: 1543  | Training Loss: 0.25336 \nEpoch: 1543  | Validation balanced accuracy : 0.75652 \nEpoch: 1544  | Training Loss: 0.37763 \nEpoch: 1544  | Training Loss: 0.44313 \nEpoch: 1544  | Training Loss: 0.37627 \nEpoch: 1544  | Training Loss: 0.31926 \nEpoch: 1544  | Training Loss: 0.25336 \nEpoch: 1544  | Validation balanced accuracy : 0.75652 \nEpoch: 1545  | Training Loss: 0.37747 \nEpoch: 1545  | Training Loss: 0.44299 \nEpoch: 1545  | Training Loss: 0.37616 \nEpoch: 1545  | Training Loss: 0.31911 \nEpoch: 1545  | Training Loss: 0.25336 \nEpoch: 1545  | Validation balanced accuracy : 0.75652 \nEpoch: 1546  | Training Loss: 0.37731 \nEpoch: 1546  | Training Loss: 0.44286 \nEpoch: 1546  | Training Loss: 0.37605 \nEpoch: 1546  | Training Loss: 0.31896 \nEpoch: 1546  | Training Loss: 0.25336 \nEpoch: 1546  | Validation balanced accuracy : 0.75652 \nEpoch: 1547  | Training Loss: 0.37716 \nEpoch: 1547  | Training Loss: 0.44273 \nEpoch: 1547  | Training Loss: 0.37594 \nEpoch: 1547  | Training Loss: 0.31881 \nEpoch: 1547  | Training Loss: 0.25337 \nEpoch: 1547  | Validation balanced accuracy : 0.75652 \nEpoch: 1548  | Training Loss: 0.37700 \nEpoch: 1548  | Training Loss: 0.44259 \nEpoch: 1548  | Training Loss: 0.37583 \nEpoch: 1548  | Training Loss: 0.31865 \nEpoch: 1548  | Training Loss: 0.25338 \nEpoch: 1548  | Validation balanced accuracy : 0.75652 \nEpoch: 1549  | Training Loss: 0.37684 \nEpoch: 1549  | Training Loss: 0.44246 \nEpoch: 1549  | Training Loss: 0.37572 \nEpoch: 1549  | Training Loss: 0.31850 \nEpoch: 1549  | Training Loss: 0.25339 \nEpoch: 1549  | Validation balanced accuracy : 0.75652 \nEpoch: 1550  | Training Loss: 0.37668 \nEpoch: 1550  | Training Loss: 0.44232 \nEpoch: 1550  | Training Loss: 0.37561 \nEpoch: 1550  | Training Loss: 0.31835 \nEpoch: 1550  | Training Loss: 0.25340 \nEpoch: 1550  | Validation balanced accuracy : 0.75652 \nEpoch: 1551  | Training Loss: 0.37652 \nEpoch: 1551  | Training Loss: 0.44219 \nEpoch: 1551  | Training Loss: 0.37550 \nEpoch: 1551  | Training Loss: 0.31820 \nEpoch: 1551  | Training Loss: 0.25343 \nEpoch: 1551  | Validation balanced accuracy : 0.75652 \nEpoch: 1552  | Training Loss: 0.37635 \nEpoch: 1552  | Training Loss: 0.44204 \nEpoch: 1552  | Training Loss: 0.37539 \nEpoch: 1552  | Training Loss: 0.31805 \nEpoch: 1552  | Training Loss: 0.25348 \nEpoch: 1552  | Validation balanced accuracy : 0.75652 \nEpoch: 1553  | Training Loss: 0.37616 \nEpoch: 1553  | Training Loss: 0.44189 \nEpoch: 1553  | Training Loss: 0.37528 \nEpoch: 1553  | Training Loss: 0.31791 \nEpoch: 1553  | Training Loss: 0.25354 \nEpoch: 1553  | Validation balanced accuracy : 0.75652 \nEpoch: 1554  | Training Loss: 0.37598 \nEpoch: 1554  | Training Loss: 0.44174 \nEpoch: 1554  | Training Loss: 0.37517 \nEpoch: 1554  | Training Loss: 0.31776 \nEpoch: 1554  | Training Loss: 0.25359 \nEpoch: 1554  | Validation balanced accuracy : 0.75652 \nEpoch: 1555  | Training Loss: 0.37580 \nEpoch: 1555  | Training Loss: 0.44159 \nEpoch: 1555  | Training Loss: 0.37506 \nEpoch: 1555  | Training Loss: 0.31761 \nEpoch: 1555  | Training Loss: 0.25362 \nEpoch: 1555  | Validation balanced accuracy : 0.75652 \nEpoch: 1556  | Training Loss: 0.37563 \nEpoch: 1556  | Training Loss: 0.44145 \nEpoch: 1556  | Training Loss: 0.37495 \nEpoch: 1556  | Training Loss: 0.31746 \nEpoch: 1556  | Training Loss: 0.25364 \nEpoch: 1556  | Validation balanced accuracy : 0.75652 \nEpoch: 1557  | Training Loss: 0.37547 \nEpoch: 1557  | Training Loss: 0.44132 \nEpoch: 1557  | Training Loss: 0.37484 \nEpoch: 1557  | Training Loss: 0.31732 \nEpoch: 1557  | Training Loss: 0.25365 \nEpoch: 1557  | Validation balanced accuracy : 0.75652 \nEpoch: 1558  | Training Loss: 0.37531 \nEpoch: 1558  | Training Loss: 0.44118 \nEpoch: 1558  | Training Loss: 0.37473 \nEpoch: 1558  | Training Loss: 0.31717 \nEpoch: 1558  | Training Loss: 0.25366 \nEpoch: 1558  | Validation balanced accuracy : 0.75652 \nEpoch: 1559  | Training Loss: 0.37515 \nEpoch: 1559  | Training Loss: 0.44105 \nEpoch: 1559  | Training Loss: 0.37462 \nEpoch: 1559  | Training Loss: 0.31702 \nEpoch: 1559  | Training Loss: 0.25367 \nEpoch: 1559  | Validation balanced accuracy : 0.75652 \nEpoch: 1560  | Training Loss: 0.37500 \nEpoch: 1560  | Training Loss: 0.44092 \nEpoch: 1560  | Training Loss: 0.37452 \nEpoch: 1560  | Training Loss: 0.31687 \nEpoch: 1560  | Training Loss: 0.25367 \nEpoch: 1560  | Validation balanced accuracy : 0.75652 \nEpoch: 1561  | Training Loss: 0.37486 \nEpoch: 1561  | Training Loss: 0.44079 \nEpoch: 1561  | Training Loss: 0.37441 \nEpoch: 1561  | Training Loss: 0.31672 \nEpoch: 1561  | Training Loss: 0.25366 \nEpoch: 1561  | Validation balanced accuracy : 0.75652 \nEpoch: 1562  | Training Loss: 0.37471 \nEpoch: 1562  | Training Loss: 0.44067 \nEpoch: 1562  | Training Loss: 0.37430 \nEpoch: 1562  | Training Loss: 0.31657 \nEpoch: 1562  | Training Loss: 0.25365 \nEpoch: 1562  | Validation balanced accuracy : 0.75652 \nEpoch: 1563  | Training Loss: 0.37457 \nEpoch: 1563  | Training Loss: 0.44055 \nEpoch: 1563  | Training Loss: 0.37419 \nEpoch: 1563  | Training Loss: 0.31643 \nEpoch: 1563  | Training Loss: 0.25364 \nEpoch: 1563  | Validation balanced accuracy : 0.75652 \nEpoch: 1564  | Training Loss: 0.37442 \nEpoch: 1564  | Training Loss: 0.44042 \nEpoch: 1564  | Training Loss: 0.37409 \nEpoch: 1564  | Training Loss: 0.31628 \nEpoch: 1564  | Training Loss: 0.25363 \nEpoch: 1564  | Validation balanced accuracy : 0.75652 \nEpoch: 1565  | Training Loss: 0.37428 \nEpoch: 1565  | Training Loss: 0.44030 \nEpoch: 1565  | Training Loss: 0.37398 \nEpoch: 1565  | Training Loss: 0.31613 \nEpoch: 1565  | Training Loss: 0.25362 \nEpoch: 1565  | Validation balanced accuracy : 0.75652 \nEpoch: 1566  | Training Loss: 0.37414 \nEpoch: 1566  | Training Loss: 0.44017 \nEpoch: 1566  | Training Loss: 0.37387 \nEpoch: 1566  | Training Loss: 0.31598 \nEpoch: 1566  | Training Loss: 0.25361 \nEpoch: 1566  | Validation balanced accuracy : 0.75652 \nEpoch: 1567  | Training Loss: 0.37399 \nEpoch: 1567  | Training Loss: 0.44005 \nEpoch: 1567  | Training Loss: 0.37377 \nEpoch: 1567  | Training Loss: 0.31583 \nEpoch: 1567  | Training Loss: 0.25360 \nEpoch: 1567  | Validation balanced accuracy : 0.75652 \nEpoch: 1568  | Training Loss: 0.37385 \nEpoch: 1568  | Training Loss: 0.43992 \nEpoch: 1568  | Training Loss: 0.37366 \nEpoch: 1568  | Training Loss: 0.31569 \nEpoch: 1568  | Training Loss: 0.25359 \nEpoch: 1568  | Validation balanced accuracy : 0.75652 \nEpoch: 1569  | Training Loss: 0.37371 \nEpoch: 1569  | Training Loss: 0.43980 \nEpoch: 1569  | Training Loss: 0.37355 \nEpoch: 1569  | Training Loss: 0.31554 \nEpoch: 1569  | Training Loss: 0.25358 \nEpoch: 1569  | Validation balanced accuracy : 0.75652 \nEpoch: 1570  | Training Loss: 0.37356 \nEpoch: 1570  | Training Loss: 0.43967 \nEpoch: 1570  | Training Loss: 0.37345 \nEpoch: 1570  | Training Loss: 0.31539 \nEpoch: 1570  | Training Loss: 0.25357 \nEpoch: 1570  | Validation balanced accuracy : 0.75652 \nEpoch: 1571  | Training Loss: 0.37342 \nEpoch: 1571  | Training Loss: 0.43955 \nEpoch: 1571  | Training Loss: 0.37334 \nEpoch: 1571  | Training Loss: 0.31524 \nEpoch: 1571  | Training Loss: 0.25357 \nEpoch: 1571  | Validation balanced accuracy : 0.75652 \nEpoch: 1572  | Training Loss: 0.37327 \nEpoch: 1572  | Training Loss: 0.43943 \nEpoch: 1572  | Training Loss: 0.37323 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1572  | Training Loss: 0.31510 \nEpoch: 1572  | Training Loss: 0.25356 \nEpoch: 1572  | Validation balanced accuracy : 0.75652 \nEpoch: 1573  | Training Loss: 0.37313 \nEpoch: 1573  | Training Loss: 0.43930 \nEpoch: 1573  | Training Loss: 0.37313 \nEpoch: 1573  | Training Loss: 0.31495 \nEpoch: 1573  | Training Loss: 0.25355 \nEpoch: 1573  | Validation balanced accuracy : 0.75652 \nEpoch: 1574  | Training Loss: 0.37298 \nEpoch: 1574  | Training Loss: 0.43918 \nEpoch: 1574  | Training Loss: 0.37302 \nEpoch: 1574  | Training Loss: 0.31480 \nEpoch: 1574  | Training Loss: 0.25354 \nEpoch: 1574  | Validation balanced accuracy : 0.75652 \nEpoch: 1575  | Training Loss: 0.37284 \nEpoch: 1575  | Training Loss: 0.43905 \nEpoch: 1575  | Training Loss: 0.37291 \nEpoch: 1575  | Training Loss: 0.31466 \nEpoch: 1575  | Training Loss: 0.25353 \nEpoch: 1575  | Validation balanced accuracy : 0.75652 \nEpoch: 1576  | Training Loss: 0.37270 \nEpoch: 1576  | Training Loss: 0.43893 \nEpoch: 1576  | Training Loss: 0.37281 \nEpoch: 1576  | Training Loss: 0.31451 \nEpoch: 1576  | Training Loss: 0.25352 \nEpoch: 1576  | Validation balanced accuracy : 0.75652 \nEpoch: 1577  | Training Loss: 0.37255 \nEpoch: 1577  | Training Loss: 0.43881 \nEpoch: 1577  | Training Loss: 0.37270 \nEpoch: 1577  | Training Loss: 0.31436 \nEpoch: 1577  | Training Loss: 0.25351 \nEpoch: 1577  | Validation balanced accuracy : 0.75652 \nEpoch: 1578  | Training Loss: 0.37241 \nEpoch: 1578  | Training Loss: 0.43868 \nEpoch: 1578  | Training Loss: 0.37259 \nEpoch: 1578  | Training Loss: 0.31422 \nEpoch: 1578  | Training Loss: 0.25350 \nEpoch: 1578  | Validation balanced accuracy : 0.75652 \nEpoch: 1579  | Training Loss: 0.37227 \nEpoch: 1579  | Training Loss: 0.43856 \nEpoch: 1579  | Training Loss: 0.37249 \nEpoch: 1579  | Training Loss: 0.31407 \nEpoch: 1579  | Training Loss: 0.25349 \nEpoch: 1579  | Validation balanced accuracy : 0.75652 \nEpoch: 1580  | Training Loss: 0.37212 \nEpoch: 1580  | Training Loss: 0.43843 \nEpoch: 1580  | Training Loss: 0.37238 \nEpoch: 1580  | Training Loss: 0.31392 \nEpoch: 1580  | Training Loss: 0.25350 \nEpoch: 1580  | Validation balanced accuracy : 0.75652 \nEpoch: 1581  | Training Loss: 0.37197 \nEpoch: 1581  | Training Loss: 0.43830 \nEpoch: 1581  | Training Loss: 0.37227 \nEpoch: 1581  | Training Loss: 0.31378 \nEpoch: 1581  | Training Loss: 0.25352 \nEpoch: 1581  | Validation balanced accuracy : 0.75652 \nEpoch: 1582  | Training Loss: 0.37181 \nEpoch: 1582  | Training Loss: 0.43817 \nEpoch: 1582  | Training Loss: 0.37216 \nEpoch: 1582  | Training Loss: 0.31364 \nEpoch: 1582  | Training Loss: 0.25353 \nEpoch: 1582  | Validation balanced accuracy : 0.75652 \nEpoch: 1583  | Training Loss: 0.37165 \nEpoch: 1583  | Training Loss: 0.43804 \nEpoch: 1583  | Training Loss: 0.37206 \nEpoch: 1583  | Training Loss: 0.31349 \nEpoch: 1583  | Training Loss: 0.25353 \nEpoch: 1583  | Validation balanced accuracy : 0.75652 \nEpoch: 1584  | Training Loss: 0.37150 \nEpoch: 1584  | Training Loss: 0.43791 \nEpoch: 1584  | Training Loss: 0.37195 \nEpoch: 1584  | Training Loss: 0.31335 \nEpoch: 1584  | Training Loss: 0.25353 \nEpoch: 1584  | Validation balanced accuracy : 0.75652 \nEpoch: 1585  | Training Loss: 0.37136 \nEpoch: 1585  | Training Loss: 0.43779 \nEpoch: 1585  | Training Loss: 0.37184 \nEpoch: 1585  | Training Loss: 0.31320 \nEpoch: 1585  | Training Loss: 0.25352 \nEpoch: 1585  | Validation balanced accuracy : 0.75652 \nEpoch: 1586  | Training Loss: 0.37121 \nEpoch: 1586  | Training Loss: 0.43767 \nEpoch: 1586  | Training Loss: 0.37174 \nEpoch: 1586  | Training Loss: 0.31306 \nEpoch: 1586  | Training Loss: 0.25351 \nEpoch: 1586  | Validation balanced accuracy : 0.75652 \nEpoch: 1587  | Training Loss: 0.37107 \nEpoch: 1587  | Training Loss: 0.43755 \nEpoch: 1587  | Training Loss: 0.37163 \nEpoch: 1587  | Training Loss: 0.31291 \nEpoch: 1587  | Training Loss: 0.25349 \nEpoch: 1587  | Validation balanced accuracy : 0.75652 \nEpoch: 1588  | Training Loss: 0.37093 \nEpoch: 1588  | Training Loss: 0.43743 \nEpoch: 1588  | Training Loss: 0.37153 \nEpoch: 1588  | Training Loss: 0.31277 \nEpoch: 1588  | Training Loss: 0.25348 \nEpoch: 1588  | Validation balanced accuracy : 0.75652 \nEpoch: 1589  | Training Loss: 0.37079 \nEpoch: 1589  | Training Loss: 0.43731 \nEpoch: 1589  | Training Loss: 0.37142 \nEpoch: 1589  | Training Loss: 0.31262 \nEpoch: 1589  | Training Loss: 0.25346 \nEpoch: 1589  | Validation balanced accuracy : 0.75652 \nEpoch: 1590  | Training Loss: 0.37066 \nEpoch: 1590  | Training Loss: 0.43719 \nEpoch: 1590  | Training Loss: 0.37131 \nEpoch: 1590  | Training Loss: 0.31248 \nEpoch: 1590  | Training Loss: 0.25345 \nEpoch: 1590  | Validation balanced accuracy : 0.75652 \nEpoch: 1591  | Training Loss: 0.37052 \nEpoch: 1591  | Training Loss: 0.43707 \nEpoch: 1591  | Training Loss: 0.37121 \nEpoch: 1591  | Training Loss: 0.31233 \nEpoch: 1591  | Training Loss: 0.25344 \nEpoch: 1591  | Validation balanced accuracy : 0.75652 \nEpoch: 1592  | Training Loss: 0.37037 \nEpoch: 1592  | Training Loss: 0.43695 \nEpoch: 1592  | Training Loss: 0.37110 \nEpoch: 1592  | Training Loss: 0.31219 \nEpoch: 1592  | Training Loss: 0.25342 \nEpoch: 1592  | Validation balanced accuracy : 0.75652 \nEpoch: 1593  | Training Loss: 0.37023 \nEpoch: 1593  | Training Loss: 0.43683 \nEpoch: 1593  | Training Loss: 0.37100 \nEpoch: 1593  | Training Loss: 0.31204 \nEpoch: 1593  | Training Loss: 0.25341 \nEpoch: 1593  | Validation balanced accuracy : 0.75652 \nEpoch: 1594  | Training Loss: 0.37009 \nEpoch: 1594  | Training Loss: 0.43670 \nEpoch: 1594  | Training Loss: 0.37089 \nEpoch: 1594  | Training Loss: 0.31190 \nEpoch: 1594  | Training Loss: 0.25340 \nEpoch: 1594  | Validation balanced accuracy : 0.75652 \nEpoch: 1595  | Training Loss: 0.36995 \nEpoch: 1595  | Training Loss: 0.43658 \nEpoch: 1595  | Training Loss: 0.37079 \nEpoch: 1595  | Training Loss: 0.31176 \nEpoch: 1595  | Training Loss: 0.25339 \nEpoch: 1595  | Validation balanced accuracy : 0.75652 \nEpoch: 1596  | Training Loss: 0.36981 \nEpoch: 1596  | Training Loss: 0.43646 \nEpoch: 1596  | Training Loss: 0.37068 \nEpoch: 1596  | Training Loss: 0.31161 \nEpoch: 1596  | Training Loss: 0.25337 \nEpoch: 1596  | Validation balanced accuracy : 0.75652 \nEpoch: 1597  | Training Loss: 0.36967 \nEpoch: 1597  | Training Loss: 0.43634 \nEpoch: 1597  | Training Loss: 0.37057 \nEpoch: 1597  | Training Loss: 0.31147 \nEpoch: 1597  | Training Loss: 0.25336 \nEpoch: 1597  | Validation balanced accuracy : 0.75652 \nEpoch: 1598  | Training Loss: 0.36953 \nEpoch: 1598  | Training Loss: 0.43622 \nEpoch: 1598  | Training Loss: 0.37047 \nEpoch: 1598  | Training Loss: 0.31132 \nEpoch: 1598  | Training Loss: 0.25335 \nEpoch: 1598  | Validation balanced accuracy : 0.75652 \nEpoch: 1599  | Training Loss: 0.36939 \nEpoch: 1599  | Training Loss: 0.43610 \nEpoch: 1599  | Training Loss: 0.37036 \nEpoch: 1599  | Training Loss: 0.31118 \nEpoch: 1599  | Training Loss: 0.25333 \nEpoch: 1599  | Validation balanced accuracy : 0.75652 \nEpoch: 1600  | Training Loss: 0.36925 \nEpoch: 1600  | Training Loss: 0.43598 \nEpoch: 1600  | Training Loss: 0.37026 \nEpoch: 1600  | Training Loss: 0.31104 \nEpoch: 1600  | Training Loss: 0.25332 \nEpoch: 1600  | Validation balanced accuracy : 0.75652 \nEpoch: 1601  | Training Loss: 0.36911 \nEpoch: 1601  | Training Loss: 0.43587 \nEpoch: 1601  | Training Loss: 0.37015 \nEpoch: 1601  | Training Loss: 0.31089 \nEpoch: 1601  | Training Loss: 0.25331 \nEpoch: 1601  | Validation balanced accuracy : 0.75652 \nEpoch: 1602  | Training Loss: 0.36897 \nEpoch: 1602  | Training Loss: 0.43575 \nEpoch: 1602  | Training Loss: 0.37005 \nEpoch: 1602  | Training Loss: 0.31075 \nEpoch: 1602  | Training Loss: 0.25329 \nEpoch: 1602  | Validation balanced accuracy : 0.75652 \nEpoch: 1603  | Training Loss: 0.36883 \nEpoch: 1603  | Training Loss: 0.43563 \nEpoch: 1603  | Training Loss: 0.36994 \nEpoch: 1603  | Training Loss: 0.31061 \nEpoch: 1603  | Training Loss: 0.25328 \nEpoch: 1603  | Validation balanced accuracy : 0.75652 \nEpoch: 1604  | Training Loss: 0.36869 \nEpoch: 1604  | Training Loss: 0.43551 \nEpoch: 1604  | Training Loss: 0.36984 \nEpoch: 1604  | Training Loss: 0.31046 \nEpoch: 1604  | Training Loss: 0.25326 \nEpoch: 1604  | Validation balanced accuracy : 0.75652 \nEpoch: 1605  | Training Loss: 0.36855 \nEpoch: 1605  | Training Loss: 0.43539 \nEpoch: 1605  | Training Loss: 0.36973 \nEpoch: 1605  | Training Loss: 0.31032 \nEpoch: 1605  | Training Loss: 0.25325 \nEpoch: 1605  | Validation balanced accuracy : 0.75652 \nEpoch: 1606  | Training Loss: 0.36842 \nEpoch: 1606  | Training Loss: 0.43527 \nEpoch: 1606  | Training Loss: 0.36963 \nEpoch: 1606  | Training Loss: 0.31018 \nEpoch: 1606  | Training Loss: 0.25323 \nEpoch: 1606  | Validation balanced accuracy : 0.75652 \nEpoch: 1607  | Training Loss: 0.36828 \nEpoch: 1607  | Training Loss: 0.43515 \nEpoch: 1607  | Training Loss: 0.36952 \nEpoch: 1607  | Training Loss: 0.31004 \nEpoch: 1607  | Training Loss: 0.25322 \nEpoch: 1607  | Validation balanced accuracy : 0.75652 \nEpoch: 1608  | Training Loss: 0.36814 \nEpoch: 1608  | Training Loss: 0.43504 \nEpoch: 1608  | Training Loss: 0.36942 \nEpoch: 1608  | Training Loss: 0.30989 \nEpoch: 1608  | Training Loss: 0.25320 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1608  | Validation balanced accuracy : 0.75652 \nEpoch: 1609  | Training Loss: 0.36800 \nEpoch: 1609  | Training Loss: 0.43492 \nEpoch: 1609  | Training Loss: 0.36931 \nEpoch: 1609  | Training Loss: 0.30975 \nEpoch: 1609  | Training Loss: 0.25319 \nEpoch: 1609  | Validation balanced accuracy : 0.75652 \nEpoch: 1610  | Training Loss: 0.36786 \nEpoch: 1610  | Training Loss: 0.43480 \nEpoch: 1610  | Training Loss: 0.36921 \nEpoch: 1610  | Training Loss: 0.30961 \nEpoch: 1610  | Training Loss: 0.25317 \nEpoch: 1610  | Validation balanced accuracy : 0.75652 \nEpoch: 1611  | Training Loss: 0.36772 \nEpoch: 1611  | Training Loss: 0.43468 \nEpoch: 1611  | Training Loss: 0.36910 \nEpoch: 1611  | Training Loss: 0.30946 \nEpoch: 1611  | Training Loss: 0.25316 \nEpoch: 1611  | Validation balanced accuracy : 0.75652 \nEpoch: 1612  | Training Loss: 0.36759 \nEpoch: 1612  | Training Loss: 0.43456 \nEpoch: 1612  | Training Loss: 0.36900 \nEpoch: 1612  | Training Loss: 0.30932 \nEpoch: 1612  | Training Loss: 0.25314 \nEpoch: 1612  | Validation balanced accuracy : 0.75652 \nEpoch: 1613  | Training Loss: 0.36745 \nEpoch: 1613  | Training Loss: 0.43445 \nEpoch: 1613  | Training Loss: 0.36889 \nEpoch: 1613  | Training Loss: 0.30918 \nEpoch: 1613  | Training Loss: 0.25312 \nEpoch: 1613  | Validation balanced accuracy : 0.75652 \nEpoch: 1614  | Training Loss: 0.36731 \nEpoch: 1614  | Training Loss: 0.43433 \nEpoch: 1614  | Training Loss: 0.36879 \nEpoch: 1614  | Training Loss: 0.30904 \nEpoch: 1614  | Training Loss: 0.25311 \nEpoch: 1614  | Validation balanced accuracy : 0.75652 \nEpoch: 1615  | Training Loss: 0.36717 \nEpoch: 1615  | Training Loss: 0.43421 \nEpoch: 1615  | Training Loss: 0.36868 \nEpoch: 1615  | Training Loss: 0.30890 \nEpoch: 1615  | Training Loss: 0.25309 \nEpoch: 1615  | Validation balanced accuracy : 0.75652 \nEpoch: 1616  | Training Loss: 0.36704 \nEpoch: 1616  | Training Loss: 0.43410 \nEpoch: 1616  | Training Loss: 0.36858 \nEpoch: 1616  | Training Loss: 0.30875 \nEpoch: 1616  | Training Loss: 0.25307 \nEpoch: 1616  | Validation balanced accuracy : 0.75652 \nEpoch: 1617  | Training Loss: 0.36690 \nEpoch: 1617  | Training Loss: 0.43398 \nEpoch: 1617  | Training Loss: 0.36847 \nEpoch: 1617  | Training Loss: 0.30861 \nEpoch: 1617  | Training Loss: 0.25306 \nEpoch: 1617  | Validation balanced accuracy : 0.75652 \nEpoch: 1618  | Training Loss: 0.36676 \nEpoch: 1618  | Training Loss: 0.43386 \nEpoch: 1618  | Training Loss: 0.36837 \nEpoch: 1618  | Training Loss: 0.30847 \nEpoch: 1618  | Training Loss: 0.25304 \nEpoch: 1618  | Validation balanced accuracy : 0.75652 \nEpoch: 1619  | Training Loss: 0.36662 \nEpoch: 1619  | Training Loss: 0.43375 \nEpoch: 1619  | Training Loss: 0.36826 \nEpoch: 1619  | Training Loss: 0.30833 \nEpoch: 1619  | Training Loss: 0.25302 \nEpoch: 1619  | Validation balanced accuracy : 0.75652 \nEpoch: 1620  | Training Loss: 0.36649 \nEpoch: 1620  | Training Loss: 0.43363 \nEpoch: 1620  | Training Loss: 0.36816 \nEpoch: 1620  | Training Loss: 0.30819 \nEpoch: 1620  | Training Loss: 0.25301 \nEpoch: 1620  | Validation balanced accuracy : 0.75652 \nEpoch: 1621  | Training Loss: 0.36635 \nEpoch: 1621  | Training Loss: 0.43352 \nEpoch: 1621  | Training Loss: 0.36805 \nEpoch: 1621  | Training Loss: 0.30804 \nEpoch: 1621  | Training Loss: 0.25299 \nEpoch: 1621  | Validation balanced accuracy : 0.75652 \nEpoch: 1622  | Training Loss: 0.36621 \nEpoch: 1622  | Training Loss: 0.43340 \nEpoch: 1622  | Training Loss: 0.36795 \nEpoch: 1622  | Training Loss: 0.30790 \nEpoch: 1622  | Training Loss: 0.25297 \nEpoch: 1622  | Validation balanced accuracy : 0.75652 \nEpoch: 1623  | Training Loss: 0.36608 \nEpoch: 1623  | Training Loss: 0.43328 \nEpoch: 1623  | Training Loss: 0.36785 \nEpoch: 1623  | Training Loss: 0.30776 \nEpoch: 1623  | Training Loss: 0.25295 \nEpoch: 1623  | Validation balanced accuracy : 0.75652 \nEpoch: 1624  | Training Loss: 0.36594 \nEpoch: 1624  | Training Loss: 0.43317 \nEpoch: 1624  | Training Loss: 0.36774 \nEpoch: 1624  | Training Loss: 0.30762 \nEpoch: 1624  | Training Loss: 0.25293 \nEpoch: 1624  | Validation balanced accuracy : 0.75652 \nEpoch: 1625  | Training Loss: 0.36581 \nEpoch: 1625  | Training Loss: 0.43305 \nEpoch: 1625  | Training Loss: 0.36764 \nEpoch: 1625  | Training Loss: 0.30748 \nEpoch: 1625  | Training Loss: 0.25291 \nEpoch: 1625  | Validation balanced accuracy : 0.75652 \nEpoch: 1626  | Training Loss: 0.36567 \nEpoch: 1626  | Training Loss: 0.43294 \nEpoch: 1626  | Training Loss: 0.36753 \nEpoch: 1626  | Training Loss: 0.30734 \nEpoch: 1626  | Training Loss: 0.25290 \nEpoch: 1626  | Validation balanced accuracy : 0.75652 \nEpoch: 1627  | Training Loss: 0.36553 \nEpoch: 1627  | Training Loss: 0.43282 \nEpoch: 1627  | Training Loss: 0.36743 \nEpoch: 1627  | Training Loss: 0.30720 \nEpoch: 1627  | Training Loss: 0.25288 \nEpoch: 1627  | Validation balanced accuracy : 0.75652 \nEpoch: 1628  | Training Loss: 0.36540 \nEpoch: 1628  | Training Loss: 0.43271 \nEpoch: 1628  | Training Loss: 0.36733 \nEpoch: 1628  | Training Loss: 0.30706 \nEpoch: 1628  | Training Loss: 0.25286 \nEpoch: 1628  | Validation balanced accuracy : 0.75652 \nEpoch: 1629  | Training Loss: 0.36526 \nEpoch: 1629  | Training Loss: 0.43259 \nEpoch: 1629  | Training Loss: 0.36722 \nEpoch: 1629  | Training Loss: 0.30691 \nEpoch: 1629  | Training Loss: 0.25284 \nEpoch: 1629  | Validation balanced accuracy : 0.75652 \nEpoch: 1630  | Training Loss: 0.36513 \nEpoch: 1630  | Training Loss: 0.43248 \nEpoch: 1630  | Training Loss: 0.36712 \nEpoch: 1630  | Training Loss: 0.30677 \nEpoch: 1630  | Training Loss: 0.25282 \nEpoch: 1630  | Validation balanced accuracy : 0.75652 \nEpoch: 1631  | Training Loss: 0.36499 \nEpoch: 1631  | Training Loss: 0.43237 \nEpoch: 1631  | Training Loss: 0.36701 \nEpoch: 1631  | Training Loss: 0.30663 \nEpoch: 1631  | Training Loss: 0.25280 \nEpoch: 1631  | Validation balanced accuracy : 0.75652 \nEpoch: 1632  | Training Loss: 0.36486 \nEpoch: 1632  | Training Loss: 0.43225 \nEpoch: 1632  | Training Loss: 0.36691 \nEpoch: 1632  | Training Loss: 0.30649 \nEpoch: 1632  | Training Loss: 0.25278 \nEpoch: 1632  | Validation balanced accuracy : 0.75652 \nEpoch: 1633  | Training Loss: 0.36472 \nEpoch: 1633  | Training Loss: 0.43214 \nEpoch: 1633  | Training Loss: 0.36681 \nEpoch: 1633  | Training Loss: 0.30635 \nEpoch: 1633  | Training Loss: 0.25276 \nEpoch: 1633  | Validation balanced accuracy : 0.75652 \nEpoch: 1634  | Training Loss: 0.36459 \nEpoch: 1634  | Training Loss: 0.43202 \nEpoch: 1634  | Training Loss: 0.36670 \nEpoch: 1634  | Training Loss: 0.30621 \nEpoch: 1634  | Training Loss: 0.25274 \nEpoch: 1634  | Validation balanced accuracy : 0.75652 \nEpoch: 1635  | Training Loss: 0.36445 \nEpoch: 1635  | Training Loss: 0.43191 \nEpoch: 1635  | Training Loss: 0.36660 \nEpoch: 1635  | Training Loss: 0.30607 \nEpoch: 1635  | Training Loss: 0.25272 \nEpoch: 1635  | Validation balanced accuracy : 0.75652 \nEpoch: 1636  | Training Loss: 0.36432 \nEpoch: 1636  | Training Loss: 0.43180 \nEpoch: 1636  | Training Loss: 0.36650 \nEpoch: 1636  | Training Loss: 0.30593 \nEpoch: 1636  | Training Loss: 0.25270 \nEpoch: 1636  | Validation balanced accuracy : 0.75652 \nEpoch: 1637  | Training Loss: 0.36418 \nEpoch: 1637  | Training Loss: 0.43168 \nEpoch: 1637  | Training Loss: 0.36639 \nEpoch: 1637  | Training Loss: 0.30579 \nEpoch: 1637  | Training Loss: 0.25268 \nEpoch: 1637  | Validation balanced accuracy : 0.75652 \nEpoch: 1638  | Training Loss: 0.36405 \nEpoch: 1638  | Training Loss: 0.43157 \nEpoch: 1638  | Training Loss: 0.36629 \nEpoch: 1638  | Training Loss: 0.30565 \nEpoch: 1638  | Training Loss: 0.25266 \nEpoch: 1638  | Validation balanced accuracy : 0.75652 \nEpoch: 1639  | Training Loss: 0.36392 \nEpoch: 1639  | Training Loss: 0.43146 \nEpoch: 1639  | Training Loss: 0.36618 \nEpoch: 1639  | Training Loss: 0.30551 \nEpoch: 1639  | Training Loss: 0.25264 \nEpoch: 1639  | Validation balanced accuracy : 0.75652 \nEpoch: 1640  | Training Loss: 0.36378 \nEpoch: 1640  | Training Loss: 0.43135 \nEpoch: 1640  | Training Loss: 0.36608 \nEpoch: 1640  | Training Loss: 0.30537 \nEpoch: 1640  | Training Loss: 0.25262 \nEpoch: 1640  | Validation balanced accuracy : 0.73478 \nEpoch: 1641  | Training Loss: 0.36364 \nEpoch: 1641  | Training Loss: 0.43123 \nEpoch: 1641  | Training Loss: 0.36598 \nEpoch: 1641  | Training Loss: 0.30523 \nEpoch: 1641  | Training Loss: 0.25263 \nEpoch: 1641  | Validation balanced accuracy : 0.73478 \nEpoch: 1642  | Training Loss: 0.36349 \nEpoch: 1642  | Training Loss: 0.43110 \nEpoch: 1642  | Training Loss: 0.36587 \nEpoch: 1642  | Training Loss: 0.30509 \nEpoch: 1642  | Training Loss: 0.25263 \nEpoch: 1642  | Validation balanced accuracy : 0.73478 \nEpoch: 1643  | Training Loss: 0.36334 \nEpoch: 1643  | Training Loss: 0.43098 \nEpoch: 1643  | Training Loss: 0.36577 \nEpoch: 1643  | Training Loss: 0.30496 \nEpoch: 1643  | Training Loss: 0.25264 \nEpoch: 1643  | Validation balanced accuracy : 0.73478 \nEpoch: 1644  | Training Loss: 0.36319 \nEpoch: 1644  | Training Loss: 0.43086 \nEpoch: 1644  | Training Loss: 0.36567 \nEpoch: 1644  | Training Loss: 0.30482 \nEpoch: 1644  | Training Loss: 0.25263 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1644  | Validation balanced accuracy : 0.73478 \nEpoch: 1645  | Training Loss: 0.36305 \nEpoch: 1645  | Training Loss: 0.43074 \nEpoch: 1645  | Training Loss: 0.36557 \nEpoch: 1645  | Training Loss: 0.30468 \nEpoch: 1645  | Training Loss: 0.25262 \nEpoch: 1645  | Validation balanced accuracy : 0.73478 \nEpoch: 1646  | Training Loss: 0.36292 \nEpoch: 1646  | Training Loss: 0.43063 \nEpoch: 1646  | Training Loss: 0.36546 \nEpoch: 1646  | Training Loss: 0.30454 \nEpoch: 1646  | Training Loss: 0.25259 \nEpoch: 1646  | Validation balanced accuracy : 0.73478 \nEpoch: 1647  | Training Loss: 0.36278 \nEpoch: 1647  | Training Loss: 0.43052 \nEpoch: 1647  | Training Loss: 0.36536 \nEpoch: 1647  | Training Loss: 0.30440 \nEpoch: 1647  | Training Loss: 0.25257 \nEpoch: 1647  | Validation balanced accuracy : 0.73478 \nEpoch: 1648  | Training Loss: 0.36265 \nEpoch: 1648  | Training Loss: 0.43041 \nEpoch: 1648  | Training Loss: 0.36526 \nEpoch: 1648  | Training Loss: 0.30426 \nEpoch: 1648  | Training Loss: 0.25254 \nEpoch: 1648  | Validation balanced accuracy : 0.73478 \nEpoch: 1649  | Training Loss: 0.36252 \nEpoch: 1649  | Training Loss: 0.43030 \nEpoch: 1649  | Training Loss: 0.36516 \nEpoch: 1649  | Training Loss: 0.30412 \nEpoch: 1649  | Training Loss: 0.25251 \nEpoch: 1649  | Validation balanced accuracy : 0.73478 \nEpoch: 1650  | Training Loss: 0.36239 \nEpoch: 1650  | Training Loss: 0.43019 \nEpoch: 1650  | Training Loss: 0.36506 \nEpoch: 1650  | Training Loss: 0.30398 \nEpoch: 1650  | Training Loss: 0.25249 \nEpoch: 1650  | Validation balanced accuracy : 0.73478 \nEpoch: 1651  | Training Loss: 0.36226 \nEpoch: 1651  | Training Loss: 0.43008 \nEpoch: 1651  | Training Loss: 0.36496 \nEpoch: 1651  | Training Loss: 0.30384 \nEpoch: 1651  | Training Loss: 0.25246 \nEpoch: 1651  | Validation balanced accuracy : 0.73478 \nEpoch: 1652  | Training Loss: 0.36213 \nEpoch: 1652  | Training Loss: 0.42997 \nEpoch: 1652  | Training Loss: 0.36485 \nEpoch: 1652  | Training Loss: 0.30371 \nEpoch: 1652  | Training Loss: 0.25244 \nEpoch: 1652  | Validation balanced accuracy : 0.73478 \nEpoch: 1653  | Training Loss: 0.36200 \nEpoch: 1653  | Training Loss: 0.42986 \nEpoch: 1653  | Training Loss: 0.36475 \nEpoch: 1653  | Training Loss: 0.30357 \nEpoch: 1653  | Training Loss: 0.25241 \nEpoch: 1653  | Validation balanced accuracy : 0.73478 \nEpoch: 1654  | Training Loss: 0.36187 \nEpoch: 1654  | Training Loss: 0.42975 \nEpoch: 1654  | Training Loss: 0.36465 \nEpoch: 1654  | Training Loss: 0.30343 \nEpoch: 1654  | Training Loss: 0.25239 \nEpoch: 1654  | Validation balanced accuracy : 0.73478 \nEpoch: 1655  | Training Loss: 0.36174 \nEpoch: 1655  | Training Loss: 0.42964 \nEpoch: 1655  | Training Loss: 0.36455 \nEpoch: 1655  | Training Loss: 0.30329 \nEpoch: 1655  | Training Loss: 0.25237 \nEpoch: 1655  | Validation balanced accuracy : 0.73478 \nEpoch: 1656  | Training Loss: 0.36161 \nEpoch: 1656  | Training Loss: 0.42953 \nEpoch: 1656  | Training Loss: 0.36445 \nEpoch: 1656  | Training Loss: 0.30315 \nEpoch: 1656  | Training Loss: 0.25235 \nEpoch: 1656  | Validation balanced accuracy : 0.73478 \nEpoch: 1657  | Training Loss: 0.36147 \nEpoch: 1657  | Training Loss: 0.42942 \nEpoch: 1657  | Training Loss: 0.36435 \nEpoch: 1657  | Training Loss: 0.30301 \nEpoch: 1657  | Training Loss: 0.25232 \nEpoch: 1657  | Validation balanced accuracy : 0.73478 \nEpoch: 1658  | Training Loss: 0.36134 \nEpoch: 1658  | Training Loss: 0.42931 \nEpoch: 1658  | Training Loss: 0.36425 \nEpoch: 1658  | Training Loss: 0.30288 \nEpoch: 1658  | Training Loss: 0.25230 \nEpoch: 1658  | Validation balanced accuracy : 0.73478 \nEpoch: 1659  | Training Loss: 0.36121 \nEpoch: 1659  | Training Loss: 0.42920 \nEpoch: 1659  | Training Loss: 0.36415 \nEpoch: 1659  | Training Loss: 0.30274 \nEpoch: 1659  | Training Loss: 0.25227 \nEpoch: 1659  | Validation balanced accuracy : 0.73478 \nEpoch: 1660  | Training Loss: 0.36108 \nEpoch: 1660  | Training Loss: 0.42909 \nEpoch: 1660  | Training Loss: 0.36405 \nEpoch: 1660  | Training Loss: 0.30260 \nEpoch: 1660  | Training Loss: 0.25225 \nEpoch: 1660  | Validation balanced accuracy : 0.73478 \nEpoch: 1661  | Training Loss: 0.36095 \nEpoch: 1661  | Training Loss: 0.42898 \nEpoch: 1661  | Training Loss: 0.36394 \nEpoch: 1661  | Training Loss: 0.30246 \nEpoch: 1661  | Training Loss: 0.25222 \nEpoch: 1661  | Validation balanced accuracy : 0.73478 \nEpoch: 1662  | Training Loss: 0.36082 \nEpoch: 1662  | Training Loss: 0.42887 \nEpoch: 1662  | Training Loss: 0.36384 \nEpoch: 1662  | Training Loss: 0.30233 \nEpoch: 1662  | Training Loss: 0.25220 \nEpoch: 1662  | Validation balanced accuracy : 0.73478 \nEpoch: 1663  | Training Loss: 0.36069 \nEpoch: 1663  | Training Loss: 0.42877 \nEpoch: 1663  | Training Loss: 0.36374 \nEpoch: 1663  | Training Loss: 0.30219 \nEpoch: 1663  | Training Loss: 0.25217 \nEpoch: 1663  | Validation balanced accuracy : 0.73478 \nEpoch: 1664  | Training Loss: 0.36056 \nEpoch: 1664  | Training Loss: 0.42866 \nEpoch: 1664  | Training Loss: 0.36364 \nEpoch: 1664  | Training Loss: 0.30205 \nEpoch: 1664  | Training Loss: 0.25215 \nEpoch: 1664  | Validation balanced accuracy : 0.73478 \nEpoch: 1665  | Training Loss: 0.36043 \nEpoch: 1665  | Training Loss: 0.42855 \nEpoch: 1665  | Training Loss: 0.36354 \nEpoch: 1665  | Training Loss: 0.30191 \nEpoch: 1665  | Training Loss: 0.25212 \nEpoch: 1665  | Validation balanced accuracy : 0.73478 \nEpoch: 1666  | Training Loss: 0.36030 \nEpoch: 1666  | Training Loss: 0.42844 \nEpoch: 1666  | Training Loss: 0.36344 \nEpoch: 1666  | Training Loss: 0.30178 \nEpoch: 1666  | Training Loss: 0.25209 \nEpoch: 1666  | Validation balanced accuracy : 0.73478 \nEpoch: 1667  | Training Loss: 0.36017 \nEpoch: 1667  | Training Loss: 0.42833 \nEpoch: 1667  | Training Loss: 0.36334 \nEpoch: 1667  | Training Loss: 0.30164 \nEpoch: 1667  | Training Loss: 0.25207 \nEpoch: 1667  | Validation balanced accuracy : 0.73478 \nEpoch: 1668  | Training Loss: 0.36004 \nEpoch: 1668  | Training Loss: 0.42822 \nEpoch: 1668  | Training Loss: 0.36324 \nEpoch: 1668  | Training Loss: 0.30150 \nEpoch: 1668  | Training Loss: 0.25204 \nEpoch: 1668  | Validation balanced accuracy : 0.73478 \nEpoch: 1669  | Training Loss: 0.35991 \nEpoch: 1669  | Training Loss: 0.42812 \nEpoch: 1669  | Training Loss: 0.36314 \nEpoch: 1669  | Training Loss: 0.30136 \nEpoch: 1669  | Training Loss: 0.25201 \nEpoch: 1669  | Validation balanced accuracy : 0.73478 \nEpoch: 1670  | Training Loss: 0.35978 \nEpoch: 1670  | Training Loss: 0.42801 \nEpoch: 1670  | Training Loss: 0.36304 \nEpoch: 1670  | Training Loss: 0.30123 \nEpoch: 1670  | Training Loss: 0.25199 \nEpoch: 1670  | Validation balanced accuracy : 0.73478 \nEpoch: 1671  | Training Loss: 0.35966 \nEpoch: 1671  | Training Loss: 0.42790 \nEpoch: 1671  | Training Loss: 0.36294 \nEpoch: 1671  | Training Loss: 0.30109 \nEpoch: 1671  | Training Loss: 0.25196 \nEpoch: 1671  | Validation balanced accuracy : 0.73478 \nEpoch: 1672  | Training Loss: 0.35953 \nEpoch: 1672  | Training Loss: 0.42779 \nEpoch: 1672  | Training Loss: 0.36284 \nEpoch: 1672  | Training Loss: 0.30095 \nEpoch: 1672  | Training Loss: 0.25194 \nEpoch: 1672  | Validation balanced accuracy : 0.73478 \nEpoch: 1673  | Training Loss: 0.35939 \nEpoch: 1673  | Training Loss: 0.42768 \nEpoch: 1673  | Training Loss: 0.36274 \nEpoch: 1673  | Training Loss: 0.30082 \nEpoch: 1673  | Training Loss: 0.25194 \nEpoch: 1673  | Validation balanced accuracy : 0.73478 \nEpoch: 1674  | Training Loss: 0.35924 \nEpoch: 1674  | Training Loss: 0.42756 \nEpoch: 1674  | Training Loss: 0.36264 \nEpoch: 1674  | Training Loss: 0.30068 \nEpoch: 1674  | Training Loss: 0.25195 \nEpoch: 1674  | Validation balanced accuracy : 0.73478 \nEpoch: 1675  | Training Loss: 0.35910 \nEpoch: 1675  | Training Loss: 0.42744 \nEpoch: 1675  | Training Loss: 0.36254 \nEpoch: 1675  | Training Loss: 0.30055 \nEpoch: 1675  | Training Loss: 0.25195 \nEpoch: 1675  | Validation balanced accuracy : 0.73478 \nEpoch: 1676  | Training Loss: 0.35895 \nEpoch: 1676  | Training Loss: 0.42733 \nEpoch: 1676  | Training Loss: 0.36244 \nEpoch: 1676  | Training Loss: 0.30041 \nEpoch: 1676  | Training Loss: 0.25193 \nEpoch: 1676  | Validation balanced accuracy : 0.73478 \nEpoch: 1677  | Training Loss: 0.35882 \nEpoch: 1677  | Training Loss: 0.42722 \nEpoch: 1677  | Training Loss: 0.36234 \nEpoch: 1677  | Training Loss: 0.30028 \nEpoch: 1677  | Training Loss: 0.25191 \nEpoch: 1677  | Validation balanced accuracy : 0.73478 \nEpoch: 1678  | Training Loss: 0.35869 \nEpoch: 1678  | Training Loss: 0.42711 \nEpoch: 1678  | Training Loss: 0.36224 \nEpoch: 1678  | Training Loss: 0.30014 \nEpoch: 1678  | Training Loss: 0.25189 \nEpoch: 1678  | Validation balanced accuracy : 0.73478 \nEpoch: 1679  | Training Loss: 0.35856 \nEpoch: 1679  | Training Loss: 0.42701 \nEpoch: 1679  | Training Loss: 0.36214 \nEpoch: 1679  | Training Loss: 0.30000 \nEpoch: 1679  | Training Loss: 0.25185 \nEpoch: 1679  | Validation balanced accuracy : 0.73478 \nEpoch: 1680  | Training Loss: 0.35843 \nEpoch: 1680  | Training Loss: 0.42690 \nEpoch: 1680  | Training Loss: 0.36204 \nEpoch: 1680  | Training Loss: 0.29987 \nEpoch: 1680  | Training Loss: 0.25182 \nEpoch: 1680  | Validation balanced accuracy : 0.73478 \nEpoch: 1681  | Training Loss: 0.35831 \nEpoch: 1681  | Training Loss: 0.42680 \nEpoch: 1681  | Training Loss: 0.36194 \nEpoch: 1681  | Training Loss: 0.29973 \nEpoch: 1681  | Training Loss: 0.25179 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1681  | Validation balanced accuracy : 0.73478 \nEpoch: 1682  | Training Loss: 0.35819 \nEpoch: 1682  | Training Loss: 0.42669 \nEpoch: 1682  | Training Loss: 0.36185 \nEpoch: 1682  | Training Loss: 0.29960 \nEpoch: 1682  | Training Loss: 0.25175 \nEpoch: 1682  | Validation balanced accuracy : 0.73478 \nEpoch: 1683  | Training Loss: 0.35806 \nEpoch: 1683  | Training Loss: 0.42659 \nEpoch: 1683  | Training Loss: 0.36175 \nEpoch: 1683  | Training Loss: 0.29946 \nEpoch: 1683  | Training Loss: 0.25172 \nEpoch: 1683  | Validation balanced accuracy : 0.73478 \nEpoch: 1684  | Training Loss: 0.35793 \nEpoch: 1684  | Training Loss: 0.42649 \nEpoch: 1684  | Training Loss: 0.36165 \nEpoch: 1684  | Training Loss: 0.29932 \nEpoch: 1684  | Training Loss: 0.25169 \nEpoch: 1684  | Validation balanced accuracy : 0.73478 \nEpoch: 1685  | Training Loss: 0.35781 \nEpoch: 1685  | Training Loss: 0.42638 \nEpoch: 1685  | Training Loss: 0.36155 \nEpoch: 1685  | Training Loss: 0.29919 \nEpoch: 1685  | Training Loss: 0.25166 \nEpoch: 1685  | Validation balanced accuracy : 0.73478 \nEpoch: 1686  | Training Loss: 0.35768 \nEpoch: 1686  | Training Loss: 0.42628 \nEpoch: 1686  | Training Loss: 0.36145 \nEpoch: 1686  | Training Loss: 0.29905 \nEpoch: 1686  | Training Loss: 0.25164 \nEpoch: 1686  | Validation balanced accuracy : 0.73478 \nEpoch: 1687  | Training Loss: 0.35755 \nEpoch: 1687  | Training Loss: 0.42617 \nEpoch: 1687  | Training Loss: 0.36136 \nEpoch: 1687  | Training Loss: 0.29892 \nEpoch: 1687  | Training Loss: 0.25161 \nEpoch: 1687  | Validation balanced accuracy : 0.73478 \nEpoch: 1688  | Training Loss: 0.35743 \nEpoch: 1688  | Training Loss: 0.42607 \nEpoch: 1688  | Training Loss: 0.36126 \nEpoch: 1688  | Training Loss: 0.29878 \nEpoch: 1688  | Training Loss: 0.25158 \nEpoch: 1688  | Validation balanced accuracy : 0.73478 \nEpoch: 1689  | Training Loss: 0.35730 \nEpoch: 1689  | Training Loss: 0.42596 \nEpoch: 1689  | Training Loss: 0.36116 \nEpoch: 1689  | Training Loss: 0.29865 \nEpoch: 1689  | Training Loss: 0.25155 \nEpoch: 1689  | Validation balanced accuracy : 0.73478 \nEpoch: 1690  | Training Loss: 0.35717 \nEpoch: 1690  | Training Loss: 0.42586 \nEpoch: 1690  | Training Loss: 0.36106 \nEpoch: 1690  | Training Loss: 0.29851 \nEpoch: 1690  | Training Loss: 0.25152 \nEpoch: 1690  | Validation balanced accuracy : 0.73478 \nEpoch: 1691  | Training Loss: 0.35705 \nEpoch: 1691  | Training Loss: 0.42575 \nEpoch: 1691  | Training Loss: 0.36096 \nEpoch: 1691  | Training Loss: 0.29838 \nEpoch: 1691  | Training Loss: 0.25149 \nEpoch: 1691  | Validation balanced accuracy : 0.73478 \nEpoch: 1692  | Training Loss: 0.35692 \nEpoch: 1692  | Training Loss: 0.42565 \nEpoch: 1692  | Training Loss: 0.36087 \nEpoch: 1692  | Training Loss: 0.29825 \nEpoch: 1692  | Training Loss: 0.25146 \nEpoch: 1692  | Validation balanced accuracy : 0.73478 \nEpoch: 1693  | Training Loss: 0.35680 \nEpoch: 1693  | Training Loss: 0.42555 \nEpoch: 1693  | Training Loss: 0.36077 \nEpoch: 1693  | Training Loss: 0.29811 \nEpoch: 1693  | Training Loss: 0.25142 \nEpoch: 1693  | Validation balanced accuracy : 0.73478 \nEpoch: 1694  | Training Loss: 0.35667 \nEpoch: 1694  | Training Loss: 0.42544 \nEpoch: 1694  | Training Loss: 0.36067 \nEpoch: 1694  | Training Loss: 0.29798 \nEpoch: 1694  | Training Loss: 0.25139 \nEpoch: 1694  | Validation balanced accuracy : 0.73478 \nEpoch: 1695  | Training Loss: 0.35655 \nEpoch: 1695  | Training Loss: 0.42534 \nEpoch: 1695  | Training Loss: 0.36057 \nEpoch: 1695  | Training Loss: 0.29784 \nEpoch: 1695  | Training Loss: 0.25136 \nEpoch: 1695  | Validation balanced accuracy : 0.73478 \nEpoch: 1696  | Training Loss: 0.35642 \nEpoch: 1696  | Training Loss: 0.42524 \nEpoch: 1696  | Training Loss: 0.36048 \nEpoch: 1696  | Training Loss: 0.29771 \nEpoch: 1696  | Training Loss: 0.25133 \nEpoch: 1696  | Validation balanced accuracy : 0.73478 \nEpoch: 1697  | Training Loss: 0.35630 \nEpoch: 1697  | Training Loss: 0.42513 \nEpoch: 1697  | Training Loss: 0.36038 \nEpoch: 1697  | Training Loss: 0.29757 \nEpoch: 1697  | Training Loss: 0.25130 \nEpoch: 1697  | Validation balanced accuracy : 0.73478 \nEpoch: 1698  | Training Loss: 0.35617 \nEpoch: 1698  | Training Loss: 0.42503 \nEpoch: 1698  | Training Loss: 0.36028 \nEpoch: 1698  | Training Loss: 0.29744 \nEpoch: 1698  | Training Loss: 0.25127 \nEpoch: 1698  | Validation balanced accuracy : 0.73478 \nEpoch: 1699  | Training Loss: 0.35605 \nEpoch: 1699  | Training Loss: 0.42493 \nEpoch: 1699  | Training Loss: 0.36018 \nEpoch: 1699  | Training Loss: 0.29730 \nEpoch: 1699  | Training Loss: 0.25124 \nEpoch: 1699  | Validation balanced accuracy : 0.73478 \nEpoch: 1700  | Training Loss: 0.35593 \nEpoch: 1700  | Training Loss: 0.42483 \nEpoch: 1700  | Training Loss: 0.36009 \nEpoch: 1700  | Training Loss: 0.29717 \nEpoch: 1700  | Training Loss: 0.25120 \nEpoch: 1700  | Validation balanced accuracy : 0.73478 \nEpoch: 1701  | Training Loss: 0.35580 \nEpoch: 1701  | Training Loss: 0.42470 \nEpoch: 1701  | Training Loss: 0.35997 \nEpoch: 1701  | Training Loss: 0.29705 \nEpoch: 1701  | Training Loss: 0.25228 \nEpoch: 1701  | Validation balanced accuracy : 0.73478 \nEpoch: 1702  | Training Loss: 0.35483 \nEpoch: 1702  | Training Loss: 0.42374 \nEpoch: 1702  | Training Loss: 0.35980 \nEpoch: 1702  | Training Loss: 0.29697 \nEpoch: 1702  | Training Loss: 0.25435 \nEpoch: 1702  | Validation balanced accuracy : 0.73478 \nEpoch: 1703  | Training Loss: 0.35341 \nEpoch: 1703  | Training Loss: 0.42251 \nEpoch: 1703  | Training Loss: 0.35962 \nEpoch: 1703  | Training Loss: 0.29691 \nEpoch: 1703  | Training Loss: 0.25650 \nEpoch: 1703  | Validation balanced accuracy : 0.73478 \nEpoch: 1704  | Training Loss: 0.35203 \nEpoch: 1704  | Training Loss: 0.42139 \nEpoch: 1704  | Training Loss: 0.35947 \nEpoch: 1704  | Training Loss: 0.29685 \nEpoch: 1704  | Training Loss: 0.25819 \nEpoch: 1704  | Validation balanced accuracy : 0.73478 \nEpoch: 1705  | Training Loss: 0.35099 \nEpoch: 1705  | Training Loss: 0.42057 \nEpoch: 1705  | Training Loss: 0.35934 \nEpoch: 1705  | Training Loss: 0.29675 \nEpoch: 1705  | Training Loss: 0.25903 \nEpoch: 1705  | Validation balanced accuracy : 0.73478 \nEpoch: 1706  | Training Loss: 0.35045 \nEpoch: 1706  | Training Loss: 0.42018 \nEpoch: 1706  | Training Loss: 0.35923 \nEpoch: 1706  | Training Loss: 0.29662 \nEpoch: 1706  | Training Loss: 0.25908 \nEpoch: 1706  | Validation balanced accuracy : 0.73478 \nEpoch: 1707  | Training Loss: 0.35034 \nEpoch: 1707  | Training Loss: 0.42009 \nEpoch: 1707  | Training Loss: 0.35913 \nEpoch: 1707  | Training Loss: 0.29645 \nEpoch: 1707  | Training Loss: 0.25865 \nEpoch: 1707  | Validation balanced accuracy : 0.73478 \nEpoch: 1708  | Training Loss: 0.35047 \nEpoch: 1708  | Training Loss: 0.42016 \nEpoch: 1708  | Training Loss: 0.35904 \nEpoch: 1708  | Training Loss: 0.29628 \nEpoch: 1708  | Training Loss: 0.25802 \nEpoch: 1708  | Validation balanced accuracy : 0.73478 \nEpoch: 1709  | Training Loss: 0.35068 \nEpoch: 1709  | Training Loss: 0.42027 \nEpoch: 1709  | Training Loss: 0.35895 \nEpoch: 1709  | Training Loss: 0.29611 \nEpoch: 1709  | Training Loss: 0.25742 \nEpoch: 1709  | Validation balanced accuracy : 0.73478 \nEpoch: 1710  | Training Loss: 0.35085 \nEpoch: 1710  | Training Loss: 0.42034 \nEpoch: 1710  | Training Loss: 0.35885 \nEpoch: 1710  | Training Loss: 0.29594 \nEpoch: 1710  | Training Loss: 0.25698 \nEpoch: 1710  | Validation balanced accuracy : 0.73478 \nEpoch: 1711  | Training Loss: 0.35093 \nEpoch: 1711  | Training Loss: 0.42033 \nEpoch: 1711  | Training Loss: 0.35876 \nEpoch: 1711  | Training Loss: 0.29579 \nEpoch: 1711  | Training Loss: 0.25672 \nEpoch: 1711  | Validation balanced accuracy : 0.73478 \nEpoch: 1712  | Training Loss: 0.35090 \nEpoch: 1712  | Training Loss: 0.42024 \nEpoch: 1712  | Training Loss: 0.35866 \nEpoch: 1712  | Training Loss: 0.29564 \nEpoch: 1712  | Training Loss: 0.25663 \nEpoch: 1712  | Validation balanced accuracy : 0.73478 \nEpoch: 1713  | Training Loss: 0.35078 \nEpoch: 1713  | Training Loss: 0.42009 \nEpoch: 1713  | Training Loss: 0.35855 \nEpoch: 1713  | Training Loss: 0.29550 \nEpoch: 1713  | Training Loss: 0.25665 \nEpoch: 1713  | Validation balanced accuracy : 0.73478 \nEpoch: 1714  | Training Loss: 0.35061 \nEpoch: 1714  | Training Loss: 0.41989 \nEpoch: 1714  | Training Loss: 0.35845 \nEpoch: 1714  | Training Loss: 0.29536 \nEpoch: 1714  | Training Loss: 0.25673 \nEpoch: 1714  | Validation balanced accuracy : 0.73478 \nEpoch: 1715  | Training Loss: 0.35041 \nEpoch: 1715  | Training Loss: 0.41968 \nEpoch: 1715  | Training Loss: 0.35834 \nEpoch: 1715  | Training Loss: 0.29522 \nEpoch: 1715  | Training Loss: 0.25681 \nEpoch: 1715  | Validation balanced accuracy : 0.73478 \nEpoch: 1716  | Training Loss: 0.35021 \nEpoch: 1716  | Training Loss: 0.41948 \nEpoch: 1716  | Training Loss: 0.35824 \nEpoch: 1716  | Training Loss: 0.29508 \nEpoch: 1716  | Training Loss: 0.25686 \nEpoch: 1716  | Validation balanced accuracy : 0.73478 \nEpoch: 1717  | Training Loss: 0.35003 \nEpoch: 1717  | Training Loss: 0.41929 \nEpoch: 1717  | Training Loss: 0.35813 \nEpoch: 1717  | Training Loss: 0.29493 \nEpoch: 1717  | Training Loss: 0.25688 \nEpoch: 1717  | Validation balanced accuracy : 0.73478 \nEpoch: 1718  | Training Loss: 0.34987 \nEpoch: 1718  | Training Loss: 0.41912 \nEpoch: 1718  | Training Loss: 0.35803 \nEpoch: 1718  | Training Loss: 0.29479 \nEpoch: 1718  | Training Loss: 0.25686 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1718  | Validation balanced accuracy : 0.73478 \nEpoch: 1719  | Training Loss: 0.34973 \nEpoch: 1719  | Training Loss: 0.41896 \nEpoch: 1719  | Training Loss: 0.35793 \nEpoch: 1719  | Training Loss: 0.29465 \nEpoch: 1719  | Training Loss: 0.25682 \nEpoch: 1719  | Validation balanced accuracy : 0.73478 \nEpoch: 1720  | Training Loss: 0.34960 \nEpoch: 1720  | Training Loss: 0.41881 \nEpoch: 1720  | Training Loss: 0.35783 \nEpoch: 1720  | Training Loss: 0.29450 \nEpoch: 1720  | Training Loss: 0.25677 \nEpoch: 1720  | Validation balanced accuracy : 0.73478 \nEpoch: 1721  | Training Loss: 0.34948 \nEpoch: 1721  | Training Loss: 0.41866 \nEpoch: 1721  | Training Loss: 0.35773 \nEpoch: 1721  | Training Loss: 0.29436 \nEpoch: 1721  | Training Loss: 0.25671 \nEpoch: 1721  | Validation balanced accuracy : 0.73478 \nEpoch: 1722  | Training Loss: 0.34936 \nEpoch: 1722  | Training Loss: 0.41851 \nEpoch: 1722  | Training Loss: 0.35762 \nEpoch: 1722  | Training Loss: 0.29421 \nEpoch: 1722  | Training Loss: 0.25666 \nEpoch: 1722  | Validation balanced accuracy : 0.73478 \nEpoch: 1723  | Training Loss: 0.34924 \nEpoch: 1723  | Training Loss: 0.41837 \nEpoch: 1723  | Training Loss: 0.35752 \nEpoch: 1723  | Training Loss: 0.29407 \nEpoch: 1723  | Training Loss: 0.25661 \nEpoch: 1723  | Validation balanced accuracy : 0.73478 \nEpoch: 1724  | Training Loss: 0.34911 \nEpoch: 1724  | Training Loss: 0.41821 \nEpoch: 1724  | Training Loss: 0.35742 \nEpoch: 1724  | Training Loss: 0.29392 \nEpoch: 1724  | Training Loss: 0.25657 \nEpoch: 1724  | Validation balanced accuracy : 0.73478 \nEpoch: 1725  | Training Loss: 0.34898 \nEpoch: 1725  | Training Loss: 0.41806 \nEpoch: 1725  | Training Loss: 0.35732 \nEpoch: 1725  | Training Loss: 0.29378 \nEpoch: 1725  | Training Loss: 0.25653 \nEpoch: 1725  | Validation balanced accuracy : 0.73478 \nEpoch: 1726  | Training Loss: 0.34885 \nEpoch: 1726  | Training Loss: 0.41790 \nEpoch: 1726  | Training Loss: 0.35722 \nEpoch: 1726  | Training Loss: 0.29364 \nEpoch: 1726  | Training Loss: 0.25650 \nEpoch: 1726  | Validation balanced accuracy : 0.73478 \nEpoch: 1727  | Training Loss: 0.34871 \nEpoch: 1727  | Training Loss: 0.41775 \nEpoch: 1727  | Training Loss: 0.35712 \nEpoch: 1727  | Training Loss: 0.29349 \nEpoch: 1727  | Training Loss: 0.25647 \nEpoch: 1727  | Validation balanced accuracy : 0.73478 \nEpoch: 1728  | Training Loss: 0.34858 \nEpoch: 1728  | Training Loss: 0.41759 \nEpoch: 1728  | Training Loss: 0.35701 \nEpoch: 1728  | Training Loss: 0.29335 \nEpoch: 1728  | Training Loss: 0.25643 \nEpoch: 1728  | Validation balanced accuracy : 0.73478 \nEpoch: 1729  | Training Loss: 0.34844 \nEpoch: 1729  | Training Loss: 0.41743 \nEpoch: 1729  | Training Loss: 0.35691 \nEpoch: 1729  | Training Loss: 0.29321 \nEpoch: 1729  | Training Loss: 0.25640 \nEpoch: 1729  | Validation balanced accuracy : 0.73478 \nEpoch: 1730  | Training Loss: 0.34831 \nEpoch: 1730  | Training Loss: 0.41728 \nEpoch: 1730  | Training Loss: 0.35681 \nEpoch: 1730  | Training Loss: 0.29306 \nEpoch: 1730  | Training Loss: 0.25637 \nEpoch: 1730  | Validation balanced accuracy : 0.73478 \nEpoch: 1731  | Training Loss: 0.34817 \nEpoch: 1731  | Training Loss: 0.41711 \nEpoch: 1731  | Training Loss: 0.35671 \nEpoch: 1731  | Training Loss: 0.29292 \nEpoch: 1731  | Training Loss: 0.25636 \nEpoch: 1731  | Validation balanced accuracy : 0.73478 \nEpoch: 1732  | Training Loss: 0.34802 \nEpoch: 1732  | Training Loss: 0.41694 \nEpoch: 1732  | Training Loss: 0.35661 \nEpoch: 1732  | Training Loss: 0.29278 \nEpoch: 1732  | Training Loss: 0.25636 \nEpoch: 1732  | Validation balanced accuracy : 0.73478 \nEpoch: 1733  | Training Loss: 0.34787 \nEpoch: 1733  | Training Loss: 0.41677 \nEpoch: 1733  | Training Loss: 0.35651 \nEpoch: 1733  | Training Loss: 0.29264 \nEpoch: 1733  | Training Loss: 0.25635 \nEpoch: 1733  | Validation balanced accuracy : 0.73478 \nEpoch: 1734  | Training Loss: 0.34772 \nEpoch: 1734  | Training Loss: 0.41661 \nEpoch: 1734  | Training Loss: 0.35641 \nEpoch: 1734  | Training Loss: 0.29250 \nEpoch: 1734  | Training Loss: 0.25633 \nEpoch: 1734  | Validation balanced accuracy : 0.78478 \nEpoch: 1735  | Training Loss: 0.34758 \nEpoch: 1735  | Training Loss: 0.41645 \nEpoch: 1735  | Training Loss: 0.35630 \nEpoch: 1735  | Training Loss: 0.29236 \nEpoch: 1735  | Training Loss: 0.25630 \nEpoch: 1735  | Validation balanced accuracy : 0.78478 \nEpoch: 1736  | Training Loss: 0.34745 \nEpoch: 1736  | Training Loss: 0.41629 \nEpoch: 1736  | Training Loss: 0.35620 \nEpoch: 1736  | Training Loss: 0.29222 \nEpoch: 1736  | Training Loss: 0.25626 \nEpoch: 1736  | Validation balanced accuracy : 0.78478 \nEpoch: 1737  | Training Loss: 0.34732 \nEpoch: 1737  | Training Loss: 0.41614 \nEpoch: 1737  | Training Loss: 0.35610 \nEpoch: 1737  | Training Loss: 0.29208 \nEpoch: 1737  | Training Loss: 0.25622 \nEpoch: 1737  | Validation balanced accuracy : 0.78478 \nEpoch: 1738  | Training Loss: 0.34719 \nEpoch: 1738  | Training Loss: 0.41599 \nEpoch: 1738  | Training Loss: 0.35600 \nEpoch: 1738  | Training Loss: 0.29194 \nEpoch: 1738  | Training Loss: 0.25617 \nEpoch: 1738  | Validation balanced accuracy : 0.78478 \nEpoch: 1739  | Training Loss: 0.34707 \nEpoch: 1739  | Training Loss: 0.41584 \nEpoch: 1739  | Training Loss: 0.35590 \nEpoch: 1739  | Training Loss: 0.29180 \nEpoch: 1739  | Training Loss: 0.25613 \nEpoch: 1739  | Validation balanced accuracy : 0.78478 \nEpoch: 1740  | Training Loss: 0.34694 \nEpoch: 1740  | Training Loss: 0.41569 \nEpoch: 1740  | Training Loss: 0.35580 \nEpoch: 1740  | Training Loss: 0.29166 \nEpoch: 1740  | Training Loss: 0.25608 \nEpoch: 1740  | Validation balanced accuracy : 0.78478 \nEpoch: 1741  | Training Loss: 0.34681 \nEpoch: 1741  | Training Loss: 0.41554 \nEpoch: 1741  | Training Loss: 0.35570 \nEpoch: 1741  | Training Loss: 0.29152 \nEpoch: 1741  | Training Loss: 0.25604 \nEpoch: 1741  | Validation balanced accuracy : 0.78478 \nEpoch: 1742  | Training Loss: 0.34669 \nEpoch: 1742  | Training Loss: 0.41539 \nEpoch: 1742  | Training Loss: 0.35560 \nEpoch: 1742  | Training Loss: 0.29138 \nEpoch: 1742  | Training Loss: 0.25600 \nEpoch: 1742  | Validation balanced accuracy : 0.78478 \nEpoch: 1743  | Training Loss: 0.34656 \nEpoch: 1743  | Training Loss: 0.41523 \nEpoch: 1743  | Training Loss: 0.35550 \nEpoch: 1743  | Training Loss: 0.29124 \nEpoch: 1743  | Training Loss: 0.25596 \nEpoch: 1743  | Validation balanced accuracy : 0.78478 \nEpoch: 1744  | Training Loss: 0.34643 \nEpoch: 1744  | Training Loss: 0.41508 \nEpoch: 1744  | Training Loss: 0.35540 \nEpoch: 1744  | Training Loss: 0.29110 \nEpoch: 1744  | Training Loss: 0.25592 \nEpoch: 1744  | Validation balanced accuracy : 0.78478 \nEpoch: 1745  | Training Loss: 0.34630 \nEpoch: 1745  | Training Loss: 0.41493 \nEpoch: 1745  | Training Loss: 0.35530 \nEpoch: 1745  | Training Loss: 0.29096 \nEpoch: 1745  | Training Loss: 0.25588 \nEpoch: 1745  | Validation balanced accuracy : 0.78478 \nEpoch: 1746  | Training Loss: 0.34617 \nEpoch: 1746  | Training Loss: 0.41477 \nEpoch: 1746  | Training Loss: 0.35520 \nEpoch: 1746  | Training Loss: 0.29082 \nEpoch: 1746  | Training Loss: 0.25585 \nEpoch: 1746  | Validation balanced accuracy : 0.78478 \nEpoch: 1747  | Training Loss: 0.34603 \nEpoch: 1747  | Training Loss: 0.41461 \nEpoch: 1747  | Training Loss: 0.35510 \nEpoch: 1747  | Training Loss: 0.29068 \nEpoch: 1747  | Training Loss: 0.25584 \nEpoch: 1747  | Validation balanced accuracy : 0.78478 \nEpoch: 1748  | Training Loss: 0.34588 \nEpoch: 1748  | Training Loss: 0.41444 \nEpoch: 1748  | Training Loss: 0.35500 \nEpoch: 1748  | Training Loss: 0.29054 \nEpoch: 1748  | Training Loss: 0.25584 \nEpoch: 1748  | Validation balanced accuracy : 0.78478 \nEpoch: 1749  | Training Loss: 0.34573 \nEpoch: 1749  | Training Loss: 0.41428 \nEpoch: 1749  | Training Loss: 0.35490 \nEpoch: 1749  | Training Loss: 0.29040 \nEpoch: 1749  | Training Loss: 0.25583 \nEpoch: 1749  | Validation balanced accuracy : 0.78478 \nEpoch: 1750  | Training Loss: 0.34559 \nEpoch: 1750  | Training Loss: 0.41411 \nEpoch: 1750  | Training Loss: 0.35480 \nEpoch: 1750  | Training Loss: 0.29027 \nEpoch: 1750  | Training Loss: 0.25581 \nEpoch: 1750  | Validation balanced accuracy : 0.78478 \nEpoch: 1751  | Training Loss: 0.34545 \nEpoch: 1751  | Training Loss: 0.41395 \nEpoch: 1751  | Training Loss: 0.35471 \nEpoch: 1751  | Training Loss: 0.29013 \nEpoch: 1751  | Training Loss: 0.25578 \nEpoch: 1751  | Validation balanced accuracy : 0.78478 \nEpoch: 1752  | Training Loss: 0.34532 \nEpoch: 1752  | Training Loss: 0.41380 \nEpoch: 1752  | Training Loss: 0.35461 \nEpoch: 1752  | Training Loss: 0.28999 \nEpoch: 1752  | Training Loss: 0.25574 \nEpoch: 1752  | Validation balanced accuracy : 0.78478 \nEpoch: 1753  | Training Loss: 0.34519 \nEpoch: 1753  | Training Loss: 0.41365 \nEpoch: 1753  | Training Loss: 0.35451 \nEpoch: 1753  | Training Loss: 0.28985 \nEpoch: 1753  | Training Loss: 0.25569 \nEpoch: 1753  | Validation balanced accuracy : 0.78478 \nEpoch: 1754  | Training Loss: 0.34507 \nEpoch: 1754  | Training Loss: 0.41350 \nEpoch: 1754  | Training Loss: 0.35441 \nEpoch: 1754  | Training Loss: 0.28971 \nEpoch: 1754  | Training Loss: 0.25564 \nEpoch: 1754  | Validation balanced accuracy : 0.78478 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1755  | Training Loss: 0.34495 \nEpoch: 1755  | Training Loss: 0.41336 \nEpoch: 1755  | Training Loss: 0.35431 \nEpoch: 1755  | Training Loss: 0.28957 \nEpoch: 1755  | Training Loss: 0.25559 \nEpoch: 1755  | Validation balanced accuracy : 0.78478 \nEpoch: 1756  | Training Loss: 0.34483 \nEpoch: 1756  | Training Loss: 0.41321 \nEpoch: 1756  | Training Loss: 0.35421 \nEpoch: 1756  | Training Loss: 0.28944 \nEpoch: 1756  | Training Loss: 0.25554 \nEpoch: 1756  | Validation balanced accuracy : 0.78478 \nEpoch: 1757  | Training Loss: 0.34470 \nEpoch: 1757  | Training Loss: 0.41306 \nEpoch: 1757  | Training Loss: 0.35411 \nEpoch: 1757  | Training Loss: 0.28930 \nEpoch: 1757  | Training Loss: 0.25550 \nEpoch: 1757  | Validation balanced accuracy : 0.78478 \nEpoch: 1758  | Training Loss: 0.34458 \nEpoch: 1758  | Training Loss: 0.41291 \nEpoch: 1758  | Training Loss: 0.35402 \nEpoch: 1758  | Training Loss: 0.28916 \nEpoch: 1758  | Training Loss: 0.25545 \nEpoch: 1758  | Validation balanced accuracy : 0.78478 \nEpoch: 1759  | Training Loss: 0.34445 \nEpoch: 1759  | Training Loss: 0.41276 \nEpoch: 1759  | Training Loss: 0.35392 \nEpoch: 1759  | Training Loss: 0.28902 \nEpoch: 1759  | Training Loss: 0.25541 \nEpoch: 1759  | Validation balanced accuracy : 0.78478 \nEpoch: 1760  | Training Loss: 0.34433 \nEpoch: 1760  | Training Loss: 0.41261 \nEpoch: 1760  | Training Loss: 0.35382 \nEpoch: 1760  | Training Loss: 0.28889 \nEpoch: 1760  | Training Loss: 0.25537 \nEpoch: 1760  | Validation balanced accuracy : 0.78478 \nEpoch: 1761  | Training Loss: 0.34420 \nEpoch: 1761  | Training Loss: 0.41246 \nEpoch: 1761  | Training Loss: 0.35372 \nEpoch: 1761  | Training Loss: 0.28875 \nEpoch: 1761  | Training Loss: 0.25533 \nEpoch: 1761  | Validation balanced accuracy : 0.78478 \nEpoch: 1762  | Training Loss: 0.34407 \nEpoch: 1762  | Training Loss: 0.41231 \nEpoch: 1762  | Training Loss: 0.35362 \nEpoch: 1762  | Training Loss: 0.28861 \nEpoch: 1762  | Training Loss: 0.25528 \nEpoch: 1762  | Validation balanced accuracy : 0.78478 \nEpoch: 1763  | Training Loss: 0.34395 \nEpoch: 1763  | Training Loss: 0.41216 \nEpoch: 1763  | Training Loss: 0.35353 \nEpoch: 1763  | Training Loss: 0.28847 \nEpoch: 1763  | Training Loss: 0.25524 \nEpoch: 1763  | Validation balanced accuracy : 0.78478 \nEpoch: 1764  | Training Loss: 0.34382 \nEpoch: 1764  | Training Loss: 0.41201 \nEpoch: 1764  | Training Loss: 0.35343 \nEpoch: 1764  | Training Loss: 0.28834 \nEpoch: 1764  | Training Loss: 0.25519 \nEpoch: 1764  | Validation balanced accuracy : 0.78478 \nEpoch: 1765  | Training Loss: 0.34370 \nEpoch: 1765  | Training Loss: 0.41186 \nEpoch: 1765  | Training Loss: 0.35333 \nEpoch: 1765  | Training Loss: 0.28820 \nEpoch: 1765  | Training Loss: 0.25515 \nEpoch: 1765  | Validation balanced accuracy : 0.78478 \nEpoch: 1766  | Training Loss: 0.34357 \nEpoch: 1766  | Training Loss: 0.41171 \nEpoch: 1766  | Training Loss: 0.35324 \nEpoch: 1766  | Training Loss: 0.28806 \nEpoch: 1766  | Training Loss: 0.25510 \nEpoch: 1766  | Validation balanced accuracy : 0.78478 \nEpoch: 1767  | Training Loss: 0.34345 \nEpoch: 1767  | Training Loss: 0.41156 \nEpoch: 1767  | Training Loss: 0.35314 \nEpoch: 1767  | Training Loss: 0.28793 \nEpoch: 1767  | Training Loss: 0.25506 \nEpoch: 1767  | Validation balanced accuracy : 0.78478 \nEpoch: 1768  | Training Loss: 0.34333 \nEpoch: 1768  | Training Loss: 0.41141 \nEpoch: 1768  | Training Loss: 0.35304 \nEpoch: 1768  | Training Loss: 0.28779 \nEpoch: 1768  | Training Loss: 0.25501 \nEpoch: 1768  | Validation balanced accuracy : 0.78478 \nEpoch: 1769  | Training Loss: 0.34320 \nEpoch: 1769  | Training Loss: 0.41126 \nEpoch: 1769  | Training Loss: 0.35294 \nEpoch: 1769  | Training Loss: 0.28765 \nEpoch: 1769  | Training Loss: 0.25497 \nEpoch: 1769  | Validation balanced accuracy : 0.78478 \nEpoch: 1770  | Training Loss: 0.34308 \nEpoch: 1770  | Training Loss: 0.41112 \nEpoch: 1770  | Training Loss: 0.35285 \nEpoch: 1770  | Training Loss: 0.28752 \nEpoch: 1770  | Training Loss: 0.25492 \nEpoch: 1770  | Validation balanced accuracy : 0.78478 \nEpoch: 1771  | Training Loss: 0.34295 \nEpoch: 1771  | Training Loss: 0.41097 \nEpoch: 1771  | Training Loss: 0.35275 \nEpoch: 1771  | Training Loss: 0.28738 \nEpoch: 1771  | Training Loss: 0.25487 \nEpoch: 1771  | Validation balanced accuracy : 0.78478 \nEpoch: 1772  | Training Loss: 0.34283 \nEpoch: 1772  | Training Loss: 0.41082 \nEpoch: 1772  | Training Loss: 0.35265 \nEpoch: 1772  | Training Loss: 0.28724 \nEpoch: 1772  | Training Loss: 0.25483 \nEpoch: 1772  | Validation balanced accuracy : 0.78478 \nEpoch: 1773  | Training Loss: 0.34271 \nEpoch: 1773  | Training Loss: 0.41067 \nEpoch: 1773  | Training Loss: 0.35256 \nEpoch: 1773  | Training Loss: 0.28711 \nEpoch: 1773  | Training Loss: 0.25478 \nEpoch: 1773  | Validation balanced accuracy : 0.78478 \nEpoch: 1774  | Training Loss: 0.34259 \nEpoch: 1774  | Training Loss: 0.41052 \nEpoch: 1774  | Training Loss: 0.35246 \nEpoch: 1774  | Training Loss: 0.28697 \nEpoch: 1774  | Training Loss: 0.25473 \nEpoch: 1774  | Validation balanced accuracy : 0.78478 \nEpoch: 1775  | Training Loss: 0.34246 \nEpoch: 1775  | Training Loss: 0.41037 \nEpoch: 1775  | Training Loss: 0.35237 \nEpoch: 1775  | Training Loss: 0.28684 \nEpoch: 1775  | Training Loss: 0.25468 \nEpoch: 1775  | Validation balanced accuracy : 0.76304 \nEpoch: 1776  | Training Loss: 0.34234 \nEpoch: 1776  | Training Loss: 0.41023 \nEpoch: 1776  | Training Loss: 0.35227 \nEpoch: 1776  | Training Loss: 0.28670 \nEpoch: 1776  | Training Loss: 0.25464 \nEpoch: 1776  | Validation balanced accuracy : 0.76304 \nEpoch: 1777  | Training Loss: 0.34222 \nEpoch: 1777  | Training Loss: 0.41008 \nEpoch: 1777  | Training Loss: 0.35217 \nEpoch: 1777  | Training Loss: 0.28656 \nEpoch: 1777  | Training Loss: 0.25459 \nEpoch: 1777  | Validation balanced accuracy : 0.76304 \nEpoch: 1778  | Training Loss: 0.34210 \nEpoch: 1778  | Training Loss: 0.40993 \nEpoch: 1778  | Training Loss: 0.35208 \nEpoch: 1778  | Training Loss: 0.28643 \nEpoch: 1778  | Training Loss: 0.25454 \nEpoch: 1778  | Validation balanced accuracy : 0.76304 \nEpoch: 1779  | Training Loss: 0.34197 \nEpoch: 1779  | Training Loss: 0.40978 \nEpoch: 1779  | Training Loss: 0.35198 \nEpoch: 1779  | Training Loss: 0.28629 \nEpoch: 1779  | Training Loss: 0.25449 \nEpoch: 1779  | Validation balanced accuracy : 0.76304 \nEpoch: 1780  | Training Loss: 0.34185 \nEpoch: 1780  | Training Loss: 0.40964 \nEpoch: 1780  | Training Loss: 0.35189 \nEpoch: 1780  | Training Loss: 0.28616 \nEpoch: 1780  | Training Loss: 0.25444 \nEpoch: 1780  | Validation balanced accuracy : 0.76304 \nEpoch: 1781  | Training Loss: 0.34173 \nEpoch: 1781  | Training Loss: 0.40949 \nEpoch: 1781  | Training Loss: 0.35179 \nEpoch: 1781  | Training Loss: 0.28602 \nEpoch: 1781  | Training Loss: 0.25440 \nEpoch: 1781  | Validation balanced accuracy : 0.76304 \nEpoch: 1782  | Training Loss: 0.34161 \nEpoch: 1782  | Training Loss: 0.40934 \nEpoch: 1782  | Training Loss: 0.35170 \nEpoch: 1782  | Training Loss: 0.28589 \nEpoch: 1782  | Training Loss: 0.25435 \nEpoch: 1782  | Validation balanced accuracy : 0.76304 \nEpoch: 1783  | Training Loss: 0.34149 \nEpoch: 1783  | Training Loss: 0.40919 \nEpoch: 1783  | Training Loss: 0.35160 \nEpoch: 1783  | Training Loss: 0.28575 \nEpoch: 1783  | Training Loss: 0.25430 \nEpoch: 1783  | Validation balanced accuracy : 0.76304 \nEpoch: 1784  | Training Loss: 0.34137 \nEpoch: 1784  | Training Loss: 0.40905 \nEpoch: 1784  | Training Loss: 0.35151 \nEpoch: 1784  | Training Loss: 0.28562 \nEpoch: 1784  | Training Loss: 0.25425 \nEpoch: 1784  | Validation balanced accuracy : 0.76304 \nEpoch: 1785  | Training Loss: 0.34125 \nEpoch: 1785  | Training Loss: 0.40890 \nEpoch: 1785  | Training Loss: 0.35141 \nEpoch: 1785  | Training Loss: 0.28548 \nEpoch: 1785  | Training Loss: 0.25420 \nEpoch: 1785  | Validation balanced accuracy : 0.76304 \nEpoch: 1786  | Training Loss: 0.34113 \nEpoch: 1786  | Training Loss: 0.40875 \nEpoch: 1786  | Training Loss: 0.35132 \nEpoch: 1786  | Training Loss: 0.28535 \nEpoch: 1786  | Training Loss: 0.25415 \nEpoch: 1786  | Validation balanced accuracy : 0.76304 \nEpoch: 1787  | Training Loss: 0.34101 \nEpoch: 1787  | Training Loss: 0.40861 \nEpoch: 1787  | Training Loss: 0.35122 \nEpoch: 1787  | Training Loss: 0.28521 \nEpoch: 1787  | Training Loss: 0.25410 \nEpoch: 1787  | Validation balanced accuracy : 0.76304 \nEpoch: 1788  | Training Loss: 0.34089 \nEpoch: 1788  | Training Loss: 0.40846 \nEpoch: 1788  | Training Loss: 0.35113 \nEpoch: 1788  | Training Loss: 0.28508 \nEpoch: 1788  | Training Loss: 0.25405 \nEpoch: 1788  | Validation balanced accuracy : 0.76304 \nEpoch: 1789  | Training Loss: 0.34077 \nEpoch: 1789  | Training Loss: 0.40832 \nEpoch: 1789  | Training Loss: 0.35104 \nEpoch: 1789  | Training Loss: 0.28494 \nEpoch: 1789  | Training Loss: 0.25400 \nEpoch: 1789  | Validation balanced accuracy : 0.76304 \nEpoch: 1790  | Training Loss: 0.34065 \nEpoch: 1790  | Training Loss: 0.40817 \nEpoch: 1790  | Training Loss: 0.35094 \nEpoch: 1790  | Training Loss: 0.28481 \nEpoch: 1790  | Training Loss: 0.25394 \nEpoch: 1790  | Validation balanced accuracy : 0.76304 \nEpoch: 1791  | Training Loss: 0.34053 \nEpoch: 1791  | Training Loss: 0.40802 \nEpoch: 1791  | Training Loss: 0.35085 \nEpoch: 1791  | Training Loss: 0.28468 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1791  | Training Loss: 0.25389 \nEpoch: 1791  | Validation balanced accuracy : 0.76304 \nEpoch: 1792  | Training Loss: 0.34041 \nEpoch: 1792  | Training Loss: 0.40788 \nEpoch: 1792  | Training Loss: 0.35075 \nEpoch: 1792  | Training Loss: 0.28454 \nEpoch: 1792  | Training Loss: 0.25384 \nEpoch: 1792  | Validation balanced accuracy : 0.76304 \nEpoch: 1793  | Training Loss: 0.34029 \nEpoch: 1793  | Training Loss: 0.40773 \nEpoch: 1793  | Training Loss: 0.35066 \nEpoch: 1793  | Training Loss: 0.28441 \nEpoch: 1793  | Training Loss: 0.25379 \nEpoch: 1793  | Validation balanced accuracy : 0.76304 \nEpoch: 1794  | Training Loss: 0.34017 \nEpoch: 1794  | Training Loss: 0.40759 \nEpoch: 1794  | Training Loss: 0.35057 \nEpoch: 1794  | Training Loss: 0.28427 \nEpoch: 1794  | Training Loss: 0.25374 \nEpoch: 1794  | Validation balanced accuracy : 0.76304 \nEpoch: 1795  | Training Loss: 0.34005 \nEpoch: 1795  | Training Loss: 0.40744 \nEpoch: 1795  | Training Loss: 0.35047 \nEpoch: 1795  | Training Loss: 0.28414 \nEpoch: 1795  | Training Loss: 0.25369 \nEpoch: 1795  | Validation balanced accuracy : 0.76304 \nEpoch: 1796  | Training Loss: 0.33993 \nEpoch: 1796  | Training Loss: 0.40730 \nEpoch: 1796  | Training Loss: 0.35038 \nEpoch: 1796  | Training Loss: 0.28401 \nEpoch: 1796  | Training Loss: 0.25363 \nEpoch: 1796  | Validation balanced accuracy : 0.76304 \nEpoch: 1797  | Training Loss: 0.33981 \nEpoch: 1797  | Training Loss: 0.40715 \nEpoch: 1797  | Training Loss: 0.35029 \nEpoch: 1797  | Training Loss: 0.28387 \nEpoch: 1797  | Training Loss: 0.25358 \nEpoch: 1797  | Validation balanced accuracy : 0.76304 \nEpoch: 1798  | Training Loss: 0.33969 \nEpoch: 1798  | Training Loss: 0.40701 \nEpoch: 1798  | Training Loss: 0.35019 \nEpoch: 1798  | Training Loss: 0.28374 \nEpoch: 1798  | Training Loss: 0.25353 \nEpoch: 1798  | Validation balanced accuracy : 0.76304 \nEpoch: 1799  | Training Loss: 0.33958 \nEpoch: 1799  | Training Loss: 0.40686 \nEpoch: 1799  | Training Loss: 0.35010 \nEpoch: 1799  | Training Loss: 0.28360 \nEpoch: 1799  | Training Loss: 0.25348 \nEpoch: 1799  | Validation balanced accuracy : 0.76304 \nEpoch: 1800  | Training Loss: 0.33946 \nEpoch: 1800  | Training Loss: 0.40672 \nEpoch: 1800  | Training Loss: 0.35001 \nEpoch: 1800  | Training Loss: 0.28347 \nEpoch: 1800  | Training Loss: 0.25342 \nEpoch: 1800  | Validation balanced accuracy : 0.76304 \nEpoch: 1801  | Training Loss: 0.33934 \nEpoch: 1801  | Training Loss: 0.40655 \nEpoch: 1801  | Training Loss: 0.34992 \nEpoch: 1801  | Training Loss: 0.28334 \nEpoch: 1801  | Training Loss: 0.25307 \nEpoch: 1801  | Validation balanced accuracy : 0.76304 \nEpoch: 1802  | Training Loss: 0.33923 \nEpoch: 1802  | Training Loss: 0.40642 \nEpoch: 1802  | Training Loss: 0.34984 \nEpoch: 1802  | Training Loss: 0.28322 \nEpoch: 1802  | Training Loss: 0.25304 \nEpoch: 1802  | Validation balanced accuracy : 0.76304 \nEpoch: 1803  | Training Loss: 0.33911 \nEpoch: 1803  | Training Loss: 0.40627 \nEpoch: 1803  | Training Loss: 0.34975 \nEpoch: 1803  | Training Loss: 0.28310 \nEpoch: 1803  | Training Loss: 0.25302 \nEpoch: 1803  | Validation balanced accuracy : 0.76304 \nEpoch: 1804  | Training Loss: 0.33899 \nEpoch: 1804  | Training Loss: 0.40613 \nEpoch: 1804  | Training Loss: 0.34967 \nEpoch: 1804  | Training Loss: 0.28298 \nEpoch: 1804  | Training Loss: 0.25300 \nEpoch: 1804  | Validation balanced accuracy : 0.76304 \nEpoch: 1805  | Training Loss: 0.33887 \nEpoch: 1805  | Training Loss: 0.40599 \nEpoch: 1805  | Training Loss: 0.34959 \nEpoch: 1805  | Training Loss: 0.28286 \nEpoch: 1805  | Training Loss: 0.25297 \nEpoch: 1805  | Validation balanced accuracy : 0.76304 \nEpoch: 1806  | Training Loss: 0.33875 \nEpoch: 1806  | Training Loss: 0.40585 \nEpoch: 1806  | Training Loss: 0.34950 \nEpoch: 1806  | Training Loss: 0.28274 \nEpoch: 1806  | Training Loss: 0.25293 \nEpoch: 1806  | Validation balanced accuracy : 0.76304 \nEpoch: 1807  | Training Loss: 0.33864 \nEpoch: 1807  | Training Loss: 0.40572 \nEpoch: 1807  | Training Loss: 0.34942 \nEpoch: 1807  | Training Loss: 0.28263 \nEpoch: 1807  | Training Loss: 0.25288 \nEpoch: 1807  | Validation balanced accuracy : 0.76304 \nEpoch: 1808  | Training Loss: 0.33854 \nEpoch: 1808  | Training Loss: 0.40559 \nEpoch: 1808  | Training Loss: 0.34934 \nEpoch: 1808  | Training Loss: 0.28251 \nEpoch: 1808  | Training Loss: 0.25283 \nEpoch: 1808  | Validation balanced accuracy : 0.76304 \nEpoch: 1809  | Training Loss: 0.33843 \nEpoch: 1809  | Training Loss: 0.40546 \nEpoch: 1809  | Training Loss: 0.34925 \nEpoch: 1809  | Training Loss: 0.28239 \nEpoch: 1809  | Training Loss: 0.25277 \nEpoch: 1809  | Validation balanced accuracy : 0.76304 \nEpoch: 1810  | Training Loss: 0.33833 \nEpoch: 1810  | Training Loss: 0.40534 \nEpoch: 1810  | Training Loss: 0.34917 \nEpoch: 1810  | Training Loss: 0.28227 \nEpoch: 1810  | Training Loss: 0.25271 \nEpoch: 1810  | Validation balanced accuracy : 0.76304 \nEpoch: 1811  | Training Loss: 0.33823 \nEpoch: 1811  | Training Loss: 0.40521 \nEpoch: 1811  | Training Loss: 0.34909 \nEpoch: 1811  | Training Loss: 0.28215 \nEpoch: 1811  | Training Loss: 0.25266 \nEpoch: 1811  | Validation balanced accuracy : 0.76304 \nEpoch: 1812  | Training Loss: 0.33813 \nEpoch: 1812  | Training Loss: 0.40508 \nEpoch: 1812  | Training Loss: 0.34901 \nEpoch: 1812  | Training Loss: 0.28203 \nEpoch: 1812  | Training Loss: 0.25261 \nEpoch: 1812  | Validation balanced accuracy : 0.76304 \nEpoch: 1813  | Training Loss: 0.33803 \nEpoch: 1813  | Training Loss: 0.40495 \nEpoch: 1813  | Training Loss: 0.34893 \nEpoch: 1813  | Training Loss: 0.28191 \nEpoch: 1813  | Training Loss: 0.25255 \nEpoch: 1813  | Validation balanced accuracy : 0.76304 \nEpoch: 1814  | Training Loss: 0.33792 \nEpoch: 1814  | Training Loss: 0.40483 \nEpoch: 1814  | Training Loss: 0.34884 \nEpoch: 1814  | Training Loss: 0.28179 \nEpoch: 1814  | Training Loss: 0.25250 \nEpoch: 1814  | Validation balanced accuracy : 0.76304 \nEpoch: 1815  | Training Loss: 0.33782 \nEpoch: 1815  | Training Loss: 0.40470 \nEpoch: 1815  | Training Loss: 0.34876 \nEpoch: 1815  | Training Loss: 0.28167 \nEpoch: 1815  | Training Loss: 0.25245 \nEpoch: 1815  | Validation balanced accuracy : 0.76304 \nEpoch: 1816  | Training Loss: 0.33771 \nEpoch: 1816  | Training Loss: 0.40457 \nEpoch: 1816  | Training Loss: 0.34868 \nEpoch: 1816  | Training Loss: 0.28155 \nEpoch: 1816  | Training Loss: 0.25240 \nEpoch: 1816  | Validation balanced accuracy : 0.76304 \nEpoch: 1817  | Training Loss: 0.33761 \nEpoch: 1817  | Training Loss: 0.40444 \nEpoch: 1817  | Training Loss: 0.34860 \nEpoch: 1817  | Training Loss: 0.28143 \nEpoch: 1817  | Training Loss: 0.25235 \nEpoch: 1817  | Validation balanced accuracy : 0.76304 \nEpoch: 1818  | Training Loss: 0.33750 \nEpoch: 1818  | Training Loss: 0.40431 \nEpoch: 1818  | Training Loss: 0.34852 \nEpoch: 1818  | Training Loss: 0.28131 \nEpoch: 1818  | Training Loss: 0.25230 \nEpoch: 1818  | Validation balanced accuracy : 0.76304 \nEpoch: 1819  | Training Loss: 0.33740 \nEpoch: 1819  | Training Loss: 0.40418 \nEpoch: 1819  | Training Loss: 0.34843 \nEpoch: 1819  | Training Loss: 0.28119 \nEpoch: 1819  | Training Loss: 0.25225 \nEpoch: 1819  | Validation balanced accuracy : 0.76304 \nEpoch: 1820  | Training Loss: 0.33730 \nEpoch: 1820  | Training Loss: 0.40405 \nEpoch: 1820  | Training Loss: 0.34835 \nEpoch: 1820  | Training Loss: 0.28107 \nEpoch: 1820  | Training Loss: 0.25219 \nEpoch: 1820  | Validation balanced accuracy : 0.76304 \nEpoch: 1821  | Training Loss: 0.33719 \nEpoch: 1821  | Training Loss: 0.40392 \nEpoch: 1821  | Training Loss: 0.34827 \nEpoch: 1821  | Training Loss: 0.28096 \nEpoch: 1821  | Training Loss: 0.25214 \nEpoch: 1821  | Validation balanced accuracy : 0.76304 \nEpoch: 1822  | Training Loss: 0.33709 \nEpoch: 1822  | Training Loss: 0.40379 \nEpoch: 1822  | Training Loss: 0.34819 \nEpoch: 1822  | Training Loss: 0.28084 \nEpoch: 1822  | Training Loss: 0.25209 \nEpoch: 1822  | Validation balanced accuracy : 0.76304 \nEpoch: 1823  | Training Loss: 0.33699 \nEpoch: 1823  | Training Loss: 0.40367 \nEpoch: 1823  | Training Loss: 0.34811 \nEpoch: 1823  | Training Loss: 0.28072 \nEpoch: 1823  | Training Loss: 0.25203 \nEpoch: 1823  | Validation balanced accuracy : 0.76304 \nEpoch: 1824  | Training Loss: 0.33689 \nEpoch: 1824  | Training Loss: 0.40354 \nEpoch: 1824  | Training Loss: 0.34803 \nEpoch: 1824  | Training Loss: 0.28060 \nEpoch: 1824  | Training Loss: 0.25198 \nEpoch: 1824  | Validation balanced accuracy : 0.76304 \nEpoch: 1825  | Training Loss: 0.33678 \nEpoch: 1825  | Training Loss: 0.40341 \nEpoch: 1825  | Training Loss: 0.34795 \nEpoch: 1825  | Training Loss: 0.28048 \nEpoch: 1825  | Training Loss: 0.25192 \nEpoch: 1825  | Validation balanced accuracy : 0.76304 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1826  | Training Loss: 0.33668 \nEpoch: 1826  | Training Loss: 0.40328 \nEpoch: 1826  | Training Loss: 0.34787 \nEpoch: 1826  | Training Loss: 0.28036 \nEpoch: 1826  | Training Loss: 0.25187 \nEpoch: 1826  | Validation balanced accuracy : 0.76304 \nEpoch: 1827  | Training Loss: 0.33658 \nEpoch: 1827  | Training Loss: 0.40315 \nEpoch: 1827  | Training Loss: 0.34779 \nEpoch: 1827  | Training Loss: 0.28024 \nEpoch: 1827  | Training Loss: 0.25182 \nEpoch: 1827  | Validation balanced accuracy : 0.76304 \nEpoch: 1828  | Training Loss: 0.33648 \nEpoch: 1828  | Training Loss: 0.40303 \nEpoch: 1828  | Training Loss: 0.34771 \nEpoch: 1828  | Training Loss: 0.28013 \nEpoch: 1828  | Training Loss: 0.25176 \nEpoch: 1828  | Validation balanced accuracy : 0.76304 \nEpoch: 1829  | Training Loss: 0.33637 \nEpoch: 1829  | Training Loss: 0.40290 \nEpoch: 1829  | Training Loss: 0.34762 \nEpoch: 1829  | Training Loss: 0.28001 \nEpoch: 1829  | Training Loss: 0.25173 \nEpoch: 1829  | Validation balanced accuracy : 0.76304 \nEpoch: 1830  | Training Loss: 0.33626 \nEpoch: 1830  | Training Loss: 0.40276 \nEpoch: 1830  | Training Loss: 0.34754 \nEpoch: 1830  | Training Loss: 0.27989 \nEpoch: 1830  | Training Loss: 0.25172 \nEpoch: 1830  | Validation balanced accuracy : 0.76304 \nEpoch: 1831  | Training Loss: 0.33613 \nEpoch: 1831  | Training Loss: 0.40261 \nEpoch: 1831  | Training Loss: 0.34746 \nEpoch: 1831  | Training Loss: 0.27977 \nEpoch: 1831  | Training Loss: 0.25171 \nEpoch: 1831  | Validation balanced accuracy : 0.76304 \nEpoch: 1832  | Training Loss: 0.33601 \nEpoch: 1832  | Training Loss: 0.40247 \nEpoch: 1832  | Training Loss: 0.34738 \nEpoch: 1832  | Training Loss: 0.27966 \nEpoch: 1832  | Training Loss: 0.25169 \nEpoch: 1832  | Validation balanced accuracy : 0.76304 \nEpoch: 1833  | Training Loss: 0.33589 \nEpoch: 1833  | Training Loss: 0.40233 \nEpoch: 1833  | Training Loss: 0.34730 \nEpoch: 1833  | Training Loss: 0.27954 \nEpoch: 1833  | Training Loss: 0.25165 \nEpoch: 1833  | Validation balanced accuracy : 0.76304 \nEpoch: 1834  | Training Loss: 0.33578 \nEpoch: 1834  | Training Loss: 0.40220 \nEpoch: 1834  | Training Loss: 0.34722 \nEpoch: 1834  | Training Loss: 0.27942 \nEpoch: 1834  | Training Loss: 0.25160 \nEpoch: 1834  | Validation balanced accuracy : 0.76304 \nEpoch: 1835  | Training Loss: 0.33567 \nEpoch: 1835  | Training Loss: 0.40207 \nEpoch: 1835  | Training Loss: 0.34714 \nEpoch: 1835  | Training Loss: 0.27930 \nEpoch: 1835  | Training Loss: 0.25156 \nEpoch: 1835  | Validation balanced accuracy : 0.76304 \nEpoch: 1836  | Training Loss: 0.33556 \nEpoch: 1836  | Training Loss: 0.40194 \nEpoch: 1836  | Training Loss: 0.34706 \nEpoch: 1836  | Training Loss: 0.27918 \nEpoch: 1836  | Training Loss: 0.25154 \nEpoch: 1836  | Validation balanced accuracy : 0.76304 \nEpoch: 1837  | Training Loss: 0.33544 \nEpoch: 1837  | Training Loss: 0.40179 \nEpoch: 1837  | Training Loss: 0.34698 \nEpoch: 1837  | Training Loss: 0.27907 \nEpoch: 1837  | Training Loss: 0.25152 \nEpoch: 1837  | Validation balanced accuracy : 0.76304 \nEpoch: 1838  | Training Loss: 0.33532 \nEpoch: 1838  | Training Loss: 0.40165 \nEpoch: 1838  | Training Loss: 0.34690 \nEpoch: 1838  | Training Loss: 0.27895 \nEpoch: 1838  | Training Loss: 0.25149 \nEpoch: 1838  | Validation balanced accuracy : 0.76304 \nEpoch: 1839  | Training Loss: 0.33521 \nEpoch: 1839  | Training Loss: 0.40152 \nEpoch: 1839  | Training Loss: 0.34683 \nEpoch: 1839  | Training Loss: 0.27883 \nEpoch: 1839  | Training Loss: 0.25145 \nEpoch: 1839  | Validation balanced accuracy : 0.76304 \nEpoch: 1840  | Training Loss: 0.33510 \nEpoch: 1840  | Training Loss: 0.40139 \nEpoch: 1840  | Training Loss: 0.34675 \nEpoch: 1840  | Training Loss: 0.27872 \nEpoch: 1840  | Training Loss: 0.25140 \nEpoch: 1840  | Validation balanced accuracy : 0.76304 \nEpoch: 1841  | Training Loss: 0.33500 \nEpoch: 1841  | Training Loss: 0.40126 \nEpoch: 1841  | Training Loss: 0.34667 \nEpoch: 1841  | Training Loss: 0.27860 \nEpoch: 1841  | Training Loss: 0.25135 \nEpoch: 1841  | Validation balanced accuracy : 0.76304 \nEpoch: 1842  | Training Loss: 0.33490 \nEpoch: 1842  | Training Loss: 0.40114 \nEpoch: 1842  | Training Loss: 0.34659 \nEpoch: 1842  | Training Loss: 0.27848 \nEpoch: 1842  | Training Loss: 0.25128 \nEpoch: 1842  | Validation balanced accuracy : 0.76304 \nEpoch: 1843  | Training Loss: 0.33480 \nEpoch: 1843  | Training Loss: 0.40102 \nEpoch: 1843  | Training Loss: 0.34651 \nEpoch: 1843  | Training Loss: 0.27836 \nEpoch: 1843  | Training Loss: 0.25122 \nEpoch: 1843  | Validation balanced accuracy : 0.76304 \nEpoch: 1844  | Training Loss: 0.33471 \nEpoch: 1844  | Training Loss: 0.40090 \nEpoch: 1844  | Training Loss: 0.34643 \nEpoch: 1844  | Training Loss: 0.27825 \nEpoch: 1844  | Training Loss: 0.25116 \nEpoch: 1844  | Validation balanced accuracy : 0.76304 \nEpoch: 1845  | Training Loss: 0.33461 \nEpoch: 1845  | Training Loss: 0.40077 \nEpoch: 1845  | Training Loss: 0.34636 \nEpoch: 1845  | Training Loss: 0.27813 \nEpoch: 1845  | Training Loss: 0.25110 \nEpoch: 1845  | Validation balanced accuracy : 0.76304 \nEpoch: 1846  | Training Loss: 0.33451 \nEpoch: 1846  | Training Loss: 0.40065 \nEpoch: 1846  | Training Loss: 0.34628 \nEpoch: 1846  | Training Loss: 0.27801 \nEpoch: 1846  | Training Loss: 0.25104 \nEpoch: 1846  | Validation balanced accuracy : 0.76304 \nEpoch: 1847  | Training Loss: 0.33441 \nEpoch: 1847  | Training Loss: 0.40053 \nEpoch: 1847  | Training Loss: 0.34620 \nEpoch: 1847  | Training Loss: 0.27789 \nEpoch: 1847  | Training Loss: 0.25098 \nEpoch: 1847  | Validation balanced accuracy : 0.76304 \nEpoch: 1848  | Training Loss: 0.33432 \nEpoch: 1848  | Training Loss: 0.40040 \nEpoch: 1848  | Training Loss: 0.34612 \nEpoch: 1848  | Training Loss: 0.27778 \nEpoch: 1848  | Training Loss: 0.25092 \nEpoch: 1848  | Validation balanced accuracy : 0.76304 \nEpoch: 1849  | Training Loss: 0.33422 \nEpoch: 1849  | Training Loss: 0.40028 \nEpoch: 1849  | Training Loss: 0.34605 \nEpoch: 1849  | Training Loss: 0.27766 \nEpoch: 1849  | Training Loss: 0.25087 \nEpoch: 1849  | Validation balanced accuracy : 0.76304 \nEpoch: 1850  | Training Loss: 0.33412 \nEpoch: 1850  | Training Loss: 0.40015 \nEpoch: 1850  | Training Loss: 0.34597 \nEpoch: 1850  | Training Loss: 0.27754 \nEpoch: 1850  | Training Loss: 0.25081 \nEpoch: 1850  | Validation balanced accuracy : 0.76304 \nEpoch: 1851  | Training Loss: 0.33402 \nEpoch: 1851  | Training Loss: 0.40003 \nEpoch: 1851  | Training Loss: 0.34589 \nEpoch: 1851  | Training Loss: 0.27742 \nEpoch: 1851  | Training Loss: 0.25075 \nEpoch: 1851  | Validation balanced accuracy : 0.76304 \nEpoch: 1852  | Training Loss: 0.33392 \nEpoch: 1852  | Training Loss: 0.39990 \nEpoch: 1852  | Training Loss: 0.34581 \nEpoch: 1852  | Training Loss: 0.27731 \nEpoch: 1852  | Training Loss: 0.25070 \nEpoch: 1852  | Validation balanced accuracy : 0.76304 \nEpoch: 1853  | Training Loss: 0.33382 \nEpoch: 1853  | Training Loss: 0.39978 \nEpoch: 1853  | Training Loss: 0.34574 \nEpoch: 1853  | Training Loss: 0.27719 \nEpoch: 1853  | Training Loss: 0.25064 \nEpoch: 1853  | Validation balanced accuracy : 0.76304 \nEpoch: 1854  | Training Loss: 0.33372 \nEpoch: 1854  | Training Loss: 0.39966 \nEpoch: 1854  | Training Loss: 0.34566 \nEpoch: 1854  | Training Loss: 0.27707 \nEpoch: 1854  | Training Loss: 0.25058 \nEpoch: 1854  | Validation balanced accuracy : 0.76304 \nEpoch: 1855  | Training Loss: 0.33363 \nEpoch: 1855  | Training Loss: 0.39953 \nEpoch: 1855  | Training Loss: 0.34558 \nEpoch: 1855  | Training Loss: 0.27696 \nEpoch: 1855  | Training Loss: 0.25052 \nEpoch: 1855  | Validation balanced accuracy : 0.76304 \nEpoch: 1856  | Training Loss: 0.33353 \nEpoch: 1856  | Training Loss: 0.39941 \nEpoch: 1856  | Training Loss: 0.34551 \nEpoch: 1856  | Training Loss: 0.27684 \nEpoch: 1856  | Training Loss: 0.25046 \nEpoch: 1856  | Validation balanced accuracy : 0.76304 \nEpoch: 1857  | Training Loss: 0.33343 \nEpoch: 1857  | Training Loss: 0.39929 \nEpoch: 1857  | Training Loss: 0.34543 \nEpoch: 1857  | Training Loss: 0.27672 \nEpoch: 1857  | Training Loss: 0.25040 \nEpoch: 1857  | Validation balanced accuracy : 0.76304 \nEpoch: 1858  | Training Loss: 0.33333 \nEpoch: 1858  | Training Loss: 0.39917 \nEpoch: 1858  | Training Loss: 0.34535 \nEpoch: 1858  | Training Loss: 0.27661 \nEpoch: 1858  | Training Loss: 0.25034 \nEpoch: 1858  | Validation balanced accuracy : 0.76304 \nEpoch: 1859  | Training Loss: 0.33324 \nEpoch: 1859  | Training Loss: 0.39904 \nEpoch: 1859  | Training Loss: 0.34528 \nEpoch: 1859  | Training Loss: 0.27649 \nEpoch: 1859  | Training Loss: 0.25028 \nEpoch: 1859  | Validation balanced accuracy : 0.76304 \nEpoch: 1860  | Training Loss: 0.33314 \nEpoch: 1860  | Training Loss: 0.39892 \nEpoch: 1860  | Training Loss: 0.34520 \nEpoch: 1860  | Training Loss: 0.27638 \nEpoch: 1860  | Training Loss: 0.25022 \nEpoch: 1860  | Validation balanced accuracy : 0.76304 \nEpoch: 1861  | Training Loss: 0.33304 \nEpoch: 1861  | Training Loss: 0.39880 \nEpoch: 1861  | Training Loss: 0.34512 \nEpoch: 1861  | Training Loss: 0.27626 \nEpoch: 1861  | Training Loss: 0.25016 \nEpoch: 1861  | Validation balanced accuracy : 0.76304 \nEpoch: 1862  | Training Loss: 0.33295 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1862  | Training Loss: 0.39867 \nEpoch: 1862  | Training Loss: 0.34505 \nEpoch: 1862  | Training Loss: 0.27614 \nEpoch: 1862  | Training Loss: 0.25010 \nEpoch: 1862  | Validation balanced accuracy : 0.76304 \nEpoch: 1863  | Training Loss: 0.33285 \nEpoch: 1863  | Training Loss: 0.39855 \nEpoch: 1863  | Training Loss: 0.34497 \nEpoch: 1863  | Training Loss: 0.27603 \nEpoch: 1863  | Training Loss: 0.25004 \nEpoch: 1863  | Validation balanced accuracy : 0.76304 \nEpoch: 1864  | Training Loss: 0.33275 \nEpoch: 1864  | Training Loss: 0.39843 \nEpoch: 1864  | Training Loss: 0.34490 \nEpoch: 1864  | Training Loss: 0.27591 \nEpoch: 1864  | Training Loss: 0.24998 \nEpoch: 1864  | Validation balanced accuracy : 0.76304 \nEpoch: 1865  | Training Loss: 0.33266 \nEpoch: 1865  | Training Loss: 0.39831 \nEpoch: 1865  | Training Loss: 0.34482 \nEpoch: 1865  | Training Loss: 0.27579 \nEpoch: 1865  | Training Loss: 0.24993 \nEpoch: 1865  | Validation balanced accuracy : 0.76304 \nEpoch: 1866  | Training Loss: 0.33255 \nEpoch: 1866  | Training Loss: 0.39817 \nEpoch: 1866  | Training Loss: 0.34475 \nEpoch: 1866  | Training Loss: 0.27568 \nEpoch: 1866  | Training Loss: 0.24991 \nEpoch: 1866  | Validation balanced accuracy : 0.76304 \nEpoch: 1867  | Training Loss: 0.33243 \nEpoch: 1867  | Training Loss: 0.39803 \nEpoch: 1867  | Training Loss: 0.34467 \nEpoch: 1867  | Training Loss: 0.27557 \nEpoch: 1867  | Training Loss: 0.24989 \nEpoch: 1867  | Validation balanced accuracy : 0.76304 \nEpoch: 1868  | Training Loss: 0.33231 \nEpoch: 1868  | Training Loss: 0.39789 \nEpoch: 1868  | Training Loss: 0.34459 \nEpoch: 1868  | Training Loss: 0.27545 \nEpoch: 1868  | Training Loss: 0.24990 \nEpoch: 1868  | Validation balanced accuracy : 0.76304 \nEpoch: 1869  | Training Loss: 0.33218 \nEpoch: 1869  | Training Loss: 0.39774 \nEpoch: 1869  | Training Loss: 0.34452 \nEpoch: 1869  | Training Loss: 0.27534 \nEpoch: 1869  | Training Loss: 0.24991 \nEpoch: 1869  | Validation balanced accuracy : 0.76304 \nEpoch: 1870  | Training Loss: 0.33204 \nEpoch: 1870  | Training Loss: 0.39759 \nEpoch: 1870  | Training Loss: 0.34444 \nEpoch: 1870  | Training Loss: 0.27522 \nEpoch: 1870  | Training Loss: 0.24990 \nEpoch: 1870  | Validation balanced accuracy : 0.76304 \nEpoch: 1871  | Training Loss: 0.33192 \nEpoch: 1871  | Training Loss: 0.39744 \nEpoch: 1871  | Training Loss: 0.34437 \nEpoch: 1871  | Training Loss: 0.27511 \nEpoch: 1871  | Training Loss: 0.24988 \nEpoch: 1871  | Validation balanced accuracy : 0.76304 \nEpoch: 1872  | Training Loss: 0.33181 \nEpoch: 1872  | Training Loss: 0.39731 \nEpoch: 1872  | Training Loss: 0.34429 \nEpoch: 1872  | Training Loss: 0.27499 \nEpoch: 1872  | Training Loss: 0.24983 \nEpoch: 1872  | Validation balanced accuracy : 0.76304 \nEpoch: 1873  | Training Loss: 0.33171 \nEpoch: 1873  | Training Loss: 0.39719 \nEpoch: 1873  | Training Loss: 0.34422 \nEpoch: 1873  | Training Loss: 0.27488 \nEpoch: 1873  | Training Loss: 0.24976 \nEpoch: 1873  | Validation balanced accuracy : 0.76304 \nEpoch: 1874  | Training Loss: 0.33162 \nEpoch: 1874  | Training Loss: 0.39707 \nEpoch: 1874  | Training Loss: 0.34414 \nEpoch: 1874  | Training Loss: 0.27476 \nEpoch: 1874  | Training Loss: 0.24968 \nEpoch: 1874  | Validation balanced accuracy : 0.76304 \nEpoch: 1875  | Training Loss: 0.33153 \nEpoch: 1875  | Training Loss: 0.39696 \nEpoch: 1875  | Training Loss: 0.34407 \nEpoch: 1875  | Training Loss: 0.27465 \nEpoch: 1875  | Training Loss: 0.24961 \nEpoch: 1875  | Validation balanced accuracy : 0.76304 \nEpoch: 1876  | Training Loss: 0.33144 \nEpoch: 1876  | Training Loss: 0.39685 \nEpoch: 1876  | Training Loss: 0.34399 \nEpoch: 1876  | Training Loss: 0.27453 \nEpoch: 1876  | Training Loss: 0.24953 \nEpoch: 1876  | Validation balanced accuracy : 0.76304 \nEpoch: 1877  | Training Loss: 0.33136 \nEpoch: 1877  | Training Loss: 0.39673 \nEpoch: 1877  | Training Loss: 0.34392 \nEpoch: 1877  | Training Loss: 0.27442 \nEpoch: 1877  | Training Loss: 0.24947 \nEpoch: 1877  | Validation balanced accuracy : 0.76304 \nEpoch: 1878  | Training Loss: 0.33127 \nEpoch: 1878  | Training Loss: 0.39661 \nEpoch: 1878  | Training Loss: 0.34384 \nEpoch: 1878  | Training Loss: 0.27431 \nEpoch: 1878  | Training Loss: 0.24940 \nEpoch: 1878  | Validation balanced accuracy : 0.76304 \nEpoch: 1879  | Training Loss: 0.33117 \nEpoch: 1879  | Training Loss: 0.39649 \nEpoch: 1879  | Training Loss: 0.34377 \nEpoch: 1879  | Training Loss: 0.27419 \nEpoch: 1879  | Training Loss: 0.24934 \nEpoch: 1879  | Validation balanced accuracy : 0.76304 \nEpoch: 1880  | Training Loss: 0.33108 \nEpoch: 1880  | Training Loss: 0.39637 \nEpoch: 1880  | Training Loss: 0.34370 \nEpoch: 1880  | Training Loss: 0.27408 \nEpoch: 1880  | Training Loss: 0.24928 \nEpoch: 1880  | Validation balanced accuracy : 0.76304 \nEpoch: 1881  | Training Loss: 0.33098 \nEpoch: 1881  | Training Loss: 0.39625 \nEpoch: 1881  | Training Loss: 0.34362 \nEpoch: 1881  | Training Loss: 0.27396 \nEpoch: 1881  | Training Loss: 0.24922 \nEpoch: 1881  | Validation balanced accuracy : 0.76304 \nEpoch: 1882  | Training Loss: 0.33089 \nEpoch: 1882  | Training Loss: 0.39613 \nEpoch: 1882  | Training Loss: 0.34355 \nEpoch: 1882  | Training Loss: 0.27385 \nEpoch: 1882  | Training Loss: 0.24916 \nEpoch: 1882  | Validation balanced accuracy : 0.76304 \nEpoch: 1883  | Training Loss: 0.33079 \nEpoch: 1883  | Training Loss: 0.39601 \nEpoch: 1883  | Training Loss: 0.34347 \nEpoch: 1883  | Training Loss: 0.27373 \nEpoch: 1883  | Training Loss: 0.24910 \nEpoch: 1883  | Validation balanced accuracy : 0.76304 \nEpoch: 1884  | Training Loss: 0.33070 \nEpoch: 1884  | Training Loss: 0.39589 \nEpoch: 1884  | Training Loss: 0.34340 \nEpoch: 1884  | Training Loss: 0.27362 \nEpoch: 1884  | Training Loss: 0.24903 \nEpoch: 1884  | Validation balanced accuracy : 0.76304 \nEpoch: 1885  | Training Loss: 0.33061 \nEpoch: 1885  | Training Loss: 0.39577 \nEpoch: 1885  | Training Loss: 0.34333 \nEpoch: 1885  | Training Loss: 0.27351 \nEpoch: 1885  | Training Loss: 0.24897 \nEpoch: 1885  | Validation balanced accuracy : 0.76304 \nEpoch: 1886  | Training Loss: 0.33052 \nEpoch: 1886  | Training Loss: 0.39565 \nEpoch: 1886  | Training Loss: 0.34325 \nEpoch: 1886  | Training Loss: 0.27339 \nEpoch: 1886  | Training Loss: 0.24891 \nEpoch: 1886  | Validation balanced accuracy : 0.76304 \nEpoch: 1887  | Training Loss: 0.33042 \nEpoch: 1887  | Training Loss: 0.39554 \nEpoch: 1887  | Training Loss: 0.34318 \nEpoch: 1887  | Training Loss: 0.27328 \nEpoch: 1887  | Training Loss: 0.24884 \nEpoch: 1887  | Validation balanced accuracy : 0.76304 \nEpoch: 1888  | Training Loss: 0.33033 \nEpoch: 1888  | Training Loss: 0.39542 \nEpoch: 1888  | Training Loss: 0.34311 \nEpoch: 1888  | Training Loss: 0.27316 \nEpoch: 1888  | Training Loss: 0.24878 \nEpoch: 1888  | Validation balanced accuracy : 0.76304 \nEpoch: 1889  | Training Loss: 0.33024 \nEpoch: 1889  | Training Loss: 0.39530 \nEpoch: 1889  | Training Loss: 0.34303 \nEpoch: 1889  | Training Loss: 0.27305 \nEpoch: 1889  | Training Loss: 0.24871 \nEpoch: 1889  | Validation balanced accuracy : 0.76304 \nEpoch: 1890  | Training Loss: 0.33015 \nEpoch: 1890  | Training Loss: 0.39518 \nEpoch: 1890  | Training Loss: 0.34296 \nEpoch: 1890  | Training Loss: 0.27294 \nEpoch: 1890  | Training Loss: 0.24865 \nEpoch: 1890  | Validation balanced accuracy : 0.76304 \nEpoch: 1891  | Training Loss: 0.33006 \nEpoch: 1891  | Training Loss: 0.39506 \nEpoch: 1891  | Training Loss: 0.34289 \nEpoch: 1891  | Training Loss: 0.27282 \nEpoch: 1891  | Training Loss: 0.24858 \nEpoch: 1891  | Validation balanced accuracy : 0.76304 \nEpoch: 1892  | Training Loss: 0.32996 \nEpoch: 1892  | Training Loss: 0.39494 \nEpoch: 1892  | Training Loss: 0.34282 \nEpoch: 1892  | Training Loss: 0.27271 \nEpoch: 1892  | Training Loss: 0.24852 \nEpoch: 1892  | Validation balanced accuracy : 0.76304 \nEpoch: 1893  | Training Loss: 0.32987 \nEpoch: 1893  | Training Loss: 0.39483 \nEpoch: 1893  | Training Loss: 0.34274 \nEpoch: 1893  | Training Loss: 0.27260 \nEpoch: 1893  | Training Loss: 0.24845 \nEpoch: 1893  | Validation balanced accuracy : 0.76304 \nEpoch: 1894  | Training Loss: 0.32978 \nEpoch: 1894  | Training Loss: 0.39471 \nEpoch: 1894  | Training Loss: 0.34267 \nEpoch: 1894  | Training Loss: 0.27248 \nEpoch: 1894  | Training Loss: 0.24839 \nEpoch: 1894  | Validation balanced accuracy : 0.76304 \nEpoch: 1895  | Training Loss: 0.32969 \nEpoch: 1895  | Training Loss: 0.39459 \nEpoch: 1895  | Training Loss: 0.34260 \nEpoch: 1895  | Training Loss: 0.27237 \nEpoch: 1895  | Training Loss: 0.24832 \nEpoch: 1895  | Validation balanced accuracy : 0.76304 \nEpoch: 1896  | Training Loss: 0.32960 \nEpoch: 1896  | Training Loss: 0.39447 \nEpoch: 1896  | Training Loss: 0.34253 \nEpoch: 1896  | Training Loss: 0.27226 \nEpoch: 1896  | Training Loss: 0.24825 \nEpoch: 1896  | Validation balanced accuracy : 0.76304 \nEpoch: 1897  | Training Loss: 0.32951 \nEpoch: 1897  | Training Loss: 0.39436 \nEpoch: 1897  | Training Loss: 0.34246 \nEpoch: 1897  | Training Loss: 0.27214 \nEpoch: 1897  | Training Loss: 0.24819 \nEpoch: 1897  | Validation balanced accuracy : 0.76304 \nEpoch: 1898  | Training Loss: 0.32942 \nEpoch: 1898  | Training Loss: 0.39424 \nEpoch: 1898  | Training Loss: 0.34238 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1898  | Training Loss: 0.27203 \nEpoch: 1898  | Training Loss: 0.24812 \nEpoch: 1898  | Validation balanced accuracy : 0.76304 \nEpoch: 1899  | Training Loss: 0.32933 \nEpoch: 1899  | Training Loss: 0.39412 \nEpoch: 1899  | Training Loss: 0.34231 \nEpoch: 1899  | Training Loss: 0.27192 \nEpoch: 1899  | Training Loss: 0.24805 \nEpoch: 1899  | Validation balanced accuracy : 0.76304 \nEpoch: 1900  | Training Loss: 0.32924 \nEpoch: 1900  | Training Loss: 0.39400 \nEpoch: 1900  | Training Loss: 0.34224 \nEpoch: 1900  | Training Loss: 0.27180 \nEpoch: 1900  | Training Loss: 0.24799 \nEpoch: 1900  | Validation balanced accuracy : 0.76304 \nEpoch: 1901  | Training Loss: 0.32915 \nEpoch: 1901  | Training Loss: 0.39389 \nEpoch: 1901  | Training Loss: 0.34217 \nEpoch: 1901  | Training Loss: 0.27169 \nEpoch: 1901  | Training Loss: 0.24792 \nEpoch: 1901  | Validation balanced accuracy : 0.76304 \nEpoch: 1902  | Training Loss: 0.32906 \nEpoch: 1902  | Training Loss: 0.39377 \nEpoch: 1902  | Training Loss: 0.34210 \nEpoch: 1902  | Training Loss: 0.27158 \nEpoch: 1902  | Training Loss: 0.24785 \nEpoch: 1902  | Validation balanced accuracy : 0.76304 \nEpoch: 1903  | Training Loss: 0.32897 \nEpoch: 1903  | Training Loss: 0.39365 \nEpoch: 1903  | Training Loss: 0.34203 \nEpoch: 1903  | Training Loss: 0.27147 \nEpoch: 1903  | Training Loss: 0.24779 \nEpoch: 1903  | Validation balanced accuracy : 0.76304 \nEpoch: 1904  | Training Loss: 0.32888 \nEpoch: 1904  | Training Loss: 0.39354 \nEpoch: 1904  | Training Loss: 0.34196 \nEpoch: 1904  | Training Loss: 0.27135 \nEpoch: 1904  | Training Loss: 0.24772 \nEpoch: 1904  | Validation balanced accuracy : 0.76304 \nEpoch: 1905  | Training Loss: 0.32879 \nEpoch: 1905  | Training Loss: 0.39342 \nEpoch: 1905  | Training Loss: 0.34189 \nEpoch: 1905  | Training Loss: 0.27124 \nEpoch: 1905  | Training Loss: 0.24765 \nEpoch: 1905  | Validation balanced accuracy : 0.76304 \nEpoch: 1906  | Training Loss: 0.32870 \nEpoch: 1906  | Training Loss: 0.39330 \nEpoch: 1906  | Training Loss: 0.34182 \nEpoch: 1906  | Training Loss: 0.27113 \nEpoch: 1906  | Training Loss: 0.24758 \nEpoch: 1906  | Validation balanced accuracy : 0.76304 \nEpoch: 1907  | Training Loss: 0.32861 \nEpoch: 1907  | Training Loss: 0.39319 \nEpoch: 1907  | Training Loss: 0.34175 \nEpoch: 1907  | Training Loss: 0.27102 \nEpoch: 1907  | Training Loss: 0.24751 \nEpoch: 1907  | Validation balanced accuracy : 0.76304 \nEpoch: 1908  | Training Loss: 0.32852 \nEpoch: 1908  | Training Loss: 0.39307 \nEpoch: 1908  | Training Loss: 0.34168 \nEpoch: 1908  | Training Loss: 0.27090 \nEpoch: 1908  | Training Loss: 0.24744 \nEpoch: 1908  | Validation balanced accuracy : 0.76304 \nEpoch: 1909  | Training Loss: 0.32843 \nEpoch: 1909  | Training Loss: 0.39295 \nEpoch: 1909  | Training Loss: 0.34161 \nEpoch: 1909  | Training Loss: 0.27079 \nEpoch: 1909  | Training Loss: 0.24738 \nEpoch: 1909  | Validation balanced accuracy : 0.76304 \nEpoch: 1910  | Training Loss: 0.32834 \nEpoch: 1910  | Training Loss: 0.39284 \nEpoch: 1910  | Training Loss: 0.34154 \nEpoch: 1910  | Training Loss: 0.27068 \nEpoch: 1910  | Training Loss: 0.24731 \nEpoch: 1910  | Validation balanced accuracy : 0.76304 \nEpoch: 1911  | Training Loss: 0.32826 \nEpoch: 1911  | Training Loss: 0.39272 \nEpoch: 1911  | Training Loss: 0.34147 \nEpoch: 1911  | Training Loss: 0.27057 \nEpoch: 1911  | Training Loss: 0.24724 \nEpoch: 1911  | Validation balanced accuracy : 0.76304 \nEpoch: 1912  | Training Loss: 0.32817 \nEpoch: 1912  | Training Loss: 0.39261 \nEpoch: 1912  | Training Loss: 0.34140 \nEpoch: 1912  | Training Loss: 0.27046 \nEpoch: 1912  | Training Loss: 0.24717 \nEpoch: 1912  | Validation balanced accuracy : 0.76304 \nEpoch: 1913  | Training Loss: 0.32808 \nEpoch: 1913  | Training Loss: 0.39249 \nEpoch: 1913  | Training Loss: 0.34133 \nEpoch: 1913  | Training Loss: 0.27034 \nEpoch: 1913  | Training Loss: 0.24710 \nEpoch: 1913  | Validation balanced accuracy : 0.76304 \nEpoch: 1914  | Training Loss: 0.32799 \nEpoch: 1914  | Training Loss: 0.39237 \nEpoch: 1914  | Training Loss: 0.34126 \nEpoch: 1914  | Training Loss: 0.27023 \nEpoch: 1914  | Training Loss: 0.24703 \nEpoch: 1914  | Validation balanced accuracy : 0.76304 \nEpoch: 1915  | Training Loss: 0.32790 \nEpoch: 1915  | Training Loss: 0.39226 \nEpoch: 1915  | Training Loss: 0.34119 \nEpoch: 1915  | Training Loss: 0.27012 \nEpoch: 1915  | Training Loss: 0.24696 \nEpoch: 1915  | Validation balanced accuracy : 0.76304 \nEpoch: 1916  | Training Loss: 0.32782 \nEpoch: 1916  | Training Loss: 0.39214 \nEpoch: 1916  | Training Loss: 0.34112 \nEpoch: 1916  | Training Loss: 0.27001 \nEpoch: 1916  | Training Loss: 0.24689 \nEpoch: 1916  | Validation balanced accuracy : 0.76304 \nEpoch: 1917  | Training Loss: 0.32773 \nEpoch: 1917  | Training Loss: 0.39203 \nEpoch: 1917  | Training Loss: 0.34105 \nEpoch: 1917  | Training Loss: 0.26990 \nEpoch: 1917  | Training Loss: 0.24682 \nEpoch: 1917  | Validation balanced accuracy : 0.76304 \nEpoch: 1918  | Training Loss: 0.32764 \nEpoch: 1918  | Training Loss: 0.39191 \nEpoch: 1918  | Training Loss: 0.34098 \nEpoch: 1918  | Training Loss: 0.26979 \nEpoch: 1918  | Training Loss: 0.24675 \nEpoch: 1918  | Validation balanced accuracy : 0.76304 \nEpoch: 1919  | Training Loss: 0.32755 \nEpoch: 1919  | Training Loss: 0.39180 \nEpoch: 1919  | Training Loss: 0.34091 \nEpoch: 1919  | Training Loss: 0.26967 \nEpoch: 1919  | Training Loss: 0.24668 \nEpoch: 1919  | Validation balanced accuracy : 0.76304 \nEpoch: 1920  | Training Loss: 0.32747 \nEpoch: 1920  | Training Loss: 0.39168 \nEpoch: 1920  | Training Loss: 0.34084 \nEpoch: 1920  | Training Loss: 0.26956 \nEpoch: 1920  | Training Loss: 0.24661 \nEpoch: 1920  | Validation balanced accuracy : 0.76304 \nEpoch: 1921  | Training Loss: 0.32738 \nEpoch: 1921  | Training Loss: 0.39157 \nEpoch: 1921  | Training Loss: 0.34078 \nEpoch: 1921  | Training Loss: 0.26945 \nEpoch: 1921  | Training Loss: 0.24653 \nEpoch: 1921  | Validation balanced accuracy : 0.76304 \nEpoch: 1922  | Training Loss: 0.32729 \nEpoch: 1922  | Training Loss: 0.39145 \nEpoch: 1922  | Training Loss: 0.34071 \nEpoch: 1922  | Training Loss: 0.26934 \nEpoch: 1922  | Training Loss: 0.24646 \nEpoch: 1922  | Validation balanced accuracy : 0.76304 \nEpoch: 1923  | Training Loss: 0.32721 \nEpoch: 1923  | Training Loss: 0.39134 \nEpoch: 1923  | Training Loss: 0.34064 \nEpoch: 1923  | Training Loss: 0.26923 \nEpoch: 1923  | Training Loss: 0.24639 \nEpoch: 1923  | Validation balanced accuracy : 0.76304 \nEpoch: 1924  | Training Loss: 0.32712 \nEpoch: 1924  | Training Loss: 0.39123 \nEpoch: 1924  | Training Loss: 0.34057 \nEpoch: 1924  | Training Loss: 0.26912 \nEpoch: 1924  | Training Loss: 0.24632 \nEpoch: 1924  | Validation balanced accuracy : 0.76304 \nEpoch: 1925  | Training Loss: 0.32704 \nEpoch: 1925  | Training Loss: 0.39111 \nEpoch: 1925  | Training Loss: 0.34050 \nEpoch: 1925  | Training Loss: 0.26901 \nEpoch: 1925  | Training Loss: 0.24625 \nEpoch: 1925  | Validation balanced accuracy : 0.76304 \nEpoch: 1926  | Training Loss: 0.32695 \nEpoch: 1926  | Training Loss: 0.39100 \nEpoch: 1926  | Training Loss: 0.34044 \nEpoch: 1926  | Training Loss: 0.26890 \nEpoch: 1926  | Training Loss: 0.24617 \nEpoch: 1926  | Validation balanced accuracy : 0.76304 \nEpoch: 1927  | Training Loss: 0.32686 \nEpoch: 1927  | Training Loss: 0.39088 \nEpoch: 1927  | Training Loss: 0.34037 \nEpoch: 1927  | Training Loss: 0.26879 \nEpoch: 1927  | Training Loss: 0.24610 \nEpoch: 1927  | Validation balanced accuracy : 0.76304 \nEpoch: 1928  | Training Loss: 0.32678 \nEpoch: 1928  | Training Loss: 0.39077 \nEpoch: 1928  | Training Loss: 0.34030 \nEpoch: 1928  | Training Loss: 0.26867 \nEpoch: 1928  | Training Loss: 0.24603 \nEpoch: 1928  | Validation balanced accuracy : 0.76304 \nEpoch: 1929  | Training Loss: 0.32669 \nEpoch: 1929  | Training Loss: 0.39066 \nEpoch: 1929  | Training Loss: 0.34023 \nEpoch: 1929  | Training Loss: 0.26856 \nEpoch: 1929  | Training Loss: 0.24596 \nEpoch: 1929  | Validation balanced accuracy : 0.76304 \nEpoch: 1930  | Training Loss: 0.32661 \nEpoch: 1930  | Training Loss: 0.39054 \nEpoch: 1930  | Training Loss: 0.34017 \nEpoch: 1930  | Training Loss: 0.26845 \nEpoch: 1930  | Training Loss: 0.24588 \nEpoch: 1930  | Validation balanced accuracy : 0.76304 \nEpoch: 1931  | Training Loss: 0.32652 \nEpoch: 1931  | Training Loss: 0.39043 \nEpoch: 1931  | Training Loss: 0.34010 \nEpoch: 1931  | Training Loss: 0.26834 \nEpoch: 1931  | Training Loss: 0.24581 \nEpoch: 1931  | Validation balanced accuracy : 0.76304 \nEpoch: 1932  | Training Loss: 0.32644 \nEpoch: 1932  | Training Loss: 0.39031 \nEpoch: 1932  | Training Loss: 0.34003 \nEpoch: 1932  | Training Loss: 0.26823 \nEpoch: 1932  | Training Loss: 0.24574 \nEpoch: 1932  | Validation balanced accuracy : 0.76304 \nEpoch: 1933  | Training Loss: 0.32635 \nEpoch: 1933  | Training Loss: 0.39020 \nEpoch: 1933  | Training Loss: 0.33997 \nEpoch: 1933  | Training Loss: 0.26812 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1933  | Training Loss: 0.24566 \nEpoch: 1933  | Validation balanced accuracy : 0.76304 \nEpoch: 1934  | Training Loss: 0.32627 \nEpoch: 1934  | Training Loss: 0.39009 \nEpoch: 1934  | Training Loss: 0.33990 \nEpoch: 1934  | Training Loss: 0.26801 \nEpoch: 1934  | Training Loss: 0.24562 \nEpoch: 1934  | Validation balanced accuracy : 0.76304 \nEpoch: 1935  | Training Loss: 0.32617 \nEpoch: 1935  | Training Loss: 0.38996 \nEpoch: 1935  | Training Loss: 0.33983 \nEpoch: 1935  | Training Loss: 0.26790 \nEpoch: 1935  | Training Loss: 0.24559 \nEpoch: 1935  | Validation balanced accuracy : 0.76304 \nEpoch: 1936  | Training Loss: 0.32605 \nEpoch: 1936  | Training Loss: 0.38982 \nEpoch: 1936  | Training Loss: 0.33977 \nEpoch: 1936  | Training Loss: 0.26779 \nEpoch: 1936  | Training Loss: 0.24557 \nEpoch: 1936  | Validation balanced accuracy : 0.76304 \nEpoch: 1937  | Training Loss: 0.32594 \nEpoch: 1937  | Training Loss: 0.38969 \nEpoch: 1937  | Training Loss: 0.33970 \nEpoch: 1937  | Training Loss: 0.26768 \nEpoch: 1937  | Training Loss: 0.24553 \nEpoch: 1937  | Validation balanced accuracy : 0.76304 \nEpoch: 1938  | Training Loss: 0.32584 \nEpoch: 1938  | Training Loss: 0.38957 \nEpoch: 1938  | Training Loss: 0.33964 \nEpoch: 1938  | Training Loss: 0.26757 \nEpoch: 1938  | Training Loss: 0.24547 \nEpoch: 1938  | Validation balanced accuracy : 0.76304 \nEpoch: 1939  | Training Loss: 0.32575 \nEpoch: 1939  | Training Loss: 0.38945 \nEpoch: 1939  | Training Loss: 0.33957 \nEpoch: 1939  | Training Loss: 0.26746 \nEpoch: 1939  | Training Loss: 0.24540 \nEpoch: 1939  | Validation balanced accuracy : 0.76304 \nEpoch: 1940  | Training Loss: 0.32567 \nEpoch: 1940  | Training Loss: 0.38934 \nEpoch: 1940  | Training Loss: 0.33950 \nEpoch: 1940  | Training Loss: 0.26735 \nEpoch: 1940  | Training Loss: 0.24532 \nEpoch: 1940  | Validation balanced accuracy : 0.76304 \nEpoch: 1941  | Training Loss: 0.32559 \nEpoch: 1941  | Training Loss: 0.38923 \nEpoch: 1941  | Training Loss: 0.33944 \nEpoch: 1941  | Training Loss: 0.26724 \nEpoch: 1941  | Training Loss: 0.24523 \nEpoch: 1941  | Validation balanced accuracy : 0.76304 \nEpoch: 1942  | Training Loss: 0.32551 \nEpoch: 1942  | Training Loss: 0.38912 \nEpoch: 1942  | Training Loss: 0.33937 \nEpoch: 1942  | Training Loss: 0.26713 \nEpoch: 1942  | Training Loss: 0.24515 \nEpoch: 1942  | Validation balanced accuracy : 0.76304 \nEpoch: 1943  | Training Loss: 0.32543 \nEpoch: 1943  | Training Loss: 0.38902 \nEpoch: 1943  | Training Loss: 0.33931 \nEpoch: 1943  | Training Loss: 0.26702 \nEpoch: 1943  | Training Loss: 0.24507 \nEpoch: 1943  | Validation balanced accuracy : 0.76304 \nEpoch: 1944  | Training Loss: 0.32535 \nEpoch: 1944  | Training Loss: 0.38891 \nEpoch: 1944  | Training Loss: 0.33924 \nEpoch: 1944  | Training Loss: 0.26691 \nEpoch: 1944  | Training Loss: 0.24499 \nEpoch: 1944  | Validation balanced accuracy : 0.76304 \nEpoch: 1945  | Training Loss: 0.32527 \nEpoch: 1945  | Training Loss: 0.38880 \nEpoch: 1945  | Training Loss: 0.33918 \nEpoch: 1945  | Training Loss: 0.26680 \nEpoch: 1945  | Training Loss: 0.24491 \nEpoch: 1945  | Validation balanced accuracy : 0.76304 \nEpoch: 1946  | Training Loss: 0.32519 \nEpoch: 1946  | Training Loss: 0.38869 \nEpoch: 1946  | Training Loss: 0.33911 \nEpoch: 1946  | Training Loss: 0.26669 \nEpoch: 1946  | Training Loss: 0.24484 \nEpoch: 1946  | Validation balanced accuracy : 0.76304 \nEpoch: 1947  | Training Loss: 0.32511 \nEpoch: 1947  | Training Loss: 0.38857 \nEpoch: 1947  | Training Loss: 0.33905 \nEpoch: 1947  | Training Loss: 0.26659 \nEpoch: 1947  | Training Loss: 0.24477 \nEpoch: 1947  | Validation balanced accuracy : 0.76304 \nEpoch: 1948  | Training Loss: 0.32502 \nEpoch: 1948  | Training Loss: 0.38846 \nEpoch: 1948  | Training Loss: 0.33898 \nEpoch: 1948  | Training Loss: 0.26648 \nEpoch: 1948  | Training Loss: 0.24469 \nEpoch: 1948  | Validation balanced accuracy : 0.76304 \nEpoch: 1949  | Training Loss: 0.32494 \nEpoch: 1949  | Training Loss: 0.38835 \nEpoch: 1949  | Training Loss: 0.33892 \nEpoch: 1949  | Training Loss: 0.26637 \nEpoch: 1949  | Training Loss: 0.24462 \nEpoch: 1949  | Validation balanced accuracy : 0.76304 \nEpoch: 1950  | Training Loss: 0.32486 \nEpoch: 1950  | Training Loss: 0.38824 \nEpoch: 1950  | Training Loss: 0.33886 \nEpoch: 1950  | Training Loss: 0.26626 \nEpoch: 1950  | Training Loss: 0.24454 \nEpoch: 1950  | Validation balanced accuracy : 0.76304 \nEpoch: 1951  | Training Loss: 0.32478 \nEpoch: 1951  | Training Loss: 0.38813 \nEpoch: 1951  | Training Loss: 0.33879 \nEpoch: 1951  | Training Loss: 0.26615 \nEpoch: 1951  | Training Loss: 0.24446 \nEpoch: 1951  | Validation balanced accuracy : 0.76304 \nEpoch: 1952  | Training Loss: 0.32470 \nEpoch: 1952  | Training Loss: 0.38802 \nEpoch: 1952  | Training Loss: 0.33873 \nEpoch: 1952  | Training Loss: 0.26604 \nEpoch: 1952  | Training Loss: 0.24439 \nEpoch: 1952  | Validation balanced accuracy : 0.76304 \nEpoch: 1953  | Training Loss: 0.32461 \nEpoch: 1953  | Training Loss: 0.38791 \nEpoch: 1953  | Training Loss: 0.33866 \nEpoch: 1953  | Training Loss: 0.26593 \nEpoch: 1953  | Training Loss: 0.24431 \nEpoch: 1953  | Validation balanced accuracy : 0.76304 \nEpoch: 1954  | Training Loss: 0.32453 \nEpoch: 1954  | Training Loss: 0.38780 \nEpoch: 1954  | Training Loss: 0.33860 \nEpoch: 1954  | Training Loss: 0.26582 \nEpoch: 1954  | Training Loss: 0.24423 \nEpoch: 1954  | Validation balanced accuracy : 0.76304 \nEpoch: 1955  | Training Loss: 0.32445 \nEpoch: 1955  | Training Loss: 0.38769 \nEpoch: 1955  | Training Loss: 0.33854 \nEpoch: 1955  | Training Loss: 0.26571 \nEpoch: 1955  | Training Loss: 0.24415 \nEpoch: 1955  | Validation balanced accuracy : 0.76304 \nEpoch: 1956  | Training Loss: 0.32437 \nEpoch: 1956  | Training Loss: 0.38758 \nEpoch: 1956  | Training Loss: 0.33847 \nEpoch: 1956  | Training Loss: 0.26560 \nEpoch: 1956  | Training Loss: 0.24407 \nEpoch: 1956  | Validation balanced accuracy : 0.76304 \nEpoch: 1957  | Training Loss: 0.32429 \nEpoch: 1957  | Training Loss: 0.38747 \nEpoch: 1957  | Training Loss: 0.33841 \nEpoch: 1957  | Training Loss: 0.26550 \nEpoch: 1957  | Training Loss: 0.24400 \nEpoch: 1957  | Validation balanced accuracy : 0.76304 \nEpoch: 1958  | Training Loss: 0.32421 \nEpoch: 1958  | Training Loss: 0.38736 \nEpoch: 1958  | Training Loss: 0.33835 \nEpoch: 1958  | Training Loss: 0.26539 \nEpoch: 1958  | Training Loss: 0.24392 \nEpoch: 1958  | Validation balanced accuracy : 0.76304 \nEpoch: 1959  | Training Loss: 0.32413 \nEpoch: 1959  | Training Loss: 0.38725 \nEpoch: 1959  | Training Loss: 0.33829 \nEpoch: 1959  | Training Loss: 0.26528 \nEpoch: 1959  | Training Loss: 0.24384 \nEpoch: 1959  | Validation balanced accuracy : 0.76304 \nEpoch: 1960  | Training Loss: 0.32405 \nEpoch: 1960  | Training Loss: 0.38714 \nEpoch: 1960  | Training Loss: 0.33822 \nEpoch: 1960  | Training Loss: 0.26517 \nEpoch: 1960  | Training Loss: 0.24376 \nEpoch: 1960  | Validation balanced accuracy : 0.76304 \nEpoch: 1961  | Training Loss: 0.32397 \nEpoch: 1961  | Training Loss: 0.38704 \nEpoch: 1961  | Training Loss: 0.33816 \nEpoch: 1961  | Training Loss: 0.26506 \nEpoch: 1961  | Training Loss: 0.24368 \nEpoch: 1961  | Validation balanced accuracy : 0.76304 \nEpoch: 1962  | Training Loss: 0.32389 \nEpoch: 1962  | Training Loss: 0.38693 \nEpoch: 1962  | Training Loss: 0.33810 \nEpoch: 1962  | Training Loss: 0.26495 \nEpoch: 1962  | Training Loss: 0.24360 \nEpoch: 1962  | Validation balanced accuracy : 0.76304 \nEpoch: 1963  | Training Loss: 0.32381 \nEpoch: 1963  | Training Loss: 0.38682 \nEpoch: 1963  | Training Loss: 0.33804 \nEpoch: 1963  | Training Loss: 0.26485 \nEpoch: 1963  | Training Loss: 0.24352 \nEpoch: 1963  | Validation balanced accuracy : 0.76304 \nEpoch: 1964  | Training Loss: 0.32373 \nEpoch: 1964  | Training Loss: 0.38671 \nEpoch: 1964  | Training Loss: 0.33797 \nEpoch: 1964  | Training Loss: 0.26474 \nEpoch: 1964  | Training Loss: 0.24345 \nEpoch: 1964  | Validation balanced accuracy : 0.76304 \nEpoch: 1965  | Training Loss: 0.32366 \nEpoch: 1965  | Training Loss: 0.38660 \nEpoch: 1965  | Training Loss: 0.33791 \nEpoch: 1965  | Training Loss: 0.26463 \nEpoch: 1965  | Training Loss: 0.24337 \nEpoch: 1965  | Validation balanced accuracy : 0.76304 \nEpoch: 1966  | Training Loss: 0.32358 \nEpoch: 1966  | Training Loss: 0.38649 \nEpoch: 1966  | Training Loss: 0.33785 \nEpoch: 1966  | Training Loss: 0.26452 \nEpoch: 1966  | Training Loss: 0.24329 \nEpoch: 1966  | Validation balanced accuracy : 0.76304 \nEpoch: 1967  | Training Loss: 0.32350 \nEpoch: 1967  | Training Loss: 0.38638 \nEpoch: 1967  | Training Loss: 0.33779 \nEpoch: 1967  | Training Loss: 0.26442 \nEpoch: 1967  | Training Loss: 0.24321 \nEpoch: 1967  | Validation balanced accuracy : 0.76304 \nEpoch: 1968  | Training Loss: 0.32342 \nEpoch: 1968  | Training Loss: 0.38628 \nEpoch: 1968  | Training Loss: 0.33773 \nEpoch: 1968  | Training Loss: 0.26431 \nEpoch: 1968  | Training Loss: 0.24313 \nEpoch: 1968  | Validation balanced accuracy : 0.76304 \nEpoch: 1969  | Training Loss: 0.32334 \nEpoch: 1969  | Training Loss: 0.38617 \nEpoch: 1969  | Training Loss: 0.33767 \nEpoch: 1969  | Training Loss: 0.26420 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 1969  | Training Loss: 0.24304 \nEpoch: 1969  | Validation balanced accuracy : 0.76304 \nEpoch: 1970  | Training Loss: 0.32326 \nEpoch: 1970  | Training Loss: 0.38606 \nEpoch: 1970  | Training Loss: 0.33761 \nEpoch: 1970  | Training Loss: 0.26409 \nEpoch: 1970  | Training Loss: 0.24296 \nEpoch: 1970  | Validation balanced accuracy : 0.76304 \nEpoch: 1971  | Training Loss: 0.32319 \nEpoch: 1971  | Training Loss: 0.38595 \nEpoch: 1971  | Training Loss: 0.33755 \nEpoch: 1971  | Training Loss: 0.26399 \nEpoch: 1971  | Training Loss: 0.24288 \nEpoch: 1971  | Validation balanced accuracy : 0.76304 \nEpoch: 1972  | Training Loss: 0.32311 \nEpoch: 1972  | Training Loss: 0.38585 \nEpoch: 1972  | Training Loss: 0.33748 \nEpoch: 1972  | Training Loss: 0.26388 \nEpoch: 1972  | Training Loss: 0.24280 \nEpoch: 1972  | Validation balanced accuracy : 0.76304 \nEpoch: 1973  | Training Loss: 0.32303 \nEpoch: 1973  | Training Loss: 0.38574 \nEpoch: 1973  | Training Loss: 0.33742 \nEpoch: 1973  | Training Loss: 0.26377 \nEpoch: 1973  | Training Loss: 0.24272 \nEpoch: 1973  | Validation balanced accuracy : 0.76304 \nEpoch: 1974  | Training Loss: 0.32295 \nEpoch: 1974  | Training Loss: 0.38563 \nEpoch: 1974  | Training Loss: 0.33736 \nEpoch: 1974  | Training Loss: 0.26366 \nEpoch: 1974  | Training Loss: 0.24264 \nEpoch: 1974  | Validation balanced accuracy : 0.76304 \nEpoch: 1975  | Training Loss: 0.32288 \nEpoch: 1975  | Training Loss: 0.38552 \nEpoch: 1975  | Training Loss: 0.33730 \nEpoch: 1975  | Training Loss: 0.26356 \nEpoch: 1975  | Training Loss: 0.24256 \nEpoch: 1975  | Validation balanced accuracy : 0.76304 \nEpoch: 1976  | Training Loss: 0.32280 \nEpoch: 1976  | Training Loss: 0.38542 \nEpoch: 1976  | Training Loss: 0.33724 \nEpoch: 1976  | Training Loss: 0.26345 \nEpoch: 1976  | Training Loss: 0.24248 \nEpoch: 1976  | Validation balanced accuracy : 0.76304 \nEpoch: 1977  | Training Loss: 0.32272 \nEpoch: 1977  | Training Loss: 0.38531 \nEpoch: 1977  | Training Loss: 0.33718 \nEpoch: 1977  | Training Loss: 0.26334 \nEpoch: 1977  | Training Loss: 0.24239 \nEpoch: 1977  | Validation balanced accuracy : 0.76304 \nEpoch: 1978  | Training Loss: 0.32265 \nEpoch: 1978  | Training Loss: 0.38520 \nEpoch: 1978  | Training Loss: 0.33712 \nEpoch: 1978  | Training Loss: 0.26324 \nEpoch: 1978  | Training Loss: 0.24231 \nEpoch: 1978  | Validation balanced accuracy : 0.76304 \nEpoch: 1979  | Training Loss: 0.32257 \nEpoch: 1979  | Training Loss: 0.38510 \nEpoch: 1979  | Training Loss: 0.33707 \nEpoch: 1979  | Training Loss: 0.26313 \nEpoch: 1979  | Training Loss: 0.24223 \nEpoch: 1979  | Validation balanced accuracy : 0.76304 \nEpoch: 1980  | Training Loss: 0.32249 \nEpoch: 1980  | Training Loss: 0.38499 \nEpoch: 1980  | Training Loss: 0.33701 \nEpoch: 1980  | Training Loss: 0.26302 \nEpoch: 1980  | Training Loss: 0.24215 \nEpoch: 1980  | Validation balanced accuracy : 0.76304 \nEpoch: 1981  | Training Loss: 0.32242 \nEpoch: 1981  | Training Loss: 0.38488 \nEpoch: 1981  | Training Loss: 0.33695 \nEpoch: 1981  | Training Loss: 0.26292 \nEpoch: 1981  | Training Loss: 0.24206 \nEpoch: 1981  | Validation balanced accuracy : 0.76304 \nEpoch: 1982  | Training Loss: 0.32234 \nEpoch: 1982  | Training Loss: 0.38478 \nEpoch: 1982  | Training Loss: 0.33689 \nEpoch: 1982  | Training Loss: 0.26281 \nEpoch: 1982  | Training Loss: 0.24198 \nEpoch: 1982  | Validation balanced accuracy : 0.76304 \nEpoch: 1983  | Training Loss: 0.32227 \nEpoch: 1983  | Training Loss: 0.38467 \nEpoch: 1983  | Training Loss: 0.33683 \nEpoch: 1983  | Training Loss: 0.26270 \nEpoch: 1983  | Training Loss: 0.24190 \nEpoch: 1983  | Validation balanced accuracy : 0.76304 \nEpoch: 1984  | Training Loss: 0.32219 \nEpoch: 1984  | Training Loss: 0.38457 \nEpoch: 1984  | Training Loss: 0.33677 \nEpoch: 1984  | Training Loss: 0.26260 \nEpoch: 1984  | Training Loss: 0.24181 \nEpoch: 1984  | Validation balanced accuracy : 0.76304 \nEpoch: 1985  | Training Loss: 0.32211 \nEpoch: 1985  | Training Loss: 0.38446 \nEpoch: 1985  | Training Loss: 0.33671 \nEpoch: 1985  | Training Loss: 0.26249 \nEpoch: 1985  | Training Loss: 0.24173 \nEpoch: 1985  | Validation balanced accuracy : 0.76304 \nEpoch: 1986  | Training Loss: 0.32204 \nEpoch: 1986  | Training Loss: 0.38436 \nEpoch: 1986  | Training Loss: 0.33665 \nEpoch: 1986  | Training Loss: 0.26238 \nEpoch: 1986  | Training Loss: 0.24165 \nEpoch: 1986  | Validation balanced accuracy : 0.76304 \nEpoch: 1987  | Training Loss: 0.32196 \nEpoch: 1987  | Training Loss: 0.38425 \nEpoch: 1987  | Training Loss: 0.33660 \nEpoch: 1987  | Training Loss: 0.26228 \nEpoch: 1987  | Training Loss: 0.24156 \nEpoch: 1987  | Validation balanced accuracy : 0.76304 \nEpoch: 1988  | Training Loss: 0.32189 \nEpoch: 1988  | Training Loss: 0.38414 \nEpoch: 1988  | Training Loss: 0.33654 \nEpoch: 1988  | Training Loss: 0.26217 \nEpoch: 1988  | Training Loss: 0.24148 \nEpoch: 1988  | Validation balanced accuracy : 0.76304 \nEpoch: 1989  | Training Loss: 0.32181 \nEpoch: 1989  | Training Loss: 0.38404 \nEpoch: 1989  | Training Loss: 0.33648 \nEpoch: 1989  | Training Loss: 0.26207 \nEpoch: 1989  | Training Loss: 0.24139 \nEpoch: 1989  | Validation balanced accuracy : 0.76304 \nEpoch: 1990  | Training Loss: 0.32174 \nEpoch: 1990  | Training Loss: 0.38393 \nEpoch: 1990  | Training Loss: 0.33642 \nEpoch: 1990  | Training Loss: 0.26196 \nEpoch: 1990  | Training Loss: 0.24131 \nEpoch: 1990  | Validation balanced accuracy : 0.76304 \nEpoch: 1991  | Training Loss: 0.32167 \nEpoch: 1991  | Training Loss: 0.38383 \nEpoch: 1991  | Training Loss: 0.33637 \nEpoch: 1991  | Training Loss: 0.26185 \nEpoch: 1991  | Training Loss: 0.24122 \nEpoch: 1991  | Validation balanced accuracy : 0.76304 \nEpoch: 1992  | Training Loss: 0.32159 \nEpoch: 1992  | Training Loss: 0.38373 \nEpoch: 1992  | Training Loss: 0.33631 \nEpoch: 1992  | Training Loss: 0.26175 \nEpoch: 1992  | Training Loss: 0.24114 \nEpoch: 1992  | Validation balanced accuracy : 0.76304 \nEpoch: 1993  | Training Loss: 0.32152 \nEpoch: 1993  | Training Loss: 0.38362 \nEpoch: 1993  | Training Loss: 0.33625 \nEpoch: 1993  | Training Loss: 0.26164 \nEpoch: 1993  | Training Loss: 0.24105 \nEpoch: 1993  | Validation balanced accuracy : 0.76304 \nEpoch: 1994  | Training Loss: 0.32144 \nEpoch: 1994  | Training Loss: 0.38352 \nEpoch: 1994  | Training Loss: 0.33619 \nEpoch: 1994  | Training Loss: 0.26154 \nEpoch: 1994  | Training Loss: 0.24097 \nEpoch: 1994  | Validation balanced accuracy : 0.76304 \nEpoch: 1995  | Training Loss: 0.32137 \nEpoch: 1995  | Training Loss: 0.38341 \nEpoch: 1995  | Training Loss: 0.33614 \nEpoch: 1995  | Training Loss: 0.26143 \nEpoch: 1995  | Training Loss: 0.24088 \nEpoch: 1995  | Validation balanced accuracy : 0.76304 \nEpoch: 1996  | Training Loss: 0.32130 \nEpoch: 1996  | Training Loss: 0.38331 \nEpoch: 1996  | Training Loss: 0.33608 \nEpoch: 1996  | Training Loss: 0.26133 \nEpoch: 1996  | Training Loss: 0.24080 \nEpoch: 1996  | Validation balanced accuracy : 0.76304 \nEpoch: 1997  | Training Loss: 0.32122 \nEpoch: 1997  | Training Loss: 0.38320 \nEpoch: 1997  | Training Loss: 0.33602 \nEpoch: 1997  | Training Loss: 0.26122 \nEpoch: 1997  | Training Loss: 0.24071 \nEpoch: 1997  | Validation balanced accuracy : 0.76304 \nEpoch: 1998  | Training Loss: 0.32115 \nEpoch: 1998  | Training Loss: 0.38310 \nEpoch: 1998  | Training Loss: 0.33597 \nEpoch: 1998  | Training Loss: 0.26112 \nEpoch: 1998  | Training Loss: 0.24062 \nEpoch: 1998  | Validation balanced accuracy : 0.76304 \nEpoch: 1999  | Training Loss: 0.32108 \nEpoch: 1999  | Training Loss: 0.38300 \nEpoch: 1999  | Training Loss: 0.33591 \nEpoch: 1999  | Training Loss: 0.26101 \nEpoch: 1999  | Training Loss: 0.24054 \nEpoch: 1999  | Validation balanced accuracy : 0.76304 \nEpoch: 2000  | Training Loss: 0.32101 \nEpoch: 2000  | Training Loss: 0.38289 \nEpoch: 2000  | Training Loss: 0.33586 \nEpoch: 2000  | Training Loss: 0.26091 \nEpoch: 2000  | Training Loss: 0.24045 \nEpoch: 2000  | Validation balanced accuracy : 0.76304 \nEpoch: 2001  | Training Loss: 0.32093 \nEpoch: 2001  | Training Loss: 0.38279 \nEpoch: 2001  | Training Loss: 0.33580 \nEpoch: 2001  | Training Loss: 0.26080 \nEpoch: 2001  | Training Loss: 0.24036 \nEpoch: 2001  | Validation balanced accuracy : 0.76304 \nEpoch: 2002  | Training Loss: 0.32086 \nEpoch: 2002  | Training Loss: 0.38269 \nEpoch: 2002  | Training Loss: 0.33575 \nEpoch: 2002  | Training Loss: 0.26070 \nEpoch: 2002  | Training Loss: 0.24028 \nEpoch: 2002  | Validation balanced accuracy : 0.76304 \nEpoch: 2003  | Training Loss: 0.32079 \nEpoch: 2003  | Training Loss: 0.38258 \nEpoch: 2003  | Training Loss: 0.33569 \nEpoch: 2003  | Training Loss: 0.26059 \nEpoch: 2003  | Training Loss: 0.24019 \nEpoch: 2003  | Validation balanced accuracy : 0.76304 \nEpoch: 2004  | Training Loss: 0.32072 \nEpoch: 2004  | Training Loss: 0.38248 \nEpoch: 2004  | Training Loss: 0.33563 \nEpoch: 2004  | Training Loss: 0.26049 \nEpoch: 2004  | Training Loss: 0.24010 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2004  | Validation balanced accuracy : 0.76304 \nEpoch: 2005  | Training Loss: 0.32065 \nEpoch: 2005  | Training Loss: 0.38238 \nEpoch: 2005  | Training Loss: 0.33558 \nEpoch: 2005  | Training Loss: 0.26038 \nEpoch: 2005  | Training Loss: 0.24001 \nEpoch: 2005  | Validation balanced accuracy : 0.76304 \nEpoch: 2006  | Training Loss: 0.32057 \nEpoch: 2006  | Training Loss: 0.38227 \nEpoch: 2006  | Training Loss: 0.33552 \nEpoch: 2006  | Training Loss: 0.26028 \nEpoch: 2006  | Training Loss: 0.23993 \nEpoch: 2006  | Validation balanced accuracy : 0.76304 \nEpoch: 2007  | Training Loss: 0.32050 \nEpoch: 2007  | Training Loss: 0.38217 \nEpoch: 2007  | Training Loss: 0.33547 \nEpoch: 2007  | Training Loss: 0.26017 \nEpoch: 2007  | Training Loss: 0.23984 \nEpoch: 2007  | Validation balanced accuracy : 0.76304 \nEpoch: 2008  | Training Loss: 0.32043 \nEpoch: 2008  | Training Loss: 0.38207 \nEpoch: 2008  | Training Loss: 0.33542 \nEpoch: 2008  | Training Loss: 0.26007 \nEpoch: 2008  | Training Loss: 0.23975 \nEpoch: 2008  | Validation balanced accuracy : 0.76304 \nEpoch: 2009  | Training Loss: 0.32036 \nEpoch: 2009  | Training Loss: 0.38197 \nEpoch: 2009  | Training Loss: 0.33536 \nEpoch: 2009  | Training Loss: 0.25997 \nEpoch: 2009  | Training Loss: 0.23966 \nEpoch: 2009  | Validation balanced accuracy : 0.76304 \nEpoch: 2010  | Training Loss: 0.32029 \nEpoch: 2010  | Training Loss: 0.38187 \nEpoch: 2010  | Training Loss: 0.33531 \nEpoch: 2010  | Training Loss: 0.25986 \nEpoch: 2010  | Training Loss: 0.23957 \nEpoch: 2010  | Validation balanced accuracy : 0.76304 \nEpoch: 2011  | Training Loss: 0.32022 \nEpoch: 2011  | Training Loss: 0.38176 \nEpoch: 2011  | Training Loss: 0.33525 \nEpoch: 2011  | Training Loss: 0.25976 \nEpoch: 2011  | Training Loss: 0.23948 \nEpoch: 2011  | Validation balanced accuracy : 0.76304 \nEpoch: 2012  | Training Loss: 0.32015 \nEpoch: 2012  | Training Loss: 0.38166 \nEpoch: 2012  | Training Loss: 0.33520 \nEpoch: 2012  | Training Loss: 0.25965 \nEpoch: 2012  | Training Loss: 0.23939 \nEpoch: 2012  | Validation balanced accuracy : 0.76304 \nEpoch: 2013  | Training Loss: 0.32008 \nEpoch: 2013  | Training Loss: 0.38156 \nEpoch: 2013  | Training Loss: 0.33515 \nEpoch: 2013  | Training Loss: 0.25955 \nEpoch: 2013  | Training Loss: 0.23930 \nEpoch: 2013  | Validation balanced accuracy : 0.76304 \nEpoch: 2014  | Training Loss: 0.32001 \nEpoch: 2014  | Training Loss: 0.38028 \nEpoch: 2014  | Training Loss: 0.33512 \nEpoch: 2014  | Training Loss: 0.25936 \nEpoch: 2014  | Training Loss: 0.25515 \nEpoch: 2014  | Validation balanced accuracy : 0.74130 \nEpoch: 2015  | Training Loss: 0.31327 \nEpoch: 2015  | Training Loss: 0.37680 \nEpoch: 2015  | Training Loss: 0.33518 \nEpoch: 2015  | Training Loss: 0.25919 \nEpoch: 2015  | Training Loss: 0.25064 \nEpoch: 2015  | Validation balanced accuracy : 0.74130 \nEpoch: 2016  | Training Loss: 0.31538 \nEpoch: 2016  | Training Loss: 0.37880 \nEpoch: 2016  | Training Loss: 0.33484 \nEpoch: 2016  | Training Loss: 0.25894 \nEpoch: 2016  | Training Loss: 0.24271 \nEpoch: 2016  | Validation balanced accuracy : 0.76304 \nEpoch: 2017  | Training Loss: 0.31908 \nEpoch: 2017  | Training Loss: 0.38150 \nEpoch: 2017  | Training Loss: 0.33471 \nEpoch: 2017  | Training Loss: 0.25884 \nEpoch: 2017  | Training Loss: 0.23703 \nEpoch: 2017  | Validation balanced accuracy : 0.76304 \nEpoch: 2018  | Training Loss: 0.32161 \nEpoch: 2018  | Training Loss: 0.38316 \nEpoch: 2018  | Training Loss: 0.33466 \nEpoch: 2018  | Training Loss: 0.25878 \nEpoch: 2018  | Training Loss: 0.23470 \nEpoch: 2018  | Validation balanced accuracy : 0.76304 \nEpoch: 2019  | Training Loss: 0.32241 \nEpoch: 2019  | Training Loss: 0.38348 \nEpoch: 2019  | Training Loss: 0.33461 \nEpoch: 2019  | Training Loss: 0.25867 \nEpoch: 2019  | Training Loss: 0.23498 \nEpoch: 2019  | Validation balanced accuracy : 0.76304 \nEpoch: 2020  | Training Loss: 0.32187 \nEpoch: 2020  | Training Loss: 0.38282 \nEpoch: 2020  | Training Loss: 0.33454 \nEpoch: 2020  | Training Loss: 0.25853 \nEpoch: 2020  | Training Loss: 0.23662 \nEpoch: 2020  | Validation balanced accuracy : 0.76304 \nEpoch: 2021  | Training Loss: 0.32072 \nEpoch: 2021  | Training Loss: 0.38180 \nEpoch: 2021  | Training Loss: 0.33447 \nEpoch: 2021  | Training Loss: 0.25839 \nEpoch: 2021  | Training Loss: 0.23844 \nEpoch: 2021  | Validation balanced accuracy : 0.76304 \nEpoch: 2022  | Training Loss: 0.31959 \nEpoch: 2022  | Training Loss: 0.38088 \nEpoch: 2022  | Training Loss: 0.33442 \nEpoch: 2022  | Training Loss: 0.25827 \nEpoch: 2022  | Training Loss: 0.23963 \nEpoch: 2022  | Validation balanced accuracy : 0.76304 \nEpoch: 2023  | Training Loss: 0.31889 \nEpoch: 2023  | Training Loss: 0.38035 \nEpoch: 2023  | Training Loss: 0.33436 \nEpoch: 2023  | Training Loss: 0.25815 \nEpoch: 2023  | Training Loss: 0.23992 \nEpoch: 2023  | Validation balanced accuracy : 0.76304 \nEpoch: 2024  | Training Loss: 0.31868 \nEpoch: 2024  | Training Loss: 0.38019 \nEpoch: 2024  | Training Loss: 0.33430 \nEpoch: 2024  | Training Loss: 0.25804 \nEpoch: 2024  | Training Loss: 0.23955 \nEpoch: 2024  | Validation balanced accuracy : 0.76304 \nEpoch: 2025  | Training Loss: 0.31879 \nEpoch: 2025  | Training Loss: 0.38026 \nEpoch: 2025  | Training Loss: 0.33424 \nEpoch: 2025  | Training Loss: 0.25793 \nEpoch: 2025  | Training Loss: 0.23890 \nEpoch: 2025  | Validation balanced accuracy : 0.76304 \nEpoch: 2026  | Training Loss: 0.31902 \nEpoch: 2026  | Training Loss: 0.38038 \nEpoch: 2026  | Training Loss: 0.33418 \nEpoch: 2026  | Training Loss: 0.25783 \nEpoch: 2026  | Training Loss: 0.23829 \nEpoch: 2026  | Validation balanced accuracy : 0.76304 \nEpoch: 2027  | Training Loss: 0.31921 \nEpoch: 2027  | Training Loss: 0.38046 \nEpoch: 2027  | Training Loss: 0.33412 \nEpoch: 2027  | Training Loss: 0.25772 \nEpoch: 2027  | Training Loss: 0.23788 \nEpoch: 2027  | Validation balanced accuracy : 0.76304 \nEpoch: 2028  | Training Loss: 0.31927 \nEpoch: 2028  | Training Loss: 0.38044 \nEpoch: 2028  | Training Loss: 0.33406 \nEpoch: 2028  | Training Loss: 0.25761 \nEpoch: 2028  | Training Loss: 0.23771 \nEpoch: 2028  | Validation balanced accuracy : 0.76304 \nEpoch: 2029  | Training Loss: 0.31922 \nEpoch: 2029  | Training Loss: 0.38033 \nEpoch: 2029  | Training Loss: 0.33401 \nEpoch: 2029  | Training Loss: 0.25750 \nEpoch: 2029  | Training Loss: 0.23770 \nEpoch: 2029  | Validation balanced accuracy : 0.76304 \nEpoch: 2030  | Training Loss: 0.31908 \nEpoch: 2030  | Training Loss: 0.38016 \nEpoch: 2030  | Training Loss: 0.33395 \nEpoch: 2030  | Training Loss: 0.25739 \nEpoch: 2030  | Training Loss: 0.23776 \nEpoch: 2030  | Validation balanced accuracy : 0.76304 \nEpoch: 2031  | Training Loss: 0.31892 \nEpoch: 2031  | Training Loss: 0.37998 \nEpoch: 2031  | Training Loss: 0.33389 \nEpoch: 2031  | Training Loss: 0.25728 \nEpoch: 2031  | Training Loss: 0.23781 \nEpoch: 2031  | Validation balanced accuracy : 0.76304 \nEpoch: 2032  | Training Loss: 0.31876 \nEpoch: 2032  | Training Loss: 0.37981 \nEpoch: 2032  | Training Loss: 0.33384 \nEpoch: 2032  | Training Loss: 0.25717 \nEpoch: 2032  | Training Loss: 0.23781 \nEpoch: 2032  | Validation balanced accuracy : 0.76304 \nEpoch: 2033  | Training Loss: 0.31864 \nEpoch: 2033  | Training Loss: 0.37967 \nEpoch: 2033  | Training Loss: 0.33378 \nEpoch: 2033  | Training Loss: 0.25706 \nEpoch: 2033  | Training Loss: 0.23775 \nEpoch: 2033  | Validation balanced accuracy : 0.76304 \nEpoch: 2034  | Training Loss: 0.31855 \nEpoch: 2034  | Training Loss: 0.37955 \nEpoch: 2034  | Training Loss: 0.33372 \nEpoch: 2034  | Training Loss: 0.25694 \nEpoch: 2034  | Training Loss: 0.23765 \nEpoch: 2034  | Validation balanced accuracy : 0.76304 \nEpoch: 2035  | Training Loss: 0.31849 \nEpoch: 2035  | Training Loss: 0.37946 \nEpoch: 2035  | Training Loss: 0.33366 \nEpoch: 2035  | Training Loss: 0.25683 \nEpoch: 2035  | Training Loss: 0.23753 \nEpoch: 2035  | Validation balanced accuracy : 0.76304 \nEpoch: 2036  | Training Loss: 0.31843 \nEpoch: 2036  | Training Loss: 0.37936 \nEpoch: 2036  | Training Loss: 0.33361 \nEpoch: 2036  | Training Loss: 0.25672 \nEpoch: 2036  | Training Loss: 0.23737 \nEpoch: 2036  | Validation balanced accuracy : 0.76304 \nEpoch: 2037  | Training Loss: 0.31840 \nEpoch: 2037  | Training Loss: 0.37929 \nEpoch: 2037  | Training Loss: 0.33355 \nEpoch: 2037  | Training Loss: 0.25661 \nEpoch: 2037  | Training Loss: 0.23719 \nEpoch: 2037  | Validation balanced accuracy : 0.76304 \nEpoch: 2038  | Training Loss: 0.31838 \nEpoch: 2038  | Training Loss: 0.37922 \nEpoch: 2038  | Training Loss: 0.33350 \nEpoch: 2038  | Training Loss: 0.25651 \nEpoch: 2038  | Training Loss: 0.23702 \nEpoch: 2038  | Validation balanced accuracy : 0.76304 \nEpoch: 2039  | Training Loss: 0.31834 \nEpoch: 2039  | Training Loss: 0.37914 \nEpoch: 2039  | Training Loss: 0.33344 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2039  | Training Loss: 0.25640 \nEpoch: 2039  | Training Loss: 0.23688 \nEpoch: 2039  | Validation balanced accuracy : 0.76304 \nEpoch: 2040  | Training Loss: 0.31829 \nEpoch: 2040  | Training Loss: 0.37904 \nEpoch: 2040  | Training Loss: 0.33339 \nEpoch: 2040  | Training Loss: 0.25629 \nEpoch: 2040  | Training Loss: 0.23678 \nEpoch: 2040  | Validation balanced accuracy : 0.76304 \nEpoch: 2041  | Training Loss: 0.31822 \nEpoch: 2041  | Training Loss: 0.37893 \nEpoch: 2041  | Training Loss: 0.33334 \nEpoch: 2041  | Training Loss: 0.25618 \nEpoch: 2041  | Training Loss: 0.23667 \nEpoch: 2041  | Validation balanced accuracy : 0.76304 \nEpoch: 2042  | Training Loss: 0.31816 \nEpoch: 2042  | Training Loss: 0.37884 \nEpoch: 2042  | Training Loss: 0.33329 \nEpoch: 2042  | Training Loss: 0.25608 \nEpoch: 2042  | Training Loss: 0.23653 \nEpoch: 2042  | Validation balanced accuracy : 0.76304 \nEpoch: 2043  | Training Loss: 0.31812 \nEpoch: 2043  | Training Loss: 0.37875 \nEpoch: 2043  | Training Loss: 0.33324 \nEpoch: 2043  | Training Loss: 0.25597 \nEpoch: 2043  | Training Loss: 0.23639 \nEpoch: 2043  | Validation balanced accuracy : 0.76304 \nEpoch: 2044  | Training Loss: 0.31807 \nEpoch: 2044  | Training Loss: 0.37866 \nEpoch: 2044  | Training Loss: 0.33318 \nEpoch: 2044  | Training Loss: 0.25586 \nEpoch: 2044  | Training Loss: 0.23626 \nEpoch: 2044  | Validation balanced accuracy : 0.76304 \nEpoch: 2045  | Training Loss: 0.31801 \nEpoch: 2045  | Training Loss: 0.37856 \nEpoch: 2045  | Training Loss: 0.33313 \nEpoch: 2045  | Training Loss: 0.25576 \nEpoch: 2045  | Training Loss: 0.23616 \nEpoch: 2045  | Validation balanced accuracy : 0.76304 \nEpoch: 2046  | Training Loss: 0.31794 \nEpoch: 2046  | Training Loss: 0.37845 \nEpoch: 2046  | Training Loss: 0.33309 \nEpoch: 2046  | Training Loss: 0.25565 \nEpoch: 2046  | Training Loss: 0.23560 \nEpoch: 2046  | Validation balanced accuracy : 0.76304 \nEpoch: 2047  | Training Loss: 0.31824 \nEpoch: 2047  | Training Loss: 0.37871 \nEpoch: 2047  | Training Loss: 0.33302 \nEpoch: 2047  | Training Loss: 0.25556 \nEpoch: 2047  | Training Loss: 0.23487 \nEpoch: 2047  | Validation balanced accuracy : 0.76304 \nEpoch: 2048  | Training Loss: 0.31844 \nEpoch: 2048  | Training Loss: 0.37876 \nEpoch: 2048  | Training Loss: 0.33297 \nEpoch: 2048  | Training Loss: 0.25545 \nEpoch: 2048  | Training Loss: 0.23478 \nEpoch: 2048  | Validation balanced accuracy : 0.76304 \nEpoch: 2049  | Training Loss: 0.31832 \nEpoch: 2049  | Training Loss: 0.37857 \nEpoch: 2049  | Training Loss: 0.33293 \nEpoch: 2049  | Training Loss: 0.25534 \nEpoch: 2049  | Training Loss: 0.23460 \nEpoch: 2049  | Validation balanced accuracy : 0.76304 \nEpoch: 2050  | Training Loss: 0.31838 \nEpoch: 2050  | Training Loss: 0.37863 \nEpoch: 2050  | Training Loss: 0.33287 \nEpoch: 2050  | Training Loss: 0.25524 \nEpoch: 2050  | Training Loss: 0.23434 \nEpoch: 2050  | Validation balanced accuracy : 0.76304 \nEpoch: 2051  | Training Loss: 0.31833 \nEpoch: 2051  | Training Loss: 0.37849 \nEpoch: 2051  | Training Loss: 0.33284 \nEpoch: 2051  | Training Loss: 0.25514 \nEpoch: 2051  | Training Loss: 0.23414 \nEpoch: 2051  | Validation balanced accuracy : 0.76304 \nEpoch: 2052  | Training Loss: 0.31839 \nEpoch: 2052  | Training Loss: 0.37855 \nEpoch: 2052  | Training Loss: 0.33278 \nEpoch: 2052  | Training Loss: 0.25504 \nEpoch: 2052  | Training Loss: 0.23349 \nEpoch: 2052  | Validation balanced accuracy : 0.76304 \nEpoch: 2053  | Training Loss: 0.31867 \nEpoch: 2053  | Training Loss: 0.37874 \nEpoch: 2053  | Training Loss: 0.33271 \nEpoch: 2053  | Training Loss: 0.25494 \nEpoch: 2053  | Training Loss: 0.23323 \nEpoch: 2053  | Validation balanced accuracy : 0.76304 \nEpoch: 2054  | Training Loss: 0.31858 \nEpoch: 2054  | Training Loss: 0.37853 \nEpoch: 2054  | Training Loss: 0.33269 \nEpoch: 2054  | Training Loss: 0.25483 \nEpoch: 2054  | Training Loss: 0.23331 \nEpoch: 2054  | Validation balanced accuracy : 0.76304 \nEpoch: 2055  | Training Loss: 0.31846 \nEpoch: 2055  | Training Loss: 0.37819 \nEpoch: 2055  | Training Loss: 0.33271 \nEpoch: 2055  | Training Loss: 0.25471 \nEpoch: 2055  | Training Loss: 0.23474 \nEpoch: 2055  | Validation balanced accuracy : 0.76304 \nEpoch: 2056  | Training Loss: 0.31718 \nEpoch: 2056  | Training Loss: 0.37721 \nEpoch: 2056  | Training Loss: 0.33284 \nEpoch: 2056  | Training Loss: 0.25459 \nEpoch: 2056  | Training Loss: 0.23634 \nEpoch: 2056  | Validation balanced accuracy : 0.76304 \nEpoch: 2057  | Training Loss: 0.31609 \nEpoch: 2057  | Training Loss: 0.37664 \nEpoch: 2057  | Training Loss: 0.33290 \nEpoch: 2057  | Training Loss: 0.25448 \nEpoch: 2057  | Training Loss: 0.23612 \nEpoch: 2057  | Validation balanced accuracy : 0.76304 \nEpoch: 2058  | Training Loss: 0.31627 \nEpoch: 2058  | Training Loss: 0.37685 \nEpoch: 2058  | Training Loss: 0.33277 \nEpoch: 2058  | Training Loss: 0.25438 \nEpoch: 2058  | Training Loss: 0.23471 \nEpoch: 2058  | Validation balanced accuracy : 0.76304 \nEpoch: 2059  | Training Loss: 0.31713 \nEpoch: 2059  | Training Loss: 0.37733 \nEpoch: 2059  | Training Loss: 0.33263 \nEpoch: 2059  | Training Loss: 0.25429 \nEpoch: 2059  | Training Loss: 0.23385 \nEpoch: 2059  | Validation balanced accuracy : 0.76304 \nEpoch: 2060  | Training Loss: 0.31743 \nEpoch: 2060  | Training Loss: 0.37742 \nEpoch: 2060  | Training Loss: 0.33258 \nEpoch: 2060  | Training Loss: 0.25418 \nEpoch: 2060  | Training Loss: 0.23374 \nEpoch: 2060  | Validation balanced accuracy : 0.76304 \nEpoch: 2061  | Training Loss: 0.31726 \nEpoch: 2061  | Training Loss: 0.37722 \nEpoch: 2061  | Training Loss: 0.33260 \nEpoch: 2061  | Training Loss: 0.25407 \nEpoch: 2061  | Training Loss: 0.23408 \nEpoch: 2061  | Validation balanced accuracy : 0.76304 \nEpoch: 2062  | Training Loss: 0.31683 \nEpoch: 2062  | Training Loss: 0.37687 \nEpoch: 2062  | Training Loss: 0.33264 \nEpoch: 2062  | Training Loss: 0.25396 \nEpoch: 2062  | Training Loss: 0.23455 \nEpoch: 2062  | Validation balanced accuracy : 0.76304 \nEpoch: 2063  | Training Loss: 0.31640 \nEpoch: 2063  | Training Loss: 0.37664 \nEpoch: 2063  | Training Loss: 0.33263 \nEpoch: 2063  | Training Loss: 0.25386 \nEpoch: 2063  | Training Loss: 0.23407 \nEpoch: 2063  | Validation balanced accuracy : 0.76304 \nEpoch: 2064  | Training Loss: 0.31665 \nEpoch: 2064  | Training Loss: 0.37685 \nEpoch: 2064  | Training Loss: 0.33252 \nEpoch: 2064  | Training Loss: 0.25376 \nEpoch: 2064  | Training Loss: 0.23300 \nEpoch: 2064  | Validation balanced accuracy : 0.76304 \nEpoch: 2065  | Training Loss: 0.31722 \nEpoch: 2065  | Training Loss: 0.37711 \nEpoch: 2065  | Training Loss: 0.33244 \nEpoch: 2065  | Training Loss: 0.25366 \nEpoch: 2065  | Training Loss: 0.23274 \nEpoch: 2065  | Validation balanced accuracy : 0.76304 \nEpoch: 2066  | Training Loss: 0.31712 \nEpoch: 2066  | Training Loss: 0.37705 \nEpoch: 2066  | Training Loss: 0.33240 \nEpoch: 2066  | Training Loss: 0.25356 \nEpoch: 2066  | Training Loss: 0.23234 \nEpoch: 2066  | Validation balanced accuracy : 0.76304 \nEpoch: 2067  | Training Loss: 0.31726 \nEpoch: 2067  | Training Loss: 0.37702 \nEpoch: 2067  | Training Loss: 0.33239 \nEpoch: 2067  | Training Loss: 0.25346 \nEpoch: 2067  | Training Loss: 0.23263 \nEpoch: 2067  | Validation balanced accuracy : 0.76304 \nEpoch: 2068  | Training Loss: 0.31685 \nEpoch: 2068  | Training Loss: 0.37674 \nEpoch: 2068  | Training Loss: 0.33239 \nEpoch: 2068  | Training Loss: 0.25335 \nEpoch: 2068  | Training Loss: 0.23254 \nEpoch: 2068  | Validation balanced accuracy : 0.76304 \nEpoch: 2069  | Training Loss: 0.31683 \nEpoch: 2069  | Training Loss: 0.37673 \nEpoch: 2069  | Training Loss: 0.33234 \nEpoch: 2069  | Training Loss: 0.25325 \nEpoch: 2069  | Training Loss: 0.23206 \nEpoch: 2069  | Validation balanced accuracy : 0.76304 \nEpoch: 2070  | Training Loss: 0.31702 \nEpoch: 2070  | Training Loss: 0.37685 \nEpoch: 2070  | Training Loss: 0.33227 \nEpoch: 2070  | Training Loss: 0.25315 \nEpoch: 2070  | Training Loss: 0.23148 \nEpoch: 2070  | Validation balanced accuracy : 0.76304 \nEpoch: 2071  | Training Loss: 0.31724 \nEpoch: 2071  | Training Loss: 0.37697 \nEpoch: 2071  | Training Loss: 0.33220 \nEpoch: 2071  | Training Loss: 0.25305 \nEpoch: 2071  | Training Loss: 0.23100 \nEpoch: 2071  | Validation balanced accuracy : 0.76304 \nEpoch: 2072  | Training Loss: 0.31738 \nEpoch: 2072  | Training Loss: 0.37702 \nEpoch: 2072  | Training Loss: 0.33215 \nEpoch: 2072  | Training Loss: 0.25295 \nEpoch: 2072  | Training Loss: 0.23072 \nEpoch: 2072  | Validation balanced accuracy : 0.76304 \nEpoch: 2073  | Training Loss: 0.31740 \nEpoch: 2073  | Training Loss: 0.37698 \nEpoch: 2073  | Training Loss: 0.33211 \nEpoch: 2073  | Training Loss: 0.25285 \nEpoch: 2073  | Training Loss: 0.23061 \nEpoch: 2073  | Validation balanced accuracy : 0.76304 \nEpoch: 2074  | Training Loss: 0.31731 \nEpoch: 2074  | Training Loss: 0.37687 \nEpoch: 2074  | Training Loss: 0.33210 \nEpoch: 2074  | Training Loss: 0.25274 \nEpoch: 2074  | Training Loss: 0.23062 \nEpoch: 2074  | Validation balanced accuracy : 0.76304 \nEpoch: 2075  | Training Loss: 0.31716 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2075  | Training Loss: 0.37672 \nEpoch: 2075  | Training Loss: 0.33209 \nEpoch: 2075  | Training Loss: 0.25264 \nEpoch: 2075  | Training Loss: 0.23066 \nEpoch: 2075  | Validation balanced accuracy : 0.76304 \nEpoch: 2076  | Training Loss: 0.31700 \nEpoch: 2076  | Training Loss: 0.37656 \nEpoch: 2076  | Training Loss: 0.33208 \nEpoch: 2076  | Training Loss: 0.25253 \nEpoch: 2076  | Training Loss: 0.23069 \nEpoch: 2076  | Validation balanced accuracy : 0.76304 \nEpoch: 2077  | Training Loss: 0.31685 \nEpoch: 2077  | Training Loss: 0.37642 \nEpoch: 2077  | Training Loss: 0.33206 \nEpoch: 2077  | Training Loss: 0.25242 \nEpoch: 2077  | Training Loss: 0.23067 \nEpoch: 2077  | Validation balanced accuracy : 0.76304 \nEpoch: 2078  | Training Loss: 0.31674 \nEpoch: 2078  | Training Loss: 0.37631 \nEpoch: 2078  | Training Loss: 0.33205 \nEpoch: 2078  | Training Loss: 0.25232 \nEpoch: 2078  | Training Loss: 0.23060 \nEpoch: 2078  | Validation balanced accuracy : 0.76304 \nEpoch: 2079  | Training Loss: 0.31665 \nEpoch: 2079  | Training Loss: 0.37621 \nEpoch: 2079  | Training Loss: 0.33202 \nEpoch: 2079  | Training Loss: 0.25222 \nEpoch: 2079  | Training Loss: 0.23049 \nEpoch: 2079  | Validation balanced accuracy : 0.76304 \nEpoch: 2080  | Training Loss: 0.31659 \nEpoch: 2080  | Training Loss: 0.37613 \nEpoch: 2080  | Training Loss: 0.33200 \nEpoch: 2080  | Training Loss: 0.25211 \nEpoch: 2080  | Training Loss: 0.23038 \nEpoch: 2080  | Validation balanced accuracy : 0.76304 \nEpoch: 2081  | Training Loss: 0.31652 \nEpoch: 2081  | Training Loss: 0.37605 \nEpoch: 2081  | Training Loss: 0.33197 \nEpoch: 2081  | Training Loss: 0.25201 \nEpoch: 2081  | Training Loss: 0.23026 \nEpoch: 2081  | Validation balanced accuracy : 0.76304 \nEpoch: 2082  | Training Loss: 0.31646 \nEpoch: 2082  | Training Loss: 0.37596 \nEpoch: 2082  | Training Loss: 0.33195 \nEpoch: 2082  | Training Loss: 0.25190 \nEpoch: 2082  | Training Loss: 0.23016 \nEpoch: 2082  | Validation balanced accuracy : 0.76304 \nEpoch: 2083  | Training Loss: 0.31639 \nEpoch: 2083  | Training Loss: 0.37587 \nEpoch: 2083  | Training Loss: 0.33193 \nEpoch: 2083  | Training Loss: 0.25180 \nEpoch: 2083  | Training Loss: 0.23007 \nEpoch: 2083  | Validation balanced accuracy : 0.76304 \nEpoch: 2084  | Training Loss: 0.31631 \nEpoch: 2084  | Training Loss: 0.37589 \nEpoch: 2084  | Training Loss: 0.33185 \nEpoch: 2084  | Training Loss: 0.25171 \nEpoch: 2084  | Training Loss: 0.22916 \nEpoch: 2084  | Validation balanced accuracy : 0.76304 \nEpoch: 2085  | Training Loss: 0.31683 \nEpoch: 2085  | Training Loss: 0.37618 \nEpoch: 2085  | Training Loss: 0.33176 \nEpoch: 2085  | Training Loss: 0.25162 \nEpoch: 2085  | Training Loss: 0.22870 \nEpoch: 2085  | Validation balanced accuracy : 0.76304 \nEpoch: 2086  | Training Loss: 0.31691 \nEpoch: 2086  | Training Loss: 0.37615 \nEpoch: 2086  | Training Loss: 0.33173 \nEpoch: 2086  | Training Loss: 0.25151 \nEpoch: 2086  | Training Loss: 0.22881 \nEpoch: 2086  | Validation balanced accuracy : 0.76304 \nEpoch: 2087  | Training Loss: 0.31666 \nEpoch: 2087  | Training Loss: 0.37590 \nEpoch: 2087  | Training Loss: 0.33175 \nEpoch: 2087  | Training Loss: 0.25140 \nEpoch: 2087  | Training Loss: 0.22918 \nEpoch: 2087  | Validation balanced accuracy : 0.76304 \nEpoch: 2088  | Training Loss: 0.31630 \nEpoch: 2088  | Training Loss: 0.37569 \nEpoch: 2088  | Training Loss: 0.33173 \nEpoch: 2088  | Training Loss: 0.25130 \nEpoch: 2088  | Training Loss: 0.22873 \nEpoch: 2088  | Validation balanced accuracy : 0.76304 \nEpoch: 2089  | Training Loss: 0.31654 \nEpoch: 2089  | Training Loss: 0.37591 \nEpoch: 2089  | Training Loss: 0.33162 \nEpoch: 2089  | Training Loss: 0.25121 \nEpoch: 2089  | Training Loss: 0.22774 \nEpoch: 2089  | Validation balanced accuracy : 0.76304 \nEpoch: 2090  | Training Loss: 0.31705 \nEpoch: 2090  | Training Loss: 0.37616 \nEpoch: 2090  | Training Loss: 0.33154 \nEpoch: 2090  | Training Loss: 0.25112 \nEpoch: 2090  | Training Loss: 0.22758 \nEpoch: 2090  | Validation balanced accuracy : 0.76304 \nEpoch: 2091  | Training Loss: 0.31691 \nEpoch: 2091  | Training Loss: 0.37595 \nEpoch: 2091  | Training Loss: 0.33156 \nEpoch: 2091  | Training Loss: 0.25100 \nEpoch: 2091  | Training Loss: 0.22810 \nEpoch: 2091  | Validation balanced accuracy : 0.76304 \nEpoch: 2092  | Training Loss: 0.31643 \nEpoch: 2092  | Training Loss: 0.37564 \nEpoch: 2092  | Training Loss: 0.33156 \nEpoch: 2092  | Training Loss: 0.25090 \nEpoch: 2092  | Training Loss: 0.22799 \nEpoch: 2092  | Validation balanced accuracy : 0.76304 \nEpoch: 2093  | Training Loss: 0.31646 \nEpoch: 2093  | Training Loss: 0.37569 \nEpoch: 2093  | Training Loss: 0.33149 \nEpoch: 2093  | Training Loss: 0.25080 \nEpoch: 2093  | Training Loss: 0.22734 \nEpoch: 2093  | Validation balanced accuracy : 0.76304 \nEpoch: 2094  | Training Loss: 0.31676 \nEpoch: 2094  | Training Loss: 0.37592 \nEpoch: 2094  | Training Loss: 0.33139 \nEpoch: 2094  | Training Loss: 0.25072 \nEpoch: 2094  | Training Loss: 0.22657 \nEpoch: 2094  | Validation balanced accuracy : 0.76304 \nEpoch: 2095  | Training Loss: 0.31711 \nEpoch: 2095  | Training Loss: 0.37602 \nEpoch: 2095  | Training Loss: 0.33135 \nEpoch: 2095  | Training Loss: 0.25061 \nEpoch: 2095  | Training Loss: 0.22680 \nEpoch: 2095  | Validation balanced accuracy : 0.76304 \nEpoch: 2096  | Training Loss: 0.31673 \nEpoch: 2096  | Training Loss: 0.37575 \nEpoch: 2096  | Training Loss: 0.33135 \nEpoch: 2096  | Training Loss: 0.25050 \nEpoch: 2096  | Training Loss: 0.22684 \nEpoch: 2096  | Validation balanced accuracy : 0.76304 \nEpoch: 2097  | Training Loss: 0.31663 \nEpoch: 2097  | Training Loss: 0.37568 \nEpoch: 2097  | Training Loss: 0.33131 \nEpoch: 2097  | Training Loss: 0.25040 \nEpoch: 2097  | Training Loss: 0.22657 \nEpoch: 2097  | Validation balanced accuracy : 0.76304 \nEpoch: 2098  | Training Loss: 0.31670 \nEpoch: 2098  | Training Loss: 0.37573 \nEpoch: 2098  | Training Loss: 0.33125 \nEpoch: 2098  | Training Loss: 0.25031 \nEpoch: 2098  | Training Loss: 0.22618 \nEpoch: 2098  | Validation balanced accuracy : 0.76304 \nEpoch: 2099  | Training Loss: 0.31682 \nEpoch: 2099  | Training Loss: 0.37580 \nEpoch: 2099  | Training Loss: 0.33119 \nEpoch: 2099  | Training Loss: 0.25021 \nEpoch: 2099  | Training Loss: 0.22582 \nEpoch: 2099  | Validation balanced accuracy : 0.76304 \nEpoch: 2100  | Training Loss: 0.31692 \nEpoch: 2100  | Training Loss: 0.37571 \nEpoch: 2100  | Training Loss: 0.33118 \nEpoch: 2100  | Training Loss: 0.25010 \nEpoch: 2100  | Training Loss: 0.22641 \nEpoch: 2100  | Validation balanced accuracy : 0.76304 \nEpoch: 2101  | Training Loss: 0.31635 \nEpoch: 2101  | Training Loss: 0.37538 \nEpoch: 2101  | Training Loss: 0.33115 \nEpoch: 2101  | Training Loss: 0.25001 \nEpoch: 2101  | Training Loss: 0.22553 \nEpoch: 2101  | Validation balanced accuracy : 0.76304 \nEpoch: 2102  | Training Loss: 0.31667 \nEpoch: 2102  | Training Loss: 0.37559 \nEpoch: 2102  | Training Loss: 0.33107 \nEpoch: 2102  | Training Loss: 0.24993 \nEpoch: 2102  | Training Loss: 0.22502 \nEpoch: 2102  | Validation balanced accuracy : 0.76304 \nEpoch: 2103  | Training Loss: 0.31683 \nEpoch: 2103  | Training Loss: 0.37568 \nEpoch: 2103  | Training Loss: 0.33101 \nEpoch: 2103  | Training Loss: 0.24985 \nEpoch: 2103  | Training Loss: 0.22480 \nEpoch: 2103  | Validation balanced accuracy : 0.76304 \nEpoch: 2104  | Training Loss: 0.31683 \nEpoch: 2104  | Training Loss: 0.37552 \nEpoch: 2104  | Training Loss: 0.33102 \nEpoch: 2104  | Training Loss: 0.24974 \nEpoch: 2104  | Training Loss: 0.22554 \nEpoch: 2104  | Validation balanced accuracy : 0.76304 \nEpoch: 2105  | Training Loss: 0.31621 \nEpoch: 2105  | Training Loss: 0.37515 \nEpoch: 2105  | Training Loss: 0.33103 \nEpoch: 2105  | Training Loss: 0.24965 \nEpoch: 2105  | Training Loss: 0.22521 \nEpoch: 2105  | Validation balanced accuracy : 0.76304 \nEpoch: 2106  | Training Loss: 0.31643 \nEpoch: 2106  | Training Loss: 0.37530 \nEpoch: 2106  | Training Loss: 0.33096 \nEpoch: 2106  | Training Loss: 0.24957 \nEpoch: 2106  | Training Loss: 0.22479 \nEpoch: 2106  | Validation balanced accuracy : 0.76304 \nEpoch: 2107  | Training Loss: 0.31656 \nEpoch: 2107  | Training Loss: 0.37537 \nEpoch: 2107  | Training Loss: 0.33090 \nEpoch: 2107  | Training Loss: 0.24949 \nEpoch: 2107  | Training Loss: 0.22456 \nEpoch: 2107  | Validation balanced accuracy : 0.76304 \nEpoch: 2108  | Training Loss: 0.31657 \nEpoch: 2108  | Training Loss: 0.37533 \nEpoch: 2108  | Training Loss: 0.33087 \nEpoch: 2108  | Training Loss: 0.24940 \nEpoch: 2108  | Training Loss: 0.22449 \nEpoch: 2108  | Validation balanced accuracy : 0.76304 \nEpoch: 2109  | Training Loss: 0.31649 \nEpoch: 2109  | Training Loss: 0.37524 \nEpoch: 2109  | Training Loss: 0.33085 \nEpoch: 2109  | Training Loss: 0.24931 \nEpoch: 2109  | Training Loss: 0.22452 \nEpoch: 2109  | Validation balanced accuracy : 0.76304 \nEpoch: 2110  | Training Loss: 0.31636 \nEpoch: 2110  | Training Loss: 0.37511 \nEpoch: 2110  | Training Loss: 0.33084 \nEpoch: 2110  | Training Loss: 0.24922 \nEpoch: 2110  | Training Loss: 0.22458 \nEpoch: 2110  | Validation balanced accuracy : 0.76304 \nEpoch: 2111  | Training Loss: 0.31624 \nEpoch: 2111  | Training Loss: 0.37509 \nEpoch: 2111  | Training Loss: 0.33078 \nEpoch: 2111  | Training Loss: 0.24914 \nEpoch: 2111  | Training Loss: 0.22386 \nEpoch: 2111  | Validation balanced accuracy : 0.76304 \nEpoch: 2112  | Training Loss: 0.31663 \nEpoch: 2112  | Training Loss: 0.37534 \nEpoch: 2112  | Training Loss: 0.33070 \nEpoch: 2112  | Training Loss: 0.24907 \nEpoch: 2112  | Training Loss: 0.22349 \nEpoch: 2112  | Validation balanced accuracy : 0.76304 \nEpoch: 2113  | Training Loss: 0.31669 \nEpoch: 2113  | Training Loss: 0.37532 \nEpoch: 2113  | Training Loss: 0.33067 \nEpoch: 2113  | Training Loss: 0.24898 \nEpoch: 2113  | Training Loss: 0.22355 \nEpoch: 2113  | Validation balanced accuracy : 0.76304 \nEpoch: 2114  | Training Loss: 0.31651 \nEpoch: 2114  | Training Loss: 0.37512 \nEpoch: 2114  | Training Loss: 0.33067 \nEpoch: 2114  | Training Loss: 0.24888 \nEpoch: 2114  | Training Loss: 0.22384 \nEpoch: 2114  | Validation balanced accuracy : 0.76304 \nEpoch: 2115  | Training Loss: 0.31623 \nEpoch: 2115  | Training Loss: 0.37498 \nEpoch: 2115  | Training Loss: 0.33064 \nEpoch: 2115  | Training Loss: 0.24880 \nEpoch: 2115  | Training Loss: 0.22340 \nEpoch: 2115  | Validation balanced accuracy : 0.76304 \nEpoch: 2116  | Training Loss: 0.31647 \nEpoch: 2116  | Training Loss: 0.37510 \nEpoch: 2116  | Training Loss: 0.33058 \nEpoch: 2116  | Training Loss: 0.24872 \nEpoch: 2116  | Training Loss: 0.22323 \nEpoch: 2116  | Validation balanced accuracy : 0.76304 \nEpoch: 2117  | Training Loss: 0.31642 \nEpoch: 2117  | Training Loss: 0.37501 \nEpoch: 2117  | Training Loss: 0.33057 \nEpoch: 2117  | Training Loss: 0.24863 \nEpoch: 2117  | Training Loss: 0.22338 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2117  | Validation balanced accuracy : 0.76304 \nEpoch: 2118  | Training Loss: 0.31621 \nEpoch: 2118  | Training Loss: 0.37491 \nEpoch: 2118  | Training Loss: 0.33053 \nEpoch: 2118  | Training Loss: 0.24855 \nEpoch: 2118  | Training Loss: 0.22289 \nEpoch: 2118  | Validation balanced accuracy : 0.76304 \nEpoch: 2119  | Training Loss: 0.31647 \nEpoch: 2119  | Training Loss: 0.37504 \nEpoch: 2119  | Training Loss: 0.33048 \nEpoch: 2119  | Training Loss: 0.24847 \nEpoch: 2119  | Training Loss: 0.22276 \nEpoch: 2119  | Validation balanced accuracy : 0.76304 \nEpoch: 2120  | Training Loss: 0.31639 \nEpoch: 2120  | Training Loss: 0.37491 \nEpoch: 2120  | Training Loss: 0.33047 \nEpoch: 2120  | Training Loss: 0.24838 \nEpoch: 2120  | Training Loss: 0.22300 \nEpoch: 2120  | Validation balanced accuracy : 0.76304 \nEpoch: 2121  | Training Loss: 0.31612 \nEpoch: 2121  | Training Loss: 0.37476 \nEpoch: 2121  | Training Loss: 0.33045 \nEpoch: 2121  | Training Loss: 0.24830 \nEpoch: 2121  | Training Loss: 0.22262 \nEpoch: 2121  | Validation balanced accuracy : 0.76304 \nEpoch: 2122  | Training Loss: 0.31631 \nEpoch: 2122  | Training Loss: 0.37484 \nEpoch: 2122  | Training Loss: 0.33041 \nEpoch: 2122  | Training Loss: 0.24822 \nEpoch: 2122  | Training Loss: 0.22257 \nEpoch: 2122  | Validation balanced accuracy : 0.76304 \nEpoch: 2123  | Training Loss: 0.31619 \nEpoch: 2123  | Training Loss: 0.37479 \nEpoch: 2123  | Training Loss: 0.33036 \nEpoch: 2123  | Training Loss: 0.24814 \nEpoch: 2123  | Training Loss: 0.22210 \nEpoch: 2123  | Validation balanced accuracy : 0.76304 \nEpoch: 2124  | Training Loss: 0.31642 \nEpoch: 2124  | Training Loss: 0.37488 \nEpoch: 2124  | Training Loss: 0.33032 \nEpoch: 2124  | Training Loss: 0.24806 \nEpoch: 2124  | Training Loss: 0.22211 \nEpoch: 2124  | Validation balanced accuracy : 0.76304 \nEpoch: 2125  | Training Loss: 0.31625 \nEpoch: 2125  | Training Loss: 0.37467 \nEpoch: 2125  | Training Loss: 0.33033 \nEpoch: 2125  | Training Loss: 0.24796 \nEpoch: 2125  | Training Loss: 0.22252 \nEpoch: 2125  | Validation balanced accuracy : 0.76304 \nEpoch: 2126  | Training Loss: 0.31590 \nEpoch: 2126  | Training Loss: 0.37445 \nEpoch: 2126  | Training Loss: 0.33032 \nEpoch: 2126  | Training Loss: 0.24788 \nEpoch: 2126  | Training Loss: 0.22228 \nEpoch: 2126  | Validation balanced accuracy : 0.76304 \nEpoch: 2127  | Training Loss: 0.31601 \nEpoch: 2127  | Training Loss: 0.37459 \nEpoch: 2127  | Training Loss: 0.33025 \nEpoch: 2127  | Training Loss: 0.24782 \nEpoch: 2127  | Training Loss: 0.22154 \nEpoch: 2127  | Validation balanced accuracy : 0.76304 \nEpoch: 2128  | Training Loss: 0.31637 \nEpoch: 2128  | Training Loss: 0.37477 \nEpoch: 2128  | Training Loss: 0.33019 \nEpoch: 2128  | Training Loss: 0.24774 \nEpoch: 2128  | Training Loss: 0.22148 \nEpoch: 2128  | Validation balanced accuracy : 0.76304 \nEpoch: 2129  | Training Loss: 0.31622 \nEpoch: 2129  | Training Loss: 0.37457 \nEpoch: 2129  | Training Loss: 0.33020 \nEpoch: 2129  | Training Loss: 0.24764 \nEpoch: 2129  | Training Loss: 0.22195 \nEpoch: 2129  | Validation balanced accuracy : 0.76304 \nEpoch: 2130  | Training Loss: 0.31583 \nEpoch: 2130  | Training Loss: 0.37430 \nEpoch: 2130  | Training Loss: 0.33020 \nEpoch: 2130  | Training Loss: 0.24755 \nEpoch: 2130  | Training Loss: 0.22182 \nEpoch: 2130  | Validation balanced accuracy : 0.76304 \nEpoch: 2131  | Training Loss: 0.31587 \nEpoch: 2131  | Training Loss: 0.37438 \nEpoch: 2131  | Training Loss: 0.33014 \nEpoch: 2131  | Training Loss: 0.24749 \nEpoch: 2131  | Training Loss: 0.22121 \nEpoch: 2131  | Validation balanced accuracy : 0.76304 \nEpoch: 2132  | Training Loss: 0.31615 \nEpoch: 2132  | Training Loss: 0.37451 \nEpoch: 2132  | Training Loss: 0.33009 \nEpoch: 2132  | Training Loss: 0.24740 \nEpoch: 2132  | Training Loss: 0.22122 \nEpoch: 2132  | Validation balanced accuracy : 0.76304 \nEpoch: 2133  | Training Loss: 0.31597 \nEpoch: 2133  | Training Loss: 0.37439 \nEpoch: 2133  | Training Loss: 0.33007 \nEpoch: 2133  | Training Loss: 0.24732 \nEpoch: 2133  | Training Loss: 0.22098 \nEpoch: 2133  | Validation balanced accuracy : 0.76304 \nEpoch: 2134  | Training Loss: 0.31605 \nEpoch: 2134  | Training Loss: 0.37448 \nEpoch: 2134  | Training Loss: 0.33000 \nEpoch: 2134  | Training Loss: 0.24726 \nEpoch: 2134  | Training Loss: 0.22050 \nEpoch: 2134  | Validation balanced accuracy : 0.76304 \nEpoch: 2135  | Training Loss: 0.31626 \nEpoch: 2135  | Training Loss: 0.37452 \nEpoch: 2135  | Training Loss: 0.32998 \nEpoch: 2135  | Training Loss: 0.24717 \nEpoch: 2135  | Training Loss: 0.22074 \nEpoch: 2135  | Validation balanced accuracy : 0.76304 \nEpoch: 2136  | Training Loss: 0.31593 \nEpoch: 2136  | Training Loss: 0.37429 \nEpoch: 2136  | Training Loss: 0.32997 \nEpoch: 2136  | Training Loss: 0.24708 \nEpoch: 2136  | Training Loss: 0.22072 \nEpoch: 2136  | Validation balanced accuracy : 0.76304 \nEpoch: 2137  | Training Loss: 0.31590 \nEpoch: 2137  | Training Loss: 0.37428 \nEpoch: 2137  | Training Loss: 0.32993 \nEpoch: 2137  | Training Loss: 0.24700 \nEpoch: 2137  | Training Loss: 0.22037 \nEpoch: 2137  | Validation balanced accuracy : 0.76304 \nEpoch: 2138  | Training Loss: 0.31602 \nEpoch: 2138  | Training Loss: 0.37428 \nEpoch: 2138  | Training Loss: 0.32991 \nEpoch: 2138  | Training Loss: 0.24691 \nEpoch: 2138  | Training Loss: 0.22067 \nEpoch: 2138  | Validation balanced accuracy : 0.76304 \nEpoch: 2139  | Training Loss: 0.31569 \nEpoch: 2139  | Training Loss: 0.37404 \nEpoch: 2139  | Training Loss: 0.32991 \nEpoch: 2139  | Training Loss: 0.24683 \nEpoch: 2139  | Training Loss: 0.22063 \nEpoch: 2139  | Validation balanced accuracy : 0.76304 \nEpoch: 2140  | Training Loss: 0.31567 \nEpoch: 2140  | Training Loss: 0.37404 \nEpoch: 2140  | Training Loss: 0.32986 \nEpoch: 2140  | Training Loss: 0.24675 \nEpoch: 2140  | Training Loss: 0.22023 \nEpoch: 2140  | Validation balanced accuracy : 0.76304 \nEpoch: 2141  | Training Loss: 0.31582 \nEpoch: 2141  | Training Loss: 0.37418 \nEpoch: 2141  | Training Loss: 0.32979 \nEpoch: 2141  | Training Loss: 0.24669 \nEpoch: 2141  | Training Loss: 0.21972 \nEpoch: 2141  | Validation balanced accuracy : 0.76304 \nEpoch: 2142  | Training Loss: 0.31602 \nEpoch: 2142  | Training Loss: 0.37422 \nEpoch: 2142  | Training Loss: 0.32977 \nEpoch: 2142  | Training Loss: 0.24660 \nEpoch: 2142  | Training Loss: 0.22004 \nEpoch: 2142  | Validation balanced accuracy : 0.76304 \nEpoch: 2143  | Training Loss: 0.31566 \nEpoch: 2143  | Training Loss: 0.37394 \nEpoch: 2143  | Training Loss: 0.32978 \nEpoch: 2143  | Training Loss: 0.24651 \nEpoch: 2143  | Training Loss: 0.22011 \nEpoch: 2143  | Validation balanced accuracy : 0.76304 \nEpoch: 2144  | Training Loss: 0.31557 \nEpoch: 2144  | Training Loss: 0.37389 \nEpoch: 2144  | Training Loss: 0.32974 \nEpoch: 2144  | Training Loss: 0.24643 \nEpoch: 2144  | Training Loss: 0.21985 \nEpoch: 2144  | Validation balanced accuracy : 0.76304 \nEpoch: 2145  | Training Loss: 0.31564 \nEpoch: 2145  | Training Loss: 0.37396 \nEpoch: 2145  | Training Loss: 0.32969 \nEpoch: 2145  | Training Loss: 0.24636 \nEpoch: 2145  | Training Loss: 0.21945 \nEpoch: 2145  | Validation balanced accuracy : 0.76304 \nEpoch: 2146  | Training Loss: 0.31578 \nEpoch: 2146  | Training Loss: 0.37396 \nEpoch: 2146  | Training Loss: 0.32967 \nEpoch: 2146  | Training Loss: 0.24627 \nEpoch: 2146  | Training Loss: 0.21982 \nEpoch: 2146  | Validation balanced accuracy : 0.76304 \nEpoch: 2147  | Training Loss: 0.31540 \nEpoch: 2147  | Training Loss: 0.37367 \nEpoch: 2147  | Training Loss: 0.32968 \nEpoch: 2147  | Training Loss: 0.24618 \nEpoch: 2147  | Training Loss: 0.21988 \nEpoch: 2147  | Validation balanced accuracy : 0.76304 \nEpoch: 2148  | Training Loss: 0.31533 \nEpoch: 2148  | Training Loss: 0.37363 \nEpoch: 2148  | Training Loss: 0.32965 \nEpoch: 2148  | Training Loss: 0.24610 \nEpoch: 2148  | Training Loss: 0.21956 \nEpoch: 2148  | Validation balanced accuracy : 0.76304 \nEpoch: 2149  | Training Loss: 0.31544 \nEpoch: 2149  | Training Loss: 0.37373 \nEpoch: 2149  | Training Loss: 0.32959 \nEpoch: 2149  | Training Loss: 0.24604 \nEpoch: 2149  | Training Loss: 0.21909 \nEpoch: 2149  | Validation balanced accuracy : 0.76304 \nEpoch: 2150  | Training Loss: 0.31561 \nEpoch: 2150  | Training Loss: 0.37387 \nEpoch: 2150  | Training Loss: 0.32952 \nEpoch: 2150  | Training Loss: 0.24597 \nEpoch: 2150  | Training Loss: 0.21866 \nEpoch: 2150  | Validation balanced accuracy : 0.76304 \nEpoch: 2151  | Training Loss: 0.31576 \nEpoch: 2151  | Training Loss: 0.37386 \nEpoch: 2151  | Training Loss: 0.32952 \nEpoch: 2151  | Training Loss: 0.24587 \nEpoch: 2151  | Training Loss: 0.21911 \nEpoch: 2151  | Validation balanced accuracy : 0.76304 \nEpoch: 2152  | Training Loss: 0.31532 \nEpoch: 2152  | Training Loss: 0.37351 \nEpoch: 2152  | Training Loss: 0.32955 \nEpoch: 2152  | Training Loss: 0.24578 \nEpoch: 2152  | Training Loss: 0.21931 \nEpoch: 2152  | Validation balanced accuracy : 0.76304 \nEpoch: 2153  | Training Loss: 0.31517 \nEpoch: 2153  | Training Loss: 0.37340 \nEpoch: 2153  | Training Loss: 0.32953 \nEpoch: 2153  | Training Loss: 0.24570 \nEpoch: 2153  | Training Loss: 0.21913 \nEpoch: 2153  | Validation balanced accuracy : 0.76304 \nEpoch: 2154  | Training Loss: 0.31521 \nEpoch: 2154  | Training Loss: 0.37344 \nEpoch: 2154  | Training Loss: 0.32948 \nEpoch: 2154  | Training Loss: 0.24563 \nEpoch: 2154  | Training Loss: 0.21875 \nEpoch: 2154  | Validation balanced accuracy : 0.76304 \nEpoch: 2155  | Training Loss: 0.31533 \nEpoch: 2155  | Training Loss: 0.37354 \nEpoch: 2155  | Training Loss: 0.32943 \nEpoch: 2155  | Training Loss: 0.24556 \nEpoch: 2155  | Training Loss: 0.21836 \nEpoch: 2155  | Validation balanced accuracy : 0.76304 \nEpoch: 2156  | Training Loss: 0.31545 \nEpoch: 2156  | Training Loss: 0.37363 \nEpoch: 2156  | Training Loss: 0.32938 \nEpoch: 2156  | Training Loss: 0.24549 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2156  | Training Loss: 0.21806 \nEpoch: 2156  | Validation balanced accuracy : 0.76304 \nEpoch: 2157  | Training Loss: 0.31552 \nEpoch: 2157  | Training Loss: 0.37355 \nEpoch: 2157  | Training Loss: 0.32938 \nEpoch: 2157  | Training Loss: 0.24539 \nEpoch: 2157  | Training Loss: 0.21863 \nEpoch: 2157  | Validation balanced accuracy : 0.76304 \nEpoch: 2158  | Training Loss: 0.31503 \nEpoch: 2158  | Training Loss: 0.37315 \nEpoch: 2158  | Training Loss: 0.32942 \nEpoch: 2158  | Training Loss: 0.24529 \nEpoch: 2158  | Training Loss: 0.21890 \nEpoch: 2158  | Validation balanced accuracy : 0.76304 \nEpoch: 2159  | Training Loss: 0.31484 \nEpoch: 2159  | Training Loss: 0.37301 \nEpoch: 2159  | Training Loss: 0.32941 \nEpoch: 2159  | Training Loss: 0.24522 \nEpoch: 2159  | Training Loss: 0.21874 \nEpoch: 2159  | Validation balanced accuracy : 0.76304 \nEpoch: 2160  | Training Loss: 0.31487 \nEpoch: 2160  | Training Loss: 0.37305 \nEpoch: 2160  | Training Loss: 0.32937 \nEpoch: 2160  | Training Loss: 0.24515 \nEpoch: 2160  | Training Loss: 0.21835 \nEpoch: 2160  | Validation balanced accuracy : 0.76304 \nEpoch: 2161  | Training Loss: 0.31501 \nEpoch: 2161  | Training Loss: 0.37317 \nEpoch: 2161  | Training Loss: 0.32931 \nEpoch: 2161  | Training Loss: 0.24508 \nEpoch: 2161  | Training Loss: 0.21793 \nEpoch: 2161  | Validation balanced accuracy : 0.76304 \nEpoch: 2162  | Training Loss: 0.31515 \nEpoch: 2162  | Training Loss: 0.37327 \nEpoch: 2162  | Training Loss: 0.32926 \nEpoch: 2162  | Training Loss: 0.24501 \nEpoch: 2162  | Training Loss: 0.21759 \nEpoch: 2162  | Validation balanced accuracy : 0.76304 \nEpoch: 2163  | Training Loss: 0.31523 \nEpoch: 2163  | Training Loss: 0.37332 \nEpoch: 2163  | Training Loss: 0.32922 \nEpoch: 2163  | Training Loss: 0.24494 \nEpoch: 2163  | Training Loss: 0.21740 \nEpoch: 2163  | Validation balanced accuracy : 0.76304 \nEpoch: 2164  | Training Loss: 0.31524 \nEpoch: 2164  | Training Loss: 0.37329 \nEpoch: 2164  | Training Loss: 0.32920 \nEpoch: 2164  | Training Loss: 0.24486 \nEpoch: 2164  | Training Loss: 0.21732 \nEpoch: 2164  | Validation balanced accuracy : 0.76304 \nEpoch: 2165  | Training Loss: 0.31518 \nEpoch: 2165  | Training Loss: 0.37322 \nEpoch: 2165  | Training Loss: 0.32918 \nEpoch: 2165  | Training Loss: 0.24478 \nEpoch: 2165  | Training Loss: 0.21731 \nEpoch: 2165  | Validation balanced accuracy : 0.76304 \nEpoch: 2166  | Training Loss: 0.31508 \nEpoch: 2166  | Training Loss: 0.37313 \nEpoch: 2166  | Training Loss: 0.32917 \nEpoch: 2166  | Training Loss: 0.24469 \nEpoch: 2166  | Training Loss: 0.21732 \nEpoch: 2166  | Validation balanced accuracy : 0.76304 \nEpoch: 2167  | Training Loss: 0.31499 \nEpoch: 2167  | Training Loss: 0.37303 \nEpoch: 2167  | Training Loss: 0.32915 \nEpoch: 2167  | Training Loss: 0.24461 \nEpoch: 2167  | Training Loss: 0.21732 \nEpoch: 2167  | Validation balanced accuracy : 0.76304 \nEpoch: 2168  | Training Loss: 0.31490 \nEpoch: 2168  | Training Loss: 0.37295 \nEpoch: 2168  | Training Loss: 0.32914 \nEpoch: 2168  | Training Loss: 0.24453 \nEpoch: 2168  | Training Loss: 0.21727 \nEpoch: 2168  | Validation balanced accuracy : 0.76304 \nEpoch: 2169  | Training Loss: 0.31484 \nEpoch: 2169  | Training Loss: 0.37288 \nEpoch: 2169  | Training Loss: 0.32912 \nEpoch: 2169  | Training Loss: 0.24445 \nEpoch: 2169  | Training Loss: 0.21720 \nEpoch: 2169  | Validation balanced accuracy : 0.76304 \nEpoch: 2170  | Training Loss: 0.31479 \nEpoch: 2170  | Training Loss: 0.37283 \nEpoch: 2170  | Training Loss: 0.32910 \nEpoch: 2170  | Training Loss: 0.24437 \nEpoch: 2170  | Training Loss: 0.21710 \nEpoch: 2170  | Validation balanced accuracy : 0.76304 \nEpoch: 2171  | Training Loss: 0.31476 \nEpoch: 2171  | Training Loss: 0.37279 \nEpoch: 2171  | Training Loss: 0.32908 \nEpoch: 2171  | Training Loss: 0.24429 \nEpoch: 2171  | Training Loss: 0.21700 \nEpoch: 2171  | Validation balanced accuracy : 0.76304 \nEpoch: 2172  | Training Loss: 0.31472 \nEpoch: 2172  | Training Loss: 0.37275 \nEpoch: 2172  | Training Loss: 0.32905 \nEpoch: 2172  | Training Loss: 0.24422 \nEpoch: 2172  | Training Loss: 0.21690 \nEpoch: 2172  | Validation balanced accuracy : 0.76304 \nEpoch: 2173  | Training Loss: 0.31469 \nEpoch: 2173  | Training Loss: 0.37270 \nEpoch: 2173  | Training Loss: 0.32903 \nEpoch: 2173  | Training Loss: 0.24414 \nEpoch: 2173  | Training Loss: 0.21681 \nEpoch: 2173  | Validation balanced accuracy : 0.76304 \nEpoch: 2174  | Training Loss: 0.31465 \nEpoch: 2174  | Training Loss: 0.37265 \nEpoch: 2174  | Training Loss: 0.32901 \nEpoch: 2174  | Training Loss: 0.24406 \nEpoch: 2174  | Training Loss: 0.21673 \nEpoch: 2174  | Validation balanced accuracy : 0.76304 \nEpoch: 2175  | Training Loss: 0.31460 \nEpoch: 2175  | Training Loss: 0.37260 \nEpoch: 2175  | Training Loss: 0.32899 \nEpoch: 2175  | Training Loss: 0.24398 \nEpoch: 2175  | Training Loss: 0.21665 \nEpoch: 2175  | Validation balanced accuracy : 0.76304 \nEpoch: 2176  | Training Loss: 0.31455 \nEpoch: 2176  | Training Loss: 0.37254 \nEpoch: 2176  | Training Loss: 0.32897 \nEpoch: 2176  | Training Loss: 0.24390 \nEpoch: 2176  | Training Loss: 0.21657 \nEpoch: 2176  | Validation balanced accuracy : 0.76304 \nEpoch: 2177  | Training Loss: 0.31450 \nEpoch: 2177  | Training Loss: 0.37249 \nEpoch: 2177  | Training Loss: 0.32896 \nEpoch: 2177  | Training Loss: 0.24382 \nEpoch: 2177  | Training Loss: 0.21650 \nEpoch: 2177  | Validation balanced accuracy : 0.76304 \nEpoch: 2178  | Training Loss: 0.31446 \nEpoch: 2178  | Training Loss: 0.37243 \nEpoch: 2178  | Training Loss: 0.32894 \nEpoch: 2178  | Training Loss: 0.24375 \nEpoch: 2178  | Training Loss: 0.21642 \nEpoch: 2178  | Validation balanced accuracy : 0.76304 \nEpoch: 2179  | Training Loss: 0.31441 \nEpoch: 2179  | Training Loss: 0.37238 \nEpoch: 2179  | Training Loss: 0.32892 \nEpoch: 2179  | Training Loss: 0.24367 \nEpoch: 2179  | Training Loss: 0.21633 \nEpoch: 2179  | Validation balanced accuracy : 0.76304 \nEpoch: 2180  | Training Loss: 0.31437 \nEpoch: 2180  | Training Loss: 0.37233 \nEpoch: 2180  | Training Loss: 0.32890 \nEpoch: 2180  | Training Loss: 0.24359 \nEpoch: 2180  | Training Loss: 0.21622 \nEpoch: 2180  | Validation balanced accuracy : 0.76304 \nEpoch: 2181  | Training Loss: 0.31435 \nEpoch: 2181  | Training Loss: 0.37230 \nEpoch: 2181  | Training Loss: 0.32888 \nEpoch: 2181  | Training Loss: 0.24351 \nEpoch: 2181  | Training Loss: 0.21611 \nEpoch: 2181  | Validation balanced accuracy : 0.76304 \nEpoch: 2182  | Training Loss: 0.31432 \nEpoch: 2182  | Training Loss: 0.37225 \nEpoch: 2182  | Training Loss: 0.32887 \nEpoch: 2182  | Training Loss: 0.24344 \nEpoch: 2182  | Training Loss: 0.21601 \nEpoch: 2182  | Validation balanced accuracy : 0.76304 \nEpoch: 2183  | Training Loss: 0.31428 \nEpoch: 2183  | Training Loss: 0.37221 \nEpoch: 2183  | Training Loss: 0.32885 \nEpoch: 2183  | Training Loss: 0.24336 \nEpoch: 2183  | Training Loss: 0.21592 \nEpoch: 2183  | Validation balanced accuracy : 0.76304 \nEpoch: 2184  | Training Loss: 0.31425 \nEpoch: 2184  | Training Loss: 0.37215 \nEpoch: 2184  | Training Loss: 0.32884 \nEpoch: 2184  | Training Loss: 0.24328 \nEpoch: 2184  | Training Loss: 0.21584 \nEpoch: 2184  | Validation balanced accuracy : 0.76304 \nEpoch: 2185  | Training Loss: 0.31420 \nEpoch: 2185  | Training Loss: 0.37210 \nEpoch: 2185  | Training Loss: 0.32882 \nEpoch: 2185  | Training Loss: 0.24321 \nEpoch: 2185  | Training Loss: 0.21576 \nEpoch: 2185  | Validation balanced accuracy : 0.76304 \nEpoch: 2186  | Training Loss: 0.31415 \nEpoch: 2186  | Training Loss: 0.37204 \nEpoch: 2186  | Training Loss: 0.32881 \nEpoch: 2186  | Training Loss: 0.24313 \nEpoch: 2186  | Training Loss: 0.21568 \nEpoch: 2186  | Validation balanced accuracy : 0.76304 \nEpoch: 2187  | Training Loss: 0.31411 \nEpoch: 2187  | Training Loss: 0.37198 \nEpoch: 2187  | Training Loss: 0.32880 \nEpoch: 2187  | Training Loss: 0.24305 \nEpoch: 2187  | Training Loss: 0.21561 \nEpoch: 2187  | Validation balanced accuracy : 0.76304 \nEpoch: 2188  | Training Loss: 0.31406 \nEpoch: 2188  | Training Loss: 0.37192 \nEpoch: 2188  | Training Loss: 0.32879 \nEpoch: 2188  | Training Loss: 0.24297 \nEpoch: 2188  | Training Loss: 0.21552 \nEpoch: 2188  | Validation balanced accuracy : 0.76304 \nEpoch: 2189  | Training Loss: 0.31402 \nEpoch: 2189  | Training Loss: 0.37187 \nEpoch: 2189  | Training Loss: 0.32877 \nEpoch: 2189  | Training Loss: 0.24290 \nEpoch: 2189  | Training Loss: 0.21544 \nEpoch: 2189  | Validation balanced accuracy : 0.76304 \nEpoch: 2190  | Training Loss: 0.31398 \nEpoch: 2190  | Training Loss: 0.37182 \nEpoch: 2190  | Training Loss: 0.32876 \nEpoch: 2190  | Training Loss: 0.24282 \nEpoch: 2190  | Training Loss: 0.21536 \nEpoch: 2190  | Validation balanced accuracy : 0.76304 \nEpoch: 2191  | Training Loss: 0.31394 \nEpoch: 2191  | Training Loss: 0.37176 \nEpoch: 2191  | Training Loss: 0.32875 \nEpoch: 2191  | Training Loss: 0.24274 \nEpoch: 2191  | Training Loss: 0.21527 \nEpoch: 2191  | Validation balanced accuracy : 0.76304 \nEpoch: 2192  | Training Loss: 0.31390 \nEpoch: 2192  | Training Loss: 0.37171 \nEpoch: 2192  | Training Loss: 0.32874 \nEpoch: 2192  | Training Loss: 0.24267 \nEpoch: 2192  | Training Loss: 0.21518 \nEpoch: 2192  | Validation balanced accuracy : 0.76304 \nEpoch: 2193  | Training Loss: 0.31386 \nEpoch: 2193  | Training Loss: 0.37165 \nEpoch: 2193  | Training Loss: 0.32872 \nEpoch: 2193  | Training Loss: 0.24259 \nEpoch: 2193  | Training Loss: 0.21510 \nEpoch: 2193  | Validation balanced accuracy : 0.76304 \nEpoch: 2194  | Training Loss: 0.31382 \nEpoch: 2194  | Training Loss: 0.37160 \nEpoch: 2194  | Training Loss: 0.32871 \nEpoch: 2194  | Training Loss: 0.24251 \nEpoch: 2194  | Training Loss: 0.21501 \nEpoch: 2194  | Validation balanced accuracy : 0.76304 \nEpoch: 2195  | Training Loss: 0.31378 \nEpoch: 2195  | Training Loss: 0.37155 \nEpoch: 2195  | Training Loss: 0.32870 \nEpoch: 2195  | Training Loss: 0.24244 \nEpoch: 2195  | Training Loss: 0.21493 \nEpoch: 2195  | Validation balanced accuracy : 0.76304 \nEpoch: 2196  | Training Loss: 0.31374 \nEpoch: 2196  | Training Loss: 0.37149 \nEpoch: 2196  | Training Loss: 0.32869 \nEpoch: 2196  | Training Loss: 0.24236 \nEpoch: 2196  | Training Loss: 0.21485 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2196  | Validation balanced accuracy : 0.76304 \nEpoch: 2197  | Training Loss: 0.31370 \nEpoch: 2197  | Training Loss: 0.37144 \nEpoch: 2197  | Training Loss: 0.32868 \nEpoch: 2197  | Training Loss: 0.24228 \nEpoch: 2197  | Training Loss: 0.21476 \nEpoch: 2197  | Validation balanced accuracy : 0.76304 \nEpoch: 2198  | Training Loss: 0.31366 \nEpoch: 2198  | Training Loss: 0.37138 \nEpoch: 2198  | Training Loss: 0.32867 \nEpoch: 2198  | Training Loss: 0.24221 \nEpoch: 2198  | Training Loss: 0.21468 \nEpoch: 2198  | Validation balanced accuracy : 0.76304 \nEpoch: 2199  | Training Loss: 0.31362 \nEpoch: 2199  | Training Loss: 0.37133 \nEpoch: 2199  | Training Loss: 0.32866 \nEpoch: 2199  | Training Loss: 0.24213 \nEpoch: 2199  | Training Loss: 0.21459 \nEpoch: 2199  | Validation balanced accuracy : 0.76304 \nEpoch: 2200  | Training Loss: 0.31358 \nEpoch: 2200  | Training Loss: 0.37128 \nEpoch: 2200  | Training Loss: 0.32865 \nEpoch: 2200  | Training Loss: 0.24206 \nEpoch: 2200  | Training Loss: 0.21451 \nEpoch: 2200  | Validation balanced accuracy : 0.76304 \nEpoch: 2201  | Training Loss: 0.31354 \nEpoch: 2201  | Training Loss: 0.37122 \nEpoch: 2201  | Training Loss: 0.32864 \nEpoch: 2201  | Training Loss: 0.24198 \nEpoch: 2201  | Training Loss: 0.21442 \nEpoch: 2201  | Validation balanced accuracy : 0.76304 \nEpoch: 2202  | Training Loss: 0.31350 \nEpoch: 2202  | Training Loss: 0.37117 \nEpoch: 2202  | Training Loss: 0.32863 \nEpoch: 2202  | Training Loss: 0.24190 \nEpoch: 2202  | Training Loss: 0.21434 \nEpoch: 2202  | Validation balanced accuracy : 0.76304 \nEpoch: 2203  | Training Loss: 0.31346 \nEpoch: 2203  | Training Loss: 0.37111 \nEpoch: 2203  | Training Loss: 0.32862 \nEpoch: 2203  | Training Loss: 0.24183 \nEpoch: 2203  | Training Loss: 0.21425 \nEpoch: 2203  | Validation balanced accuracy : 0.76304 \nEpoch: 2204  | Training Loss: 0.31342 \nEpoch: 2204  | Training Loss: 0.37106 \nEpoch: 2204  | Training Loss: 0.32861 \nEpoch: 2204  | Training Loss: 0.24175 \nEpoch: 2204  | Training Loss: 0.21416 \nEpoch: 2204  | Validation balanced accuracy : 0.76304 \nEpoch: 2205  | Training Loss: 0.31338 \nEpoch: 2205  | Training Loss: 0.37101 \nEpoch: 2205  | Training Loss: 0.32860 \nEpoch: 2205  | Training Loss: 0.24168 \nEpoch: 2205  | Training Loss: 0.21408 \nEpoch: 2205  | Validation balanced accuracy : 0.76304 \nEpoch: 2206  | Training Loss: 0.31334 \nEpoch: 2206  | Training Loss: 0.37095 \nEpoch: 2206  | Training Loss: 0.32860 \nEpoch: 2206  | Training Loss: 0.24160 \nEpoch: 2206  | Training Loss: 0.21399 \nEpoch: 2206  | Validation balanced accuracy : 0.76304 \nEpoch: 2207  | Training Loss: 0.31330 \nEpoch: 2207  | Training Loss: 0.37090 \nEpoch: 2207  | Training Loss: 0.32859 \nEpoch: 2207  | Training Loss: 0.24153 \nEpoch: 2207  | Training Loss: 0.21391 \nEpoch: 2207  | Validation balanced accuracy : 0.76304 \nEpoch: 2208  | Training Loss: 0.31327 \nEpoch: 2208  | Training Loss: 0.37084 \nEpoch: 2208  | Training Loss: 0.32858 \nEpoch: 2208  | Training Loss: 0.24145 \nEpoch: 2208  | Training Loss: 0.21382 \nEpoch: 2208  | Validation balanced accuracy : 0.76304 \nEpoch: 2209  | Training Loss: 0.31323 \nEpoch: 2209  | Training Loss: 0.37079 \nEpoch: 2209  | Training Loss: 0.32857 \nEpoch: 2209  | Training Loss: 0.24138 \nEpoch: 2209  | Training Loss: 0.21373 \nEpoch: 2209  | Validation balanced accuracy : 0.76304 \nEpoch: 2210  | Training Loss: 0.31319 \nEpoch: 2210  | Training Loss: 0.37074 \nEpoch: 2210  | Training Loss: 0.32856 \nEpoch: 2210  | Training Loss: 0.24130 \nEpoch: 2210  | Training Loss: 0.21365 \nEpoch: 2210  | Validation balanced accuracy : 0.76304 \nEpoch: 2211  | Training Loss: 0.31315 \nEpoch: 2211  | Training Loss: 0.37068 \nEpoch: 2211  | Training Loss: 0.32856 \nEpoch: 2211  | Training Loss: 0.24123 \nEpoch: 2211  | Training Loss: 0.21356 \nEpoch: 2211  | Validation balanced accuracy : 0.76304 \nEpoch: 2212  | Training Loss: 0.31311 \nEpoch: 2212  | Training Loss: 0.37063 \nEpoch: 2212  | Training Loss: 0.32855 \nEpoch: 2212  | Training Loss: 0.24115 \nEpoch: 2212  | Training Loss: 0.21347 \nEpoch: 2212  | Validation balanced accuracy : 0.76304 \nEpoch: 2213  | Training Loss: 0.31308 \nEpoch: 2213  | Training Loss: 0.37058 \nEpoch: 2213  | Training Loss: 0.32854 \nEpoch: 2213  | Training Loss: 0.24109 \nEpoch: 2213  | Training Loss: 0.21297 \nEpoch: 2213  | Validation balanced accuracy : 0.76304 \nEpoch: 2214  | Training Loss: 0.31338 \nEpoch: 2214  | Training Loss: 0.37089 \nEpoch: 2214  | Training Loss: 0.32844 \nEpoch: 2214  | Training Loss: 0.24104 \nEpoch: 2214  | Training Loss: 0.21230 \nEpoch: 2214  | Validation balanced accuracy : 0.76304 \nEpoch: 2215  | Training Loss: 0.31360 \nEpoch: 2215  | Training Loss: 0.37101 \nEpoch: 2215  | Training Loss: 0.32841 \nEpoch: 2215  | Training Loss: 0.24097 \nEpoch: 2215  | Training Loss: 0.21221 \nEpoch: 2215  | Validation balanced accuracy : 0.76304 \nEpoch: 2216  | Training Loss: 0.31351 \nEpoch: 2216  | Training Loss: 0.37087 \nEpoch: 2216  | Training Loss: 0.32843 \nEpoch: 2216  | Training Loss: 0.24089 \nEpoch: 2216  | Training Loss: 0.21247 \nEpoch: 2216  | Validation balanced accuracy : 0.76304 \nEpoch: 2217  | Training Loss: 0.31325 \nEpoch: 2217  | Training Loss: 0.37062 \nEpoch: 2217  | Training Loss: 0.32846 \nEpoch: 2217  | Training Loss: 0.24079 \nEpoch: 2217  | Training Loss: 0.21281 \nEpoch: 2217  | Validation balanced accuracy : 0.76304 \nEpoch: 2218  | Training Loss: 0.31297 \nEpoch: 2218  | Training Loss: 0.37037 \nEpoch: 2218  | Training Loss: 0.32851 \nEpoch: 2218  | Training Loss: 0.24071 \nEpoch: 2218  | Training Loss: 0.21264 \nEpoch: 2218  | Validation balanced accuracy : 0.76304 \nEpoch: 2219  | Training Loss: 0.31310 \nEpoch: 2219  | Training Loss: 0.37055 \nEpoch: 2219  | Training Loss: 0.32842 \nEpoch: 2219  | Training Loss: 0.24066 \nEpoch: 2219  | Training Loss: 0.21213 \nEpoch: 2219  | Validation balanced accuracy : 0.76304 \nEpoch: 2220  | Training Loss: 0.31325 \nEpoch: 2220  | Training Loss: 0.37062 \nEpoch: 2220  | Training Loss: 0.32840 \nEpoch: 2220  | Training Loss: 0.24059 \nEpoch: 2220  | Training Loss: 0.21205 \nEpoch: 2220  | Validation balanced accuracy : 0.76304 \nEpoch: 2221  | Training Loss: 0.31317 \nEpoch: 2221  | Training Loss: 0.37051 \nEpoch: 2221  | Training Loss: 0.32841 \nEpoch: 2221  | Training Loss: 0.24051 \nEpoch: 2221  | Training Loss: 0.21222 \nEpoch: 2221  | Validation balanced accuracy : 0.76304 \nEpoch: 2222  | Training Loss: 0.31298 \nEpoch: 2222  | Training Loss: 0.37031 \nEpoch: 2222  | Training Loss: 0.32845 \nEpoch: 2222  | Training Loss: 0.24043 \nEpoch: 2222  | Training Loss: 0.21203 \nEpoch: 2222  | Validation balanced accuracy : 0.76304 \nEpoch: 2223  | Training Loss: 0.31310 \nEpoch: 2223  | Training Loss: 0.37048 \nEpoch: 2223  | Training Loss: 0.32836 \nEpoch: 2223  | Training Loss: 0.24038 \nEpoch: 2223  | Training Loss: 0.21160 \nEpoch: 2223  | Validation balanced accuracy : 0.76304 \nEpoch: 2224  | Training Loss: 0.31320 \nEpoch: 2224  | Training Loss: 0.37050 \nEpoch: 2224  | Training Loss: 0.32835 \nEpoch: 2224  | Training Loss: 0.24030 \nEpoch: 2224  | Training Loss: 0.21163 \nEpoch: 2224  | Validation balanced accuracy : 0.76304 \nEpoch: 2225  | Training Loss: 0.31305 \nEpoch: 2225  | Training Loss: 0.37033 \nEpoch: 2225  | Training Loss: 0.32838 \nEpoch: 2225  | Training Loss: 0.24022 \nEpoch: 2225  | Training Loss: 0.21147 \nEpoch: 2225  | Validation balanced accuracy : 0.76304 \nEpoch: 2226  | Training Loss: 0.31315 \nEpoch: 2226  | Training Loss: 0.37046 \nEpoch: 2226  | Training Loss: 0.32831 \nEpoch: 2226  | Training Loss: 0.24016 \nEpoch: 2226  | Training Loss: 0.21117 \nEpoch: 2226  | Validation balanced accuracy : 0.76304 \nEpoch: 2227  | Training Loss: 0.31317 \nEpoch: 2227  | Training Loss: 0.37042 \nEpoch: 2227  | Training Loss: 0.32831 \nEpoch: 2227  | Training Loss: 0.24008 \nEpoch: 2227  | Training Loss: 0.21133 \nEpoch: 2227  | Validation balanced accuracy : 0.76304 \nEpoch: 2228  | Training Loss: 0.31296 \nEpoch: 2228  | Training Loss: 0.37019 \nEpoch: 2228  | Training Loss: 0.32836 \nEpoch: 2228  | Training Loss: 0.24000 \nEpoch: 2228  | Training Loss: 0.21126 \nEpoch: 2228  | Validation balanced accuracy : 0.76304 \nEpoch: 2229  | Training Loss: 0.31300 \nEpoch: 2229  | Training Loss: 0.37029 \nEpoch: 2229  | Training Loss: 0.32830 \nEpoch: 2229  | Training Loss: 0.23994 \nEpoch: 2229  | Training Loss: 0.21100 \nEpoch: 2229  | Validation balanced accuracy : 0.76304 \nEpoch: 2230  | Training Loss: 0.31301 \nEpoch: 2230  | Training Loss: 0.37023 \nEpoch: 2230  | Training Loss: 0.32830 \nEpoch: 2230  | Training Loss: 0.23987 \nEpoch: 2230  | Training Loss: 0.21073 \nEpoch: 2230  | Validation balanced accuracy : 0.76304 \nEpoch: 2231  | Training Loss: 0.31314 \nEpoch: 2231  | Training Loss: 0.37039 \nEpoch: 2231  | Training Loss: 0.32824 \nEpoch: 2231  | Training Loss: 0.23981 \nEpoch: 2231  | Training Loss: 0.21048 \nEpoch: 2231  | Validation balanced accuracy : 0.76304 \nEpoch: 2232  | Training Loss: 0.31313 \nEpoch: 2232  | Training Loss: 0.37030 \nEpoch: 2232  | Training Loss: 0.32825 \nEpoch: 2232  | Training Loss: 0.23973 \nEpoch: 2232  | Training Loss: 0.21076 \nEpoch: 2232  | Validation balanced accuracy : 0.76304 \nEpoch: 2233  | Training Loss: 0.31284 \nEpoch: 2233  | Training Loss: 0.37001 \nEpoch: 2233  | Training Loss: 0.32832 \nEpoch: 2233  | Training Loss: 0.23964 \nEpoch: 2233  | Training Loss: 0.21081 \nEpoch: 2233  | Validation balanced accuracy : 0.76304 \nEpoch: 2234  | Training Loss: 0.31282 \nEpoch: 2234  | Training Loss: 0.37006 \nEpoch: 2234  | Training Loss: 0.32826 \nEpoch: 2234  | Training Loss: 0.23959 \nEpoch: 2234  | Training Loss: 0.21020 \nEpoch: 2234  | Validation balanced accuracy : 0.76304 \nEpoch: 2235  | Training Loss: 0.31313 \nEpoch: 2235  | Training Loss: 0.37035 \nEpoch: 2235  | Training Loss: 0.32817 \nEpoch: 2235  | Training Loss: 0.23954 \nEpoch: 2235  | Training Loss: 0.20981 \nEpoch: 2235  | Validation balanced accuracy : 0.76304 \nEpoch: 2236  | Training Loss: 0.31317 \nEpoch: 2236  | Training Loss: 0.37029 \nEpoch: 2236  | Training Loss: 0.32818 \nEpoch: 2236  | Training Loss: 0.23945 \nEpoch: 2236  | Training Loss: 0.21012 \nEpoch: 2236  | Validation balanced accuracy : 0.76304 \nEpoch: 2237  | Training Loss: 0.31285 \nEpoch: 2237  | Training Loss: 0.36996 \nEpoch: 2237  | Training Loss: 0.32826 \nEpoch: 2237  | Training Loss: 0.23936 \nEpoch: 2237  | Training Loss: 0.21029 \nEpoch: 2237  | Validation balanced accuracy : 0.76304 \nEpoch: 2238  | Training Loss: 0.31276 \nEpoch: 2238  | Training Loss: 0.36994 \nEpoch: 2238  | Training Loss: 0.32822 \nEpoch: 2238  | Training Loss: 0.23930 \nEpoch: 2238  | Training Loss: 0.20982 \nEpoch: 2238  | Validation balanced accuracy : 0.76304 \nEpoch: 2239  | Training Loss: 0.31300 \nEpoch: 2239  | Training Loss: 0.37017 \nEpoch: 2239  | Training Loss: 0.32814 \nEpoch: 2239  | Training Loss: 0.23925 \nEpoch: 2239  | Training Loss: 0.20952 \nEpoch: 2239  | Validation balanced accuracy : 0.76304 \nEpoch: 2240  | Training Loss: 0.31299 \nEpoch: 2240  | Training Loss: 0.37008 \nEpoch: 2240  | Training Loss: 0.32815 \nEpoch: 2240  | Training Loss: 0.23916 \nEpoch: 2240  | Training Loss: 0.20986 \nEpoch: 2240  | Validation balanced accuracy : 0.76304 \nEpoch: 2241  | Training Loss: 0.31266 \nEpoch: 2241  | Training Loss: 0.36975 \nEpoch: 2241  | Training Loss: 0.32824 \nEpoch: 2241  | Training Loss: 0.23907 \nEpoch: 2241  | Training Loss: 0.21003 \nEpoch: 2241  | Validation balanced accuracy : 0.76304 \nEpoch: 2242  | Training Loss: 0.31258 \nEpoch: 2242  | Training Loss: 0.36974 \nEpoch: 2242  | Training Loss: 0.32820 \nEpoch: 2242  | Training Loss: 0.23902 \nEpoch: 2242  | Training Loss: 0.20952 \nEpoch: 2242  | Validation balanced accuracy : 0.76304 \nEpoch: 2243  | Training Loss: 0.31283 \nEpoch: 2243  | Training Loss: 0.36999 \nEpoch: 2243  | Training Loss: 0.32811 \nEpoch: 2243  | Training Loss: 0.23896 \nEpoch: 2243  | Training Loss: 0.20918 \nEpoch: 2243  | Validation balanced accuracy : 0.76304 \nEpoch: 2244  | Training Loss: 0.31285 \nEpoch: 2244  | Training Loss: 0.36991 \nEpoch: 2244  | Training Loss: 0.32812 \nEpoch: 2244  | Training Loss: 0.23889 \nEpoch: 2244  | Training Loss: 0.20909 \nEpoch: 2244  | Validation balanced accuracy : 0.76304 \nEpoch: 2245  | Training Loss: 0.31287 \nEpoch: 2245  | Training Loss: 0.36996 \nEpoch: 2245  | Training Loss: 0.32809 \nEpoch: 2245  | Training Loss: 0.23882 \nEpoch: 2245  | Training Loss: 0.20908 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2245  | Validation balanced accuracy : 0.76304 \nEpoch: 2246  | Training Loss: 0.31271 \nEpoch: 2246  | Training Loss: 0.36975 \nEpoch: 2246  | Training Loss: 0.32814 \nEpoch: 2246  | Training Loss: 0.23874 \nEpoch: 2246  | Training Loss: 0.20916 \nEpoch: 2246  | Validation balanced accuracy : 0.76304 \nEpoch: 2247  | Training Loss: 0.31265 \nEpoch: 2247  | Training Loss: 0.36974 \nEpoch: 2247  | Training Loss: 0.32811 \nEpoch: 2247  | Training Loss: 0.23868 \nEpoch: 2247  | Training Loss: 0.20875 \nEpoch: 2247  | Validation balanced accuracy : 0.76304 \nEpoch: 2248  | Training Loss: 0.31284 \nEpoch: 2248  | Training Loss: 0.36992 \nEpoch: 2248  | Training Loss: 0.32805 \nEpoch: 2248  | Training Loss: 0.23862 \nEpoch: 2248  | Training Loss: 0.20859 \nEpoch: 2248  | Validation balanced accuracy : 0.76304 \nEpoch: 2249  | Training Loss: 0.31275 \nEpoch: 2249  | Training Loss: 0.36976 \nEpoch: 2249  | Training Loss: 0.32808 \nEpoch: 2249  | Training Loss: 0.23854 \nEpoch: 2249  | Training Loss: 0.20866 \nEpoch: 2249  | Validation balanced accuracy : 0.76304 \nEpoch: 2250  | Training Loss: 0.31268 \nEpoch: 2250  | Training Loss: 0.36973 \nEpoch: 2250  | Training Loss: 0.32806 \nEpoch: 2250  | Training Loss: 0.23846 \nEpoch: 2250  | Training Loss: 0.20874 \nEpoch: 2250  | Validation balanced accuracy : 0.76304 \nEpoch: 2251  | Training Loss: 0.31248 \nEpoch: 2251  | Training Loss: 0.36949 \nEpoch: 2251  | Training Loss: 0.32813 \nEpoch: 2251  | Training Loss: 0.23838 \nEpoch: 2251  | Training Loss: 0.20884 \nEpoch: 2251  | Validation balanced accuracy : 0.76304 \nEpoch: 2252  | Training Loss: 0.31241 \nEpoch: 2252  | Training Loss: 0.36949 \nEpoch: 2252  | Training Loss: 0.32810 \nEpoch: 2252  | Training Loss: 0.23832 \nEpoch: 2252  | Training Loss: 0.20841 \nEpoch: 2252  | Validation balanced accuracy : 0.76304 \nEpoch: 2253  | Training Loss: 0.31262 \nEpoch: 2253  | Training Loss: 0.36968 \nEpoch: 2253  | Training Loss: 0.32802 \nEpoch: 2253  | Training Loss: 0.23827 \nEpoch: 2253  | Training Loss: 0.20820 \nEpoch: 2253  | Validation balanced accuracy : 0.76304 \nEpoch: 2254  | Training Loss: 0.31256 \nEpoch: 2254  | Training Loss: 0.36954 \nEpoch: 2254  | Training Loss: 0.32806 \nEpoch: 2254  | Training Loss: 0.23819 \nEpoch: 2254  | Training Loss: 0.20822 \nEpoch: 2254  | Validation balanced accuracy : 0.76304 \nEpoch: 2255  | Training Loss: 0.31252 \nEpoch: 2255  | Training Loss: 0.36954 \nEpoch: 2255  | Training Loss: 0.32803 \nEpoch: 2255  | Training Loss: 0.23813 \nEpoch: 2255  | Training Loss: 0.20787 \nEpoch: 2255  | Validation balanced accuracy : 0.76304 \nEpoch: 2256  | Training Loss: 0.31267 \nEpoch: 2256  | Training Loss: 0.36968 \nEpoch: 2256  | Training Loss: 0.32798 \nEpoch: 2256  | Training Loss: 0.23806 \nEpoch: 2256  | Training Loss: 0.20780 \nEpoch: 2256  | Validation balanced accuracy : 0.76304 \nEpoch: 2257  | Training Loss: 0.31252 \nEpoch: 2257  | Training Loss: 0.36946 \nEpoch: 2257  | Training Loss: 0.32803 \nEpoch: 2257  | Training Loss: 0.23798 \nEpoch: 2257  | Training Loss: 0.20796 \nEpoch: 2257  | Validation balanced accuracy : 0.76304 \nEpoch: 2258  | Training Loss: 0.31241 \nEpoch: 2258  | Training Loss: 0.36940 \nEpoch: 2258  | Training Loss: 0.32802 \nEpoch: 2258  | Training Loss: 0.23791 \nEpoch: 2258  | Training Loss: 0.20769 \nEpoch: 2258  | Validation balanced accuracy : 0.76304 \nEpoch: 2259  | Training Loss: 0.31252 \nEpoch: 2259  | Training Loss: 0.36951 \nEpoch: 2259  | Training Loss: 0.32797 \nEpoch: 2259  | Training Loss: 0.23785 \nEpoch: 2259  | Training Loss: 0.20764 \nEpoch: 2259  | Validation balanced accuracy : 0.76304 \nEpoch: 2260  | Training Loss: 0.31237 \nEpoch: 2260  | Training Loss: 0.36930 \nEpoch: 2260  | Training Loss: 0.32803 \nEpoch: 2260  | Training Loss: 0.23777 \nEpoch: 2260  | Training Loss: 0.20774 \nEpoch: 2260  | Validation balanced accuracy : 0.76304 \nEpoch: 2261  | Training Loss: 0.31229 \nEpoch: 2261  | Training Loss: 0.36929 \nEpoch: 2261  | Training Loss: 0.32800 \nEpoch: 2261  | Training Loss: 0.23771 \nEpoch: 2261  | Training Loss: 0.20739 \nEpoch: 2261  | Validation balanced accuracy : 0.76304 \nEpoch: 2262  | Training Loss: 0.31245 \nEpoch: 2262  | Training Loss: 0.36943 \nEpoch: 2262  | Training Loss: 0.32794 \nEpoch: 2262  | Training Loss: 0.23765 \nEpoch: 2262  | Training Loss: 0.20731 \nEpoch: 2262  | Validation balanced accuracy : 0.76304 \nEpoch: 2263  | Training Loss: 0.31231 \nEpoch: 2263  | Training Loss: 0.36923 \nEpoch: 2263  | Training Loss: 0.32801 \nEpoch: 2263  | Training Loss: 0.23756 \nEpoch: 2263  | Training Loss: 0.20741 \nEpoch: 2263  | Validation balanced accuracy : 0.76304 \nEpoch: 2264  | Training Loss: 0.31224 \nEpoch: 2264  | Training Loss: 0.36920 \nEpoch: 2264  | Training Loss: 0.32798 \nEpoch: 2264  | Training Loss: 0.23750 \nEpoch: 2264  | Training Loss: 0.20705 \nEpoch: 2264  | Validation balanced accuracy : 0.76304 \nEpoch: 2265  | Training Loss: 0.31240 \nEpoch: 2265  | Training Loss: 0.36936 \nEpoch: 2265  | Training Loss: 0.32792 \nEpoch: 2265  | Training Loss: 0.23744 \nEpoch: 2265  | Training Loss: 0.20696 \nEpoch: 2265  | Validation balanced accuracy : 0.76304 \nEpoch: 2266  | Training Loss: 0.31226 \nEpoch: 2266  | Training Loss: 0.36915 \nEpoch: 2266  | Training Loss: 0.32798 \nEpoch: 2266  | Training Loss: 0.23736 \nEpoch: 2266  | Training Loss: 0.20709 \nEpoch: 2266  | Validation balanced accuracy : 0.76304 \nEpoch: 2267  | Training Loss: 0.31217 \nEpoch: 2267  | Training Loss: 0.36911 \nEpoch: 2267  | Training Loss: 0.32797 \nEpoch: 2267  | Training Loss: 0.23730 \nEpoch: 2267  | Training Loss: 0.20676 \nEpoch: 2267  | Validation balanced accuracy : 0.76304 \nEpoch: 2268  | Training Loss: 0.31231 \nEpoch: 2268  | Training Loss: 0.36925 \nEpoch: 2268  | Training Loss: 0.32790 \nEpoch: 2268  | Training Loss: 0.23724 \nEpoch: 2268  | Training Loss: 0.20670 \nEpoch: 2268  | Validation balanced accuracy : 0.76304 \nEpoch: 2269  | Training Loss: 0.31217 \nEpoch: 2269  | Training Loss: 0.36903 \nEpoch: 2269  | Training Loss: 0.32798 \nEpoch: 2269  | Training Loss: 0.23715 \nEpoch: 2269  | Training Loss: 0.20684 \nEpoch: 2269  | Validation balanced accuracy : 0.76304 \nEpoch: 2270  | Training Loss: 0.31207 \nEpoch: 2270  | Training Loss: 0.36899 \nEpoch: 2270  | Training Loss: 0.32796 \nEpoch: 2270  | Training Loss: 0.23709 \nEpoch: 2270  | Training Loss: 0.20652 \nEpoch: 2270  | Validation balanced accuracy : 0.76304 \nEpoch: 2271  | Training Loss: 0.31221 \nEpoch: 2271  | Training Loss: 0.36913 \nEpoch: 2271  | Training Loss: 0.32790 \nEpoch: 2271  | Training Loss: 0.23705 \nEpoch: 2271  | Training Loss: 0.20601 \nEpoch: 2271  | Validation balanced accuracy : 0.76304 \nEpoch: 2272  | Training Loss: 0.31243 \nEpoch: 2272  | Training Loss: 0.36932 \nEpoch: 2272  | Training Loss: 0.32784 \nEpoch: 2272  | Training Loss: 0.23699 \nEpoch: 2272  | Training Loss: 0.20598 \nEpoch: 2272  | Validation balanced accuracy : 0.76304 \nEpoch: 2273  | Training Loss: 0.31225 \nEpoch: 2273  | Training Loss: 0.36905 \nEpoch: 2273  | Training Loss: 0.32792 \nEpoch: 2273  | Training Loss: 0.23689 \nEpoch: 2273  | Training Loss: 0.20627 \nEpoch: 2273  | Validation balanced accuracy : 0.76304 \nEpoch: 2274  | Training Loss: 0.31205 \nEpoch: 2274  | Training Loss: 0.36892 \nEpoch: 2274  | Training Loss: 0.32793 \nEpoch: 2274  | Training Loss: 0.23683 \nEpoch: 2274  | Training Loss: 0.20612 \nEpoch: 2274  | Validation balanced accuracy : 0.76304 \nEpoch: 2275  | Training Loss: 0.31210 \nEpoch: 2275  | Training Loss: 0.36899 \nEpoch: 2275  | Training Loss: 0.32789 \nEpoch: 2275  | Training Loss: 0.23677 \nEpoch: 2275  | Training Loss: 0.20572 \nEpoch: 2275  | Validation balanced accuracy : 0.76304 \nEpoch: 2276  | Training Loss: 0.31226 \nEpoch: 2276  | Training Loss: 0.36913 \nEpoch: 2276  | Training Loss: 0.32783 \nEpoch: 2276  | Training Loss: 0.23671 \nEpoch: 2276  | Training Loss: 0.20574 \nEpoch: 2276  | Validation balanced accuracy : 0.76304 \nEpoch: 2277  | Training Loss: 0.31206 \nEpoch: 2277  | Training Loss: 0.36886 \nEpoch: 2277  | Training Loss: 0.32792 \nEpoch: 2277  | Training Loss: 0.23662 \nEpoch: 2277  | Training Loss: 0.20602 \nEpoch: 2277  | Validation balanced accuracy : 0.76304 \nEpoch: 2278  | Training Loss: 0.31188 \nEpoch: 2278  | Training Loss: 0.36874 \nEpoch: 2278  | Training Loss: 0.32793 \nEpoch: 2278  | Training Loss: 0.23655 \nEpoch: 2278  | Training Loss: 0.20582 \nEpoch: 2278  | Validation balanced accuracy : 0.76304 \nEpoch: 2279  | Training Loss: 0.31195 \nEpoch: 2279  | Training Loss: 0.36883 \nEpoch: 2279  | Training Loss: 0.32788 \nEpoch: 2279  | Training Loss: 0.23650 \nEpoch: 2279  | Training Loss: 0.20538 \nEpoch: 2279  | Validation balanced accuracy : 0.76304 \nEpoch: 2280  | Training Loss: 0.31215 \nEpoch: 2280  | Training Loss: 0.36899 \nEpoch: 2280  | Training Loss: 0.32782 \nEpoch: 2280  | Training Loss: 0.23644 \nEpoch: 2280  | Training Loss: 0.20533 \nEpoch: 2280  | Validation balanced accuracy : 0.76304 \nEpoch: 2281  | Training Loss: 0.31198 \nEpoch: 2281  | Training Loss: 0.36876 \nEpoch: 2281  | Training Loss: 0.32790 \nEpoch: 2281  | Training Loss: 0.23636 \nEpoch: 2281  | Training Loss: 0.20556 \nEpoch: 2281  | Validation balanced accuracy : 0.76304 \nEpoch: 2282  | Training Loss: 0.31183 \nEpoch: 2282  | Training Loss: 0.36866 \nEpoch: 2282  | Training Loss: 0.32790 \nEpoch: 2282  | Training Loss: 0.23629 \nEpoch: 2282  | Training Loss: 0.20536 \nEpoch: 2282  | Validation balanced accuracy : 0.76304 \nEpoch: 2283  | Training Loss: 0.31189 \nEpoch: 2283  | Training Loss: 0.36873 \nEpoch: 2283  | Training Loss: 0.32786 \nEpoch: 2283  | Training Loss: 0.23624 \nEpoch: 2283  | Training Loss: 0.20496 \nEpoch: 2283  | Validation balanced accuracy : 0.76304 \nEpoch: 2284  | Training Loss: 0.31206 \nEpoch: 2284  | Training Loss: 0.36887 \nEpoch: 2284  | Training Loss: 0.32781 \nEpoch: 2284  | Training Loss: 0.23618 \nEpoch: 2284  | Training Loss: 0.20496 \nEpoch: 2284  | Validation balanced accuracy : 0.76304 \nEpoch: 2285  | Training Loss: 0.31187 \nEpoch: 2285  | Training Loss: 0.36862 \nEpoch: 2285  | Training Loss: 0.32790 \nEpoch: 2285  | Training Loss: 0.23609 \nEpoch: 2285  | Training Loss: 0.20522 \nEpoch: 2285  | Validation balanced accuracy : 0.76304 \nEpoch: 2286  | Training Loss: 0.31170 \nEpoch: 2286  | Training Loss: 0.36848 \nEpoch: 2286  | Training Loss: 0.32792 \nEpoch: 2286  | Training Loss: 0.23602 \nEpoch: 2286  | Training Loss: 0.20518 \nEpoch: 2286  | Validation balanced accuracy : 0.76304 \nEpoch: 2287  | Training Loss: 0.31166 \nEpoch: 2287  | Training Loss: 0.36846 \nEpoch: 2287  | Training Loss: 0.32791 \nEpoch: 2287  | Training Loss: 0.23595 \nEpoch: 2287  | Training Loss: 0.20499 \nEpoch: 2287  | Validation balanced accuracy : 0.76304 \nEpoch: 2288  | Training Loss: 0.31171 \nEpoch: 2288  | Training Loss: 0.36850 \nEpoch: 2288  | Training Loss: 0.32789 \nEpoch: 2288  | Training Loss: 0.23590 \nEpoch: 2288  | Training Loss: 0.20473 \nEpoch: 2288  | Validation balanced accuracy : 0.76304 \nEpoch: 2289  | Training Loss: 0.31178 \nEpoch: 2289  | Training Loss: 0.36857 \nEpoch: 2289  | Training Loss: 0.32785 \nEpoch: 2289  | Training Loss: 0.23584 \nEpoch: 2289  | Training Loss: 0.20436 \nEpoch: 2289  | Validation balanced accuracy : 0.76304 \nEpoch: 2290  | Training Loss: 0.31193 \nEpoch: 2290  | Training Loss: 0.36869 \nEpoch: 2290  | Training Loss: 0.32780 \nEpoch: 2290  | Training Loss: 0.23579 \nEpoch: 2290  | Training Loss: 0.20399 \nEpoch: 2290  | Validation balanced accuracy : 0.76304 \nEpoch: 2291  | Training Loss: 0.31206 \nEpoch: 2291  | Training Loss: 0.36879 \nEpoch: 2291  | Training Loss: 0.32777 \nEpoch: 2291  | Training Loss: 0.23573 \nEpoch: 2291  | Training Loss: 0.20413 \nEpoch: 2291  | Validation balanced accuracy : 0.76304 \nEpoch: 2292  | Training Loss: 0.31178 \nEpoch: 2292  | Training Loss: 0.36843 \nEpoch: 2292  | Training Loss: 0.32790 \nEpoch: 2292  | Training Loss: 0.23562 \nEpoch: 2292  | Training Loss: 0.20470 \nEpoch: 2292  | Validation balanced accuracy : 0.76304 \nEpoch: 2293  | Training Loss: 0.31141 \nEpoch: 2293  | Training Loss: 0.36814 \nEpoch: 2293  | Training Loss: 0.32796 \nEpoch: 2293  | Training Loss: 0.23554 \nEpoch: 2293  | Training Loss: 0.20484 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2293  | Validation balanced accuracy : 0.76304 \nEpoch: 2294  | Training Loss: 0.31129 \nEpoch: 2294  | Training Loss: 0.36807 \nEpoch: 2294  | Training Loss: 0.32797 \nEpoch: 2294  | Training Loss: 0.23548 \nEpoch: 2294  | Training Loss: 0.20465 \nEpoch: 2294  | Validation balanced accuracy : 0.76304 \nEpoch: 2295  | Training Loss: 0.31135 \nEpoch: 2295  | Training Loss: 0.36812 \nEpoch: 2295  | Training Loss: 0.32794 \nEpoch: 2295  | Training Loss: 0.23543 \nEpoch: 2295  | Training Loss: 0.20430 \nEpoch: 2295  | Validation balanced accuracy : 0.76304 \nEpoch: 2296  | Training Loss: 0.31149 \nEpoch: 2296  | Training Loss: 0.36823 \nEpoch: 2296  | Training Loss: 0.32790 \nEpoch: 2296  | Training Loss: 0.23537 \nEpoch: 2296  | Training Loss: 0.20395 \nEpoch: 2296  | Validation balanced accuracy : 0.76304 \nEpoch: 2297  | Training Loss: 0.31161 \nEpoch: 2297  | Training Loss: 0.36831 \nEpoch: 2297  | Training Loss: 0.32787 \nEpoch: 2297  | Training Loss: 0.23532 \nEpoch: 2297  | Training Loss: 0.20369 \nEpoch: 2297  | Validation balanced accuracy : 0.76304 \nEpoch: 2298  | Training Loss: 0.31166 \nEpoch: 2298  | Training Loss: 0.36834 \nEpoch: 2298  | Training Loss: 0.32786 \nEpoch: 2298  | Training Loss: 0.23526 \nEpoch: 2298  | Training Loss: 0.20356 \nEpoch: 2298  | Validation balanced accuracy : 0.76304 \nEpoch: 2299  | Training Loss: 0.31165 \nEpoch: 2299  | Training Loss: 0.36830 \nEpoch: 2299  | Training Loss: 0.32786 \nEpoch: 2299  | Training Loss: 0.23519 \nEpoch: 2299  | Training Loss: 0.20351 \nEpoch: 2299  | Validation balanced accuracy : 0.76304 \nEpoch: 2300  | Training Loss: 0.31159 \nEpoch: 2300  | Training Loss: 0.36824 \nEpoch: 2300  | Training Loss: 0.32787 \nEpoch: 2300  | Training Loss: 0.23512 \nEpoch: 2300  | Training Loss: 0.20350 \nEpoch: 2300  | Validation balanced accuracy : 0.76304 \nEpoch: 2301  | Training Loss: 0.31152 \nEpoch: 2301  | Training Loss: 0.36816 \nEpoch: 2301  | Training Loss: 0.32789 \nEpoch: 2301  | Training Loss: 0.23505 \nEpoch: 2301  | Training Loss: 0.20348 \nEpoch: 2301  | Validation balanced accuracy : 0.76304 \nEpoch: 2302  | Training Loss: 0.31145 \nEpoch: 2302  | Training Loss: 0.36810 \nEpoch: 2302  | Training Loss: 0.32790 \nEpoch: 2302  | Training Loss: 0.23499 \nEpoch: 2302  | Training Loss: 0.20343 \nEpoch: 2302  | Validation balanced accuracy : 0.76304 \nEpoch: 2303  | Training Loss: 0.31140 \nEpoch: 2303  | Training Loss: 0.36805 \nEpoch: 2303  | Training Loss: 0.32791 \nEpoch: 2303  | Training Loss: 0.23492 \nEpoch: 2303  | Training Loss: 0.20336 \nEpoch: 2303  | Validation balanced accuracy : 0.76304 \nEpoch: 2304  | Training Loss: 0.31137 \nEpoch: 2304  | Training Loss: 0.36802 \nEpoch: 2304  | Training Loss: 0.32792 \nEpoch: 2304  | Training Loss: 0.23486 \nEpoch: 2304  | Training Loss: 0.20325 \nEpoch: 2304  | Validation balanced accuracy : 0.76304 \nEpoch: 2305  | Training Loss: 0.31136 \nEpoch: 2305  | Training Loss: 0.36799 \nEpoch: 2305  | Training Loss: 0.32792 \nEpoch: 2305  | Training Loss: 0.23479 \nEpoch: 2305  | Training Loss: 0.20314 \nEpoch: 2305  | Validation balanced accuracy : 0.76304 \nEpoch: 2306  | Training Loss: 0.31134 \nEpoch: 2306  | Training Loss: 0.36797 \nEpoch: 2306  | Training Loss: 0.32792 \nEpoch: 2306  | Training Loss: 0.23473 \nEpoch: 2306  | Training Loss: 0.20304 \nEpoch: 2306  | Validation balanced accuracy : 0.76304 \nEpoch: 2307  | Training Loss: 0.31133 \nEpoch: 2307  | Training Loss: 0.36794 \nEpoch: 2307  | Training Loss: 0.32792 \nEpoch: 2307  | Training Loss: 0.23467 \nEpoch: 2307  | Training Loss: 0.20294 \nEpoch: 2307  | Validation balanced accuracy : 0.76304 \nEpoch: 2308  | Training Loss: 0.31130 \nEpoch: 2308  | Training Loss: 0.36791 \nEpoch: 2308  | Training Loss: 0.32793 \nEpoch: 2308  | Training Loss: 0.23460 \nEpoch: 2308  | Training Loss: 0.20285 \nEpoch: 2308  | Validation balanced accuracy : 0.76304 \nEpoch: 2309  | Training Loss: 0.31128 \nEpoch: 2309  | Training Loss: 0.36787 \nEpoch: 2309  | Training Loss: 0.32794 \nEpoch: 2309  | Training Loss: 0.23454 \nEpoch: 2309  | Training Loss: 0.20277 \nEpoch: 2309  | Validation balanced accuracy : 0.76304 \nEpoch: 2310  | Training Loss: 0.31125 \nEpoch: 2310  | Training Loss: 0.36783 \nEpoch: 2310  | Training Loss: 0.32794 \nEpoch: 2310  | Training Loss: 0.23447 \nEpoch: 2310  | Training Loss: 0.20268 \nEpoch: 2310  | Validation balanced accuracy : 0.76304 \nEpoch: 2311  | Training Loss: 0.31122 \nEpoch: 2311  | Training Loss: 0.36779 \nEpoch: 2311  | Training Loss: 0.32795 \nEpoch: 2311  | Training Loss: 0.23441 \nEpoch: 2311  | Training Loss: 0.20260 \nEpoch: 2311  | Validation balanced accuracy : 0.76304 \nEpoch: 2312  | Training Loss: 0.31119 \nEpoch: 2312  | Training Loss: 0.36776 \nEpoch: 2312  | Training Loss: 0.32796 \nEpoch: 2312  | Training Loss: 0.23435 \nEpoch: 2312  | Training Loss: 0.20251 \nEpoch: 2312  | Validation balanced accuracy : 0.76304 \nEpoch: 2313  | Training Loss: 0.31116 \nEpoch: 2313  | Training Loss: 0.36772 \nEpoch: 2313  | Training Loss: 0.32797 \nEpoch: 2313  | Training Loss: 0.23428 \nEpoch: 2313  | Training Loss: 0.20243 \nEpoch: 2313  | Validation balanced accuracy : 0.76304 \nEpoch: 2314  | Training Loss: 0.31113 \nEpoch: 2314  | Training Loss: 0.36769 \nEpoch: 2314  | Training Loss: 0.32797 \nEpoch: 2314  | Training Loss: 0.23422 \nEpoch: 2314  | Training Loss: 0.20233 \nEpoch: 2314  | Validation balanced accuracy : 0.76304 \nEpoch: 2315  | Training Loss: 0.31111 \nEpoch: 2315  | Training Loss: 0.36765 \nEpoch: 2315  | Training Loss: 0.32798 \nEpoch: 2315  | Training Loss: 0.23415 \nEpoch: 2315  | Training Loss: 0.20224 \nEpoch: 2315  | Validation balanced accuracy : 0.76304 \nEpoch: 2316  | Training Loss: 0.31108 \nEpoch: 2316  | Training Loss: 0.36762 \nEpoch: 2316  | Training Loss: 0.32799 \nEpoch: 2316  | Training Loss: 0.23409 \nEpoch: 2316  | Training Loss: 0.20215 \nEpoch: 2316  | Validation balanced accuracy : 0.76304 \nEpoch: 2317  | Training Loss: 0.31106 \nEpoch: 2317  | Training Loss: 0.36758 \nEpoch: 2317  | Training Loss: 0.32800 \nEpoch: 2317  | Training Loss: 0.23403 \nEpoch: 2317  | Training Loss: 0.20207 \nEpoch: 2317  | Validation balanced accuracy : 0.76304 \nEpoch: 2318  | Training Loss: 0.31103 \nEpoch: 2318  | Training Loss: 0.36755 \nEpoch: 2318  | Training Loss: 0.32801 \nEpoch: 2318  | Training Loss: 0.23397 \nEpoch: 2318  | Training Loss: 0.20198 \nEpoch: 2318  | Validation balanced accuracy : 0.76304 \nEpoch: 2319  | Training Loss: 0.31101 \nEpoch: 2319  | Training Loss: 0.36751 \nEpoch: 2319  | Training Loss: 0.32802 \nEpoch: 2319  | Training Loss: 0.23390 \nEpoch: 2319  | Training Loss: 0.20189 \nEpoch: 2319  | Validation balanced accuracy : 0.76304 \nEpoch: 2320  | Training Loss: 0.31098 \nEpoch: 2320  | Training Loss: 0.36748 \nEpoch: 2320  | Training Loss: 0.32803 \nEpoch: 2320  | Training Loss: 0.23384 \nEpoch: 2320  | Training Loss: 0.20180 \nEpoch: 2320  | Validation balanced accuracy : 0.76304 \nEpoch: 2321  | Training Loss: 0.31096 \nEpoch: 2321  | Training Loss: 0.36744 \nEpoch: 2321  | Training Loss: 0.32804 \nEpoch: 2321  | Training Loss: 0.23378 \nEpoch: 2321  | Training Loss: 0.20171 \nEpoch: 2321  | Validation balanced accuracy : 0.76304 \nEpoch: 2322  | Training Loss: 0.31093 \nEpoch: 2322  | Training Loss: 0.36740 \nEpoch: 2322  | Training Loss: 0.32805 \nEpoch: 2322  | Training Loss: 0.23371 \nEpoch: 2322  | Training Loss: 0.20162 \nEpoch: 2322  | Validation balanced accuracy : 0.76304 \nEpoch: 2323  | Training Loss: 0.31091 \nEpoch: 2323  | Training Loss: 0.36737 \nEpoch: 2323  | Training Loss: 0.32806 \nEpoch: 2323  | Training Loss: 0.23365 \nEpoch: 2323  | Training Loss: 0.20153 \nEpoch: 2323  | Validation balanced accuracy : 0.76304 \nEpoch: 2324  | Training Loss: 0.31088 \nEpoch: 2324  | Training Loss: 0.36733 \nEpoch: 2324  | Training Loss: 0.32807 \nEpoch: 2324  | Training Loss: 0.23359 \nEpoch: 2324  | Training Loss: 0.20141 \nEpoch: 2324  | Validation balanced accuracy : 0.76304 \nEpoch: 2325  | Training Loss: 0.31089 \nEpoch: 2325  | Training Loss: 0.36733 \nEpoch: 2325  | Training Loss: 0.32807 \nEpoch: 2325  | Training Loss: 0.23353 \nEpoch: 2325  | Training Loss: 0.20123 \nEpoch: 2325  | Validation balanced accuracy : 0.76304 \nEpoch: 2326  | Training Loss: 0.31092 \nEpoch: 2326  | Training Loss: 0.36734 \nEpoch: 2326  | Training Loss: 0.32807 \nEpoch: 2326  | Training Loss: 0.23347 \nEpoch: 2326  | Training Loss: 0.20106 \nEpoch: 2326  | Validation balanced accuracy : 0.76304 \nEpoch: 2327  | Training Loss: 0.31094 \nEpoch: 2327  | Training Loss: 0.36734 \nEpoch: 2327  | Training Loss: 0.32807 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2327  | Training Loss: 0.23342 \nEpoch: 2327  | Training Loss: 0.20092 \nEpoch: 2327  | Validation balanced accuracy : 0.76304 \nEpoch: 2328  | Training Loss: 0.31094 \nEpoch: 2328  | Training Loss: 0.36733 \nEpoch: 2328  | Training Loss: 0.32808 \nEpoch: 2328  | Training Loss: 0.23335 \nEpoch: 2328  | Training Loss: 0.20082 \nEpoch: 2328  | Validation balanced accuracy : 0.76304 \nEpoch: 2329  | Training Loss: 0.31092 \nEpoch: 2329  | Training Loss: 0.36729 \nEpoch: 2329  | Training Loss: 0.32809 \nEpoch: 2329  | Training Loss: 0.23329 \nEpoch: 2329  | Training Loss: 0.20075 \nEpoch: 2329  | Validation balanced accuracy : 0.76304 \nEpoch: 2330  | Training Loss: 0.31089 \nEpoch: 2330  | Training Loss: 0.36725 \nEpoch: 2330  | Training Loss: 0.32810 \nEpoch: 2330  | Training Loss: 0.23323 \nEpoch: 2330  | Training Loss: 0.20068 \nEpoch: 2330  | Validation balanced accuracy : 0.76304 \nEpoch: 2331  | Training Loss: 0.31085 \nEpoch: 2331  | Training Loss: 0.36720 \nEpoch: 2331  | Training Loss: 0.32812 \nEpoch: 2331  | Training Loss: 0.23317 \nEpoch: 2331  | Training Loss: 0.20061 \nEpoch: 2331  | Validation balanced accuracy : 0.76304 \nEpoch: 2332  | Training Loss: 0.31081 \nEpoch: 2332  | Training Loss: 0.36716 \nEpoch: 2332  | Training Loss: 0.32813 \nEpoch: 2332  | Training Loss: 0.23310 \nEpoch: 2332  | Training Loss: 0.20054 \nEpoch: 2332  | Validation balanced accuracy : 0.76304 \nEpoch: 2333  | Training Loss: 0.31078 \nEpoch: 2333  | Training Loss: 0.36712 \nEpoch: 2333  | Training Loss: 0.32815 \nEpoch: 2333  | Training Loss: 0.23304 \nEpoch: 2333  | Training Loss: 0.20045 \nEpoch: 2333  | Validation balanced accuracy : 0.76304 \nEpoch: 2334  | Training Loss: 0.31076 \nEpoch: 2334  | Training Loss: 0.36709 \nEpoch: 2334  | Training Loss: 0.32816 \nEpoch: 2334  | Training Loss: 0.23298 \nEpoch: 2334  | Training Loss: 0.20035 \nEpoch: 2334  | Validation balanced accuracy : 0.76304 \nEpoch: 2335  | Training Loss: 0.31074 \nEpoch: 2335  | Training Loss: 0.36707 \nEpoch: 2335  | Training Loss: 0.32816 \nEpoch: 2335  | Training Loss: 0.23292 \nEpoch: 2335  | Training Loss: 0.20019 \nEpoch: 2335  | Validation balanced accuracy : 0.76304 \nEpoch: 2336  | Training Loss: 0.31077 \nEpoch: 2336  | Training Loss: 0.36709 \nEpoch: 2336  | Training Loss: 0.32816 \nEpoch: 2336  | Training Loss: 0.23287 \nEpoch: 2336  | Training Loss: 0.20000 \nEpoch: 2336  | Validation balanced accuracy : 0.76304 \nEpoch: 2337  | Training Loss: 0.31081 \nEpoch: 2337  | Training Loss: 0.36710 \nEpoch: 2337  | Training Loss: 0.32815 \nEpoch: 2337  | Training Loss: 0.23281 \nEpoch: 2337  | Training Loss: 0.19984 \nEpoch: 2337  | Validation balanced accuracy : 0.76304 \nEpoch: 2338  | Training Loss: 0.31083 \nEpoch: 2338  | Training Loss: 0.36710 \nEpoch: 2338  | Training Loss: 0.32816 \nEpoch: 2338  | Training Loss: 0.23275 \nEpoch: 2338  | Training Loss: 0.19971 \nEpoch: 2338  | Validation balanced accuracy : 0.76304 \nEpoch: 2339  | Training Loss: 0.31082 \nEpoch: 2339  | Training Loss: 0.36708 \nEpoch: 2339  | Training Loss: 0.32817 \nEpoch: 2339  | Training Loss: 0.23269 \nEpoch: 2339  | Training Loss: 0.19962 \nEpoch: 2339  | Validation balanced accuracy : 0.76304 \nEpoch: 2340  | Training Loss: 0.31080 \nEpoch: 2340  | Training Loss: 0.36704 \nEpoch: 2340  | Training Loss: 0.32818 \nEpoch: 2340  | Training Loss: 0.23263 \nEpoch: 2340  | Training Loss: 0.19956 \nEpoch: 2340  | Validation balanced accuracy : 0.76304 \nEpoch: 2341  | Training Loss: 0.31076 \nEpoch: 2341  | Training Loss: 0.36700 \nEpoch: 2341  | Training Loss: 0.32820 \nEpoch: 2341  | Training Loss: 0.23257 \nEpoch: 2341  | Training Loss: 0.19950 \nEpoch: 2341  | Validation balanced accuracy : 0.76304 \nEpoch: 2342  | Training Loss: 0.31072 \nEpoch: 2342  | Training Loss: 0.36695 \nEpoch: 2342  | Training Loss: 0.32822 \nEpoch: 2342  | Training Loss: 0.23251 \nEpoch: 2342  | Training Loss: 0.19942 \nEpoch: 2342  | Validation balanced accuracy : 0.76304 \nEpoch: 2343  | Training Loss: 0.31069 \nEpoch: 2343  | Training Loss: 0.36692 \nEpoch: 2343  | Training Loss: 0.32823 \nEpoch: 2343  | Training Loss: 0.23245 \nEpoch: 2343  | Training Loss: 0.19934 \nEpoch: 2343  | Validation balanced accuracy : 0.76304 \nEpoch: 2344  | Training Loss: 0.31067 \nEpoch: 2344  | Training Loss: 0.36688 \nEpoch: 2344  | Training Loss: 0.32824 \nEpoch: 2344  | Training Loss: 0.23239 \nEpoch: 2344  | Training Loss: 0.19925 \nEpoch: 2344  | Validation balanced accuracy : 0.76304 \nEpoch: 2345  | Training Loss: 0.31065 \nEpoch: 2345  | Training Loss: 0.36685 \nEpoch: 2345  | Training Loss: 0.32825 \nEpoch: 2345  | Training Loss: 0.23233 \nEpoch: 2345  | Training Loss: 0.19915 \nEpoch: 2345  | Validation balanced accuracy : 0.76304 \nEpoch: 2346  | Training Loss: 0.31063 \nEpoch: 2346  | Training Loss: 0.36683 \nEpoch: 2346  | Training Loss: 0.32827 \nEpoch: 2346  | Training Loss: 0.23227 \nEpoch: 2346  | Training Loss: 0.19906 \nEpoch: 2346  | Validation balanced accuracy : 0.76304 \nEpoch: 2347  | Training Loss: 0.31061 \nEpoch: 2347  | Training Loss: 0.36680 \nEpoch: 2347  | Training Loss: 0.32828 \nEpoch: 2347  | Training Loss: 0.23221 \nEpoch: 2347  | Training Loss: 0.19896 \nEpoch: 2347  | Validation balanced accuracy : 0.76304 \nEpoch: 2348  | Training Loss: 0.31060 \nEpoch: 2348  | Training Loss: 0.36677 \nEpoch: 2348  | Training Loss: 0.32829 \nEpoch: 2348  | Training Loss: 0.23215 \nEpoch: 2348  | Training Loss: 0.19887 \nEpoch: 2348  | Validation balanced accuracy : 0.76304 \nEpoch: 2349  | Training Loss: 0.31058 \nEpoch: 2349  | Training Loss: 0.36674 \nEpoch: 2349  | Training Loss: 0.32831 \nEpoch: 2349  | Training Loss: 0.23209 \nEpoch: 2349  | Training Loss: 0.19878 \nEpoch: 2349  | Validation balanced accuracy : 0.76304 \nEpoch: 2350  | Training Loss: 0.31056 \nEpoch: 2350  | Training Loss: 0.36671 \nEpoch: 2350  | Training Loss: 0.32832 \nEpoch: 2350  | Training Loss: 0.23203 \nEpoch: 2350  | Training Loss: 0.19869 \nEpoch: 2350  | Validation balanced accuracy : 0.76304 \nEpoch: 2351  | Training Loss: 0.31053 \nEpoch: 2351  | Training Loss: 0.36668 \nEpoch: 2351  | Training Loss: 0.32834 \nEpoch: 2351  | Training Loss: 0.23197 \nEpoch: 2351  | Training Loss: 0.19860 \nEpoch: 2351  | Validation balanced accuracy : 0.76304 \nEpoch: 2352  | Training Loss: 0.31051 \nEpoch: 2352  | Training Loss: 0.36664 \nEpoch: 2352  | Training Loss: 0.32835 \nEpoch: 2352  | Training Loss: 0.23191 \nEpoch: 2352  | Training Loss: 0.19852 \nEpoch: 2352  | Validation balanced accuracy : 0.76304 \nEpoch: 2353  | Training Loss: 0.31049 \nEpoch: 2353  | Training Loss: 0.36661 \nEpoch: 2353  | Training Loss: 0.32837 \nEpoch: 2353  | Training Loss: 0.23185 \nEpoch: 2353  | Training Loss: 0.19843 \nEpoch: 2353  | Validation balanced accuracy : 0.76304 \nEpoch: 2354  | Training Loss: 0.31047 \nEpoch: 2354  | Training Loss: 0.36658 \nEpoch: 2354  | Training Loss: 0.32839 \nEpoch: 2354  | Training Loss: 0.23179 \nEpoch: 2354  | Training Loss: 0.19834 \nEpoch: 2354  | Validation balanced accuracy : 0.76304 \nEpoch: 2355  | Training Loss: 0.31045 \nEpoch: 2355  | Training Loss: 0.36655 \nEpoch: 2355  | Training Loss: 0.32840 \nEpoch: 2355  | Training Loss: 0.23173 \nEpoch: 2355  | Training Loss: 0.19824 \nEpoch: 2355  | Validation balanced accuracy : 0.76304 \nEpoch: 2356  | Training Loss: 0.31043 \nEpoch: 2356  | Training Loss: 0.36652 \nEpoch: 2356  | Training Loss: 0.32842 \nEpoch: 2356  | Training Loss: 0.23167 \nEpoch: 2356  | Training Loss: 0.19815 \nEpoch: 2356  | Validation balanced accuracy : 0.76304 \nEpoch: 2357  | Training Loss: 0.31042 \nEpoch: 2357  | Training Loss: 0.36649 \nEpoch: 2357  | Training Loss: 0.32843 \nEpoch: 2357  | Training Loss: 0.23162 \nEpoch: 2357  | Training Loss: 0.19806 \nEpoch: 2357  | Validation balanced accuracy : 0.76304 \nEpoch: 2358  | Training Loss: 0.31040 \nEpoch: 2358  | Training Loss: 0.36646 \nEpoch: 2358  | Training Loss: 0.32845 \nEpoch: 2358  | Training Loss: 0.23156 \nEpoch: 2358  | Training Loss: 0.19797 \nEpoch: 2358  | Validation balanced accuracy : 0.76304 \nEpoch: 2359  | Training Loss: 0.31038 \nEpoch: 2359  | Training Loss: 0.36643 \nEpoch: 2359  | Training Loss: 0.32847 \nEpoch: 2359  | Training Loss: 0.23150 \nEpoch: 2359  | Training Loss: 0.19788 \nEpoch: 2359  | Validation balanced accuracy : 0.76304 \nEpoch: 2360  | Training Loss: 0.31036 \nEpoch: 2360  | Training Loss: 0.36639 \nEpoch: 2360  | Training Loss: 0.32849 \nEpoch: 2360  | Training Loss: 0.23144 \nEpoch: 2360  | Training Loss: 0.19779 \nEpoch: 2360  | Validation balanced accuracy : 0.76304 \nEpoch: 2361  | Training Loss: 0.31034 \nEpoch: 2361  | Training Loss: 0.36636 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2361  | Training Loss: 0.32850 \nEpoch: 2361  | Training Loss: 0.23138 \nEpoch: 2361  | Training Loss: 0.19770 \nEpoch: 2361  | Validation balanced accuracy : 0.76304 \nEpoch: 2362  | Training Loss: 0.31032 \nEpoch: 2362  | Training Loss: 0.36633 \nEpoch: 2362  | Training Loss: 0.32852 \nEpoch: 2362  | Training Loss: 0.23132 \nEpoch: 2362  | Training Loss: 0.19761 \nEpoch: 2362  | Validation balanced accuracy : 0.76304 \nEpoch: 2363  | Training Loss: 0.31030 \nEpoch: 2363  | Training Loss: 0.36630 \nEpoch: 2363  | Training Loss: 0.32854 \nEpoch: 2363  | Training Loss: 0.23127 \nEpoch: 2363  | Training Loss: 0.19752 \nEpoch: 2363  | Validation balanced accuracy : 0.76304 \nEpoch: 2364  | Training Loss: 0.31028 \nEpoch: 2364  | Training Loss: 0.36627 \nEpoch: 2364  | Training Loss: 0.32856 \nEpoch: 2364  | Training Loss: 0.23121 \nEpoch: 2364  | Training Loss: 0.19743 \nEpoch: 2364  | Validation balanced accuracy : 0.76304 \nEpoch: 2365  | Training Loss: 0.31026 \nEpoch: 2365  | Training Loss: 0.36624 \nEpoch: 2365  | Training Loss: 0.32858 \nEpoch: 2365  | Training Loss: 0.23115 \nEpoch: 2365  | Training Loss: 0.19734 \nEpoch: 2365  | Validation balanced accuracy : 0.76304 \nEpoch: 2366  | Training Loss: 0.31025 \nEpoch: 2366  | Training Loss: 0.36621 \nEpoch: 2366  | Training Loss: 0.32860 \nEpoch: 2366  | Training Loss: 0.23109 \nEpoch: 2366  | Training Loss: 0.19725 \nEpoch: 2366  | Validation balanced accuracy : 0.76304 \nEpoch: 2367  | Training Loss: 0.31023 \nEpoch: 2367  | Training Loss: 0.36617 \nEpoch: 2367  | Training Loss: 0.32862 \nEpoch: 2367  | Training Loss: 0.23103 \nEpoch: 2367  | Training Loss: 0.19716 \nEpoch: 2367  | Validation balanced accuracy : 0.76304 \nEpoch: 2368  | Training Loss: 0.31021 \nEpoch: 2368  | Training Loss: 0.36614 \nEpoch: 2368  | Training Loss: 0.32864 \nEpoch: 2368  | Training Loss: 0.23098 \nEpoch: 2368  | Training Loss: 0.19707 \nEpoch: 2368  | Validation balanced accuracy : 0.76304 \nEpoch: 2369  | Training Loss: 0.31019 \nEpoch: 2369  | Training Loss: 0.36611 \nEpoch: 2369  | Training Loss: 0.32866 \nEpoch: 2369  | Training Loss: 0.23092 \nEpoch: 2369  | Training Loss: 0.19698 \nEpoch: 2369  | Validation balanced accuracy : 0.76304 \nEpoch: 2370  | Training Loss: 0.31017 \nEpoch: 2370  | Training Loss: 0.36608 \nEpoch: 2370  | Training Loss: 0.32868 \nEpoch: 2370  | Training Loss: 0.23086 \nEpoch: 2370  | Training Loss: 0.19689 \nEpoch: 2370  | Validation balanced accuracy : 0.76304 \nEpoch: 2371  | Training Loss: 0.31016 \nEpoch: 2371  | Training Loss: 0.36605 \nEpoch: 2371  | Training Loss: 0.32870 \nEpoch: 2371  | Training Loss: 0.23080 \nEpoch: 2371  | Training Loss: 0.19680 \nEpoch: 2371  | Validation balanced accuracy : 0.76304 \nEpoch: 2372  | Training Loss: 0.31014 \nEpoch: 2372  | Training Loss: 0.36602 \nEpoch: 2372  | Training Loss: 0.32872 \nEpoch: 2372  | Training Loss: 0.23075 \nEpoch: 2372  | Training Loss: 0.19671 \nEpoch: 2372  | Validation balanced accuracy : 0.76304 \nEpoch: 2373  | Training Loss: 0.31012 \nEpoch: 2373  | Training Loss: 0.36600 \nEpoch: 2373  | Training Loss: 0.32873 \nEpoch: 2373  | Training Loss: 0.23069 \nEpoch: 2373  | Training Loss: 0.19655 \nEpoch: 2373  | Validation balanced accuracy : 0.76304 \nEpoch: 2374  | Training Loss: 0.31015 \nEpoch: 2374  | Training Loss: 0.36601 \nEpoch: 2374  | Training Loss: 0.32874 \nEpoch: 2374  | Training Loss: 0.23064 \nEpoch: 2374  | Training Loss: 0.19636 \nEpoch: 2374  | Validation balanced accuracy : 0.76304 \nEpoch: 2375  | Training Loss: 0.31020 \nEpoch: 2375  | Training Loss: 0.36603 \nEpoch: 2375  | Training Loss: 0.32874 \nEpoch: 2375  | Training Loss: 0.23059 \nEpoch: 2375  | Training Loss: 0.19619 \nEpoch: 2375  | Validation balanced accuracy : 0.76304 \nEpoch: 2376  | Training Loss: 0.31023 \nEpoch: 2376  | Training Loss: 0.36604 \nEpoch: 2376  | Training Loss: 0.32875 \nEpoch: 2376  | Training Loss: 0.23054 \nEpoch: 2376  | Training Loss: 0.19606 \nEpoch: 2376  | Validation balanced accuracy : 0.76304 \nEpoch: 2377  | Training Loss: 0.31023 \nEpoch: 2377  | Training Loss: 0.36602 \nEpoch: 2377  | Training Loss: 0.32877 \nEpoch: 2377  | Training Loss: 0.23048 \nEpoch: 2377  | Training Loss: 0.19597 \nEpoch: 2377  | Validation balanced accuracy : 0.76304 \nEpoch: 2378  | Training Loss: 0.31021 \nEpoch: 2378  | Training Loss: 0.36598 \nEpoch: 2378  | Training Loss: 0.32879 \nEpoch: 2378  | Training Loss: 0.23042 \nEpoch: 2378  | Training Loss: 0.19591 \nEpoch: 2378  | Validation balanced accuracy : 0.76304 \nEpoch: 2379  | Training Loss: 0.31017 \nEpoch: 2379  | Training Loss: 0.36594 \nEpoch: 2379  | Training Loss: 0.32882 \nEpoch: 2379  | Training Loss: 0.23036 \nEpoch: 2379  | Training Loss: 0.19585 \nEpoch: 2379  | Validation balanced accuracy : 0.76304 \nEpoch: 2380  | Training Loss: 0.31014 \nEpoch: 2380  | Training Loss: 0.36589 \nEpoch: 2380  | Training Loss: 0.32884 \nEpoch: 2380  | Training Loss: 0.23031 \nEpoch: 2380  | Training Loss: 0.19578 \nEpoch: 2380  | Validation balanced accuracy : 0.76304 \nEpoch: 2381  | Training Loss: 0.31011 \nEpoch: 2381  | Training Loss: 0.36586 \nEpoch: 2381  | Training Loss: 0.32886 \nEpoch: 2381  | Training Loss: 0.23025 \nEpoch: 2381  | Training Loss: 0.19569 \nEpoch: 2381  | Validation balanced accuracy : 0.76304 \nEpoch: 2382  | Training Loss: 0.31010 \nEpoch: 2382  | Training Loss: 0.36583 \nEpoch: 2382  | Training Loss: 0.32889 \nEpoch: 2382  | Training Loss: 0.23020 \nEpoch: 2382  | Training Loss: 0.19560 \nEpoch: 2382  | Validation balanced accuracy : 0.76304 \nEpoch: 2383  | Training Loss: 0.31008 \nEpoch: 2383  | Training Loss: 0.36580 \nEpoch: 2383  | Training Loss: 0.32891 \nEpoch: 2383  | Training Loss: 0.23014 \nEpoch: 2383  | Training Loss: 0.19550 \nEpoch: 2383  | Validation balanced accuracy : 0.76304 \nEpoch: 2384  | Training Loss: 0.31007 \nEpoch: 2384  | Training Loss: 0.36578 \nEpoch: 2384  | Training Loss: 0.32893 \nEpoch: 2384  | Training Loss: 0.23008 \nEpoch: 2384  | Training Loss: 0.19540 \nEpoch: 2384  | Validation balanced accuracy : 0.76304 \nEpoch: 2385  | Training Loss: 0.31006 \nEpoch: 2385  | Training Loss: 0.36575 \nEpoch: 2385  | Training Loss: 0.32895 \nEpoch: 2385  | Training Loss: 0.23003 \nEpoch: 2385  | Training Loss: 0.19531 \nEpoch: 2385  | Validation balanced accuracy : 0.76304 \nEpoch: 2386  | Training Loss: 0.31005 \nEpoch: 2386  | Training Loss: 0.36573 \nEpoch: 2386  | Training Loss: 0.32897 \nEpoch: 2386  | Training Loss: 0.22997 \nEpoch: 2386  | Training Loss: 0.19522 \nEpoch: 2386  | Validation balanced accuracy : 0.76304 \nEpoch: 2387  | Training Loss: 0.31003 \nEpoch: 2387  | Training Loss: 0.36571 \nEpoch: 2387  | Training Loss: 0.32898 \nEpoch: 2387  | Training Loss: 0.22992 \nEpoch: 2387  | Training Loss: 0.19506 \nEpoch: 2387  | Validation balanced accuracy : 0.76304 \nEpoch: 2388  | Training Loss: 0.31007 \nEpoch: 2388  | Training Loss: 0.36573 \nEpoch: 2388  | Training Loss: 0.32899 \nEpoch: 2388  | Training Loss: 0.22987 \nEpoch: 2388  | Training Loss: 0.19487 \nEpoch: 2388  | Validation balanced accuracy : 0.76304 \nEpoch: 2389  | Training Loss: 0.31012 \nEpoch: 2389  | Training Loss: 0.36575 \nEpoch: 2389  | Training Loss: 0.32899 \nEpoch: 2389  | Training Loss: 0.22982 \nEpoch: 2389  | Training Loss: 0.19470 \nEpoch: 2389  | Validation balanced accuracy : 0.76304 \nEpoch: 2390  | Training Loss: 0.31014 \nEpoch: 2390  | Training Loss: 0.36575 \nEpoch: 2390  | Training Loss: 0.32900 \nEpoch: 2390  | Training Loss: 0.22977 \nEpoch: 2390  | Training Loss: 0.19457 \nEpoch: 2390  | Validation balanced accuracy : 0.76304 \nEpoch: 2391  | Training Loss: 0.31015 \nEpoch: 2391  | Training Loss: 0.36574 \nEpoch: 2391  | Training Loss: 0.32902 \nEpoch: 2391  | Training Loss: 0.22972 \nEpoch: 2391  | Training Loss: 0.19449 \nEpoch: 2391  | Validation balanced accuracy : 0.76304 \nEpoch: 2392  | Training Loss: 0.31013 \nEpoch: 2392  | Training Loss: 0.36570 \nEpoch: 2392  | Training Loss: 0.32904 \nEpoch: 2392  | Training Loss: 0.22966 \nEpoch: 2392  | Training Loss: 0.19442 \nEpoch: 2392  | Validation balanced accuracy : 0.76304 \nEpoch: 2393  | Training Loss: 0.31010 \nEpoch: 2393  | Training Loss: 0.36566 \nEpoch: 2393  | Training Loss: 0.32907 \nEpoch: 2393  | Training Loss: 0.22960 \nEpoch: 2393  | Training Loss: 0.19436 \nEpoch: 2393  | Validation balanced accuracy : 0.76304 \nEpoch: 2394  | Training Loss: 0.31007 \nEpoch: 2394  | Training Loss: 0.36562 \nEpoch: 2394  | Training Loss: 0.32910 \nEpoch: 2394  | Training Loss: 0.22955 \nEpoch: 2394  | Training Loss: 0.19429 \nEpoch: 2394  | Validation balanced accuracy : 0.76304 \nEpoch: 2395  | Training Loss: 0.31004 \nEpoch: 2395  | Training Loss: 0.36559 \nEpoch: 2395  | Training Loss: 0.32912 \nEpoch: 2395  | Training Loss: 0.22949 \nEpoch: 2395  | Training Loss: 0.19420 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2395  | Validation balanced accuracy : 0.76304 \nEpoch: 2396  | Training Loss: 0.31003 \nEpoch: 2396  | Training Loss: 0.36556 \nEpoch: 2396  | Training Loss: 0.32914 \nEpoch: 2396  | Training Loss: 0.22944 \nEpoch: 2396  | Training Loss: 0.19411 \nEpoch: 2396  | Validation balanced accuracy : 0.76304 \nEpoch: 2397  | Training Loss: 0.31002 \nEpoch: 2397  | Training Loss: 0.36554 \nEpoch: 2397  | Training Loss: 0.32916 \nEpoch: 2397  | Training Loss: 0.22938 \nEpoch: 2397  | Training Loss: 0.19401 \nEpoch: 2397  | Validation balanced accuracy : 0.76304 \nEpoch: 2398  | Training Loss: 0.31001 \nEpoch: 2398  | Training Loss: 0.36552 \nEpoch: 2398  | Training Loss: 0.32918 \nEpoch: 2398  | Training Loss: 0.22933 \nEpoch: 2398  | Training Loss: 0.19391 \nEpoch: 2398  | Validation balanced accuracy : 0.76304 \nEpoch: 2399  | Training Loss: 0.31000 \nEpoch: 2399  | Training Loss: 0.36550 \nEpoch: 2399  | Training Loss: 0.32920 \nEpoch: 2399  | Training Loss: 0.22928 \nEpoch: 2399  | Training Loss: 0.19382 \nEpoch: 2399  | Validation balanced accuracy : 0.76304 \nEpoch: 2400  | Training Loss: 0.30999 \nEpoch: 2400  | Training Loss: 0.36547 \nEpoch: 2400  | Training Loss: 0.32923 \nEpoch: 2400  | Training Loss: 0.22922 \nEpoch: 2400  | Training Loss: 0.19373 \nEpoch: 2400  | Validation balanced accuracy : 0.76304 \nEpoch: 2401  | Training Loss: 0.30998 \nEpoch: 2401  | Training Loss: 0.36542 \nEpoch: 2401  | Training Loss: 0.32922 \nEpoch: 2401  | Training Loss: 0.22919 \nEpoch: 2401  | Training Loss: 0.19325 \nEpoch: 2401  | Validation balanced accuracy : 0.76304 \nEpoch: 2402  | Training Loss: 0.30995 \nEpoch: 2402  | Training Loss: 0.36538 \nEpoch: 2402  | Training Loss: 0.32925 \nEpoch: 2402  | Training Loss: 0.22914 \nEpoch: 2402  | Training Loss: 0.19323 \nEpoch: 2402  | Validation balanced accuracy : 0.76304 \nEpoch: 2403  | Training Loss: 0.30990 \nEpoch: 2403  | Training Loss: 0.36532 \nEpoch: 2403  | Training Loss: 0.32928 \nEpoch: 2403  | Training Loss: 0.22909 \nEpoch: 2403  | Training Loss: 0.19322 \nEpoch: 2403  | Validation balanced accuracy : 0.76304 \nEpoch: 2404  | Training Loss: 0.30985 \nEpoch: 2404  | Training Loss: 0.36527 \nEpoch: 2404  | Training Loss: 0.32931 \nEpoch: 2404  | Training Loss: 0.22903 \nEpoch: 2404  | Training Loss: 0.19319 \nEpoch: 2404  | Validation balanced accuracy : 0.76304 \nEpoch: 2405  | Training Loss: 0.30981 \nEpoch: 2405  | Training Loss: 0.36522 \nEpoch: 2405  | Training Loss: 0.32934 \nEpoch: 2405  | Training Loss: 0.22898 \nEpoch: 2405  | Training Loss: 0.19313 \nEpoch: 2405  | Validation balanced accuracy : 0.76304 \nEpoch: 2406  | Training Loss: 0.30979 \nEpoch: 2406  | Training Loss: 0.36519 \nEpoch: 2406  | Training Loss: 0.32936 \nEpoch: 2406  | Training Loss: 0.22894 \nEpoch: 2406  | Training Loss: 0.19304 \nEpoch: 2406  | Validation balanced accuracy : 0.76304 \nEpoch: 2407  | Training Loss: 0.30978 \nEpoch: 2407  | Training Loss: 0.36518 \nEpoch: 2407  | Training Loss: 0.32938 \nEpoch: 2407  | Training Loss: 0.22889 \nEpoch: 2407  | Training Loss: 0.19295 \nEpoch: 2407  | Validation balanced accuracy : 0.76304 \nEpoch: 2408  | Training Loss: 0.30978 \nEpoch: 2408  | Training Loss: 0.36516 \nEpoch: 2408  | Training Loss: 0.32940 \nEpoch: 2408  | Training Loss: 0.22884 \nEpoch: 2408  | Training Loss: 0.19285 \nEpoch: 2408  | Validation balanced accuracy : 0.76304 \nEpoch: 2409  | Training Loss: 0.30978 \nEpoch: 2409  | Training Loss: 0.36515 \nEpoch: 2409  | Training Loss: 0.32942 \nEpoch: 2409  | Training Loss: 0.22880 \nEpoch: 2409  | Training Loss: 0.19275 \nEpoch: 2409  | Validation balanced accuracy : 0.76304 \nEpoch: 2410  | Training Loss: 0.30978 \nEpoch: 2410  | Training Loss: 0.36513 \nEpoch: 2410  | Training Loss: 0.32944 \nEpoch: 2410  | Training Loss: 0.22875 \nEpoch: 2410  | Training Loss: 0.19267 \nEpoch: 2410  | Validation balanced accuracy : 0.76304 \nEpoch: 2411  | Training Loss: 0.30977 \nEpoch: 2411  | Training Loss: 0.36511 \nEpoch: 2411  | Training Loss: 0.32946 \nEpoch: 2411  | Training Loss: 0.22870 \nEpoch: 2411  | Training Loss: 0.19259 \nEpoch: 2411  | Validation balanced accuracy : 0.76304 \nEpoch: 2412  | Training Loss: 0.30976 \nEpoch: 2412  | Training Loss: 0.36508 \nEpoch: 2412  | Training Loss: 0.32948 \nEpoch: 2412  | Training Loss: 0.22865 \nEpoch: 2412  | Training Loss: 0.19251 \nEpoch: 2412  | Validation balanced accuracy : 0.76304 \nEpoch: 2413  | Training Loss: 0.30974 \nEpoch: 2413  | Training Loss: 0.36505 \nEpoch: 2413  | Training Loss: 0.32951 \nEpoch: 2413  | Training Loss: 0.22861 \nEpoch: 2413  | Training Loss: 0.19243 \nEpoch: 2413  | Validation balanced accuracy : 0.76304 \nEpoch: 2414  | Training Loss: 0.30973 \nEpoch: 2414  | Training Loss: 0.36503 \nEpoch: 2414  | Training Loss: 0.32953 \nEpoch: 2414  | Training Loss: 0.22856 \nEpoch: 2414  | Training Loss: 0.19236 \nEpoch: 2414  | Validation balanced accuracy : 0.76304 \nEpoch: 2415  | Training Loss: 0.30972 \nEpoch: 2415  | Training Loss: 0.36500 \nEpoch: 2415  | Training Loss: 0.32955 \nEpoch: 2415  | Training Loss: 0.22851 \nEpoch: 2415  | Training Loss: 0.19228 \nEpoch: 2415  | Validation balanced accuracy : 0.76304 \nEpoch: 2416  | Training Loss: 0.30971 \nEpoch: 2416  | Training Loss: 0.36498 \nEpoch: 2416  | Training Loss: 0.32958 \nEpoch: 2416  | Training Loss: 0.22846 \nEpoch: 2416  | Training Loss: 0.19219 \nEpoch: 2416  | Validation balanced accuracy : 0.76304 \nEpoch: 2417  | Training Loss: 0.30970 \nEpoch: 2417  | Training Loss: 0.36496 \nEpoch: 2417  | Training Loss: 0.32960 \nEpoch: 2417  | Training Loss: 0.22842 \nEpoch: 2417  | Training Loss: 0.19211 \nEpoch: 2417  | Validation balanced accuracy : 0.76304 \nEpoch: 2418  | Training Loss: 0.30969 \nEpoch: 2418  | Training Loss: 0.36493 \nEpoch: 2418  | Training Loss: 0.32962 \nEpoch: 2418  | Training Loss: 0.22837 \nEpoch: 2418  | Training Loss: 0.19203 \nEpoch: 2418  | Validation balanced accuracy : 0.76304 \nEpoch: 2419  | Training Loss: 0.30968 \nEpoch: 2419  | Training Loss: 0.36491 \nEpoch: 2419  | Training Loss: 0.32965 \nEpoch: 2419  | Training Loss: 0.22832 \nEpoch: 2419  | Training Loss: 0.19195 \nEpoch: 2419  | Validation balanced accuracy : 0.76304 \nEpoch: 2420  | Training Loss: 0.30967 \nEpoch: 2420  | Training Loss: 0.36489 \nEpoch: 2420  | Training Loss: 0.32967 \nEpoch: 2420  | Training Loss: 0.22828 \nEpoch: 2420  | Training Loss: 0.19187 \nEpoch: 2420  | Validation balanced accuracy : 0.76304 \nEpoch: 2421  | Training Loss: 0.30966 \nEpoch: 2421  | Training Loss: 0.36486 \nEpoch: 2421  | Training Loss: 0.32969 \nEpoch: 2421  | Training Loss: 0.22823 \nEpoch: 2421  | Training Loss: 0.19179 \nEpoch: 2421  | Validation balanced accuracy : 0.76304 \nEpoch: 2422  | Training Loss: 0.30965 \nEpoch: 2422  | Training Loss: 0.36484 \nEpoch: 2422  | Training Loss: 0.32972 \nEpoch: 2422  | Training Loss: 0.22818 \nEpoch: 2422  | Training Loss: 0.19170 \nEpoch: 2422  | Validation balanced accuracy : 0.76304 \nEpoch: 2423  | Training Loss: 0.30964 \nEpoch: 2423  | Training Loss: 0.36482 \nEpoch: 2423  | Training Loss: 0.32975 \nEpoch: 2423  | Training Loss: 0.22815 \nEpoch: 2423  | Training Loss: 0.19126 \nEpoch: 2423  | Validation balanced accuracy : 0.76304 \nEpoch: 2424  | Training Loss: 0.30995 \nEpoch: 2424  | Training Loss: 0.36513 \nEpoch: 2424  | Training Loss: 0.32963 \nEpoch: 2424  | Training Loss: 0.22814 \nEpoch: 2424  | Training Loss: 0.19067 \nEpoch: 2424  | Validation balanced accuracy : 0.76304 \nEpoch: 2425  | Training Loss: 0.31018 \nEpoch: 2425  | Training Loss: 0.36525 \nEpoch: 2425  | Training Loss: 0.32962 \nEpoch: 2425  | Training Loss: 0.22810 \nEpoch: 2425  | Training Loss: 0.19061 \nEpoch: 2425  | Validation balanced accuracy : 0.76304 \nEpoch: 2426  | Training Loss: 0.31011 \nEpoch: 2426  | Training Loss: 0.36515 \nEpoch: 2426  | Training Loss: 0.32968 \nEpoch: 2426  | Training Loss: 0.22803 \nEpoch: 2426  | Training Loss: 0.19084 \nEpoch: 2426  | Validation balanced accuracy : 0.76304 \nEpoch: 2427  | Training Loss: 0.30988 \nEpoch: 2427  | Training Loss: 0.36494 \nEpoch: 2427  | Training Loss: 0.32977 \nEpoch: 2427  | Training Loss: 0.22797 \nEpoch: 2427  | Training Loss: 0.19114 \nEpoch: 2427  | Validation balanced accuracy : 0.76304 \nEpoch: 2428  | Training Loss: 0.30965 \nEpoch: 2428  | Training Loss: 0.36474 \nEpoch: 2428  | Training Loss: 0.32987 \nEpoch: 2428  | Training Loss: 0.22791 \nEpoch: 2428  | Training Loss: 0.19098 \nEpoch: 2428  | Validation balanced accuracy : 0.76304 \nEpoch: 2429  | Training Loss: 0.30980 \nEpoch: 2429  | Training Loss: 0.36493 \nEpoch: 2429  | Training Loss: 0.32977 \nEpoch: 2429  | Training Loss: 0.22789 \nEpoch: 2429  | Training Loss: 0.19052 \nEpoch: 2429  | Validation balanced accuracy : 0.76304 \nEpoch: 2430  | Training Loss: 0.30997 \nEpoch: 2430  | Training Loss: 0.36503 \nEpoch: 2430  | Training Loss: 0.32976 \nEpoch: 2430  | Training Loss: 0.22785 \nEpoch: 2430  | Training Loss: 0.19044 \nEpoch: 2430  | Validation balanced accuracy : 0.76304 \nEpoch: 2431  | Training Loss: 0.30993 \nEpoch: 2431  | Training Loss: 0.36495 \nEpoch: 2431  | Training Loss: 0.32981 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2431  | Training Loss: 0.22780 \nEpoch: 2431  | Training Loss: 0.19058 \nEpoch: 2431  | Validation balanced accuracy : 0.76304 \nEpoch: 2432  | Training Loss: 0.30977 \nEpoch: 2432  | Training Loss: 0.36479 \nEpoch: 2432  | Training Loss: 0.32990 \nEpoch: 2432  | Training Loss: 0.22774 \nEpoch: 2432  | Training Loss: 0.19041 \nEpoch: 2432  | Validation balanced accuracy : 0.76304 \nEpoch: 2433  | Training Loss: 0.30991 \nEpoch: 2433  | Training Loss: 0.36497 \nEpoch: 2433  | Training Loss: 0.32981 \nEpoch: 2433  | Training Loss: 0.22772 \nEpoch: 2433  | Training Loss: 0.19004 \nEpoch: 2433  | Validation balanced accuracy : 0.76304 \nEpoch: 2434  | Training Loss: 0.31002 \nEpoch: 2434  | Training Loss: 0.36501 \nEpoch: 2434  | Training Loss: 0.32983 \nEpoch: 2434  | Training Loss: 0.22768 \nEpoch: 2434  | Training Loss: 0.19007 \nEpoch: 2434  | Validation balanced accuracy : 0.76304 \nEpoch: 2435  | Training Loss: 0.30991 \nEpoch: 2435  | Training Loss: 0.36488 \nEpoch: 2435  | Training Loss: 0.32990 \nEpoch: 2435  | Training Loss: 0.22762 \nEpoch: 2435  | Training Loss: 0.18993 \nEpoch: 2435  | Validation balanced accuracy : 0.76304 \nEpoch: 2436  | Training Loss: 0.31002 \nEpoch: 2436  | Training Loss: 0.36503 \nEpoch: 2436  | Training Loss: 0.32984 \nEpoch: 2436  | Training Loss: 0.22760 \nEpoch: 2436  | Training Loss: 0.18966 \nEpoch: 2436  | Validation balanced accuracy : 0.76304 \nEpoch: 2437  | Training Loss: 0.31007 \nEpoch: 2437  | Training Loss: 0.36501 \nEpoch: 2437  | Training Loss: 0.32988 \nEpoch: 2437  | Training Loss: 0.22754 \nEpoch: 2437  | Training Loss: 0.18980 \nEpoch: 2437  | Validation balanced accuracy : 0.76304 \nEpoch: 2438  | Training Loss: 0.30989 \nEpoch: 2438  | Training Loss: 0.36483 \nEpoch: 2438  | Training Loss: 0.32997 \nEpoch: 2438  | Training Loss: 0.22749 \nEpoch: 2438  | Training Loss: 0.18974 \nEpoch: 2438  | Validation balanced accuracy : 0.76304 \nEpoch: 2439  | Training Loss: 0.30996 \nEpoch: 2439  | Training Loss: 0.36494 \nEpoch: 2439  | Training Loss: 0.32991 \nEpoch: 2439  | Training Loss: 0.22746 \nEpoch: 2439  | Training Loss: 0.18950 \nEpoch: 2439  | Validation balanced accuracy : 0.76304 \nEpoch: 2440  | Training Loss: 0.30999 \nEpoch: 2440  | Training Loss: 0.36492 \nEpoch: 2440  | Training Loss: 0.32995 \nEpoch: 2440  | Training Loss: 0.22742 \nEpoch: 2440  | Training Loss: 0.18927 \nEpoch: 2440  | Validation balanced accuracy : 0.76304 \nEpoch: 2441  | Training Loss: 0.31014 \nEpoch: 2441  | Training Loss: 0.36509 \nEpoch: 2441  | Training Loss: 0.32989 \nEpoch: 2441  | Training Loss: 0.22739 \nEpoch: 2441  | Training Loss: 0.18904 \nEpoch: 2441  | Validation balanced accuracy : 0.76304 \nEpoch: 2442  | Training Loss: 0.31015 \nEpoch: 2442  | Training Loss: 0.36503 \nEpoch: 2442  | Training Loss: 0.32994 \nEpoch: 2442  | Training Loss: 0.22733 \nEpoch: 2442  | Training Loss: 0.18929 \nEpoch: 2442  | Validation balanced accuracy : 0.76304 \nEpoch: 2443  | Training Loss: 0.30991 \nEpoch: 2443  | Training Loss: 0.36479 \nEpoch: 2443  | Training Loss: 0.33006 \nEpoch: 2443  | Training Loss: 0.22727 \nEpoch: 2443  | Training Loss: 0.18933 \nEpoch: 2443  | Validation balanced accuracy : 0.76304 \nEpoch: 2444  | Training Loss: 0.30991 \nEpoch: 2444  | Training Loss: 0.36486 \nEpoch: 2444  | Training Loss: 0.33002 \nEpoch: 2444  | Training Loss: 0.22725 \nEpoch: 2444  | Training Loss: 0.18880 \nEpoch: 2444  | Validation balanced accuracy : 0.76304 \nEpoch: 2445  | Training Loss: 0.31023 \nEpoch: 2445  | Training Loss: 0.36515 \nEpoch: 2445  | Training Loss: 0.32992 \nEpoch: 2445  | Training Loss: 0.22723 \nEpoch: 2445  | Training Loss: 0.18845 \nEpoch: 2445  | Validation balanced accuracy : 0.76304 \nEpoch: 2446  | Training Loss: 0.31029 \nEpoch: 2446  | Training Loss: 0.36512 \nEpoch: 2446  | Training Loss: 0.32996 \nEpoch: 2446  | Training Loss: 0.22717 \nEpoch: 2446  | Training Loss: 0.18873 \nEpoch: 2446  | Validation balanced accuracy : 0.76304 \nEpoch: 2447  | Training Loss: 0.31001 \nEpoch: 2447  | Training Loss: 0.36485 \nEpoch: 2447  | Training Loss: 0.33009 \nEpoch: 2447  | Training Loss: 0.22710 \nEpoch: 2447  | Training Loss: 0.18888 \nEpoch: 2447  | Validation balanced accuracy : 0.76304 \nEpoch: 2448  | Training Loss: 0.30995 \nEpoch: 2448  | Training Loss: 0.36486 \nEpoch: 2448  | Training Loss: 0.33007 \nEpoch: 2448  | Training Loss: 0.22707 \nEpoch: 2448  | Training Loss: 0.18846 \nEpoch: 2448  | Validation balanced accuracy : 0.76304 \nEpoch: 2449  | Training Loss: 0.31020 \nEpoch: 2449  | Training Loss: 0.36509 \nEpoch: 2449  | Training Loss: 0.32999 \nEpoch: 2449  | Training Loss: 0.22705 \nEpoch: 2449  | Training Loss: 0.18819 \nEpoch: 2449  | Validation balanced accuracy : 0.76304 \nEpoch: 2450  | Training Loss: 0.31022 \nEpoch: 2450  | Training Loss: 0.36503 \nEpoch: 2450  | Training Loss: 0.33005 \nEpoch: 2450  | Training Loss: 0.22699 \nEpoch: 2450  | Training Loss: 0.18850 \nEpoch: 2450  | Validation balanced accuracy : 0.76304 \nEpoch: 2451  | Training Loss: 0.30993 \nEpoch: 2451  | Training Loss: 0.36476 \nEpoch: 2451  | Training Loss: 0.33018 \nEpoch: 2451  | Training Loss: 0.22692 \nEpoch: 2451  | Training Loss: 0.18863 \nEpoch: 2451  | Validation balanced accuracy : 0.76304 \nEpoch: 2452  | Training Loss: 0.30988 \nEpoch: 2452  | Training Loss: 0.36477 \nEpoch: 2452  | Training Loss: 0.33016 \nEpoch: 2452  | Training Loss: 0.22689 \nEpoch: 2452  | Training Loss: 0.18819 \nEpoch: 2452  | Validation balanced accuracy : 0.76304 \nEpoch: 2453  | Training Loss: 0.31015 \nEpoch: 2453  | Training Loss: 0.36502 \nEpoch: 2453  | Training Loss: 0.33007 \nEpoch: 2453  | Training Loss: 0.22688 \nEpoch: 2453  | Training Loss: 0.18789 \nEpoch: 2453  | Validation balanced accuracy : 0.76304 \nEpoch: 2454  | Training Loss: 0.31019 \nEpoch: 2454  | Training Loss: 0.36498 \nEpoch: 2454  | Training Loss: 0.33012 \nEpoch: 2454  | Training Loss: 0.22681 \nEpoch: 2454  | Training Loss: 0.18817 \nEpoch: 2454  | Validation balanced accuracy : 0.76304 \nEpoch: 2455  | Training Loss: 0.30991 \nEpoch: 2455  | Training Loss: 0.36471 \nEpoch: 2455  | Training Loss: 0.33026 \nEpoch: 2455  | Training Loss: 0.22675 \nEpoch: 2455  | Training Loss: 0.18826 \nEpoch: 2455  | Validation balanced accuracy : 0.76304 \nEpoch: 2456  | Training Loss: 0.30990 \nEpoch: 2456  | Training Loss: 0.36477 \nEpoch: 2456  | Training Loss: 0.33022 \nEpoch: 2456  | Training Loss: 0.22673 \nEpoch: 2456  | Training Loss: 0.18776 \nEpoch: 2456  | Validation balanced accuracy : 0.76304 \nEpoch: 2457  | Training Loss: 0.31019 \nEpoch: 2457  | Training Loss: 0.36503 \nEpoch: 2457  | Training Loss: 0.33012 \nEpoch: 2457  | Training Loss: 0.22671 \nEpoch: 2457  | Training Loss: 0.18747 \nEpoch: 2457  | Validation balanced accuracy : 0.76304 \nEpoch: 2458  | Training Loss: 0.31022 \nEpoch: 2458  | Training Loss: 0.36498 \nEpoch: 2458  | Training Loss: 0.33018 \nEpoch: 2458  | Training Loss: 0.22665 \nEpoch: 2458  | Training Loss: 0.18780 \nEpoch: 2458  | Validation balanced accuracy : 0.76304 \nEpoch: 2459  | Training Loss: 0.30992 \nEpoch: 2459  | Training Loss: 0.36468 \nEpoch: 2459  | Training Loss: 0.33033 \nEpoch: 2459  | Training Loss: 0.22658 \nEpoch: 2459  | Training Loss: 0.18794 \nEpoch: 2459  | Validation balanced accuracy : 0.76304 \nEpoch: 2460  | Training Loss: 0.30987 \nEpoch: 2460  | Training Loss: 0.36472 \nEpoch: 2460  | Training Loss: 0.33030 \nEpoch: 2460  | Training Loss: 0.22656 \nEpoch: 2460  | Training Loss: 0.18743 \nEpoch: 2460  | Validation balanced accuracy : 0.76304 \nEpoch: 2461  | Training Loss: 0.31019 \nEpoch: 2461  | Training Loss: 0.36501 \nEpoch: 2461  | Training Loss: 0.33019 \nEpoch: 2461  | Training Loss: 0.22654 \nEpoch: 2461  | Training Loss: 0.18710 \nEpoch: 2461  | Validation balanced accuracy : 0.76304 \nEpoch: 2462  | Training Loss: 0.31024 \nEpoch: 2462  | Training Loss: 0.36497 \nEpoch: 2462  | Training Loss: 0.33024 \nEpoch: 2462  | Training Loss: 0.22648 \nEpoch: 2462  | Training Loss: 0.18742 \nEpoch: 2462  | Validation balanced accuracy : 0.76304 \nEpoch: 2463  | Training Loss: 0.30993 \nEpoch: 2463  | Training Loss: 0.36466 \nEpoch: 2463  | Training Loss: 0.33040 \nEpoch: 2463  | Training Loss: 0.22641 \nEpoch: 2463  | Training Loss: 0.18758 \nEpoch: 2463  | Validation balanced accuracy : 0.76304 \nEpoch: 2464  | Training Loss: 0.30987 \nEpoch: 2464  | Training Loss: 0.36469 \nEpoch: 2464  | Training Loss: 0.33038 \nEpoch: 2464  | Training Loss: 0.22639 \nEpoch: 2464  | Training Loss: 0.18710 \nEpoch: 2464  | Validation balanced accuracy : 0.76304 \nEpoch: 2465  | Training Loss: 0.31017 \nEpoch: 2465  | Training Loss: 0.36496 \nEpoch: 2465  | Training Loss: 0.33027 \nEpoch: 2465  | Training Loss: 0.22637 \nEpoch: 2465  | Training Loss: 0.18680 \nEpoch: 2465  | Validation balanced accuracy : 0.76304 \nEpoch: 2466  | Training Loss: 0.31020 \nEpoch: 2466  | Training Loss: 0.36491 \nEpoch: 2466  | Training Loss: 0.33033 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2466  | Training Loss: 0.22632 \nEpoch: 2466  | Training Loss: 0.18677 \nEpoch: 2466  | Validation balanced accuracy : 0.76304 \nEpoch: 2467  | Training Loss: 0.31021 \nEpoch: 2467  | Training Loss: 0.36494 \nEpoch: 2467  | Training Loss: 0.33032 \nEpoch: 2467  | Training Loss: 0.22628 \nEpoch: 2467  | Training Loss: 0.18684 \nEpoch: 2467  | Validation balanced accuracy : 0.76304 \nEpoch: 2468  | Training Loss: 0.31003 \nEpoch: 2468  | Training Loss: 0.36473 \nEpoch: 2468  | Training Loss: 0.33044 \nEpoch: 2468  | Training Loss: 0.22622 \nEpoch: 2468  | Training Loss: 0.18693 \nEpoch: 2468  | Validation balanced accuracy : 0.76304 \nEpoch: 2469  | Training Loss: 0.31001 \nEpoch: 2469  | Training Loss: 0.36477 \nEpoch: 2469  | Training Loss: 0.33042 \nEpoch: 2469  | Training Loss: 0.22619 \nEpoch: 2469  | Training Loss: 0.18650 \nEpoch: 2469  | Validation balanced accuracy : 0.76304 \nEpoch: 2470  | Training Loss: 0.31026 \nEpoch: 2470  | Training Loss: 0.36500 \nEpoch: 2470  | Training Loss: 0.33033 \nEpoch: 2470  | Training Loss: 0.22617 \nEpoch: 2470  | Training Loss: 0.18630 \nEpoch: 2470  | Validation balanced accuracy : 0.76304 \nEpoch: 2471  | Training Loss: 0.31022 \nEpoch: 2471  | Training Loss: 0.36489 \nEpoch: 2471  | Training Loss: 0.33042 \nEpoch: 2471  | Training Loss: 0.22612 \nEpoch: 2471  | Training Loss: 0.18634 \nEpoch: 2471  | Validation balanced accuracy : 0.76304 \nEpoch: 2472  | Training Loss: 0.31020 \nEpoch: 2472  | Training Loss: 0.36491 \nEpoch: 2472  | Training Loss: 0.33040 \nEpoch: 2472  | Training Loss: 0.22607 \nEpoch: 2472  | Training Loss: 0.18642 \nEpoch: 2472  | Validation balanced accuracy : 0.76304 \nEpoch: 2473  | Training Loss: 0.31003 \nEpoch: 2473  | Training Loss: 0.36470 \nEpoch: 2473  | Training Loss: 0.33053 \nEpoch: 2473  | Training Loss: 0.22601 \nEpoch: 2473  | Training Loss: 0.18652 \nEpoch: 2473  | Validation balanced accuracy : 0.76304 \nEpoch: 2474  | Training Loss: 0.30999 \nEpoch: 2474  | Training Loss: 0.36472 \nEpoch: 2474  | Training Loss: 0.33051 \nEpoch: 2474  | Training Loss: 0.22599 \nEpoch: 2474  | Training Loss: 0.18612 \nEpoch: 2474  | Validation balanced accuracy : 0.76304 \nEpoch: 2475  | Training Loss: 0.31023 \nEpoch: 2475  | Training Loss: 0.36495 \nEpoch: 2475  | Training Loss: 0.33043 \nEpoch: 2475  | Training Loss: 0.22596 \nEpoch: 2475  | Training Loss: 0.18593 \nEpoch: 2475  | Validation balanced accuracy : 0.76304 \nEpoch: 2476  | Training Loss: 0.31019 \nEpoch: 2476  | Training Loss: 0.36483 \nEpoch: 2476  | Training Loss: 0.33052 \nEpoch: 2476  | Training Loss: 0.22591 \nEpoch: 2476  | Training Loss: 0.18597 \nEpoch: 2476  | Validation balanced accuracy : 0.76304 \nEpoch: 2477  | Training Loss: 0.31017 \nEpoch: 2477  | Training Loss: 0.36485 \nEpoch: 2477  | Training Loss: 0.33051 \nEpoch: 2477  | Training Loss: 0.22588 \nEpoch: 2477  | Training Loss: 0.18565 \nEpoch: 2477  | Validation balanced accuracy : 0.76304 \nEpoch: 2478  | Training Loss: 0.31034 \nEpoch: 2478  | Training Loss: 0.36502 \nEpoch: 2478  | Training Loss: 0.33045 \nEpoch: 2478  | Training Loss: 0.22585 \nEpoch: 2478  | Training Loss: 0.18560 \nEpoch: 2478  | Validation balanced accuracy : 0.76304 \nEpoch: 2479  | Training Loss: 0.31022 \nEpoch: 2479  | Training Loss: 0.36483 \nEpoch: 2479  | Training Loss: 0.33057 \nEpoch: 2479  | Training Loss: 0.22578 \nEpoch: 2479  | Training Loss: 0.18576 \nEpoch: 2479  | Validation balanced accuracy : 0.76304 \nEpoch: 2480  | Training Loss: 0.31013 \nEpoch: 2480  | Training Loss: 0.36480 \nEpoch: 2480  | Training Loss: 0.33058 \nEpoch: 2480  | Training Loss: 0.22575 \nEpoch: 2480  | Training Loss: 0.18550 \nEpoch: 2480  | Validation balanced accuracy : 0.76304 \nEpoch: 2481  | Training Loss: 0.31027 \nEpoch: 2481  | Training Loss: 0.36494 \nEpoch: 2481  | Training Loss: 0.33053 \nEpoch: 2481  | Training Loss: 0.22572 \nEpoch: 2481  | Training Loss: 0.18546 \nEpoch: 2481  | Validation balanced accuracy : 0.76304 \nEpoch: 2482  | Training Loss: 0.31015 \nEpoch: 2482  | Training Loss: 0.36476 \nEpoch: 2482  | Training Loss: 0.33064 \nEpoch: 2482  | Training Loss: 0.22566 \nEpoch: 2482  | Training Loss: 0.18560 \nEpoch: 2482  | Validation balanced accuracy : 0.76304 \nEpoch: 2483  | Training Loss: 0.31008 \nEpoch: 2483  | Training Loss: 0.36475 \nEpoch: 2483  | Training Loss: 0.33064 \nEpoch: 2483  | Training Loss: 0.22563 \nEpoch: 2483  | Training Loss: 0.18530 \nEpoch: 2483  | Validation balanced accuracy : 0.76304 \nEpoch: 2484  | Training Loss: 0.31025 \nEpoch: 2484  | Training Loss: 0.36491 \nEpoch: 2484  | Training Loss: 0.33058 \nEpoch: 2484  | Training Loss: 0.22560 \nEpoch: 2484  | Training Loss: 0.18519 \nEpoch: 2484  | Validation balanced accuracy : 0.76304 \nEpoch: 2485  | Training Loss: 0.31018 \nEpoch: 2485  | Training Loss: 0.36479 \nEpoch: 2485  | Training Loss: 0.33068 \nEpoch: 2485  | Training Loss: 0.22554 \nEpoch: 2485  | Training Loss: 0.18524 \nEpoch: 2485  | Validation balanced accuracy : 0.76304 \nEpoch: 2486  | Training Loss: 0.31015 \nEpoch: 2486  | Training Loss: 0.36479 \nEpoch: 2486  | Training Loss: 0.33067 \nEpoch: 2486  | Training Loss: 0.22551 \nEpoch: 2486  | Training Loss: 0.18495 \nEpoch: 2486  | Validation balanced accuracy : 0.76304 \nEpoch: 2487  | Training Loss: 0.31031 \nEpoch: 2487  | Training Loss: 0.36494 \nEpoch: 2487  | Training Loss: 0.33062 \nEpoch: 2487  | Training Loss: 0.22548 \nEpoch: 2487  | Training Loss: 0.18488 \nEpoch: 2487  | Validation balanced accuracy : 0.76304 \nEpoch: 2488  | Training Loss: 0.31021 \nEpoch: 2488  | Training Loss: 0.36479 \nEpoch: 2488  | Training Loss: 0.33073 \nEpoch: 2488  | Training Loss: 0.22543 \nEpoch: 2488  | Training Loss: 0.18500 \nEpoch: 2488  | Validation balanced accuracy : 0.76304 \nEpoch: 2489  | Training Loss: 0.31014 \nEpoch: 2489  | Training Loss: 0.36477 \nEpoch: 2489  | Training Loss: 0.33073 \nEpoch: 2489  | Training Loss: 0.22539 \nEpoch: 2489  | Training Loss: 0.18474 \nEpoch: 2489  | Validation balanced accuracy : 0.76304 \nEpoch: 2490  | Training Loss: 0.31028 \nEpoch: 2490  | Training Loss: 0.36490 \nEpoch: 2490  | Training Loss: 0.33069 \nEpoch: 2490  | Training Loss: 0.22536 \nEpoch: 2490  | Training Loss: 0.18469 \nEpoch: 2490  | Validation balanced accuracy : 0.76304 \nEpoch: 2491  | Training Loss: 0.31017 \nEpoch: 2491  | Training Loss: 0.36475 \nEpoch: 2491  | Training Loss: 0.33079 \nEpoch: 2491  | Training Loss: 0.22530 \nEpoch: 2491  | Training Loss: 0.18480 \nEpoch: 2491  | Validation balanced accuracy : 0.76304 \nEpoch: 2492  | Training Loss: 0.31010 \nEpoch: 2492  | Training Loss: 0.36473 \nEpoch: 2492  | Training Loss: 0.33080 \nEpoch: 2492  | Training Loss: 0.22527 \nEpoch: 2492  | Training Loss: 0.18454 \nEpoch: 2492  | Validation balanced accuracy : 0.76304 \nEpoch: 2493  | Training Loss: 0.31025 \nEpoch: 2493  | Training Loss: 0.36487 \nEpoch: 2493  | Training Loss: 0.33075 \nEpoch: 2493  | Training Loss: 0.22524 \nEpoch: 2493  | Training Loss: 0.18447 \nEpoch: 2493  | Validation balanced accuracy : 0.76304 \nEpoch: 2494  | Training Loss: 0.31015 \nEpoch: 2494  | Training Loss: 0.36472 \nEpoch: 2494  | Training Loss: 0.33086 \nEpoch: 2494  | Training Loss: 0.22518 \nEpoch: 2494  | Training Loss: 0.18457 \nEpoch: 2494  | Validation balanced accuracy : 0.76304 \nEpoch: 2495  | Training Loss: 0.31010 \nEpoch: 2495  | Training Loss: 0.36471 \nEpoch: 2495  | Training Loss: 0.33086 \nEpoch: 2495  | Training Loss: 0.22515 \nEpoch: 2495  | Training Loss: 0.18430 \nEpoch: 2495  | Validation balanced accuracy : 0.76304 \nEpoch: 2496  | Training Loss: 0.31025 \nEpoch: 2496  | Training Loss: 0.36485 \nEpoch: 2496  | Training Loss: 0.33081 \nEpoch: 2496  | Training Loss: 0.22512 \nEpoch: 2496  | Training Loss: 0.18424 \nEpoch: 2496  | Validation balanced accuracy : 0.76304 \nEpoch: 2497  | Training Loss: 0.31015 \nEpoch: 2497  | Training Loss: 0.36470 \nEpoch: 2497  | Training Loss: 0.33092 \nEpoch: 2497  | Training Loss: 0.22507 \nEpoch: 2497  | Training Loss: 0.18434 \nEpoch: 2497  | Validation balanced accuracy : 0.76304 \nEpoch: 2498  | Training Loss: 0.31009 \nEpoch: 2498  | Training Loss: 0.36469 \nEpoch: 2498  | Training Loss: 0.33092 \nEpoch: 2498  | Training Loss: 0.22504 \nEpoch: 2498  | Training Loss: 0.18408 \nEpoch: 2498  | Validation balanced accuracy : 0.76304 \nEpoch: 2499  | Training Loss: 0.31023 \nEpoch: 2499  | Training Loss: 0.36483 \nEpoch: 2499  | Training Loss: 0.33087 \nEpoch: 2499  | Training Loss: 0.22501 \nEpoch: 2499  | Training Loss: 0.18402 \nEpoch: 2499  | Validation balanced accuracy : 0.76304 \nEpoch: 2500  | Training Loss: 0.31013 \nEpoch: 2500  | Training Loss: 0.36467 \nEpoch: 2500  | Training Loss: 0.33099 \nEpoch: 2500  | Training Loss: 0.22495 \nEpoch: 2500  | Training Loss: 0.18412 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2500  | Validation balanced accuracy : 0.76304 \nEpoch: 2501  | Training Loss: 0.31007 \nEpoch: 2501  | Training Loss: 0.36466 \nEpoch: 2501  | Training Loss: 0.33099 \nEpoch: 2501  | Training Loss: 0.22492 \nEpoch: 2501  | Training Loss: 0.18386 \nEpoch: 2501  | Validation balanced accuracy : 0.76304 \nEpoch: 2502  | Training Loss: 0.31022 \nEpoch: 2502  | Training Loss: 0.36480 \nEpoch: 2502  | Training Loss: 0.33094 \nEpoch: 2502  | Training Loss: 0.22490 \nEpoch: 2502  | Training Loss: 0.18344 \nEpoch: 2502  | Validation balanced accuracy : 0.76304 \nEpoch: 2503  | Training Loss: 0.31044 \nEpoch: 2503  | Training Loss: 0.36497 \nEpoch: 2503  | Training Loss: 0.33089 \nEpoch: 2503  | Training Loss: 0.22487 \nEpoch: 2503  | Training Loss: 0.18342 \nEpoch: 2503  | Validation balanced accuracy : 0.76304 \nEpoch: 2504  | Training Loss: 0.31029 \nEpoch: 2504  | Training Loss: 0.36477 \nEpoch: 2504  | Training Loss: 0.33102 \nEpoch: 2504  | Training Loss: 0.22481 \nEpoch: 2504  | Training Loss: 0.18366 \nEpoch: 2504  | Validation balanced accuracy : 0.76304 \nEpoch: 2505  | Training Loss: 0.31014 \nEpoch: 2505  | Training Loss: 0.36469 \nEpoch: 2505  | Training Loss: 0.33106 \nEpoch: 2505  | Training Loss: 0.22477 \nEpoch: 2505  | Training Loss: 0.18353 \nEpoch: 2505  | Validation balanced accuracy : 0.76304 \nEpoch: 2506  | Training Loss: 0.31021 \nEpoch: 2506  | Training Loss: 0.36476 \nEpoch: 2506  | Training Loss: 0.33103 \nEpoch: 2506  | Training Loss: 0.22474 \nEpoch: 2506  | Training Loss: 0.18321 \nEpoch: 2506  | Validation balanced accuracy : 0.76304 \nEpoch: 2507  | Training Loss: 0.31037 \nEpoch: 2507  | Training Loss: 0.36490 \nEpoch: 2507  | Training Loss: 0.33099 \nEpoch: 2507  | Training Loss: 0.22471 \nEpoch: 2507  | Training Loss: 0.18322 \nEpoch: 2507  | Validation balanced accuracy : 0.76304 \nEpoch: 2508  | Training Loss: 0.31022 \nEpoch: 2508  | Training Loss: 0.36470 \nEpoch: 2508  | Training Loss: 0.33113 \nEpoch: 2508  | Training Loss: 0.22465 \nEpoch: 2508  | Training Loss: 0.18344 \nEpoch: 2508  | Validation balanced accuracy : 0.76304 \nEpoch: 2509  | Training Loss: 0.31008 \nEpoch: 2509  | Training Loss: 0.36462 \nEpoch: 2509  | Training Loss: 0.33116 \nEpoch: 2509  | Training Loss: 0.22461 \nEpoch: 2509  | Training Loss: 0.18328 \nEpoch: 2509  | Validation balanced accuracy : 0.76304 \nEpoch: 2510  | Training Loss: 0.31017 \nEpoch: 2510  | Training Loss: 0.36472 \nEpoch: 2510  | Training Loss: 0.33112 \nEpoch: 2510  | Training Loss: 0.22459 \nEpoch: 2510  | Training Loss: 0.18292 \nEpoch: 2510  | Validation balanced accuracy : 0.76304 \nEpoch: 2511  | Training Loss: 0.31036 \nEpoch: 2511  | Training Loss: 0.36488 \nEpoch: 2511  | Training Loss: 0.33108 \nEpoch: 2511  | Training Loss: 0.22456 \nEpoch: 2511  | Training Loss: 0.18291 \nEpoch: 2511  | Validation balanced accuracy : 0.76304 \nEpoch: 2512  | Training Loss: 0.31022 \nEpoch: 2512  | Training Loss: 0.36468 \nEpoch: 2512  | Training Loss: 0.33121 \nEpoch: 2512  | Training Loss: 0.22450 \nEpoch: 2512  | Training Loss: 0.18312 \nEpoch: 2512  | Validation balanced accuracy : 0.76304 \nEpoch: 2513  | Training Loss: 0.31009 \nEpoch: 2513  | Training Loss: 0.36461 \nEpoch: 2513  | Training Loss: 0.33124 \nEpoch: 2513  | Training Loss: 0.22446 \nEpoch: 2513  | Training Loss: 0.18296 \nEpoch: 2513  | Validation balanced accuracy : 0.76304 \nEpoch: 2514  | Training Loss: 0.31017 \nEpoch: 2514  | Training Loss: 0.36470 \nEpoch: 2514  | Training Loss: 0.33121 \nEpoch: 2514  | Training Loss: 0.22444 \nEpoch: 2514  | Training Loss: 0.18262 \nEpoch: 2514  | Validation balanced accuracy : 0.76304 \nEpoch: 2515  | Training Loss: 0.31035 \nEpoch: 2515  | Training Loss: 0.36485 \nEpoch: 2515  | Training Loss: 0.33116 \nEpoch: 2515  | Training Loss: 0.22441 \nEpoch: 2515  | Training Loss: 0.18261 \nEpoch: 2515  | Validation balanced accuracy : 0.76304 \nEpoch: 2516  | Training Loss: 0.31021 \nEpoch: 2516  | Training Loss: 0.36465 \nEpoch: 2516  | Training Loss: 0.33130 \nEpoch: 2516  | Training Loss: 0.22434 \nEpoch: 2516  | Training Loss: 0.18283 \nEpoch: 2516  | Validation balanced accuracy : 0.76304 \nEpoch: 2517  | Training Loss: 0.31007 \nEpoch: 2517  | Training Loss: 0.36457 \nEpoch: 2517  | Training Loss: 0.33134 \nEpoch: 2517  | Training Loss: 0.22431 \nEpoch: 2517  | Training Loss: 0.18268 \nEpoch: 2517  | Validation balanced accuracy : 0.76304 \nEpoch: 2518  | Training Loss: 0.31016 \nEpoch: 2518  | Training Loss: 0.36466 \nEpoch: 2518  | Training Loss: 0.33131 \nEpoch: 2518  | Training Loss: 0.22429 \nEpoch: 2518  | Training Loss: 0.18233 \nEpoch: 2518  | Validation balanced accuracy : 0.76304 \nEpoch: 2519  | Training Loss: 0.31034 \nEpoch: 2519  | Training Loss: 0.36481 \nEpoch: 2519  | Training Loss: 0.33126 \nEpoch: 2519  | Training Loss: 0.22427 \nEpoch: 2519  | Training Loss: 0.18197 \nEpoch: 2519  | Validation balanced accuracy : 0.76304 \nEpoch: 2520  | Training Loss: 0.31051 \nEpoch: 2520  | Training Loss: 0.36494 \nEpoch: 2520  | Training Loss: 0.33123 \nEpoch: 2520  | Training Loss: 0.22423 \nEpoch: 2520  | Training Loss: 0.18207 \nEpoch: 2520  | Validation balanced accuracy : 0.76304 \nEpoch: 2521  | Training Loss: 0.31029 \nEpoch: 2521  | Training Loss: 0.36468 \nEpoch: 2521  | Training Loss: 0.33139 \nEpoch: 2521  | Training Loss: 0.22416 \nEpoch: 2521  | Training Loss: 0.18241 \nEpoch: 2521  | Validation balanced accuracy : 0.76304 \nEpoch: 2522  | Training Loss: 0.31008 \nEpoch: 2522  | Training Loss: 0.36455 \nEpoch: 2522  | Training Loss: 0.33146 \nEpoch: 2522  | Training Loss: 0.22412 \nEpoch: 2522  | Training Loss: 0.18235 \nEpoch: 2522  | Validation balanced accuracy : 0.76304 \nEpoch: 2523  | Training Loss: 0.31011 \nEpoch: 2523  | Training Loss: 0.36460 \nEpoch: 2523  | Training Loss: 0.33144 \nEpoch: 2523  | Training Loss: 0.22410 \nEpoch: 2523  | Training Loss: 0.18205 \nEpoch: 2523  | Validation balanced accuracy : 0.76304 \nEpoch: 2524  | Training Loss: 0.31027 \nEpoch: 2524  | Training Loss: 0.36473 \nEpoch: 2524  | Training Loss: 0.33139 \nEpoch: 2524  | Training Loss: 0.22408 \nEpoch: 2524  | Training Loss: 0.18168 \nEpoch: 2524  | Validation balanced accuracy : 0.76304 \nEpoch: 2525  | Training Loss: 0.31045 \nEpoch: 2525  | Training Loss: 0.36487 \nEpoch: 2525  | Training Loss: 0.33136 \nEpoch: 2525  | Training Loss: 0.22405 \nEpoch: 2525  | Training Loss: 0.18175 \nEpoch: 2525  | Validation balanced accuracy : 0.76304 \nEpoch: 2526  | Training Loss: 0.31026 \nEpoch: 2526  | Training Loss: 0.36463 \nEpoch: 2526  | Training Loss: 0.33152 \nEpoch: 2526  | Training Loss: 0.22398 \nEpoch: 2526  | Training Loss: 0.18206 \nEpoch: 2526  | Validation balanced accuracy : 0.76304 \nEpoch: 2527  | Training Loss: 0.31007 \nEpoch: 2527  | Training Loss: 0.36451 \nEpoch: 2527  | Training Loss: 0.33157 \nEpoch: 2527  | Training Loss: 0.22394 \nEpoch: 2527  | Training Loss: 0.18197 \nEpoch: 2527  | Validation balanced accuracy : 0.76304 \nEpoch: 2528  | Training Loss: 0.31011 \nEpoch: 2528  | Training Loss: 0.36457 \nEpoch: 2528  | Training Loss: 0.33156 \nEpoch: 2528  | Training Loss: 0.22391 \nEpoch: 2528  | Training Loss: 0.18166 \nEpoch: 2528  | Validation balanced accuracy : 0.76304 \nEpoch: 2529  | Training Loss: 0.31028 \nEpoch: 2529  | Training Loss: 0.36471 \nEpoch: 2529  | Training Loss: 0.33151 \nEpoch: 2529  | Training Loss: 0.22390 \nEpoch: 2529  | Training Loss: 0.18130 \nEpoch: 2529  | Validation balanced accuracy : 0.76304 \nEpoch: 2530  | Training Loss: 0.31045 \nEpoch: 2530  | Training Loss: 0.36484 \nEpoch: 2530  | Training Loss: 0.33147 \nEpoch: 2530  | Training Loss: 0.22388 \nEpoch: 2530  | Training Loss: 0.18103 \nEpoch: 2530  | Validation balanced accuracy : 0.76304 \nEpoch: 2531  | Training Loss: 0.31057 \nEpoch: 2531  | Training Loss: 0.36492 \nEpoch: 2531  | Training Loss: 0.33147 \nEpoch: 2531  | Training Loss: 0.22383 \nEpoch: 2531  | Training Loss: 0.18122 \nEpoch: 2531  | Validation balanced accuracy : 0.76304 \nEpoch: 2532  | Training Loss: 0.31029 \nEpoch: 2532  | Training Loss: 0.36461 \nEpoch: 2532  | Training Loss: 0.33166 \nEpoch: 2532  | Training Loss: 0.22376 \nEpoch: 2532  | Training Loss: 0.18165 \nEpoch: 2532  | Validation balanced accuracy : 0.76304 \nEpoch: 2533  | Training Loss: 0.31003 \nEpoch: 2533  | Training Loss: 0.36444 \nEpoch: 2533  | Training Loss: 0.33173 \nEpoch: 2533  | Training Loss: 0.22371 \nEpoch: 2533  | Training Loss: 0.18162 \nEpoch: 2533  | Validation balanced accuracy : 0.76304 \nEpoch: 2534  | Training Loss: 0.31004 \nEpoch: 2534  | Training Loss: 0.36448 \nEpoch: 2534  | Training Loss: 0.33172 \nEpoch: 2534  | Training Loss: 0.22369 \nEpoch: 2534  | Training Loss: 0.18132 \nEpoch: 2534  | Validation balanced accuracy : 0.76304 \nEpoch: 2535  | Training Loss: 0.31021 \nEpoch: 2535  | Training Loss: 0.36463 \nEpoch: 2535  | Training Loss: 0.33167 \nEpoch: 2535  | Training Loss: 0.22367 \nEpoch: 2535  | Training Loss: 0.18093 \nEpoch: 2535  | Validation balanced accuracy : 0.76304 \nEpoch: 2536  | Training Loss: 0.31041 \nEpoch: 2536  | Training Loss: 0.36478 \nEpoch: 2536  | Training Loss: 0.33163 \nEpoch: 2536  | Training Loss: 0.22366 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2536  | Training Loss: 0.18061 \nEpoch: 2536  | Validation balanced accuracy : 0.76304 \nEpoch: 2537  | Training Loss: 0.31055 \nEpoch: 2537  | Training Loss: 0.36488 \nEpoch: 2537  | Training Loss: 0.33161 \nEpoch: 2537  | Training Loss: 0.22363 \nEpoch: 2537  | Training Loss: 0.18043 \nEpoch: 2537  | Validation balanced accuracy : 0.76304 \nEpoch: 2538  | Training Loss: 0.31060 \nEpoch: 2538  | Training Loss: 0.36491 \nEpoch: 2538  | Training Loss: 0.33163 \nEpoch: 2538  | Training Loss: 0.22360 \nEpoch: 2538  | Training Loss: 0.18037 \nEpoch: 2538  | Validation balanced accuracy : 0.76304 \nEpoch: 2539  | Training Loss: 0.31058 \nEpoch: 2539  | Training Loss: 0.36488 \nEpoch: 2539  | Training Loss: 0.33166 \nEpoch: 2539  | Training Loss: 0.22356 \nEpoch: 2539  | Training Loss: 0.18038 \nEpoch: 2539  | Validation balanced accuracy : 0.76304 \nEpoch: 2540  | Training Loss: 0.31053 \nEpoch: 2540  | Training Loss: 0.36483 \nEpoch: 2540  | Training Loss: 0.33170 \nEpoch: 2540  | Training Loss: 0.22351 \nEpoch: 2540  | Training Loss: 0.18040 \nEpoch: 2540  | Validation balanced accuracy : 0.76304 \nEpoch: 2541  | Training Loss: 0.31047 \nEpoch: 2541  | Training Loss: 0.36478 \nEpoch: 2541  | Training Loss: 0.33174 \nEpoch: 2541  | Training Loss: 0.22347 \nEpoch: 2541  | Training Loss: 0.18039 \nEpoch: 2541  | Validation balanced accuracy : 0.76304 \nEpoch: 2542  | Training Loss: 0.31043 \nEpoch: 2542  | Training Loss: 0.36476 \nEpoch: 2542  | Training Loss: 0.33177 \nEpoch: 2542  | Training Loss: 0.22344 \nEpoch: 2542  | Training Loss: 0.18034 \nEpoch: 2542  | Validation balanced accuracy : 0.76304 \nEpoch: 2543  | Training Loss: 0.31042 \nEpoch: 2543  | Training Loss: 0.36475 \nEpoch: 2543  | Training Loss: 0.33179 \nEpoch: 2543  | Training Loss: 0.22340 \nEpoch: 2543  | Training Loss: 0.18026 \nEpoch: 2543  | Validation balanced accuracy : 0.76304 \nEpoch: 2544  | Training Loss: 0.31043 \nEpoch: 2544  | Training Loss: 0.36475 \nEpoch: 2544  | Training Loss: 0.33181 \nEpoch: 2544  | Training Loss: 0.22337 \nEpoch: 2544  | Training Loss: 0.18017 \nEpoch: 2544  | Validation balanced accuracy : 0.76304 \nEpoch: 2545  | Training Loss: 0.31045 \nEpoch: 2545  | Training Loss: 0.36476 \nEpoch: 2545  | Training Loss: 0.33183 \nEpoch: 2545  | Training Loss: 0.22333 \nEpoch: 2545  | Training Loss: 0.18007 \nEpoch: 2545  | Validation balanced accuracy : 0.76304 \nEpoch: 2546  | Training Loss: 0.31046 \nEpoch: 2546  | Training Loss: 0.36477 \nEpoch: 2546  | Training Loss: 0.33184 \nEpoch: 2546  | Training Loss: 0.22330 \nEpoch: 2546  | Training Loss: 0.17999 \nEpoch: 2546  | Validation balanced accuracy : 0.76304 \nEpoch: 2547  | Training Loss: 0.31047 \nEpoch: 2547  | Training Loss: 0.36477 \nEpoch: 2547  | Training Loss: 0.33187 \nEpoch: 2547  | Training Loss: 0.22327 \nEpoch: 2547  | Training Loss: 0.17991 \nEpoch: 2547  | Validation balanced accuracy : 0.76304 \nEpoch: 2548  | Training Loss: 0.31047 \nEpoch: 2548  | Training Loss: 0.36477 \nEpoch: 2548  | Training Loss: 0.33189 \nEpoch: 2548  | Training Loss: 0.22323 \nEpoch: 2548  | Training Loss: 0.17985 \nEpoch: 2548  | Validation balanced accuracy : 0.76304 \nEpoch: 2549  | Training Loss: 0.31046 \nEpoch: 2549  | Training Loss: 0.36476 \nEpoch: 2549  | Training Loss: 0.33191 \nEpoch: 2549  | Training Loss: 0.22320 \nEpoch: 2549  | Training Loss: 0.17979 \nEpoch: 2549  | Validation balanced accuracy : 0.76304 \nEpoch: 2550  | Training Loss: 0.31046 \nEpoch: 2550  | Training Loss: 0.36475 \nEpoch: 2550  | Training Loss: 0.33194 \nEpoch: 2550  | Training Loss: 0.22316 \nEpoch: 2550  | Training Loss: 0.17972 \nEpoch: 2550  | Validation balanced accuracy : 0.76304 \nEpoch: 2551  | Training Loss: 0.31045 \nEpoch: 2551  | Training Loss: 0.36475 \nEpoch: 2551  | Training Loss: 0.33196 \nEpoch: 2551  | Training Loss: 0.22313 \nEpoch: 2551  | Training Loss: 0.17966 \nEpoch: 2551  | Validation balanced accuracy : 0.76304 \nEpoch: 2552  | Training Loss: 0.31045 \nEpoch: 2552  | Training Loss: 0.36474 \nEpoch: 2552  | Training Loss: 0.33199 \nEpoch: 2552  | Training Loss: 0.22309 \nEpoch: 2552  | Training Loss: 0.17959 \nEpoch: 2552  | Validation balanced accuracy : 0.76304 \nEpoch: 2553  | Training Loss: 0.31045 \nEpoch: 2553  | Training Loss: 0.36474 \nEpoch: 2553  | Training Loss: 0.33201 \nEpoch: 2553  | Training Loss: 0.22306 \nEpoch: 2553  | Training Loss: 0.17952 \nEpoch: 2553  | Validation balanced accuracy : 0.76304 \nEpoch: 2554  | Training Loss: 0.31045 \nEpoch: 2554  | Training Loss: 0.36474 \nEpoch: 2554  | Training Loss: 0.33203 \nEpoch: 2554  | Training Loss: 0.22302 \nEpoch: 2554  | Training Loss: 0.17944 \nEpoch: 2554  | Validation balanced accuracy : 0.76304 \nEpoch: 2555  | Training Loss: 0.31045 \nEpoch: 2555  | Training Loss: 0.36473 \nEpoch: 2555  | Training Loss: 0.33206 \nEpoch: 2555  | Training Loss: 0.22299 \nEpoch: 2555  | Training Loss: 0.17937 \nEpoch: 2555  | Validation balanced accuracy : 0.76304 \nEpoch: 2556  | Training Loss: 0.31045 \nEpoch: 2556  | Training Loss: 0.36473 \nEpoch: 2556  | Training Loss: 0.33208 \nEpoch: 2556  | Training Loss: 0.22296 \nEpoch: 2556  | Training Loss: 0.17930 \nEpoch: 2556  | Validation balanced accuracy : 0.76304 \nEpoch: 2557  | Training Loss: 0.31045 \nEpoch: 2557  | Training Loss: 0.36472 \nEpoch: 2557  | Training Loss: 0.33211 \nEpoch: 2557  | Training Loss: 0.22292 \nEpoch: 2557  | Training Loss: 0.17923 \nEpoch: 2557  | Validation balanced accuracy : 0.76304 \nEpoch: 2558  | Training Loss: 0.31045 \nEpoch: 2558  | Training Loss: 0.36472 \nEpoch: 2558  | Training Loss: 0.33213 \nEpoch: 2558  | Training Loss: 0.22289 \nEpoch: 2558  | Training Loss: 0.17917 \nEpoch: 2558  | Validation balanced accuracy : 0.76304 \nEpoch: 2559  | Training Loss: 0.31045 \nEpoch: 2559  | Training Loss: 0.36471 \nEpoch: 2559  | Training Loss: 0.33216 \nEpoch: 2559  | Training Loss: 0.22285 \nEpoch: 2559  | Training Loss: 0.17910 \nEpoch: 2559  | Validation balanced accuracy : 0.76304 \nEpoch: 2560  | Training Loss: 0.31045 \nEpoch: 2560  | Training Loss: 0.36471 \nEpoch: 2560  | Training Loss: 0.33218 \nEpoch: 2560  | Training Loss: 0.22282 \nEpoch: 2560  | Training Loss: 0.17903 \nEpoch: 2560  | Validation balanced accuracy : 0.76304 \nEpoch: 2561  | Training Loss: 0.31045 \nEpoch: 2561  | Training Loss: 0.36470 \nEpoch: 2561  | Training Loss: 0.33221 \nEpoch: 2561  | Training Loss: 0.22279 \nEpoch: 2561  | Training Loss: 0.17896 \nEpoch: 2561  | Validation balanced accuracy : 0.76304 \nEpoch: 2562  | Training Loss: 0.31045 \nEpoch: 2562  | Training Loss: 0.36470 \nEpoch: 2562  | Training Loss: 0.33223 \nEpoch: 2562  | Training Loss: 0.22275 \nEpoch: 2562  | Training Loss: 0.17889 \nEpoch: 2562  | Validation balanced accuracy : 0.76304 \nEpoch: 2563  | Training Loss: 0.31045 \nEpoch: 2563  | Training Loss: 0.36469 \nEpoch: 2563  | Training Loss: 0.33226 \nEpoch: 2563  | Training Loss: 0.22272 \nEpoch: 2563  | Training Loss: 0.17882 \nEpoch: 2563  | Validation balanced accuracy : 0.76304 \nEpoch: 2564  | Training Loss: 0.31045 \nEpoch: 2564  | Training Loss: 0.36469 \nEpoch: 2564  | Training Loss: 0.33228 \nEpoch: 2564  | Training Loss: 0.22269 \nEpoch: 2564  | Training Loss: 0.17875 \nEpoch: 2564  | Validation balanced accuracy : 0.76304 \nEpoch: 2565  | Training Loss: 0.31045 \nEpoch: 2565  | Training Loss: 0.36468 \nEpoch: 2565  | Training Loss: 0.33231 \nEpoch: 2565  | Training Loss: 0.22265 \nEpoch: 2565  | Training Loss: 0.17868 \nEpoch: 2565  | Validation balanced accuracy : 0.76304 \nEpoch: 2566  | Training Loss: 0.31045 \nEpoch: 2566  | Training Loss: 0.36468 \nEpoch: 2566  | Training Loss: 0.33234 \nEpoch: 2566  | Training Loss: 0.22262 \nEpoch: 2566  | Training Loss: 0.17862 \nEpoch: 2566  | Validation balanced accuracy : 0.76304 \nEpoch: 2567  | Training Loss: 0.31045 \nEpoch: 2567  | Training Loss: 0.36467 \nEpoch: 2567  | Training Loss: 0.33236 \nEpoch: 2567  | Training Loss: 0.22259 \nEpoch: 2567  | Training Loss: 0.17855 \nEpoch: 2567  | Validation balanced accuracy : 0.76304 \nEpoch: 2568  | Training Loss: 0.31045 \nEpoch: 2568  | Training Loss: 0.36467 \nEpoch: 2568  | Training Loss: 0.33239 \nEpoch: 2568  | Training Loss: 0.22255 \nEpoch: 2568  | Training Loss: 0.17848 \nEpoch: 2568  | Validation balanced accuracy : 0.76304 \nEpoch: 2569  | Training Loss: 0.31045 \nEpoch: 2569  | Training Loss: 0.36466 \nEpoch: 2569  | Training Loss: 0.33242 \nEpoch: 2569  | Training Loss: 0.22252 \nEpoch: 2569  | Training Loss: 0.17841 \nEpoch: 2569  | Validation balanced accuracy : 0.76304 \nEpoch: 2570  | Training Loss: 0.31045 \nEpoch: 2570  | Training Loss: 0.36466 \nEpoch: 2570  | Training Loss: 0.33244 \nEpoch: 2570  | Training Loss: 0.22249 \nEpoch: 2570  | Training Loss: 0.17834 \nEpoch: 2570  | Validation balanced accuracy : 0.76304 \nEpoch: 2571  | Training Loss: 0.31045 \nEpoch: 2571  | Training Loss: 0.36465 \nEpoch: 2571  | Training Loss: 0.33247 \nEpoch: 2571  | Training Loss: 0.22245 \nEpoch: 2571  | Training Loss: 0.17827 \nEpoch: 2571  | Validation balanced accuracy : 0.76304 \nEpoch: 2572  | Training Loss: 0.31045 \nEpoch: 2572  | Training Loss: 0.36465 \nEpoch: 2572  | Training Loss: 0.33250 \nEpoch: 2572  | Training Loss: 0.22242 \nEpoch: 2572  | Training Loss: 0.17821 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2572  | Validation balanced accuracy : 0.76304 \nEpoch: 2573  | Training Loss: 0.31045 \nEpoch: 2573  | Training Loss: 0.36464 \nEpoch: 2573  | Training Loss: 0.33252 \nEpoch: 2573  | Training Loss: 0.22239 \nEpoch: 2573  | Training Loss: 0.17814 \nEpoch: 2573  | Validation balanced accuracy : 0.76304 \nEpoch: 2574  | Training Loss: 0.31045 \nEpoch: 2574  | Training Loss: 0.36464 \nEpoch: 2574  | Training Loss: 0.33255 \nEpoch: 2574  | Training Loss: 0.22235 \nEpoch: 2574  | Training Loss: 0.17807 \nEpoch: 2574  | Validation balanced accuracy : 0.76304 \nEpoch: 2575  | Training Loss: 0.31045 \nEpoch: 2575  | Training Loss: 0.36463 \nEpoch: 2575  | Training Loss: 0.33258 \nEpoch: 2575  | Training Loss: 0.22232 \nEpoch: 2575  | Training Loss: 0.17800 \nEpoch: 2575  | Validation balanced accuracy : 0.76304 \nEpoch: 2576  | Training Loss: 0.31045 \nEpoch: 2576  | Training Loss: 0.36463 \nEpoch: 2576  | Training Loss: 0.33261 \nEpoch: 2576  | Training Loss: 0.22229 \nEpoch: 2576  | Training Loss: 0.17793 \nEpoch: 2576  | Validation balanced accuracy : 0.76304 \nEpoch: 2577  | Training Loss: 0.31045 \nEpoch: 2577  | Training Loss: 0.36462 \nEpoch: 2577  | Training Loss: 0.33264 \nEpoch: 2577  | Training Loss: 0.22226 \nEpoch: 2577  | Training Loss: 0.17787 \nEpoch: 2577  | Validation balanced accuracy : 0.76304 \nEpoch: 2578  | Training Loss: 0.31045 \nEpoch: 2578  | Training Loss: 0.36461 \nEpoch: 2578  | Training Loss: 0.33267 \nEpoch: 2578  | Training Loss: 0.22222 \nEpoch: 2578  | Training Loss: 0.17780 \nEpoch: 2578  | Validation balanced accuracy : 0.76304 \nEpoch: 2579  | Training Loss: 0.31045 \nEpoch: 2579  | Training Loss: 0.36461 \nEpoch: 2579  | Training Loss: 0.33269 \nEpoch: 2579  | Training Loss: 0.22219 \nEpoch: 2579  | Training Loss: 0.17773 \nEpoch: 2579  | Validation balanced accuracy : 0.76304 \nEpoch: 2580  | Training Loss: 0.31045 \nEpoch: 2580  | Training Loss: 0.36460 \nEpoch: 2580  | Training Loss: 0.33272 \nEpoch: 2580  | Training Loss: 0.22216 \nEpoch: 2580  | Training Loss: 0.17766 \nEpoch: 2580  | Validation balanced accuracy : 0.76304 \nEpoch: 2581  | Training Loss: 0.31045 \nEpoch: 2581  | Training Loss: 0.36460 \nEpoch: 2581  | Training Loss: 0.33275 \nEpoch: 2581  | Training Loss: 0.22213 \nEpoch: 2581  | Training Loss: 0.17760 \nEpoch: 2581  | Validation balanced accuracy : 0.76304 \nEpoch: 2582  | Training Loss: 0.31045 \nEpoch: 2582  | Training Loss: 0.36459 \nEpoch: 2582  | Training Loss: 0.33278 \nEpoch: 2582  | Training Loss: 0.22210 \nEpoch: 2582  | Training Loss: 0.17753 \nEpoch: 2582  | Validation balanced accuracy : 0.76304 \nEpoch: 2583  | Training Loss: 0.31045 \nEpoch: 2583  | Training Loss: 0.36458 \nEpoch: 2583  | Training Loss: 0.33281 \nEpoch: 2583  | Training Loss: 0.22206 \nEpoch: 2583  | Training Loss: 0.17746 \nEpoch: 2583  | Validation balanced accuracy : 0.76304 \nEpoch: 2584  | Training Loss: 0.31045 \nEpoch: 2584  | Training Loss: 0.36458 \nEpoch: 2584  | Training Loss: 0.33284 \nEpoch: 2584  | Training Loss: 0.22203 \nEpoch: 2584  | Training Loss: 0.17739 \nEpoch: 2584  | Validation balanced accuracy : 0.76304 \nEpoch: 2585  | Training Loss: 0.31046 \nEpoch: 2585  | Training Loss: 0.36457 \nEpoch: 2585  | Training Loss: 0.33287 \nEpoch: 2585  | Training Loss: 0.22200 \nEpoch: 2585  | Training Loss: 0.17733 \nEpoch: 2585  | Validation balanced accuracy : 0.76304 \nEpoch: 2586  | Training Loss: 0.31046 \nEpoch: 2586  | Training Loss: 0.36456 \nEpoch: 2586  | Training Loss: 0.33290 \nEpoch: 2586  | Training Loss: 0.22197 \nEpoch: 2586  | Training Loss: 0.17726 \nEpoch: 2586  | Validation balanced accuracy : 0.76304 \nEpoch: 2587  | Training Loss: 0.31046 \nEpoch: 2587  | Training Loss: 0.36456 \nEpoch: 2587  | Training Loss: 0.33293 \nEpoch: 2587  | Training Loss: 0.22194 \nEpoch: 2587  | Training Loss: 0.17719 \nEpoch: 2587  | Validation balanced accuracy : 0.76304 \nEpoch: 2588  | Training Loss: 0.31046 \nEpoch: 2588  | Training Loss: 0.36455 \nEpoch: 2588  | Training Loss: 0.33296 \nEpoch: 2588  | Training Loss: 0.22190 \nEpoch: 2588  | Training Loss: 0.17713 \nEpoch: 2588  | Validation balanced accuracy : 0.76304 \nEpoch: 2589  | Training Loss: 0.31046 \nEpoch: 2589  | Training Loss: 0.36455 \nEpoch: 2589  | Training Loss: 0.33299 \nEpoch: 2589  | Training Loss: 0.22187 \nEpoch: 2589  | Training Loss: 0.17706 \nEpoch: 2589  | Validation balanced accuracy : 0.76304 \nEpoch: 2590  | Training Loss: 0.31046 \nEpoch: 2590  | Training Loss: 0.36454 \nEpoch: 2590  | Training Loss: 0.33302 \nEpoch: 2590  | Training Loss: 0.22184 \nEpoch: 2590  | Training Loss: 0.17699 \nEpoch: 2590  | Validation balanced accuracy : 0.76304 \nEpoch: 2591  | Training Loss: 0.31046 \nEpoch: 2591  | Training Loss: 0.36453 \nEpoch: 2591  | Training Loss: 0.33305 \nEpoch: 2591  | Training Loss: 0.22181 \nEpoch: 2591  | Training Loss: 0.17693 \nEpoch: 2591  | Validation balanced accuracy : 0.76304 \nEpoch: 2592  | Training Loss: 0.31046 \nEpoch: 2592  | Training Loss: 0.36453 \nEpoch: 2592  | Training Loss: 0.33308 \nEpoch: 2592  | Training Loss: 0.22178 \nEpoch: 2592  | Training Loss: 0.17686 \nEpoch: 2592  | Validation balanced accuracy : 0.76304 \nEpoch: 2593  | Training Loss: 0.31046 \nEpoch: 2593  | Training Loss: 0.36452 \nEpoch: 2593  | Training Loss: 0.33311 \nEpoch: 2593  | Training Loss: 0.22175 \nEpoch: 2593  | Training Loss: 0.17679 \nEpoch: 2593  | Validation balanced accuracy : 0.76304 \nEpoch: 2594  | Training Loss: 0.31046 \nEpoch: 2594  | Training Loss: 0.36451 \nEpoch: 2594  | Training Loss: 0.33314 \nEpoch: 2594  | Training Loss: 0.22172 \nEpoch: 2594  | Training Loss: 0.17673 \nEpoch: 2594  | Validation balanced accuracy : 0.76304 \nEpoch: 2595  | Training Loss: 0.31046 \nEpoch: 2595  | Training Loss: 0.36451 \nEpoch: 2595  | Training Loss: 0.33317 \nEpoch: 2595  | Training Loss: 0.22168 \nEpoch: 2595  | Training Loss: 0.17666 \nEpoch: 2595  | Validation balanced accuracy : 0.76304 \nEpoch: 2596  | Training Loss: 0.31046 \nEpoch: 2596  | Training Loss: 0.36450 \nEpoch: 2596  | Training Loss: 0.33320 \nEpoch: 2596  | Training Loss: 0.22165 \nEpoch: 2596  | Training Loss: 0.17659 \nEpoch: 2596  | Validation balanced accuracy : 0.76304 \nEpoch: 2597  | Training Loss: 0.31047 \nEpoch: 2597  | Training Loss: 0.36449 \nEpoch: 2597  | Training Loss: 0.33324 \nEpoch: 2597  | Training Loss: 0.22162 \nEpoch: 2597  | Training Loss: 0.17653 \nEpoch: 2597  | Validation balanced accuracy : 0.76304 \nEpoch: 2598  | Training Loss: 0.31047 \nEpoch: 2598  | Training Loss: 0.36449 \nEpoch: 2598  | Training Loss: 0.33327 \nEpoch: 2598  | Training Loss: 0.22159 \nEpoch: 2598  | Training Loss: 0.17646 \nEpoch: 2598  | Validation balanced accuracy : 0.76304 \nEpoch: 2599  | Training Loss: 0.31047 \nEpoch: 2599  | Training Loss: 0.36448 \nEpoch: 2599  | Training Loss: 0.33330 \nEpoch: 2599  | Training Loss: 0.22156 \nEpoch: 2599  | Training Loss: 0.17640 \nEpoch: 2599  | Validation balanced accuracy : 0.76304 \nEpoch: 2600  | Training Loss: 0.31047 \nEpoch: 2600  | Training Loss: 0.36447 \nEpoch: 2600  | Training Loss: 0.33333 \nEpoch: 2600  | Training Loss: 0.22153 \nEpoch: 2600  | Training Loss: 0.17633 \nEpoch: 2600  | Validation balanced accuracy : 0.76304 \nEpoch: 2601  | Training Loss: 0.31047 \nEpoch: 2601  | Training Loss: 0.36446 \nEpoch: 2601  | Training Loss: 0.33336 \nEpoch: 2601  | Training Loss: 0.22150 \nEpoch: 2601  | Training Loss: 0.17626 \nEpoch: 2601  | Validation balanced accuracy : 0.76304 \nEpoch: 2602  | Training Loss: 0.31047 \nEpoch: 2602  | Training Loss: 0.36446 \nEpoch: 2602  | Training Loss: 0.33339 \nEpoch: 2602  | Training Loss: 0.22147 \nEpoch: 2602  | Training Loss: 0.17620 \nEpoch: 2602  | Validation balanced accuracy : 0.76304 \nEpoch: 2603  | Training Loss: 0.31047 \nEpoch: 2603  | Training Loss: 0.36445 \nEpoch: 2603  | Training Loss: 0.33343 \nEpoch: 2603  | Training Loss: 0.22144 \nEpoch: 2603  | Training Loss: 0.17613 \nEpoch: 2603  | Validation balanced accuracy : 0.76304 \nEpoch: 2604  | Training Loss: 0.31047 \nEpoch: 2604  | Training Loss: 0.36444 \nEpoch: 2604  | Training Loss: 0.33346 \nEpoch: 2604  | Training Loss: 0.22141 \nEpoch: 2604  | Training Loss: 0.17607 \nEpoch: 2604  | Validation balanced accuracy : 0.76304 \nEpoch: 2605  | Training Loss: 0.31048 \nEpoch: 2605  | Training Loss: 0.36444 \nEpoch: 2605  | Training Loss: 0.33349 \nEpoch: 2605  | Training Loss: 0.22138 \nEpoch: 2605  | Training Loss: 0.17600 \nEpoch: 2605  | Validation balanced accuracy : 0.76304 \nEpoch: 2606  | Training Loss: 0.31048 \nEpoch: 2606  | Training Loss: 0.36443 \nEpoch: 2606  | Training Loss: 0.33352 \nEpoch: 2606  | Training Loss: 0.22135 \nEpoch: 2606  | Training Loss: 0.17594 \nEpoch: 2606  | Validation balanced accuracy : 0.76304 \nEpoch: 2607  | Training Loss: 0.31048 \nEpoch: 2607  | Training Loss: 0.36442 \nEpoch: 2607  | Training Loss: 0.33356 \nEpoch: 2607  | Training Loss: 0.22132 \nEpoch: 2607  | Training Loss: 0.17587 \nEpoch: 2607  | Validation balanced accuracy : 0.76304 \nEpoch: 2608  | Training Loss: 0.31048 \nEpoch: 2608  | Training Loss: 0.36441 \nEpoch: 2608  | Training Loss: 0.33359 \nEpoch: 2608  | Training Loss: 0.22129 \nEpoch: 2608  | Training Loss: 0.17581 \nEpoch: 2608  | Validation balanced accuracy : 0.76304 \nEpoch: 2609  | Training Loss: 0.31048 \nEpoch: 2609  | Training Loss: 0.36441 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2609  | Training Loss: 0.33362 \nEpoch: 2609  | Training Loss: 0.22126 \nEpoch: 2609  | Training Loss: 0.17574 \nEpoch: 2609  | Validation balanced accuracy : 0.76304 \nEpoch: 2610  | Training Loss: 0.31048 \nEpoch: 2610  | Training Loss: 0.36440 \nEpoch: 2610  | Training Loss: 0.33366 \nEpoch: 2610  | Training Loss: 0.22123 \nEpoch: 2610  | Training Loss: 0.17568 \nEpoch: 2610  | Validation balanced accuracy : 0.76304 \nEpoch: 2611  | Training Loss: 0.31048 \nEpoch: 2611  | Training Loss: 0.36439 \nEpoch: 2611  | Training Loss: 0.33369 \nEpoch: 2611  | Training Loss: 0.22120 \nEpoch: 2611  | Training Loss: 0.17561 \nEpoch: 2611  | Validation balanced accuracy : 0.76304 \nEpoch: 2612  | Training Loss: 0.31049 \nEpoch: 2612  | Training Loss: 0.36438 \nEpoch: 2612  | Training Loss: 0.33372 \nEpoch: 2612  | Training Loss: 0.22117 \nEpoch: 2612  | Training Loss: 0.17555 \nEpoch: 2612  | Validation balanced accuracy : 0.76304 \nEpoch: 2613  | Training Loss: 0.31049 \nEpoch: 2613  | Training Loss: 0.36438 \nEpoch: 2613  | Training Loss: 0.33375 \nEpoch: 2613  | Training Loss: 0.22114 \nEpoch: 2613  | Training Loss: 0.17548 \nEpoch: 2613  | Validation balanced accuracy : 0.76304 \nEpoch: 2614  | Training Loss: 0.31049 \nEpoch: 2614  | Training Loss: 0.36437 \nEpoch: 2614  | Training Loss: 0.33379 \nEpoch: 2614  | Training Loss: 0.22111 \nEpoch: 2614  | Training Loss: 0.17542 \nEpoch: 2614  | Validation balanced accuracy : 0.76304 \nEpoch: 2615  | Training Loss: 0.31049 \nEpoch: 2615  | Training Loss: 0.36436 \nEpoch: 2615  | Training Loss: 0.33382 \nEpoch: 2615  | Training Loss: 0.22108 \nEpoch: 2615  | Training Loss: 0.17535 \nEpoch: 2615  | Validation balanced accuracy : 0.76304 \nEpoch: 2616  | Training Loss: 0.31049 \nEpoch: 2616  | Training Loss: 0.36435 \nEpoch: 2616  | Training Loss: 0.33386 \nEpoch: 2616  | Training Loss: 0.22105 \nEpoch: 2616  | Training Loss: 0.17529 \nEpoch: 2616  | Validation balanced accuracy : 0.76304 \nEpoch: 2617  | Training Loss: 0.31049 \nEpoch: 2617  | Training Loss: 0.36435 \nEpoch: 2617  | Training Loss: 0.33389 \nEpoch: 2617  | Training Loss: 0.22102 \nEpoch: 2617  | Training Loss: 0.17522 \nEpoch: 2617  | Validation balanced accuracy : 0.76304 \nEpoch: 2618  | Training Loss: 0.31049 \nEpoch: 2618  | Training Loss: 0.36434 \nEpoch: 2618  | Training Loss: 0.33392 \nEpoch: 2618  | Training Loss: 0.22099 \nEpoch: 2618  | Training Loss: 0.17516 \nEpoch: 2618  | Validation balanced accuracy : 0.76304 \nEpoch: 2619  | Training Loss: 0.31050 \nEpoch: 2619  | Training Loss: 0.36433 \nEpoch: 2619  | Training Loss: 0.33396 \nEpoch: 2619  | Training Loss: 0.22096 \nEpoch: 2619  | Training Loss: 0.17509 \nEpoch: 2619  | Validation balanced accuracy : 0.76304 \nEpoch: 2620  | Training Loss: 0.31050 \nEpoch: 2620  | Training Loss: 0.36432 \nEpoch: 2620  | Training Loss: 0.33399 \nEpoch: 2620  | Training Loss: 0.22093 \nEpoch: 2620  | Training Loss: 0.17503 \nEpoch: 2620  | Validation balanced accuracy : 0.76304 \nEpoch: 2621  | Training Loss: 0.31050 \nEpoch: 2621  | Training Loss: 0.36432 \nEpoch: 2621  | Training Loss: 0.33403 \nEpoch: 2621  | Training Loss: 0.22090 \nEpoch: 2621  | Training Loss: 0.17497 \nEpoch: 2621  | Validation balanced accuracy : 0.76304 \nEpoch: 2622  | Training Loss: 0.31050 \nEpoch: 2622  | Training Loss: 0.36431 \nEpoch: 2622  | Training Loss: 0.33406 \nEpoch: 2622  | Training Loss: 0.22087 \nEpoch: 2622  | Training Loss: 0.17490 \nEpoch: 2622  | Validation balanced accuracy : 0.76304 \nEpoch: 2623  | Training Loss: 0.31050 \nEpoch: 2623  | Training Loss: 0.36430 \nEpoch: 2623  | Training Loss: 0.33409 \nEpoch: 2623  | Training Loss: 0.22084 \nEpoch: 2623  | Training Loss: 0.17484 \nEpoch: 2623  | Validation balanced accuracy : 0.76304 \nEpoch: 2624  | Training Loss: 0.31051 \nEpoch: 2624  | Training Loss: 0.36429 \nEpoch: 2624  | Training Loss: 0.33413 \nEpoch: 2624  | Training Loss: 0.22081 \nEpoch: 2624  | Training Loss: 0.17477 \nEpoch: 2624  | Validation balanced accuracy : 0.76304 \nEpoch: 2625  | Training Loss: 0.31051 \nEpoch: 2625  | Training Loss: 0.36428 \nEpoch: 2625  | Training Loss: 0.33416 \nEpoch: 2625  | Training Loss: 0.22078 \nEpoch: 2625  | Training Loss: 0.17471 \nEpoch: 2625  | Validation balanced accuracy : 0.76304 \nEpoch: 2626  | Training Loss: 0.31051 \nEpoch: 2626  | Training Loss: 0.36428 \nEpoch: 2626  | Training Loss: 0.33420 \nEpoch: 2626  | Training Loss: 0.22075 \nEpoch: 2626  | Training Loss: 0.17465 \nEpoch: 2626  | Validation balanced accuracy : 0.76304 \nEpoch: 2627  | Training Loss: 0.31051 \nEpoch: 2627  | Training Loss: 0.36427 \nEpoch: 2627  | Training Loss: 0.33423 \nEpoch: 2627  | Training Loss: 0.22073 \nEpoch: 2627  | Training Loss: 0.17458 \nEpoch: 2627  | Validation balanced accuracy : 0.76304 \nEpoch: 2628  | Training Loss: 0.31051 \nEpoch: 2628  | Training Loss: 0.36426 \nEpoch: 2628  | Training Loss: 0.33427 \nEpoch: 2628  | Training Loss: 0.22070 \nEpoch: 2628  | Training Loss: 0.17452 \nEpoch: 2628  | Validation balanced accuracy : 0.76304 \nEpoch: 2629  | Training Loss: 0.31051 \nEpoch: 2629  | Training Loss: 0.36425 \nEpoch: 2629  | Training Loss: 0.33430 \nEpoch: 2629  | Training Loss: 0.22067 \nEpoch: 2629  | Training Loss: 0.17446 \nEpoch: 2629  | Validation balanced accuracy : 0.76304 \nEpoch: 2630  | Training Loss: 0.31052 \nEpoch: 2630  | Training Loss: 0.36424 \nEpoch: 2630  | Training Loss: 0.33434 \nEpoch: 2630  | Training Loss: 0.22064 \nEpoch: 2630  | Training Loss: 0.17439 \nEpoch: 2630  | Validation balanced accuracy : 0.76304 \nEpoch: 2631  | Training Loss: 0.31052 \nEpoch: 2631  | Training Loss: 0.36424 \nEpoch: 2631  | Training Loss: 0.33437 \nEpoch: 2631  | Training Loss: 0.22061 \nEpoch: 2631  | Training Loss: 0.17433 \nEpoch: 2631  | Validation balanced accuracy : 0.76304 \nEpoch: 2632  | Training Loss: 0.31052 \nEpoch: 2632  | Training Loss: 0.36423 \nEpoch: 2632  | Training Loss: 0.33441 \nEpoch: 2632  | Training Loss: 0.22058 \nEpoch: 2632  | Training Loss: 0.17427 \nEpoch: 2632  | Validation balanced accuracy : 0.76304 \nEpoch: 2633  | Training Loss: 0.31052 \nEpoch: 2633  | Training Loss: 0.36422 \nEpoch: 2633  | Training Loss: 0.33444 \nEpoch: 2633  | Training Loss: 0.22055 \nEpoch: 2633  | Training Loss: 0.17420 \nEpoch: 2633  | Validation balanced accuracy : 0.76304 \nEpoch: 2634  | Training Loss: 0.31052 \nEpoch: 2634  | Training Loss: 0.36421 \nEpoch: 2634  | Training Loss: 0.33448 \nEpoch: 2634  | Training Loss: 0.22053 \nEpoch: 2634  | Training Loss: 0.17414 \nEpoch: 2634  | Validation balanced accuracy : 0.76304 \nEpoch: 2635  | Training Loss: 0.31053 \nEpoch: 2635  | Training Loss: 0.36420 \nEpoch: 2635  | Training Loss: 0.33451 \nEpoch: 2635  | Training Loss: 0.22050 \nEpoch: 2635  | Training Loss: 0.17408 \nEpoch: 2635  | Validation balanced accuracy : 0.76304 \nEpoch: 2636  | Training Loss: 0.31053 \nEpoch: 2636  | Training Loss: 0.36420 \nEpoch: 2636  | Training Loss: 0.33455 \nEpoch: 2636  | Training Loss: 0.22047 \nEpoch: 2636  | Training Loss: 0.17402 \nEpoch: 2636  | Validation balanced accuracy : 0.76304 \nEpoch: 2637  | Training Loss: 0.31053 \nEpoch: 2637  | Training Loss: 0.36419 \nEpoch: 2637  | Training Loss: 0.33459 \nEpoch: 2637  | Training Loss: 0.22044 \nEpoch: 2637  | Training Loss: 0.17395 \nEpoch: 2637  | Validation balanced accuracy : 0.76304 \nEpoch: 2638  | Training Loss: 0.31053 \nEpoch: 2638  | Training Loss: 0.36418 \nEpoch: 2638  | Training Loss: 0.33462 \nEpoch: 2638  | Training Loss: 0.22041 \nEpoch: 2638  | Training Loss: 0.17389 \nEpoch: 2638  | Validation balanced accuracy : 0.76304 \nEpoch: 2639  | Training Loss: 0.31054 \nEpoch: 2639  | Training Loss: 0.36417 \nEpoch: 2639  | Training Loss: 0.33466 \nEpoch: 2639  | Training Loss: 0.22039 \nEpoch: 2639  | Training Loss: 0.17383 \nEpoch: 2639  | Validation balanced accuracy : 0.76304 \nEpoch: 2640  | Training Loss: 0.31054 \nEpoch: 2640  | Training Loss: 0.36416 \nEpoch: 2640  | Training Loss: 0.33469 \nEpoch: 2640  | Training Loss: 0.22036 \nEpoch: 2640  | Training Loss: 0.17377 \nEpoch: 2640  | Validation balanced accuracy : 0.76304 \nEpoch: 2641  | Training Loss: 0.31054 \nEpoch: 2641  | Training Loss: 0.36416 \nEpoch: 2641  | Training Loss: 0.33473 \nEpoch: 2641  | Training Loss: 0.22033 \nEpoch: 2641  | Training Loss: 0.17370 \nEpoch: 2641  | Validation balanced accuracy : 0.76304 \nEpoch: 2642  | Training Loss: 0.31054 \nEpoch: 2642  | Training Loss: 0.36415 \nEpoch: 2642  | Training Loss: 0.33477 \nEpoch: 2642  | Training Loss: 0.22030 \nEpoch: 2642  | Training Loss: 0.17364 \nEpoch: 2642  | Validation balanced accuracy : 0.76304 \nEpoch: 2643  | Training Loss: 0.31054 \nEpoch: 2643  | Training Loss: 0.36414 \nEpoch: 2643  | Training Loss: 0.33480 \nEpoch: 2643  | Training Loss: 0.22027 \nEpoch: 2643  | Training Loss: 0.17358 \nEpoch: 2643  | Validation balanced accuracy : 0.76304 \nEpoch: 2644  | Training Loss: 0.31055 \nEpoch: 2644  | Training Loss: 0.36413 \nEpoch: 2644  | Training Loss: 0.33484 \nEpoch: 2644  | Training Loss: 0.22025 \nEpoch: 2644  | Training Loss: 0.17352 \nEpoch: 2644  | Validation balanced accuracy : 0.76304 \nEpoch: 2645  | Training Loss: 0.31055 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2645  | Training Loss: 0.36412 \nEpoch: 2645  | Training Loss: 0.33487 \nEpoch: 2645  | Training Loss: 0.22022 \nEpoch: 2645  | Training Loss: 0.17346 \nEpoch: 2645  | Validation balanced accuracy : 0.76304 \nEpoch: 2646  | Training Loss: 0.31055 \nEpoch: 2646  | Training Loss: 0.36411 \nEpoch: 2646  | Training Loss: 0.33491 \nEpoch: 2646  | Training Loss: 0.22019 \nEpoch: 2646  | Training Loss: 0.17339 \nEpoch: 2646  | Validation balanced accuracy : 0.76304 \nEpoch: 2647  | Training Loss: 0.31055 \nEpoch: 2647  | Training Loss: 0.36411 \nEpoch: 2647  | Training Loss: 0.33495 \nEpoch: 2647  | Training Loss: 0.22016 \nEpoch: 2647  | Training Loss: 0.17333 \nEpoch: 2647  | Validation balanced accuracy : 0.76304 \nEpoch: 2648  | Training Loss: 0.31056 \nEpoch: 2648  | Training Loss: 0.36410 \nEpoch: 2648  | Training Loss: 0.33498 \nEpoch: 2648  | Training Loss: 0.22014 \nEpoch: 2648  | Training Loss: 0.17328 \nEpoch: 2648  | Validation balanced accuracy : 0.76304 \nEpoch: 2649  | Training Loss: 0.31055 \nEpoch: 2649  | Training Loss: 0.36409 \nEpoch: 2649  | Training Loss: 0.33502 \nEpoch: 2649  | Training Loss: 0.22011 \nEpoch: 2649  | Training Loss: 0.17322 \nEpoch: 2649  | Validation balanced accuracy : 0.76304 \nEpoch: 2650  | Training Loss: 0.31055 \nEpoch: 2650  | Training Loss: 0.36407 \nEpoch: 2650  | Training Loss: 0.33506 \nEpoch: 2650  | Training Loss: 0.22008 \nEpoch: 2650  | Training Loss: 0.17317 \nEpoch: 2650  | Validation balanced accuracy : 0.76304 \nEpoch: 2651  | Training Loss: 0.31055 \nEpoch: 2651  | Training Loss: 0.36406 \nEpoch: 2651  | Training Loss: 0.33510 \nEpoch: 2651  | Training Loss: 0.22005 \nEpoch: 2651  | Training Loss: 0.17312 \nEpoch: 2651  | Validation balanced accuracy : 0.76304 \nEpoch: 2652  | Training Loss: 0.31055 \nEpoch: 2652  | Training Loss: 0.36405 \nEpoch: 2652  | Training Loss: 0.33513 \nEpoch: 2652  | Training Loss: 0.22003 \nEpoch: 2652  | Training Loss: 0.17306 \nEpoch: 2652  | Validation balanced accuracy : 0.76304 \nEpoch: 2653  | Training Loss: 0.31055 \nEpoch: 2653  | Training Loss: 0.36405 \nEpoch: 2653  | Training Loss: 0.33517 \nEpoch: 2653  | Training Loss: 0.22000 \nEpoch: 2653  | Training Loss: 0.17299 \nEpoch: 2653  | Validation balanced accuracy : 0.76304 \nEpoch: 2654  | Training Loss: 0.31055 \nEpoch: 2654  | Training Loss: 0.36404 \nEpoch: 2654  | Training Loss: 0.33520 \nEpoch: 2654  | Training Loss: 0.21997 \nEpoch: 2654  | Training Loss: 0.17293 \nEpoch: 2654  | Validation balanced accuracy : 0.76304 \nEpoch: 2655  | Training Loss: 0.31056 \nEpoch: 2655  | Training Loss: 0.36403 \nEpoch: 2655  | Training Loss: 0.33524 \nEpoch: 2655  | Training Loss: 0.21995 \nEpoch: 2655  | Training Loss: 0.17287 \nEpoch: 2655  | Validation balanced accuracy : 0.76304 \nEpoch: 2656  | Training Loss: 0.31056 \nEpoch: 2656  | Training Loss: 0.36403 \nEpoch: 2656  | Training Loss: 0.33527 \nEpoch: 2656  | Training Loss: 0.21992 \nEpoch: 2656  | Training Loss: 0.17281 \nEpoch: 2656  | Validation balanced accuracy : 0.76304 \nEpoch: 2657  | Training Loss: 0.31056 \nEpoch: 2657  | Training Loss: 0.36402 \nEpoch: 2657  | Training Loss: 0.33531 \nEpoch: 2657  | Training Loss: 0.21990 \nEpoch: 2657  | Training Loss: 0.17270 \nEpoch: 2657  | Validation balanced accuracy : 0.76304 \nEpoch: 2658  | Training Loss: 0.31062 \nEpoch: 2658  | Training Loss: 0.36406 \nEpoch: 2658  | Training Loss: 0.33532 \nEpoch: 2658  | Training Loss: 0.21988 \nEpoch: 2658  | Training Loss: 0.17257 \nEpoch: 2658  | Validation balanced accuracy : 0.76304 \nEpoch: 2659  | Training Loss: 0.31065 \nEpoch: 2659  | Training Loss: 0.36407 \nEpoch: 2659  | Training Loss: 0.33535 \nEpoch: 2659  | Training Loss: 0.21985 \nEpoch: 2659  | Training Loss: 0.17246 \nEpoch: 2659  | Validation balanced accuracy : 0.76304 \nEpoch: 2660  | Training Loss: 0.31069 \nEpoch: 2660  | Training Loss: 0.36410 \nEpoch: 2660  | Training Loss: 0.33536 \nEpoch: 2660  | Training Loss: 0.21983 \nEpoch: 2660  | Training Loss: 0.17233 \nEpoch: 2660  | Validation balanced accuracy : 0.76304 \nEpoch: 2661  | Training Loss: 0.31074 \nEpoch: 2661  | Training Loss: 0.36413 \nEpoch: 2661  | Training Loss: 0.33538 \nEpoch: 2661  | Training Loss: 0.21981 \nEpoch: 2661  | Training Loss: 0.17221 \nEpoch: 2661  | Validation balanced accuracy : 0.76304 \nEpoch: 2662  | Training Loss: 0.31078 \nEpoch: 2662  | Training Loss: 0.36415 \nEpoch: 2662  | Training Loss: 0.33540 \nEpoch: 2662  | Training Loss: 0.21979 \nEpoch: 2662  | Training Loss: 0.17212 \nEpoch: 2662  | Validation balanced accuracy : 0.76304 \nEpoch: 2663  | Training Loss: 0.31080 \nEpoch: 2663  | Training Loss: 0.36416 \nEpoch: 2663  | Training Loss: 0.33543 \nEpoch: 2663  | Training Loss: 0.21976 \nEpoch: 2663  | Training Loss: 0.17207 \nEpoch: 2663  | Validation balanced accuracy : 0.76304 \nEpoch: 2664  | Training Loss: 0.31080 \nEpoch: 2664  | Training Loss: 0.36415 \nEpoch: 2664  | Training Loss: 0.33546 \nEpoch: 2664  | Training Loss: 0.21973 \nEpoch: 2664  | Training Loss: 0.17202 \nEpoch: 2664  | Validation balanced accuracy : 0.76304 \nEpoch: 2665  | Training Loss: 0.31079 \nEpoch: 2665  | Training Loss: 0.36414 \nEpoch: 2665  | Training Loss: 0.33550 \nEpoch: 2665  | Training Loss: 0.21971 \nEpoch: 2665  | Training Loss: 0.17198 \nEpoch: 2665  | Validation balanced accuracy : 0.76304 \nEpoch: 2666  | Training Loss: 0.31078 \nEpoch: 2666  | Training Loss: 0.36412 \nEpoch: 2666  | Training Loss: 0.33554 \nEpoch: 2666  | Training Loss: 0.21968 \nEpoch: 2666  | Training Loss: 0.17194 \nEpoch: 2666  | Validation balanced accuracy : 0.76304 \nEpoch: 2667  | Training Loss: 0.31078 \nEpoch: 2667  | Training Loss: 0.36411 \nEpoch: 2667  | Training Loss: 0.33557 \nEpoch: 2667  | Training Loss: 0.21965 \nEpoch: 2667  | Training Loss: 0.17189 \nEpoch: 2667  | Validation balanced accuracy : 0.76304 \nEpoch: 2668  | Training Loss: 0.31078 \nEpoch: 2668  | Training Loss: 0.36411 \nEpoch: 2668  | Training Loss: 0.33560 \nEpoch: 2668  | Training Loss: 0.21963 \nEpoch: 2668  | Training Loss: 0.17183 \nEpoch: 2668  | Validation balanced accuracy : 0.76304 \nEpoch: 2669  | Training Loss: 0.31078 \nEpoch: 2669  | Training Loss: 0.36411 \nEpoch: 2669  | Training Loss: 0.33563 \nEpoch: 2669  | Training Loss: 0.21960 \nEpoch: 2669  | Training Loss: 0.17176 \nEpoch: 2669  | Validation balanced accuracy : 0.76304 \nEpoch: 2670  | Training Loss: 0.31079 \nEpoch: 2670  | Training Loss: 0.36420 \nEpoch: 2670  | Training Loss: 0.33557 \nEpoch: 2670  | Training Loss: 0.21961 \nEpoch: 2670  | Training Loss: 0.17112 \nEpoch: 2670  | Validation balanced accuracy : 0.76304 \nEpoch: 2671  | Training Loss: 0.31124 \nEpoch: 2671  | Training Loss: 0.36450 \nEpoch: 2671  | Training Loss: 0.33548 \nEpoch: 2671  | Training Loss: 0.21961 \nEpoch: 2671  | Training Loss: 0.17088 \nEpoch: 2671  | Validation balanced accuracy : 0.76304 \nEpoch: 2672  | Training Loss: 0.31129 \nEpoch: 2672  | Training Loss: 0.36448 \nEpoch: 2672  | Training Loss: 0.33555 \nEpoch: 2672  | Training Loss: 0.21957 \nEpoch: 2672  | Training Loss: 0.17113 \nEpoch: 2672  | Validation balanced accuracy : 0.76304 \nEpoch: 2673  | Training Loss: 0.31105 \nEpoch: 2673  | Training Loss: 0.36426 \nEpoch: 2673  | Training Loss: 0.33569 \nEpoch: 2673  | Training Loss: 0.21951 \nEpoch: 2673  | Training Loss: 0.17148 \nEpoch: 2673  | Validation balanced accuracy : 0.76304 \nEpoch: 2674  | Training Loss: 0.31080 \nEpoch: 2674  | Training Loss: 0.36416 \nEpoch: 2674  | Training Loss: 0.33572 \nEpoch: 2674  | Training Loss: 0.21950 \nEpoch: 2674  | Training Loss: 0.17111 \nEpoch: 2674  | Validation balanced accuracy : 0.76304 \nEpoch: 2675  | Training Loss: 0.31109 \nEpoch: 2675  | Training Loss: 0.36436 \nEpoch: 2675  | Training Loss: 0.33566 \nEpoch: 2675  | Training Loss: 0.21949 \nEpoch: 2675  | Training Loss: 0.17089 \nEpoch: 2675  | Validation balanced accuracy : 0.76304 \nEpoch: 2676  | Training Loss: 0.31116 \nEpoch: 2676  | Training Loss: 0.36438 \nEpoch: 2676  | Training Loss: 0.33569 \nEpoch: 2676  | Training Loss: 0.21946 \nEpoch: 2676  | Training Loss: 0.17094 \nEpoch: 2676  | Validation balanced accuracy : 0.76304 \nEpoch: 2677  | Training Loss: 0.31107 \nEpoch: 2677  | Training Loss: 0.36429 \nEpoch: 2677  | Training Loss: 0.33577 \nEpoch: 2677  | Training Loss: 0.21942 \nEpoch: 2677  | Training Loss: 0.17111 \nEpoch: 2677  | Validation balanced accuracy : 0.76304 \nEpoch: 2678  | Training Loss: 0.31092 \nEpoch: 2678  | Training Loss: 0.36417 \nEpoch: 2678  | Training Loss: 0.33581 \nEpoch: 2678  | Training Loss: 0.21941 \nEpoch: 2678  | Training Loss: 0.17079 \nEpoch: 2678  | Validation balanced accuracy : 0.76304 \nEpoch: 2679  | Training Loss: 0.31118 \nEpoch: 2679  | Training Loss: 0.36444 \nEpoch: 2679  | Training Loss: 0.33573 \nEpoch: 2679  | Training Loss: 0.21940 \nEpoch: 2679  | Training Loss: 0.17051 \nEpoch: 2679  | Validation balanced accuracy : 0.76304 \nEpoch: 2680  | Training Loss: 0.31128 \nEpoch: 2680  | Training Loss: 0.36447 \nEpoch: 2680  | Training Loss: 0.33576 \nEpoch: 2680  | Training Loss: 0.21937 \nEpoch: 2680  | Training Loss: 0.17059 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2680  | Validation balanced accuracy : 0.76304 \nEpoch: 2681  | Training Loss: 0.31117 \nEpoch: 2681  | Training Loss: 0.36435 \nEpoch: 2681  | Training Loss: 0.33585 \nEpoch: 2681  | Training Loss: 0.21933 \nEpoch: 2681  | Training Loss: 0.17082 \nEpoch: 2681  | Validation balanced accuracy : 0.76304 \nEpoch: 2682  | Training Loss: 0.31097 \nEpoch: 2682  | Training Loss: 0.36420 \nEpoch: 2682  | Training Loss: 0.33591 \nEpoch: 2682  | Training Loss: 0.21931 \nEpoch: 2682  | Training Loss: 0.17056 \nEpoch: 2682  | Validation balanced accuracy : 0.76304 \nEpoch: 2683  | Training Loss: 0.31120 \nEpoch: 2683  | Training Loss: 0.36443 \nEpoch: 2683  | Training Loss: 0.33584 \nEpoch: 2683  | Training Loss: 0.21930 \nEpoch: 2683  | Training Loss: 0.17032 \nEpoch: 2683  | Validation balanced accuracy : 0.76304 \nEpoch: 2684  | Training Loss: 0.31127 \nEpoch: 2684  | Training Loss: 0.36445 \nEpoch: 2684  | Training Loss: 0.33588 \nEpoch: 2684  | Training Loss: 0.21927 \nEpoch: 2684  | Training Loss: 0.17041 \nEpoch: 2684  | Validation balanced accuracy : 0.76304 \nEpoch: 2685  | Training Loss: 0.31116 \nEpoch: 2685  | Training Loss: 0.36434 \nEpoch: 2685  | Training Loss: 0.33597 \nEpoch: 2685  | Training Loss: 0.21923 \nEpoch: 2685  | Training Loss: 0.17062 \nEpoch: 2685  | Validation balanced accuracy : 0.76304 \nEpoch: 2686  | Training Loss: 0.31097 \nEpoch: 2686  | Training Loss: 0.36428 \nEpoch: 2686  | Training Loss: 0.33598 \nEpoch: 2686  | Training Loss: 0.21922 \nEpoch: 2686  | Training Loss: 0.17024 \nEpoch: 2686  | Validation balanced accuracy : 0.76304 \nEpoch: 2687  | Training Loss: 0.31127 \nEpoch: 2687  | Training Loss: 0.36447 \nEpoch: 2687  | Training Loss: 0.33593 \nEpoch: 2687  | Training Loss: 0.21921 \nEpoch: 2687  | Training Loss: 0.17009 \nEpoch: 2687  | Validation balanced accuracy : 0.76304 \nEpoch: 2688  | Training Loss: 0.31129 \nEpoch: 2688  | Training Loss: 0.36445 \nEpoch: 2688  | Training Loss: 0.33599 \nEpoch: 2688  | Training Loss: 0.21918 \nEpoch: 2688  | Training Loss: 0.17023 \nEpoch: 2688  | Validation balanced accuracy : 0.76304 \nEpoch: 2689  | Training Loss: 0.31114 \nEpoch: 2689  | Training Loss: 0.36431 \nEpoch: 2689  | Training Loss: 0.33609 \nEpoch: 2689  | Training Loss: 0.21913 \nEpoch: 2689  | Training Loss: 0.17046 \nEpoch: 2689  | Validation balanced accuracy : 0.76304 \nEpoch: 2690  | Training Loss: 0.31096 \nEpoch: 2690  | Training Loss: 0.36426 \nEpoch: 2690  | Training Loss: 0.33605 \nEpoch: 2690  | Training Loss: 0.21915 \nEpoch: 2690  | Training Loss: 0.16960 \nEpoch: 2690  | Validation balanced accuracy : 0.76304 \nEpoch: 2691  | Training Loss: 0.31164 \nEpoch: 2691  | Training Loss: 0.36482 \nEpoch: 2691  | Training Loss: 0.33585 \nEpoch: 2691  | Training Loss: 0.21917 \nEpoch: 2691  | Training Loss: 0.16915 \nEpoch: 2691  | Validation balanced accuracy : 0.76304 \nEpoch: 2692  | Training Loss: 0.31179 \nEpoch: 2692  | Training Loss: 0.36484 \nEpoch: 2692  | Training Loss: 0.33591 \nEpoch: 2692  | Training Loss: 0.21913 \nEpoch: 2692  | Training Loss: 0.16950 \nEpoch: 2692  | Validation balanced accuracy : 0.76304 \nEpoch: 2693  | Training Loss: 0.31144 \nEpoch: 2693  | Training Loss: 0.36452 \nEpoch: 2693  | Training Loss: 0.33611 \nEpoch: 2693  | Training Loss: 0.21905 \nEpoch: 2693  | Training Loss: 0.17012 \nEpoch: 2693  | Validation balanced accuracy : 0.76304 \nEpoch: 2694  | Training Loss: 0.31101 \nEpoch: 2694  | Training Loss: 0.36427 \nEpoch: 2694  | Training Loss: 0.33616 \nEpoch: 2694  | Training Loss: 0.21905 \nEpoch: 2694  | Training Loss: 0.16954 \nEpoch: 2694  | Validation balanced accuracy : 0.76304 \nEpoch: 2695  | Training Loss: 0.31154 \nEpoch: 2695  | Training Loss: 0.36472 \nEpoch: 2695  | Training Loss: 0.33600 \nEpoch: 2695  | Training Loss: 0.21906 \nEpoch: 2695  | Training Loss: 0.16919 \nEpoch: 2695  | Validation balanced accuracy : 0.76304 \nEpoch: 2696  | Training Loss: 0.31163 \nEpoch: 2696  | Training Loss: 0.36472 \nEpoch: 2696  | Training Loss: 0.33606 \nEpoch: 2696  | Training Loss: 0.21902 \nEpoch: 2696  | Training Loss: 0.16945 \nEpoch: 2696  | Validation balanced accuracy : 0.76304 \nEpoch: 2697  | Training Loss: 0.31138 \nEpoch: 2697  | Training Loss: 0.36449 \nEpoch: 2697  | Training Loss: 0.33621 \nEpoch: 2697  | Training Loss: 0.21896 \nEpoch: 2697  | Training Loss: 0.16989 \nEpoch: 2697  | Validation balanced accuracy : 0.76304 \nEpoch: 2698  | Training Loss: 0.31106 \nEpoch: 2698  | Training Loss: 0.36433 \nEpoch: 2698  | Training Loss: 0.33627 \nEpoch: 2698  | Training Loss: 0.21894 \nEpoch: 2698  | Training Loss: 0.16967 \nEpoch: 2698  | Validation balanced accuracy : 0.76304 \nEpoch: 2699  | Training Loss: 0.31126 \nEpoch: 2699  | Training Loss: 0.36445 \nEpoch: 2699  | Training Loss: 0.33625 \nEpoch: 2699  | Training Loss: 0.21892 \nEpoch: 2699  | Training Loss: 0.16958 \nEpoch: 2699  | Validation balanced accuracy : 0.76304 \nEpoch: 2700  | Training Loss: 0.31125 \nEpoch: 2700  | Training Loss: 0.36442 \nEpoch: 2700  | Training Loss: 0.33631 \nEpoch: 2700  | Training Loss: 0.21889 \nEpoch: 2700  | Training Loss: 0.16970 \nEpoch: 2700  | Validation balanced accuracy : 0.76304 \nEpoch: 2701  | Training Loss: 0.31112 \nEpoch: 2701  | Training Loss: 0.36429 \nEpoch: 2701  | Training Loss: 0.33630 \nEpoch: 2701  | Training Loss: 0.21889 \nEpoch: 2701  | Training Loss: 0.16907 \nEpoch: 2701  | Validation balanced accuracy : 0.76304 \nEpoch: 2702  | Training Loss: 0.31133 \nEpoch: 2702  | Training Loss: 0.36450 \nEpoch: 2702  | Training Loss: 0.33625 \nEpoch: 2702  | Training Loss: 0.21889 \nEpoch: 2702  | Training Loss: 0.16893 \nEpoch: 2702  | Validation balanced accuracy : 0.76304 \nEpoch: 2703  | Training Loss: 0.31134 \nEpoch: 2703  | Training Loss: 0.36447 \nEpoch: 2703  | Training Loss: 0.33630 \nEpoch: 2703  | Training Loss: 0.21885 \nEpoch: 2703  | Training Loss: 0.16910 \nEpoch: 2703  | Validation balanced accuracy : 0.76304 \nEpoch: 2704  | Training Loss: 0.31118 \nEpoch: 2704  | Training Loss: 0.36432 \nEpoch: 2704  | Training Loss: 0.33637 \nEpoch: 2704  | Training Loss: 0.21883 \nEpoch: 2704  | Training Loss: 0.16896 \nEpoch: 2704  | Validation balanced accuracy : 0.76304 \nEpoch: 2705  | Training Loss: 0.31131 \nEpoch: 2705  | Training Loss: 0.36447 \nEpoch: 2705  | Training Loss: 0.33634 \nEpoch: 2705  | Training Loss: 0.21882 \nEpoch: 2705  | Training Loss: 0.16887 \nEpoch: 2705  | Validation balanced accuracy : 0.76304 \nEpoch: 2706  | Training Loss: 0.31129 \nEpoch: 2706  | Training Loss: 0.36442 \nEpoch: 2706  | Training Loss: 0.33640 \nEpoch: 2706  | Training Loss: 0.21878 \nEpoch: 2706  | Training Loss: 0.16904 \nEpoch: 2706  | Validation balanced accuracy : 0.76304 \nEpoch: 2707  | Training Loss: 0.31113 \nEpoch: 2707  | Training Loss: 0.36436 \nEpoch: 2707  | Training Loss: 0.33642 \nEpoch: 2707  | Training Loss: 0.21877 \nEpoch: 2707  | Training Loss: 0.16878 \nEpoch: 2707  | Validation balanced accuracy : 0.76304 \nEpoch: 2708  | Training Loss: 0.31134 \nEpoch: 2708  | Training Loss: 0.36448 \nEpoch: 2708  | Training Loss: 0.33640 \nEpoch: 2708  | Training Loss: 0.21876 \nEpoch: 2708  | Training Loss: 0.16874 \nEpoch: 2708  | Validation balanced accuracy : 0.76304 \nEpoch: 2709  | Training Loss: 0.31129 \nEpoch: 2709  | Training Loss: 0.36441 \nEpoch: 2709  | Training Loss: 0.33648 \nEpoch: 2709  | Training Loss: 0.21872 \nEpoch: 2709  | Training Loss: 0.16894 \nEpoch: 2709  | Validation balanced accuracy : 0.76304 \nEpoch: 2710  | Training Loss: 0.31112 \nEpoch: 2710  | Training Loss: 0.36435 \nEpoch: 2710  | Training Loss: 0.33646 \nEpoch: 2710  | Training Loss: 0.21873 \nEpoch: 2710  | Training Loss: 0.16826 \nEpoch: 2710  | Validation balanced accuracy : 0.76304 \nEpoch: 2711  | Training Loss: 0.31167 \nEpoch: 2711  | Training Loss: 0.36479 \nEpoch: 2711  | Training Loss: 0.33630 \nEpoch: 2711  | Training Loss: 0.21875 \nEpoch: 2711  | Training Loss: 0.16790 \nEpoch: 2711  | Validation balanced accuracy : 0.76304 \nEpoch: 2712  | Training Loss: 0.31179 \nEpoch: 2712  | Training Loss: 0.36481 \nEpoch: 2712  | Training Loss: 0.33635 \nEpoch: 2712  | Training Loss: 0.21871 \nEpoch: 2712  | Training Loss: 0.16815 \nEpoch: 2712  | Validation balanced accuracy : 0.76304 \nEpoch: 2713  | Training Loss: 0.31153 \nEpoch: 2713  | Training Loss: 0.36457 \nEpoch: 2713  | Training Loss: 0.33650 \nEpoch: 2713  | Training Loss: 0.21865 \nEpoch: 2713  | Training Loss: 0.16867 \nEpoch: 2713  | Validation balanced accuracy : 0.76304 \nEpoch: 2714  | Training Loss: 0.31116 \nEpoch: 2714  | Training Loss: 0.36436 \nEpoch: 2714  | Training Loss: 0.33655 \nEpoch: 2714  | Training Loss: 0.21864 \nEpoch: 2714  | Training Loss: 0.16820 \nEpoch: 2714  | Validation balanced accuracy : 0.76304 \nEpoch: 2715  | Training Loss: 0.31158 \nEpoch: 2715  | Training Loss: 0.36471 \nEpoch: 2715  | Training Loss: 0.33643 \nEpoch: 2715  | Training Loss: 0.21865 \nEpoch: 2715  | Training Loss: 0.16792 \nEpoch: 2715  | Validation balanced accuracy : 0.76304 \nEpoch: 2716  | Training Loss: 0.31166 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2716  | Training Loss: 0.36472 \nEpoch: 2716  | Training Loss: 0.33648 \nEpoch: 2716  | Training Loss: 0.21862 \nEpoch: 2716  | Training Loss: 0.16815 \nEpoch: 2716  | Validation balanced accuracy : 0.76304 \nEpoch: 2717  | Training Loss: 0.31144 \nEpoch: 2717  | Training Loss: 0.36451 \nEpoch: 2717  | Training Loss: 0.33662 \nEpoch: 2717  | Training Loss: 0.21856 \nEpoch: 2717  | Training Loss: 0.16858 \nEpoch: 2717  | Validation balanced accuracy : 0.76304 \nEpoch: 2718  | Training Loss: 0.31113 \nEpoch: 2718  | Training Loss: 0.36434 \nEpoch: 2718  | Training Loss: 0.33664 \nEpoch: 2718  | Training Loss: 0.21856 \nEpoch: 2718  | Training Loss: 0.16803 \nEpoch: 2718  | Validation balanced accuracy : 0.76304 \nEpoch: 2719  | Training Loss: 0.31160 \nEpoch: 2719  | Training Loss: 0.36474 \nEpoch: 2719  | Training Loss: 0.33651 \nEpoch: 2719  | Training Loss: 0.21858 \nEpoch: 2719  | Training Loss: 0.16769 \nEpoch: 2719  | Validation balanced accuracy : 0.76304 \nEpoch: 2720  | Training Loss: 0.31172 \nEpoch: 2720  | Training Loss: 0.36476 \nEpoch: 2720  | Training Loss: 0.33655 \nEpoch: 2720  | Training Loss: 0.21854 \nEpoch: 2720  | Training Loss: 0.16790 \nEpoch: 2720  | Validation balanced accuracy : 0.76304 \nEpoch: 2721  | Training Loss: 0.31150 \nEpoch: 2721  | Training Loss: 0.36456 \nEpoch: 2721  | Training Loss: 0.33668 \nEpoch: 2721  | Training Loss: 0.21849 \nEpoch: 2721  | Training Loss: 0.16834 \nEpoch: 2721  | Validation balanced accuracy : 0.76304 \nEpoch: 2722  | Training Loss: 0.31117 \nEpoch: 2722  | Training Loss: 0.36438 \nEpoch: 2722  | Training Loss: 0.33672 \nEpoch: 2722  | Training Loss: 0.21849 \nEpoch: 2722  | Training Loss: 0.16782 \nEpoch: 2722  | Validation balanced accuracy : 0.76304 \nEpoch: 2723  | Training Loss: 0.31164 \nEpoch: 2723  | Training Loss: 0.36477 \nEpoch: 2723  | Training Loss: 0.33658 \nEpoch: 2723  | Training Loss: 0.21850 \nEpoch: 2723  | Training Loss: 0.16750 \nEpoch: 2723  | Validation balanced accuracy : 0.76304 \nEpoch: 2724  | Training Loss: 0.31174 \nEpoch: 2724  | Training Loss: 0.36478 \nEpoch: 2724  | Training Loss: 0.33663 \nEpoch: 2724  | Training Loss: 0.21847 \nEpoch: 2724  | Training Loss: 0.16773 \nEpoch: 2724  | Validation balanced accuracy : 0.76304 \nEpoch: 2725  | Training Loss: 0.31151 \nEpoch: 2725  | Training Loss: 0.36457 \nEpoch: 2725  | Training Loss: 0.33677 \nEpoch: 2725  | Training Loss: 0.21841 \nEpoch: 2725  | Training Loss: 0.16817 \nEpoch: 2725  | Validation balanced accuracy : 0.76304 \nEpoch: 2726  | Training Loss: 0.31118 \nEpoch: 2726  | Training Loss: 0.36439 \nEpoch: 2726  | Training Loss: 0.33680 \nEpoch: 2726  | Training Loss: 0.21841 \nEpoch: 2726  | Training Loss: 0.16764 \nEpoch: 2726  | Validation balanced accuracy : 0.76304 \nEpoch: 2727  | Training Loss: 0.31165 \nEpoch: 2727  | Training Loss: 0.36478 \nEpoch: 2727  | Training Loss: 0.33667 \nEpoch: 2727  | Training Loss: 0.21842 \nEpoch: 2727  | Training Loss: 0.16733 \nEpoch: 2727  | Validation balanced accuracy : 0.76304 \nEpoch: 2728  | Training Loss: 0.31175 \nEpoch: 2728  | Training Loss: 0.36479 \nEpoch: 2728  | Training Loss: 0.33672 \nEpoch: 2728  | Training Loss: 0.21839 \nEpoch: 2728  | Training Loss: 0.16754 \nEpoch: 2728  | Validation balanced accuracy : 0.76304 \nEpoch: 2729  | Training Loss: 0.31153 \nEpoch: 2729  | Training Loss: 0.36458 \nEpoch: 2729  | Training Loss: 0.33686 \nEpoch: 2729  | Training Loss: 0.21834 \nEpoch: 2729  | Training Loss: 0.16798 \nEpoch: 2729  | Validation balanced accuracy : 0.76304 \nEpoch: 2730  | Training Loss: 0.31121 \nEpoch: 2730  | Training Loss: 0.36441 \nEpoch: 2730  | Training Loss: 0.33689 \nEpoch: 2730  | Training Loss: 0.21833 \nEpoch: 2730  | Training Loss: 0.16746 \nEpoch: 2730  | Validation balanced accuracy : 0.76304 \nEpoch: 2731  | Training Loss: 0.31167 \nEpoch: 2731  | Training Loss: 0.36479 \nEpoch: 2731  | Training Loss: 0.33676 \nEpoch: 2731  | Training Loss: 0.21835 \nEpoch: 2731  | Training Loss: 0.16714 \nEpoch: 2731  | Validation balanced accuracy : 0.76304 \nEpoch: 2732  | Training Loss: 0.31177 \nEpoch: 2732  | Training Loss: 0.36481 \nEpoch: 2732  | Training Loss: 0.33680 \nEpoch: 2732  | Training Loss: 0.21831 \nEpoch: 2732  | Training Loss: 0.16736 \nEpoch: 2732  | Validation balanced accuracy : 0.76304 \nEpoch: 2733  | Training Loss: 0.31155 \nEpoch: 2733  | Training Loss: 0.36460 \nEpoch: 2733  | Training Loss: 0.33694 \nEpoch: 2733  | Training Loss: 0.21826 \nEpoch: 2733  | Training Loss: 0.16780 \nEpoch: 2733  | Validation balanced accuracy : 0.76304 \nEpoch: 2734  | Training Loss: 0.31122 \nEpoch: 2734  | Training Loss: 0.36442 \nEpoch: 2734  | Training Loss: 0.33698 \nEpoch: 2734  | Training Loss: 0.21826 \nEpoch: 2734  | Training Loss: 0.16728 \nEpoch: 2734  | Validation balanced accuracy : 0.76304 \nEpoch: 2735  | Training Loss: 0.31169 \nEpoch: 2735  | Training Loss: 0.36480 \nEpoch: 2735  | Training Loss: 0.33684 \nEpoch: 2735  | Training Loss: 0.21827 \nEpoch: 2735  | Training Loss: 0.16696 \nEpoch: 2735  | Validation balanced accuracy : 0.76304 \nEpoch: 2736  | Training Loss: 0.31179 \nEpoch: 2736  | Training Loss: 0.36482 \nEpoch: 2736  | Training Loss: 0.33689 \nEpoch: 2736  | Training Loss: 0.21824 \nEpoch: 2736  | Training Loss: 0.16718 \nEpoch: 2736  | Validation balanced accuracy : 0.76304 \nEpoch: 2737  | Training Loss: 0.31157 \nEpoch: 2737  | Training Loss: 0.36461 \nEpoch: 2737  | Training Loss: 0.33703 \nEpoch: 2737  | Training Loss: 0.21818 \nEpoch: 2737  | Training Loss: 0.16762 \nEpoch: 2737  | Validation balanced accuracy : 0.76304 \nEpoch: 2738  | Training Loss: 0.31124 \nEpoch: 2738  | Training Loss: 0.36443 \nEpoch: 2738  | Training Loss: 0.33706 \nEpoch: 2738  | Training Loss: 0.21818 \nEpoch: 2738  | Training Loss: 0.16709 \nEpoch: 2738  | Validation balanced accuracy : 0.76304 \nEpoch: 2739  | Training Loss: 0.31171 \nEpoch: 2739  | Training Loss: 0.36482 \nEpoch: 2739  | Training Loss: 0.33693 \nEpoch: 2739  | Training Loss: 0.21820 \nEpoch: 2739  | Training Loss: 0.16678 \nEpoch: 2739  | Validation balanced accuracy : 0.76304 \nEpoch: 2740  | Training Loss: 0.31181 \nEpoch: 2740  | Training Loss: 0.36483 \nEpoch: 2740  | Training Loss: 0.33698 \nEpoch: 2740  | Training Loss: 0.21816 \nEpoch: 2740  | Training Loss: 0.16700 \nEpoch: 2740  | Validation balanced accuracy : 0.76304 \nEpoch: 2741  | Training Loss: 0.31159 \nEpoch: 2741  | Training Loss: 0.36462 \nEpoch: 2741  | Training Loss: 0.33712 \nEpoch: 2741  | Training Loss: 0.21811 \nEpoch: 2741  | Training Loss: 0.16744 \nEpoch: 2741  | Validation balanced accuracy : 0.76304 \nEpoch: 2742  | Training Loss: 0.31127 \nEpoch: 2742  | Training Loss: 0.36445 \nEpoch: 2742  | Training Loss: 0.33715 \nEpoch: 2742  | Training Loss: 0.21811 \nEpoch: 2742  | Training Loss: 0.16691 \nEpoch: 2742  | Validation balanced accuracy : 0.76304 \nEpoch: 2743  | Training Loss: 0.31173 \nEpoch: 2743  | Training Loss: 0.36483 \nEpoch: 2743  | Training Loss: 0.33702 \nEpoch: 2743  | Training Loss: 0.21812 \nEpoch: 2743  | Training Loss: 0.16660 \nEpoch: 2743  | Validation balanced accuracy : 0.76304 \nEpoch: 2744  | Training Loss: 0.31183 \nEpoch: 2744  | Training Loss: 0.36484 \nEpoch: 2744  | Training Loss: 0.33707 \nEpoch: 2744  | Training Loss: 0.21809 \nEpoch: 2744  | Training Loss: 0.16682 \nEpoch: 2744  | Validation balanced accuracy : 0.76304 \nEpoch: 2745  | Training Loss: 0.31161 \nEpoch: 2745  | Training Loss: 0.36464 \nEpoch: 2745  | Training Loss: 0.33721 \nEpoch: 2745  | Training Loss: 0.21804 \nEpoch: 2745  | Training Loss: 0.16726 \nEpoch: 2745  | Validation balanced accuracy : 0.76304 \nEpoch: 2746  | Training Loss: 0.31129 \nEpoch: 2746  | Training Loss: 0.36446 \nEpoch: 2746  | Training Loss: 0.33724 \nEpoch: 2746  | Training Loss: 0.21804 \nEpoch: 2746  | Training Loss: 0.16673 \nEpoch: 2746  | Validation balanced accuracy : 0.76304 \nEpoch: 2747  | Training Loss: 0.31175 \nEpoch: 2747  | Training Loss: 0.36484 \nEpoch: 2747  | Training Loss: 0.33711 \nEpoch: 2747  | Training Loss: 0.21805 \nEpoch: 2747  | Training Loss: 0.16642 \nEpoch: 2747  | Validation balanced accuracy : 0.76304 \nEpoch: 2748  | Training Loss: 0.31185 \nEpoch: 2748  | Training Loss: 0.36486 \nEpoch: 2748  | Training Loss: 0.33716 \nEpoch: 2748  | Training Loss: 0.21802 \nEpoch: 2748  | Training Loss: 0.16664 \nEpoch: 2748  | Validation balanced accuracy : 0.76304 \nEpoch: 2749  | Training Loss: 0.31163 \nEpoch: 2749  | Training Loss: 0.36465 \nEpoch: 2749  | Training Loss: 0.33730 \nEpoch: 2749  | Training Loss: 0.21796 \nEpoch: 2749  | Training Loss: 0.16708 \nEpoch: 2749  | Validation balanced accuracy : 0.76304 \nEpoch: 2750  | Training Loss: 0.31131 \nEpoch: 2750  | Training Loss: 0.36447 \nEpoch: 2750  | Training Loss: 0.33733 \nEpoch: 2750  | Training Loss: 0.21796 \nEpoch: 2750  | Training Loss: 0.16656 \nEpoch: 2750  | Validation balanced accuracy : 0.76304 \nEpoch: 2751  | Training Loss: 0.31177 \nEpoch: 2751  | Training Loss: 0.36485 \nEpoch: 2751  | Training Loss: 0.33720 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2751  | Training Loss: 0.21798 \nEpoch: 2751  | Training Loss: 0.16624 \nEpoch: 2751  | Validation balanced accuracy : 0.76304 \nEpoch: 2752  | Training Loss: 0.31187 \nEpoch: 2752  | Training Loss: 0.36487 \nEpoch: 2752  | Training Loss: 0.33725 \nEpoch: 2752  | Training Loss: 0.21794 \nEpoch: 2752  | Training Loss: 0.16646 \nEpoch: 2752  | Validation balanced accuracy : 0.76304 \nEpoch: 2753  | Training Loss: 0.31165 \nEpoch: 2753  | Training Loss: 0.36466 \nEpoch: 2753  | Training Loss: 0.33739 \nEpoch: 2753  | Training Loss: 0.21789 \nEpoch: 2753  | Training Loss: 0.16690 \nEpoch: 2753  | Validation balanced accuracy : 0.76304 \nEpoch: 2754  | Training Loss: 0.31133 \nEpoch: 2754  | Training Loss: 0.36448 \nEpoch: 2754  | Training Loss: 0.33743 \nEpoch: 2754  | Training Loss: 0.21789 \nEpoch: 2754  | Training Loss: 0.16638 \nEpoch: 2754  | Validation balanced accuracy : 0.76304 \nEpoch: 2755  | Training Loss: 0.31179 \nEpoch: 2755  | Training Loss: 0.36486 \nEpoch: 2755  | Training Loss: 0.33729 \nEpoch: 2755  | Training Loss: 0.21790 \nEpoch: 2755  | Training Loss: 0.16607 \nEpoch: 2755  | Validation balanced accuracy : 0.76304 \nEpoch: 2756  | Training Loss: 0.31189 \nEpoch: 2756  | Training Loss: 0.36487 \nEpoch: 2756  | Training Loss: 0.33734 \nEpoch: 2756  | Training Loss: 0.21787 \nEpoch: 2756  | Training Loss: 0.16628 \nEpoch: 2756  | Validation balanced accuracy : 0.76304 \nEpoch: 2757  | Training Loss: 0.31167 \nEpoch: 2757  | Training Loss: 0.36466 \nEpoch: 2757  | Training Loss: 0.33749 \nEpoch: 2757  | Training Loss: 0.21782 \nEpoch: 2757  | Training Loss: 0.16672 \nEpoch: 2757  | Validation balanced accuracy : 0.76304 \nEpoch: 2758  | Training Loss: 0.31135 \nEpoch: 2758  | Training Loss: 0.36450 \nEpoch: 2758  | Training Loss: 0.33752 \nEpoch: 2758  | Training Loss: 0.21782 \nEpoch: 2758  | Training Loss: 0.16620 \nEpoch: 2758  | Validation balanced accuracy : 0.76304 \nEpoch: 2759  | Training Loss: 0.31181 \nEpoch: 2759  | Training Loss: 0.36487 \nEpoch: 2759  | Training Loss: 0.33739 \nEpoch: 2759  | Training Loss: 0.21783 \nEpoch: 2759  | Training Loss: 0.16589 \nEpoch: 2759  | Validation balanced accuracy : 0.76304 \nEpoch: 2760  | Training Loss: 0.31191 \nEpoch: 2760  | Training Loss: 0.36488 \nEpoch: 2760  | Training Loss: 0.33744 \nEpoch: 2760  | Training Loss: 0.21780 \nEpoch: 2760  | Training Loss: 0.16611 \nEpoch: 2760  | Validation balanced accuracy : 0.76304 \nEpoch: 2761  | Training Loss: 0.31169 \nEpoch: 2761  | Training Loss: 0.36467 \nEpoch: 2761  | Training Loss: 0.33758 \nEpoch: 2761  | Training Loss: 0.21775 \nEpoch: 2761  | Training Loss: 0.16655 \nEpoch: 2761  | Validation balanced accuracy : 0.76304 \nEpoch: 2762  | Training Loss: 0.31138 \nEpoch: 2762  | Training Loss: 0.36451 \nEpoch: 2762  | Training Loss: 0.33761 \nEpoch: 2762  | Training Loss: 0.21775 \nEpoch: 2762  | Training Loss: 0.16603 \nEpoch: 2762  | Validation balanced accuracy : 0.76304 \nEpoch: 2763  | Training Loss: 0.31183 \nEpoch: 2763  | Training Loss: 0.36487 \nEpoch: 2763  | Training Loss: 0.33748 \nEpoch: 2763  | Training Loss: 0.21776 \nEpoch: 2763  | Training Loss: 0.16572 \nEpoch: 2763  | Validation balanced accuracy : 0.76304 \nEpoch: 2764  | Training Loss: 0.31193 \nEpoch: 2764  | Training Loss: 0.36489 \nEpoch: 2764  | Training Loss: 0.33753 \nEpoch: 2764  | Training Loss: 0.21773 \nEpoch: 2764  | Training Loss: 0.16593 \nEpoch: 2764  | Validation balanced accuracy : 0.76304 \nEpoch: 2765  | Training Loss: 0.31171 \nEpoch: 2765  | Training Loss: 0.36468 \nEpoch: 2765  | Training Loss: 0.33763 \nEpoch: 2765  | Training Loss: 0.21770 \nEpoch: 2765  | Training Loss: 0.16596 \nEpoch: 2765  | Validation balanced accuracy : 0.76304 \nEpoch: 2766  | Training Loss: 0.31173 \nEpoch: 2766  | Training Loss: 0.36473 \nEpoch: 2766  | Training Loss: 0.33765 \nEpoch: 2766  | Training Loss: 0.21768 \nEpoch: 2766  | Training Loss: 0.16605 \nEpoch: 2766  | Validation balanced accuracy : 0.76304 \nEpoch: 2767  | Training Loss: 0.31161 \nEpoch: 2767  | Training Loss: 0.36469 \nEpoch: 2767  | Training Loss: 0.33763 \nEpoch: 2767  | Training Loss: 0.21769 \nEpoch: 2767  | Training Loss: 0.16543 \nEpoch: 2767  | Validation balanced accuracy : 0.76304 \nEpoch: 2768  | Training Loss: 0.31212 \nEpoch: 2768  | Training Loss: 0.36509 \nEpoch: 2768  | Training Loss: 0.33750 \nEpoch: 2768  | Training Loss: 0.21770 \nEpoch: 2768  | Training Loss: 0.16519 \nEpoch: 2768  | Validation balanced accuracy : 0.76304 \nEpoch: 2769  | Training Loss: 0.31215 \nEpoch: 2769  | Training Loss: 0.36504 \nEpoch: 2769  | Training Loss: 0.33758 \nEpoch: 2769  | Training Loss: 0.21766 \nEpoch: 2769  | Training Loss: 0.16557 \nEpoch: 2769  | Validation balanced accuracy : 0.76304 \nEpoch: 2770  | Training Loss: 0.31182 \nEpoch: 2770  | Training Loss: 0.36474 \nEpoch: 2770  | Training Loss: 0.33773 \nEpoch: 2770  | Training Loss: 0.21762 \nEpoch: 2770  | Training Loss: 0.16575 \nEpoch: 2770  | Validation balanced accuracy : 0.76304 \nEpoch: 2771  | Training Loss: 0.31174 \nEpoch: 2771  | Training Loss: 0.36473 \nEpoch: 2771  | Training Loss: 0.33773 \nEpoch: 2771  | Training Loss: 0.21761 \nEpoch: 2771  | Training Loss: 0.16552 \nEpoch: 2771  | Validation balanced accuracy : 0.76304 \nEpoch: 2772  | Training Loss: 0.31191 \nEpoch: 2772  | Training Loss: 0.36489 \nEpoch: 2772  | Training Loss: 0.33771 \nEpoch: 2772  | Training Loss: 0.21760 \nEpoch: 2772  | Training Loss: 0.16552 \nEpoch: 2772  | Validation balanced accuracy : 0.76304 \nEpoch: 2773  | Training Loss: 0.31182 \nEpoch: 2773  | Training Loss: 0.36478 \nEpoch: 2773  | Training Loss: 0.33781 \nEpoch: 2773  | Training Loss: 0.21756 \nEpoch: 2773  | Training Loss: 0.16585 \nEpoch: 2773  | Validation balanced accuracy : 0.76304 \nEpoch: 2774  | Training Loss: 0.31156 \nEpoch: 2774  | Training Loss: 0.36464 \nEpoch: 2774  | Training Loss: 0.33783 \nEpoch: 2774  | Training Loss: 0.21756 \nEpoch: 2774  | Training Loss: 0.16534 \nEpoch: 2774  | Validation balanced accuracy : 0.76304 \nEpoch: 2775  | Training Loss: 0.31200 \nEpoch: 2775  | Training Loss: 0.36499 \nEpoch: 2775  | Training Loss: 0.33771 \nEpoch: 2775  | Training Loss: 0.21757 \nEpoch: 2775  | Training Loss: 0.16510 \nEpoch: 2775  | Validation balanced accuracy : 0.76304 \nEpoch: 2776  | Training Loss: 0.31206 \nEpoch: 2776  | Training Loss: 0.36496 \nEpoch: 2776  | Training Loss: 0.33778 \nEpoch: 2776  | Training Loss: 0.21753 \nEpoch: 2776  | Training Loss: 0.16539 \nEpoch: 2776  | Validation balanced accuracy : 0.76304 \nEpoch: 2777  | Training Loss: 0.31178 \nEpoch: 2777  | Training Loss: 0.36480 \nEpoch: 2777  | Training Loss: 0.33782 \nEpoch: 2777  | Training Loss: 0.21753 \nEpoch: 2777  | Training Loss: 0.16498 \nEpoch: 2777  | Validation balanced accuracy : 0.76304 \nEpoch: 2778  | Training Loss: 0.31216 \nEpoch: 2778  | Training Loss: 0.36510 \nEpoch: 2778  | Training Loss: 0.33774 \nEpoch: 2778  | Training Loss: 0.21753 \nEpoch: 2778  | Training Loss: 0.16488 \nEpoch: 2778  | Validation balanced accuracy : 0.76304 \nEpoch: 2779  | Training Loss: 0.31212 \nEpoch: 2779  | Training Loss: 0.36500 \nEpoch: 2779  | Training Loss: 0.33784 \nEpoch: 2779  | Training Loss: 0.21748 \nEpoch: 2779  | Training Loss: 0.16529 \nEpoch: 2779  | Validation balanced accuracy : 0.76304 \nEpoch: 2780  | Training Loss: 0.31177 \nEpoch: 2780  | Training Loss: 0.36478 \nEpoch: 2780  | Training Loss: 0.33790 \nEpoch: 2780  | Training Loss: 0.21747 \nEpoch: 2780  | Training Loss: 0.16494 \nEpoch: 2780  | Validation balanced accuracy : 0.76304 \nEpoch: 2781  | Training Loss: 0.31212 \nEpoch: 2781  | Training Loss: 0.36506 \nEpoch: 2781  | Training Loss: 0.33782 \nEpoch: 2781  | Training Loss: 0.21747 \nEpoch: 2781  | Training Loss: 0.16484 \nEpoch: 2781  | Validation balanced accuracy : 0.76304 \nEpoch: 2782  | Training Loss: 0.31207 \nEpoch: 2782  | Training Loss: 0.36497 \nEpoch: 2782  | Training Loss: 0.33792 \nEpoch: 2782  | Training Loss: 0.21743 \nEpoch: 2782  | Training Loss: 0.16523 \nEpoch: 2782  | Validation balanced accuracy : 0.76304 \nEpoch: 2783  | Training Loss: 0.31176 \nEpoch: 2783  | Training Loss: 0.36478 \nEpoch: 2783  | Training Loss: 0.33797 \nEpoch: 2783  | Training Loss: 0.21742 \nEpoch: 2783  | Training Loss: 0.16484 \nEpoch: 2783  | Validation balanced accuracy : 0.76304 \nEpoch: 2784  | Training Loss: 0.31212 \nEpoch: 2784  | Training Loss: 0.36507 \nEpoch: 2784  | Training Loss: 0.33789 \nEpoch: 2784  | Training Loss: 0.21742 \nEpoch: 2784  | Training Loss: 0.16471 \nEpoch: 2784  | Validation balanced accuracy : 0.76304 \nEpoch: 2785  | Training Loss: 0.31210 \nEpoch: 2785  | Training Loss: 0.36499 \nEpoch: 2785  | Training Loss: 0.33798 \nEpoch: 2785  | Training Loss: 0.21738 \nEpoch: 2785  | Training Loss: 0.16508 \nEpoch: 2785  | Validation balanced accuracy : 0.76304 \nEpoch: 2786  | Training Loss: 0.31179 \nEpoch: 2786  | Training Loss: 0.36480 \nEpoch: 2786  | Training Loss: 0.33803 \nEpoch: 2786  | Training Loss: 0.21737 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2786  | Training Loss: 0.16469 \nEpoch: 2786  | Validation balanced accuracy : 0.76304 \nEpoch: 2787  | Training Loss: 0.31216 \nEpoch: 2787  | Training Loss: 0.36509 \nEpoch: 2787  | Training Loss: 0.33795 \nEpoch: 2787  | Training Loss: 0.21737 \nEpoch: 2787  | Training Loss: 0.16457 \nEpoch: 2787  | Validation balanced accuracy : 0.76304 \nEpoch: 2788  | Training Loss: 0.31213 \nEpoch: 2788  | Training Loss: 0.36500 \nEpoch: 2788  | Training Loss: 0.33804 \nEpoch: 2788  | Training Loss: 0.21733 \nEpoch: 2788  | Training Loss: 0.16495 \nEpoch: 2788  | Validation balanced accuracy : 0.76304 \nEpoch: 2789  | Training Loss: 0.31181 \nEpoch: 2789  | Training Loss: 0.36481 \nEpoch: 2789  | Training Loss: 0.33809 \nEpoch: 2789  | Training Loss: 0.21732 \nEpoch: 2789  | Training Loss: 0.16457 \nEpoch: 2789  | Validation balanced accuracy : 0.76304 \nEpoch: 2790  | Training Loss: 0.31217 \nEpoch: 2790  | Training Loss: 0.36510 \nEpoch: 2790  | Training Loss: 0.33801 \nEpoch: 2790  | Training Loss: 0.21732 \nEpoch: 2790  | Training Loss: 0.16446 \nEpoch: 2790  | Validation balanced accuracy : 0.76304 \nEpoch: 2791  | Training Loss: 0.31214 \nEpoch: 2791  | Training Loss: 0.36501 \nEpoch: 2791  | Training Loss: 0.33811 \nEpoch: 2791  | Training Loss: 0.21728 \nEpoch: 2791  | Training Loss: 0.16484 \nEpoch: 2791  | Validation balanced accuracy : 0.76304 \nEpoch: 2792  | Training Loss: 0.31182 \nEpoch: 2792  | Training Loss: 0.36482 \nEpoch: 2792  | Training Loss: 0.33816 \nEpoch: 2792  | Training Loss: 0.21727 \nEpoch: 2792  | Training Loss: 0.16445 \nEpoch: 2792  | Validation balanced accuracy : 0.76304 \nEpoch: 2793  | Training Loss: 0.31218 \nEpoch: 2793  | Training Loss: 0.36511 \nEpoch: 2793  | Training Loss: 0.33808 \nEpoch: 2793  | Training Loss: 0.21727 \nEpoch: 2793  | Training Loss: 0.16434 \nEpoch: 2793  | Validation balanced accuracy : 0.76304 \nEpoch: 2794  | Training Loss: 0.31215 \nEpoch: 2794  | Training Loss: 0.36502 \nEpoch: 2794  | Training Loss: 0.33817 \nEpoch: 2794  | Training Loss: 0.21723 \nEpoch: 2794  | Training Loss: 0.16471 \nEpoch: 2794  | Validation balanced accuracy : 0.76304 \nEpoch: 2795  | Training Loss: 0.31184 \nEpoch: 2795  | Training Loss: 0.36483 \nEpoch: 2795  | Training Loss: 0.33822 \nEpoch: 2795  | Training Loss: 0.21723 \nEpoch: 2795  | Training Loss: 0.16433 \nEpoch: 2795  | Validation balanced accuracy : 0.76304 \nEpoch: 2796  | Training Loss: 0.31220 \nEpoch: 2796  | Training Loss: 0.36512 \nEpoch: 2796  | Training Loss: 0.33814 \nEpoch: 2796  | Training Loss: 0.21723 \nEpoch: 2796  | Training Loss: 0.16421 \nEpoch: 2796  | Validation balanced accuracy : 0.76304 \nEpoch: 2797  | Training Loss: 0.31217 \nEpoch: 2797  | Training Loss: 0.36503 \nEpoch: 2797  | Training Loss: 0.33824 \nEpoch: 2797  | Training Loss: 0.21718 \nEpoch: 2797  | Training Loss: 0.16460 \nEpoch: 2797  | Validation balanced accuracy : 0.76304 \nEpoch: 2798  | Training Loss: 0.31185 \nEpoch: 2798  | Training Loss: 0.36484 \nEpoch: 2798  | Training Loss: 0.33829 \nEpoch: 2798  | Training Loss: 0.21718 \nEpoch: 2798  | Training Loss: 0.16421 \nEpoch: 2798  | Validation balanced accuracy : 0.76304 \nEpoch: 2799  | Training Loss: 0.31221 \nEpoch: 2799  | Training Loss: 0.36512 \nEpoch: 2799  | Training Loss: 0.33821 \nEpoch: 2799  | Training Loss: 0.21718 \nEpoch: 2799  | Training Loss: 0.16410 \nEpoch: 2799  | Validation balanced accuracy : 0.76304 \nEpoch: 2800  | Training Loss: 0.31218 \nEpoch: 2800  | Training Loss: 0.36504 \nEpoch: 2800  | Training Loss: 0.33830 \nEpoch: 2800  | Training Loss: 0.21714 \nEpoch: 2800  | Training Loss: 0.16448 \nEpoch: 2800  | Validation balanced accuracy : 0.76304 \nEpoch: 2801  | Training Loss: 0.31187 \nEpoch: 2801  | Training Loss: 0.36485 \nEpoch: 2801  | Training Loss: 0.33836 \nEpoch: 2801  | Training Loss: 0.21713 \nEpoch: 2801  | Training Loss: 0.16410 \nEpoch: 2801  | Validation balanced accuracy : 0.76304 \nEpoch: 2802  | Training Loss: 0.31223 \nEpoch: 2802  | Training Loss: 0.36513 \nEpoch: 2802  | Training Loss: 0.33827 \nEpoch: 2802  | Training Loss: 0.21713 \nEpoch: 2802  | Training Loss: 0.16398 \nEpoch: 2802  | Validation balanced accuracy : 0.76304 \nEpoch: 2803  | Training Loss: 0.31220 \nEpoch: 2803  | Training Loss: 0.36505 \nEpoch: 2803  | Training Loss: 0.33837 \nEpoch: 2803  | Training Loss: 0.21709 \nEpoch: 2803  | Training Loss: 0.16436 \nEpoch: 2803  | Validation balanced accuracy : 0.76304 \nEpoch: 2804  | Training Loss: 0.31189 \nEpoch: 2804  | Training Loss: 0.36486 \nEpoch: 2804  | Training Loss: 0.33842 \nEpoch: 2804  | Training Loss: 0.21709 \nEpoch: 2804  | Training Loss: 0.16398 \nEpoch: 2804  | Validation balanced accuracy : 0.76304 \nEpoch: 2805  | Training Loss: 0.31224 \nEpoch: 2805  | Training Loss: 0.36514 \nEpoch: 2805  | Training Loss: 0.33834 \nEpoch: 2805  | Training Loss: 0.21709 \nEpoch: 2805  | Training Loss: 0.16386 \nEpoch: 2805  | Validation balanced accuracy : 0.76304 \nEpoch: 2806  | Training Loss: 0.31221 \nEpoch: 2806  | Training Loss: 0.36506 \nEpoch: 2806  | Training Loss: 0.33844 \nEpoch: 2806  | Training Loss: 0.21704 \nEpoch: 2806  | Training Loss: 0.16424 \nEpoch: 2806  | Validation balanced accuracy : 0.76304 \nEpoch: 2807  | Training Loss: 0.31191 \nEpoch: 2807  | Training Loss: 0.36487 \nEpoch: 2807  | Training Loss: 0.33849 \nEpoch: 2807  | Training Loss: 0.21704 \nEpoch: 2807  | Training Loss: 0.16386 \nEpoch: 2807  | Validation balanced accuracy : 0.76304 \nEpoch: 2808  | Training Loss: 0.31226 \nEpoch: 2808  | Training Loss: 0.36515 \nEpoch: 2808  | Training Loss: 0.33840 \nEpoch: 2808  | Training Loss: 0.21704 \nEpoch: 2808  | Training Loss: 0.16374 \nEpoch: 2808  | Validation balanced accuracy : 0.76304 \nEpoch: 2809  | Training Loss: 0.31223 \nEpoch: 2809  | Training Loss: 0.36506 \nEpoch: 2809  | Training Loss: 0.33850 \nEpoch: 2809  | Training Loss: 0.21700 \nEpoch: 2809  | Training Loss: 0.16412 \nEpoch: 2809  | Validation balanced accuracy : 0.76304 \nEpoch: 2810  | Training Loss: 0.31192 \nEpoch: 2810  | Training Loss: 0.36488 \nEpoch: 2810  | Training Loss: 0.33855 \nEpoch: 2810  | Training Loss: 0.21699 \nEpoch: 2810  | Training Loss: 0.16374 \nEpoch: 2810  | Validation balanced accuracy : 0.76304 \nEpoch: 2811  | Training Loss: 0.31228 \nEpoch: 2811  | Training Loss: 0.36516 \nEpoch: 2811  | Training Loss: 0.33847 \nEpoch: 2811  | Training Loss: 0.21699 \nEpoch: 2811  | Training Loss: 0.16362 \nEpoch: 2811  | Validation balanced accuracy : 0.76304 \nEpoch: 2812  | Training Loss: 0.31225 \nEpoch: 2812  | Training Loss: 0.36507 \nEpoch: 2812  | Training Loss: 0.33857 \nEpoch: 2812  | Training Loss: 0.21695 \nEpoch: 2812  | Training Loss: 0.16400 \nEpoch: 2812  | Validation balanced accuracy : 0.76304 \nEpoch: 2813  | Training Loss: 0.31194 \nEpoch: 2813  | Training Loss: 0.36489 \nEpoch: 2813  | Training Loss: 0.33862 \nEpoch: 2813  | Training Loss: 0.21695 \nEpoch: 2813  | Training Loss: 0.16362 \nEpoch: 2813  | Validation balanced accuracy : 0.76304 \nEpoch: 2814  | Training Loss: 0.31229 \nEpoch: 2814  | Training Loss: 0.36517 \nEpoch: 2814  | Training Loss: 0.33854 \nEpoch: 2814  | Training Loss: 0.21695 \nEpoch: 2814  | Training Loss: 0.16351 \nEpoch: 2814  | Validation balanced accuracy : 0.76304 \nEpoch: 2815  | Training Loss: 0.31226 \nEpoch: 2815  | Training Loss: 0.36508 \nEpoch: 2815  | Training Loss: 0.33859 \nEpoch: 2815  | Training Loss: 0.21693 \nEpoch: 2815  | Training Loss: 0.16348 \nEpoch: 2815  | Validation balanced accuracy : 0.76304 \nEpoch: 2816  | Training Loss: 0.31228 \nEpoch: 2816  | Training Loss: 0.36512 \nEpoch: 2816  | Training Loss: 0.33863 \nEpoch: 2816  | Training Loss: 0.21690 \nEpoch: 2816  | Training Loss: 0.16370 \nEpoch: 2816  | Validation balanced accuracy : 0.76304 \nEpoch: 2817  | Training Loss: 0.31207 \nEpoch: 2817  | Training Loss: 0.36499 \nEpoch: 2817  | Training Loss: 0.33866 \nEpoch: 2817  | Training Loss: 0.21690 \nEpoch: 2817  | Training Loss: 0.16328 \nEpoch: 2817  | Validation balanced accuracy : 0.76304 \nEpoch: 2818  | Training Loss: 0.31244 \nEpoch: 2818  | Training Loss: 0.36528 \nEpoch: 2818  | Training Loss: 0.33858 \nEpoch: 2818  | Training Loss: 0.21690 \nEpoch: 2818  | Training Loss: 0.16321 \nEpoch: 2818  | Validation balanced accuracy : 0.76304 \nEpoch: 2819  | Training Loss: 0.31237 \nEpoch: 2819  | Training Loss: 0.36515 \nEpoch: 2819  | Training Loss: 0.33869 \nEpoch: 2819  | Training Loss: 0.21685 \nEpoch: 2819  | Training Loss: 0.16367 \nEpoch: 2819  | Validation balanced accuracy : 0.76304 \nEpoch: 2820  | Training Loss: 0.31201 \nEpoch: 2820  | Training Loss: 0.36493 \nEpoch: 2820  | Training Loss: 0.33877 \nEpoch: 2820  | Training Loss: 0.21684 \nEpoch: 2820  | Training Loss: 0.16336 \nEpoch: 2820  | Validation balanced accuracy : 0.76304 \nEpoch: 2821  | Training Loss: 0.31232 \nEpoch: 2821  | Training Loss: 0.36517 \nEpoch: 2821  | Training Loss: 0.33870 \nEpoch: 2821  | Training Loss: 0.21684 \nEpoch: 2821  | Training Loss: 0.16328 \nEpoch: 2821  | Validation balanced accuracy : 0.76304 \nEpoch: 2822  | Training Loss: 0.31226 \nEpoch: 2822  | Training Loss: 0.36516 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2822  | Training Loss: 0.33872 \nEpoch: 2822  | Training Loss: 0.21683 \nEpoch: 2822  | Training Loss: 0.16317 \nEpoch: 2822  | Validation balanced accuracy : 0.76304 \nEpoch: 2823  | Training Loss: 0.31234 \nEpoch: 2823  | Training Loss: 0.36515 \nEpoch: 2823  | Training Loss: 0.33874 \nEpoch: 2823  | Training Loss: 0.21682 \nEpoch: 2823  | Training Loss: 0.16306 \nEpoch: 2823  | Validation balanced accuracy : 0.76304 \nEpoch: 2824  | Training Loss: 0.31241 \nEpoch: 2824  | Training Loss: 0.36521 \nEpoch: 2824  | Training Loss: 0.33876 \nEpoch: 2824  | Training Loss: 0.21679 \nEpoch: 2824  | Training Loss: 0.16327 \nEpoch: 2824  | Validation balanced accuracy : 0.76304 \nEpoch: 2825  | Training Loss: 0.31219 \nEpoch: 2825  | Training Loss: 0.36508 \nEpoch: 2825  | Training Loss: 0.33879 \nEpoch: 2825  | Training Loss: 0.21679 \nEpoch: 2825  | Training Loss: 0.16289 \nEpoch: 2825  | Validation balanced accuracy : 0.76304 \nEpoch: 2826  | Training Loss: 0.31253 \nEpoch: 2826  | Training Loss: 0.36534 \nEpoch: 2826  | Training Loss: 0.33873 \nEpoch: 2826  | Training Loss: 0.21679 \nEpoch: 2826  | Training Loss: 0.16288 \nEpoch: 2826  | Validation balanced accuracy : 0.76304 \nEpoch: 2827  | Training Loss: 0.31243 \nEpoch: 2827  | Training Loss: 0.36519 \nEpoch: 2827  | Training Loss: 0.33886 \nEpoch: 2827  | Training Loss: 0.21674 \nEpoch: 2827  | Training Loss: 0.16338 \nEpoch: 2827  | Validation balanced accuracy : 0.76304 \nEpoch: 2828  | Training Loss: 0.31205 \nEpoch: 2828  | Training Loss: 0.36495 \nEpoch: 2828  | Training Loss: 0.33894 \nEpoch: 2828  | Training Loss: 0.21672 \nEpoch: 2828  | Training Loss: 0.16309 \nEpoch: 2828  | Validation balanced accuracy : 0.76304 \nEpoch: 2829  | Training Loss: 0.31234 \nEpoch: 2829  | Training Loss: 0.36518 \nEpoch: 2829  | Training Loss: 0.33883 \nEpoch: 2829  | Training Loss: 0.21674 \nEpoch: 2829  | Training Loss: 0.16262 \nEpoch: 2829  | Validation balanced accuracy : 0.76304 \nEpoch: 2830  | Training Loss: 0.31263 \nEpoch: 2830  | Training Loss: 0.36540 \nEpoch: 2830  | Training Loss: 0.33879 \nEpoch: 2830  | Training Loss: 0.21673 \nEpoch: 2830  | Training Loss: 0.16270 \nEpoch: 2830  | Validation balanced accuracy : 0.76304 \nEpoch: 2831  | Training Loss: 0.31246 \nEpoch: 2831  | Training Loss: 0.36520 \nEpoch: 2831  | Training Loss: 0.33890 \nEpoch: 2831  | Training Loss: 0.21670 \nEpoch: 2831  | Training Loss: 0.16286 \nEpoch: 2831  | Validation balanced accuracy : 0.76304 \nEpoch: 2832  | Training Loss: 0.31236 \nEpoch: 2832  | Training Loss: 0.36516 \nEpoch: 2832  | Training Loss: 0.33894 \nEpoch: 2832  | Training Loss: 0.21668 \nEpoch: 2832  | Training Loss: 0.16280 \nEpoch: 2832  | Validation balanced accuracy : 0.76304 \nEpoch: 2833  | Training Loss: 0.31241 \nEpoch: 2833  | Training Loss: 0.36521 \nEpoch: 2833  | Training Loss: 0.33892 \nEpoch: 2833  | Training Loss: 0.21668 \nEpoch: 2833  | Training Loss: 0.16262 \nEpoch: 2833  | Validation balanced accuracy : 0.76304 \nEpoch: 2834  | Training Loss: 0.31253 \nEpoch: 2834  | Training Loss: 0.36530 \nEpoch: 2834  | Training Loss: 0.33894 \nEpoch: 2834  | Training Loss: 0.21666 \nEpoch: 2834  | Training Loss: 0.16281 \nEpoch: 2834  | Validation balanced accuracy : 0.76304 \nEpoch: 2835  | Training Loss: 0.31231 \nEpoch: 2835  | Training Loss: 0.36517 \nEpoch: 2835  | Training Loss: 0.33897 \nEpoch: 2835  | Training Loss: 0.21665 \nEpoch: 2835  | Training Loss: 0.16246 \nEpoch: 2835  | Validation balanced accuracy : 0.76304 \nEpoch: 2836  | Training Loss: 0.31263 \nEpoch: 2836  | Training Loss: 0.36541 \nEpoch: 2836  | Training Loss: 0.33891 \nEpoch: 2836  | Training Loss: 0.21665 \nEpoch: 2836  | Training Loss: 0.16249 \nEpoch: 2836  | Validation balanced accuracy : 0.76304 \nEpoch: 2837  | Training Loss: 0.31249 \nEpoch: 2837  | Training Loss: 0.36524 \nEpoch: 2837  | Training Loss: 0.33901 \nEpoch: 2837  | Training Loss: 0.21662 \nEpoch: 2837  | Training Loss: 0.16262 \nEpoch: 2837  | Validation balanced accuracy : 0.76304 \nEpoch: 2838  | Training Loss: 0.31241 \nEpoch: 2838  | Training Loss: 0.36520 \nEpoch: 2838  | Training Loss: 0.33904 \nEpoch: 2838  | Training Loss: 0.21660 \nEpoch: 2838  | Training Loss: 0.16255 \nEpoch: 2838  | Validation balanced accuracy : 0.76304 \nEpoch: 2839  | Training Loss: 0.31246 \nEpoch: 2839  | Training Loss: 0.36525 \nEpoch: 2839  | Training Loss: 0.33907 \nEpoch: 2839  | Training Loss: 0.21658 \nEpoch: 2839  | Training Loss: 0.16277 \nEpoch: 2839  | Validation balanced accuracy : 0.76304 \nEpoch: 2840  | Training Loss: 0.31224 \nEpoch: 2840  | Training Loss: 0.36512 \nEpoch: 2840  | Training Loss: 0.33910 \nEpoch: 2840  | Training Loss: 0.21658 \nEpoch: 2840  | Training Loss: 0.16238 \nEpoch: 2840  | Validation balanced accuracy : 0.76304 \nEpoch: 2841  | Training Loss: 0.31259 \nEpoch: 2841  | Training Loss: 0.36538 \nEpoch: 2841  | Training Loss: 0.33903 \nEpoch: 2841  | Training Loss: 0.21657 \nEpoch: 2841  | Training Loss: 0.16235 \nEpoch: 2841  | Validation balanced accuracy : 0.76304 \nEpoch: 2842  | Training Loss: 0.31250 \nEpoch: 2842  | Training Loss: 0.36525 \nEpoch: 2842  | Training Loss: 0.33911 \nEpoch: 2842  | Training Loss: 0.21655 \nEpoch: 2842  | Training Loss: 0.16243 \nEpoch: 2842  | Validation balanced accuracy : 0.76304 \nEpoch: 2843  | Training Loss: 0.31245 \nEpoch: 2843  | Training Loss: 0.36523 \nEpoch: 2843  | Training Loss: 0.33913 \nEpoch: 2843  | Training Loss: 0.21654 \nEpoch: 2843  | Training Loss: 0.16233 \nEpoch: 2843  | Validation balanced accuracy : 0.76304 \nEpoch: 2844  | Training Loss: 0.31252 \nEpoch: 2844  | Training Loss: 0.36529 \nEpoch: 2844  | Training Loss: 0.33916 \nEpoch: 2844  | Training Loss: 0.21651 \nEpoch: 2844  | Training Loss: 0.16255 \nEpoch: 2844  | Validation balanced accuracy : 0.76304 \nEpoch: 2845  | Training Loss: 0.31230 \nEpoch: 2845  | Training Loss: 0.36516 \nEpoch: 2845  | Training Loss: 0.33919 \nEpoch: 2845  | Training Loss: 0.21651 \nEpoch: 2845  | Training Loss: 0.16217 \nEpoch: 2845  | Validation balanced accuracy : 0.76304 \nEpoch: 2846  | Training Loss: 0.31264 \nEpoch: 2846  | Training Loss: 0.36541 \nEpoch: 2846  | Training Loss: 0.33913 \nEpoch: 2846  | Training Loss: 0.21651 \nEpoch: 2846  | Training Loss: 0.16216 \nEpoch: 2846  | Validation balanced accuracy : 0.76304 \nEpoch: 2847  | Training Loss: 0.31253 \nEpoch: 2847  | Training Loss: 0.36527 \nEpoch: 2847  | Training Loss: 0.33921 \nEpoch: 2847  | Training Loss: 0.21648 \nEpoch: 2847  | Training Loss: 0.16226 \nEpoch: 2847  | Validation balanced accuracy : 0.76304 \nEpoch: 2848  | Training Loss: 0.31248 \nEpoch: 2848  | Training Loss: 0.36532 \nEpoch: 2848  | Training Loss: 0.33920 \nEpoch: 2848  | Training Loss: 0.21647 \nEpoch: 2848  | Training Loss: 0.16207 \nEpoch: 2848  | Validation balanced accuracy : 0.76304 \nEpoch: 2849  | Training Loss: 0.31259 \nEpoch: 2849  | Training Loss: 0.36533 \nEpoch: 2849  | Training Loss: 0.33925 \nEpoch: 2849  | Training Loss: 0.21644 \nEpoch: 2849  | Training Loss: 0.16237 \nEpoch: 2849  | Validation balanced accuracy : 0.76304 \nEpoch: 2850  | Training Loss: 0.31231 \nEpoch: 2850  | Training Loss: 0.36516 \nEpoch: 2850  | Training Loss: 0.33930 \nEpoch: 2850  | Training Loss: 0.21644 \nEpoch: 2850  | Training Loss: 0.16205 \nEpoch: 2850  | Validation balanced accuracy : 0.76304 \nEpoch: 2851  | Training Loss: 0.31262 \nEpoch: 2851  | Training Loss: 0.36540 \nEpoch: 2851  | Training Loss: 0.33925 \nEpoch: 2851  | Training Loss: 0.21643 \nEpoch: 2851  | Training Loss: 0.16205 \nEpoch: 2851  | Validation balanced accuracy : 0.76304 \nEpoch: 2852  | Training Loss: 0.31252 \nEpoch: 2852  | Training Loss: 0.36533 \nEpoch: 2852  | Training Loss: 0.33925 \nEpoch: 2852  | Training Loss: 0.21644 \nEpoch: 2852  | Training Loss: 0.16164 \nEpoch: 2852  | Validation balanced accuracy : 0.76304 \nEpoch: 2853  | Training Loss: 0.31287 \nEpoch: 2853  | Training Loss: 0.36558 \nEpoch: 2853  | Training Loss: 0.33919 \nEpoch: 2853  | Training Loss: 0.21643 \nEpoch: 2853  | Training Loss: 0.16171 \nEpoch: 2853  | Validation balanced accuracy : 0.76304 \nEpoch: 2854  | Training Loss: 0.31269 \nEpoch: 2854  | Training Loss: 0.36538 \nEpoch: 2854  | Training Loss: 0.33936 \nEpoch: 2854  | Training Loss: 0.21637 \nEpoch: 2854  | Training Loss: 0.16233 \nEpoch: 2854  | Validation balanced accuracy : 0.76304 \nEpoch: 2855  | Training Loss: 0.31223 \nEpoch: 2855  | Training Loss: 0.36508 \nEpoch: 2855  | Training Loss: 0.33947 \nEpoch: 2855  | Training Loss: 0.21635 \nEpoch: 2855  | Training Loss: 0.16215 \nEpoch: 2855  | Validation balanced accuracy : 0.76304 \nEpoch: 2856  | Training Loss: 0.31246 \nEpoch: 2856  | Training Loss: 0.36535 \nEpoch: 2856  | Training Loss: 0.33930 \nEpoch: 2856  | Training Loss: 0.21640 \nEpoch: 2856  | Training Loss: 0.16124 \nEpoch: 2856  | Validation balanced accuracy : 0.76304 \nEpoch: 2857  | Training Loss: 0.31311 \nEpoch: 2857  | Training Loss: 0.36581 \nEpoch: 2857  | Training Loss: 0.33915 \nEpoch: 2857  | Training Loss: 0.21641 \nEpoch: 2857  | Training Loss: 0.16112 \nEpoch: 2857  | Validation balanced accuracy : 0.76304 \nEpoch: 2858  | Training Loss: 0.31304 \nEpoch: 2858  | Training Loss: 0.36565 \nEpoch: 2858  | Training Loss: 0.33930 \nEpoch: 2858  | Training Loss: 0.21635 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2858  | Training Loss: 0.16179 \nEpoch: 2858  | Validation balanced accuracy : 0.76304 \nEpoch: 2859  | Training Loss: 0.31249 \nEpoch: 2859  | Training Loss: 0.36527 \nEpoch: 2859  | Training Loss: 0.33945 \nEpoch: 2859  | Training Loss: 0.21632 \nEpoch: 2859  | Training Loss: 0.16179 \nEpoch: 2859  | Validation balanced accuracy : 0.76304 \nEpoch: 2860  | Training Loss: 0.31261 \nEpoch: 2860  | Training Loss: 0.36537 \nEpoch: 2860  | Training Loss: 0.33941 \nEpoch: 2860  | Training Loss: 0.21632 \nEpoch: 2860  | Training Loss: 0.16156 \nEpoch: 2860  | Validation balanced accuracy : 0.76304 \nEpoch: 2861  | Training Loss: 0.31275 \nEpoch: 2861  | Training Loss: 0.36548 \nEpoch: 2861  | Training Loss: 0.33942 \nEpoch: 2861  | Training Loss: 0.21630 \nEpoch: 2861  | Training Loss: 0.16176 \nEpoch: 2861  | Validation balanced accuracy : 0.76304 \nEpoch: 2862  | Training Loss: 0.31251 \nEpoch: 2862  | Training Loss: 0.36533 \nEpoch: 2862  | Training Loss: 0.33946 \nEpoch: 2862  | Training Loss: 0.21629 \nEpoch: 2862  | Training Loss: 0.16145 \nEpoch: 2862  | Validation balanced accuracy : 0.76304 \nEpoch: 2863  | Training Loss: 0.31281 \nEpoch: 2863  | Training Loss: 0.36554 \nEpoch: 2863  | Training Loss: 0.33942 \nEpoch: 2863  | Training Loss: 0.21628 \nEpoch: 2863  | Training Loss: 0.16152 \nEpoch: 2863  | Validation balanced accuracy : 0.76304 \nEpoch: 2864  | Training Loss: 0.31265 \nEpoch: 2864  | Training Loss: 0.36535 \nEpoch: 2864  | Training Loss: 0.33953 \nEpoch: 2864  | Training Loss: 0.21625 \nEpoch: 2864  | Training Loss: 0.16169 \nEpoch: 2864  | Validation balanced accuracy : 0.76304 \nEpoch: 2865  | Training Loss: 0.31255 \nEpoch: 2865  | Training Loss: 0.36538 \nEpoch: 2865  | Training Loss: 0.33948 \nEpoch: 2865  | Training Loss: 0.21627 \nEpoch: 2865  | Training Loss: 0.16114 \nEpoch: 2865  | Validation balanced accuracy : 0.76304 \nEpoch: 2866  | Training Loss: 0.31299 \nEpoch: 2866  | Training Loss: 0.36570 \nEpoch: 2866  | Training Loss: 0.33940 \nEpoch: 2866  | Training Loss: 0.21627 \nEpoch: 2866  | Training Loss: 0.16115 \nEpoch: 2866  | Validation balanced accuracy : 0.76304 \nEpoch: 2867  | Training Loss: 0.31285 \nEpoch: 2867  | Training Loss: 0.36551 \nEpoch: 2867  | Training Loss: 0.33956 \nEpoch: 2867  | Training Loss: 0.21621 \nEpoch: 2867  | Training Loss: 0.16177 \nEpoch: 2867  | Validation balanced accuracy : 0.76304 \nEpoch: 2868  | Training Loss: 0.31237 \nEpoch: 2868  | Training Loss: 0.36519 \nEpoch: 2868  | Training Loss: 0.33968 \nEpoch: 2868  | Training Loss: 0.21619 \nEpoch: 2868  | Training Loss: 0.16163 \nEpoch: 2868  | Validation balanced accuracy : 0.76304 \nEpoch: 2869  | Training Loss: 0.31257 \nEpoch: 2869  | Training Loss: 0.36544 \nEpoch: 2869  | Training Loss: 0.33956 \nEpoch: 2869  | Training Loss: 0.21621 \nEpoch: 2869  | Training Loss: 0.16118 \nEpoch: 2869  | Validation balanced accuracy : 0.76304 \nEpoch: 2870  | Training Loss: 0.31285 \nEpoch: 2870  | Training Loss: 0.36556 \nEpoch: 2870  | Training Loss: 0.33957 \nEpoch: 2870  | Training Loss: 0.21619 \nEpoch: 2870  | Training Loss: 0.16138 \nEpoch: 2870  | Validation balanced accuracy : 0.76304 \nEpoch: 2871  | Training Loss: 0.31261 \nEpoch: 2871  | Training Loss: 0.36540 \nEpoch: 2871  | Training Loss: 0.33962 \nEpoch: 2871  | Training Loss: 0.21618 \nEpoch: 2871  | Training Loss: 0.16110 \nEpoch: 2871  | Validation balanced accuracy : 0.76304 \nEpoch: 2872  | Training Loss: 0.31289 \nEpoch: 2872  | Training Loss: 0.36560 \nEpoch: 2872  | Training Loss: 0.33959 \nEpoch: 2872  | Training Loss: 0.21617 \nEpoch: 2872  | Training Loss: 0.16121 \nEpoch: 2872  | Validation balanced accuracy : 0.76304 \nEpoch: 2873  | Training Loss: 0.31270 \nEpoch: 2873  | Training Loss: 0.36539 \nEpoch: 2873  | Training Loss: 0.33970 \nEpoch: 2873  | Training Loss: 0.21614 \nEpoch: 2873  | Training Loss: 0.16140 \nEpoch: 2873  | Validation balanced accuracy : 0.76304 \nEpoch: 2874  | Training Loss: 0.31259 \nEpoch: 2874  | Training Loss: 0.36541 \nEpoch: 2874  | Training Loss: 0.33966 \nEpoch: 2874  | Training Loss: 0.21615 \nEpoch: 2874  | Training Loss: 0.16086 \nEpoch: 2874  | Validation balanced accuracy : 0.76304 \nEpoch: 2875  | Training Loss: 0.31302 \nEpoch: 2875  | Training Loss: 0.36572 \nEpoch: 2875  | Training Loss: 0.33958 \nEpoch: 2875  | Training Loss: 0.21615 \nEpoch: 2875  | Training Loss: 0.16087 \nEpoch: 2875  | Validation balanced accuracy : 0.76304 \nEpoch: 2876  | Training Loss: 0.31288 \nEpoch: 2876  | Training Loss: 0.36553 \nEpoch: 2876  | Training Loss: 0.33973 \nEpoch: 2876  | Training Loss: 0.21609 \nEpoch: 2876  | Training Loss: 0.16148 \nEpoch: 2876  | Validation balanced accuracy : 0.76304 \nEpoch: 2877  | Training Loss: 0.31241 \nEpoch: 2877  | Training Loss: 0.36523 \nEpoch: 2877  | Training Loss: 0.33985 \nEpoch: 2877  | Training Loss: 0.21607 \nEpoch: 2877  | Training Loss: 0.16133 \nEpoch: 2877  | Validation balanced accuracy : 0.76304 \nEpoch: 2878  | Training Loss: 0.31262 \nEpoch: 2878  | Training Loss: 0.36547 \nEpoch: 2878  | Training Loss: 0.33969 \nEpoch: 2878  | Training Loss: 0.21612 \nEpoch: 2878  | Training Loss: 0.16048 \nEpoch: 2878  | Validation balanced accuracy : 0.76304 \nEpoch: 2879  | Training Loss: 0.31324 \nEpoch: 2879  | Training Loss: 0.36591 \nEpoch: 2879  | Training Loss: 0.33956 \nEpoch: 2879  | Training Loss: 0.21613 \nEpoch: 2879  | Training Loss: 0.16039 \nEpoch: 2879  | Validation balanced accuracy : 0.76304 \nEpoch: 2880  | Training Loss: 0.31315 \nEpoch: 2880  | Training Loss: 0.36573 \nEpoch: 2880  | Training Loss: 0.33972 \nEpoch: 2880  | Training Loss: 0.21607 \nEpoch: 2880  | Training Loss: 0.16107 \nEpoch: 2880  | Validation balanced accuracy : 0.76304 \nEpoch: 2881  | Training Loss: 0.31260 \nEpoch: 2881  | Training Loss: 0.36536 \nEpoch: 2881  | Training Loss: 0.33987 \nEpoch: 2881  | Training Loss: 0.21604 \nEpoch: 2881  | Training Loss: 0.16107 \nEpoch: 2881  | Validation balanced accuracy : 0.76304 \nEpoch: 2882  | Training Loss: 0.31271 \nEpoch: 2882  | Training Loss: 0.36545 \nEpoch: 2882  | Training Loss: 0.33983 \nEpoch: 2882  | Training Loss: 0.21604 \nEpoch: 2882  | Training Loss: 0.16084 \nEpoch: 2882  | Validation balanced accuracy : 0.76304 \nEpoch: 2883  | Training Loss: 0.31286 \nEpoch: 2883  | Training Loss: 0.36556 \nEpoch: 2883  | Training Loss: 0.33984 \nEpoch: 2883  | Training Loss: 0.21602 \nEpoch: 2883  | Training Loss: 0.16103 \nEpoch: 2883  | Validation balanced accuracy : 0.76304 \nEpoch: 2884  | Training Loss: 0.31264 \nEpoch: 2884  | Training Loss: 0.36542 \nEpoch: 2884  | Training Loss: 0.33988 \nEpoch: 2884  | Training Loss: 0.21602 \nEpoch: 2884  | Training Loss: 0.16071 \nEpoch: 2884  | Validation balanced accuracy : 0.76304 \nEpoch: 2885  | Training Loss: 0.31293 \nEpoch: 2885  | Training Loss: 0.36564 \nEpoch: 2885  | Training Loss: 0.33983 \nEpoch: 2885  | Training Loss: 0.21601 \nEpoch: 2885  | Training Loss: 0.16078 \nEpoch: 2885  | Validation balanced accuracy : 0.76304 \nEpoch: 2886  | Training Loss: 0.31277 \nEpoch: 2886  | Training Loss: 0.36545 \nEpoch: 2886  | Training Loss: 0.33994 \nEpoch: 2886  | Training Loss: 0.21598 \nEpoch: 2886  | Training Loss: 0.16095 \nEpoch: 2886  | Validation balanced accuracy : 0.76304 \nEpoch: 2887  | Training Loss: 0.31268 \nEpoch: 2887  | Training Loss: 0.36548 \nEpoch: 2887  | Training Loss: 0.33990 \nEpoch: 2887  | Training Loss: 0.21599 \nEpoch: 2887  | Training Loss: 0.16041 \nEpoch: 2887  | Validation balanced accuracy : 0.76304 \nEpoch: 2888  | Training Loss: 0.31311 \nEpoch: 2888  | Training Loss: 0.36578 \nEpoch: 2888  | Training Loss: 0.33982 \nEpoch: 2888  | Training Loss: 0.21599 \nEpoch: 2888  | Training Loss: 0.16042 \nEpoch: 2888  | Validation balanced accuracy : 0.76304 \nEpoch: 2889  | Training Loss: 0.31297 \nEpoch: 2889  | Training Loss: 0.36559 \nEpoch: 2889  | Training Loss: 0.33997 \nEpoch: 2889  | Training Loss: 0.21594 \nEpoch: 2889  | Training Loss: 0.16105 \nEpoch: 2889  | Validation balanced accuracy : 0.76304 \nEpoch: 2890  | Training Loss: 0.31249 \nEpoch: 2890  | Training Loss: 0.36528 \nEpoch: 2890  | Training Loss: 0.34010 \nEpoch: 2890  | Training Loss: 0.21591 \nEpoch: 2890  | Training Loss: 0.16091 \nEpoch: 2890  | Validation balanced accuracy : 0.76304 \nEpoch: 2891  | Training Loss: 0.31269 \nEpoch: 2891  | Training Loss: 0.36552 \nEpoch: 2891  | Training Loss: 0.33994 \nEpoch: 2891  | Training Loss: 0.21596 \nEpoch: 2891  | Training Loss: 0.16006 \nEpoch: 2891  | Validation balanced accuracy : 0.76304 \nEpoch: 2892  | Training Loss: 0.31331 \nEpoch: 2892  | Training Loss: 0.36595 \nEpoch: 2892  | Training Loss: 0.33981 \nEpoch: 2892  | Training Loss: 0.21597 \nEpoch: 2892  | Training Loss: 0.15998 \nEpoch: 2892  | Validation balanced accuracy : 0.76304 \nEpoch: 2893  | Training Loss: 0.31321 \nEpoch: 2893  | Training Loss: 0.36577 \nEpoch: 2893  | Training Loss: 0.33996 \nEpoch: 2893  | Training Loss: 0.21591 \nEpoch: 2893  | Training Loss: 0.16066 \nEpoch: 2893  | Validation balanced accuracy : 0.76304 \nEpoch: 2894  | Training Loss: 0.31267 \nEpoch: 2894  | Training Loss: 0.36541 \nEpoch: 2894  | Training Loss: 0.34012 \nEpoch: 2894  | Training Loss: 0.21588 \nEpoch: 2894  | Training Loss: 0.16065 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2894  | Validation balanced accuracy : 0.76304 \nEpoch: 2895  | Training Loss: 0.31278 \nEpoch: 2895  | Training Loss: 0.36558 \nEpoch: 2895  | Training Loss: 0.34000 \nEpoch: 2895  | Training Loss: 0.21591 \nEpoch: 2895  | Training Loss: 0.15993 \nEpoch: 2895  | Validation balanced accuracy : 0.76304 \nEpoch: 2896  | Training Loss: 0.31332 \nEpoch: 2896  | Training Loss: 0.36595 \nEpoch: 2896  | Training Loss: 0.33989 \nEpoch: 2896  | Training Loss: 0.21592 \nEpoch: 2896  | Training Loss: 0.15992 \nEpoch: 2896  | Validation balanced accuracy : 0.76304 \nEpoch: 2897  | Training Loss: 0.31318 \nEpoch: 2897  | Training Loss: 0.36575 \nEpoch: 2897  | Training Loss: 0.34006 \nEpoch: 2897  | Training Loss: 0.21586 \nEpoch: 2897  | Training Loss: 0.16062 \nEpoch: 2897  | Validation balanced accuracy : 0.76304 \nEpoch: 2898  | Training Loss: 0.31264 \nEpoch: 2898  | Training Loss: 0.36538 \nEpoch: 2898  | Training Loss: 0.34021 \nEpoch: 2898  | Training Loss: 0.21583 \nEpoch: 2898  | Training Loss: 0.16059 \nEpoch: 2898  | Validation balanced accuracy : 0.76304 \nEpoch: 2899  | Training Loss: 0.31276 \nEpoch: 2899  | Training Loss: 0.36557 \nEpoch: 2899  | Training Loss: 0.34008 \nEpoch: 2899  | Training Loss: 0.21586 \nEpoch: 2899  | Training Loss: 0.15984 \nEpoch: 2899  | Validation balanced accuracy : 0.76304 \nEpoch: 2900  | Training Loss: 0.31333 \nEpoch: 2900  | Training Loss: 0.36596 \nEpoch: 2900  | Training Loss: 0.33996 \nEpoch: 2900  | Training Loss: 0.21587 \nEpoch: 2900  | Training Loss: 0.15979 \nEpoch: 2900  | Validation balanced accuracy : 0.76304 \nEpoch: 2901  | Training Loss: 0.31321 \nEpoch: 2901  | Training Loss: 0.36577 \nEpoch: 2901  | Training Loss: 0.34012 \nEpoch: 2901  | Training Loss: 0.21581 \nEpoch: 2901  | Training Loss: 0.16047 \nEpoch: 2901  | Validation balanced accuracy : 0.76304 \nEpoch: 2902  | Training Loss: 0.31267 \nEpoch: 2902  | Training Loss: 0.36541 \nEpoch: 2902  | Training Loss: 0.34027 \nEpoch: 2902  | Training Loss: 0.21578 \nEpoch: 2902  | Training Loss: 0.16044 \nEpoch: 2902  | Validation balanced accuracy : 0.76304 \nEpoch: 2903  | Training Loss: 0.31280 \nEpoch: 2903  | Training Loss: 0.36560 \nEpoch: 2903  | Training Loss: 0.34015 \nEpoch: 2903  | Training Loss: 0.21582 \nEpoch: 2903  | Training Loss: 0.15970 \nEpoch: 2903  | Validation balanced accuracy : 0.76304 \nEpoch: 2904  | Training Loss: 0.31336 \nEpoch: 2904  | Training Loss: 0.36598 \nEpoch: 2904  | Training Loss: 0.34003 \nEpoch: 2904  | Training Loss: 0.21582 \nEpoch: 2904  | Training Loss: 0.15966 \nEpoch: 2904  | Validation balanced accuracy : 0.76304 \nEpoch: 2905  | Training Loss: 0.31323 \nEpoch: 2905  | Training Loss: 0.36579 \nEpoch: 2905  | Training Loss: 0.34020 \nEpoch: 2905  | Training Loss: 0.21576 \nEpoch: 2905  | Training Loss: 0.16035 \nEpoch: 2905  | Validation balanced accuracy : 0.76304 \nEpoch: 2906  | Training Loss: 0.31269 \nEpoch: 2906  | Training Loss: 0.36543 \nEpoch: 2906  | Training Loss: 0.34035 \nEpoch: 2906  | Training Loss: 0.21574 \nEpoch: 2906  | Training Loss: 0.16033 \nEpoch: 2906  | Validation balanced accuracy : 0.76304 \nEpoch: 2907  | Training Loss: 0.31282 \nEpoch: 2907  | Training Loss: 0.36561 \nEpoch: 2907  | Training Loss: 0.34022 \nEpoch: 2907  | Training Loss: 0.21577 \nEpoch: 2907  | Training Loss: 0.15958 \nEpoch: 2907  | Validation balanced accuracy : 0.76304 \nEpoch: 2908  | Training Loss: 0.31337 \nEpoch: 2908  | Training Loss: 0.36600 \nEpoch: 2908  | Training Loss: 0.34011 \nEpoch: 2908  | Training Loss: 0.21578 \nEpoch: 2908  | Training Loss: 0.15954 \nEpoch: 2908  | Validation balanced accuracy : 0.76304 \nEpoch: 2909  | Training Loss: 0.31325 \nEpoch: 2909  | Training Loss: 0.36581 \nEpoch: 2909  | Training Loss: 0.34027 \nEpoch: 2909  | Training Loss: 0.21572 \nEpoch: 2909  | Training Loss: 0.16023 \nEpoch: 2909  | Validation balanced accuracy : 0.76304 \nEpoch: 2910  | Training Loss: 0.31271 \nEpoch: 2910  | Training Loss: 0.36544 \nEpoch: 2910  | Training Loss: 0.34042 \nEpoch: 2910  | Training Loss: 0.21569 \nEpoch: 2910  | Training Loss: 0.16020 \nEpoch: 2910  | Validation balanced accuracy : 0.76304 \nEpoch: 2911  | Training Loss: 0.31284 \nEpoch: 2911  | Training Loss: 0.36563 \nEpoch: 2911  | Training Loss: 0.34029 \nEpoch: 2911  | Training Loss: 0.21573 \nEpoch: 2911  | Training Loss: 0.15946 \nEpoch: 2911  | Validation balanced accuracy : 0.76304 \nEpoch: 2912  | Training Loss: 0.31340 \nEpoch: 2912  | Training Loss: 0.36601 \nEpoch: 2912  | Training Loss: 0.34018 \nEpoch: 2912  | Training Loss: 0.21573 \nEpoch: 2912  | Training Loss: 0.15942 \nEpoch: 2912  | Validation balanced accuracy : 0.76304 \nEpoch: 2913  | Training Loss: 0.31327 \nEpoch: 2913  | Training Loss: 0.36582 \nEpoch: 2913  | Training Loss: 0.34034 \nEpoch: 2913  | Training Loss: 0.21567 \nEpoch: 2913  | Training Loss: 0.16011 \nEpoch: 2913  | Validation balanced accuracy : 0.76304 \nEpoch: 2914  | Training Loss: 0.31274 \nEpoch: 2914  | Training Loss: 0.36546 \nEpoch: 2914  | Training Loss: 0.34049 \nEpoch: 2914  | Training Loss: 0.21565 \nEpoch: 2914  | Training Loss: 0.16008 \nEpoch: 2914  | Validation balanced accuracy : 0.76304 \nEpoch: 2915  | Training Loss: 0.31286 \nEpoch: 2915  | Training Loss: 0.36564 \nEpoch: 2915  | Training Loss: 0.34036 \nEpoch: 2915  | Training Loss: 0.21568 \nEpoch: 2915  | Training Loss: 0.15933 \nEpoch: 2915  | Validation balanced accuracy : 0.76304 \nEpoch: 2916  | Training Loss: 0.31342 \nEpoch: 2916  | Training Loss: 0.36603 \nEpoch: 2916  | Training Loss: 0.34025 \nEpoch: 2916  | Training Loss: 0.21569 \nEpoch: 2916  | Training Loss: 0.15930 \nEpoch: 2916  | Validation balanced accuracy : 0.76304 \nEpoch: 2917  | Training Loss: 0.31329 \nEpoch: 2917  | Training Loss: 0.36583 \nEpoch: 2917  | Training Loss: 0.34041 \nEpoch: 2917  | Training Loss: 0.21563 \nEpoch: 2917  | Training Loss: 0.15998 \nEpoch: 2917  | Validation balanced accuracy : 0.76304 \nEpoch: 2918  | Training Loss: 0.31276 \nEpoch: 2918  | Training Loss: 0.36548 \nEpoch: 2918  | Training Loss: 0.34056 \nEpoch: 2918  | Training Loss: 0.21560 \nEpoch: 2918  | Training Loss: 0.15996 \nEpoch: 2918  | Validation balanced accuracy : 0.76304 \nEpoch: 2919  | Training Loss: 0.31289 \nEpoch: 2919  | Training Loss: 0.36566 \nEpoch: 2919  | Training Loss: 0.34044 \nEpoch: 2919  | Training Loss: 0.21564 \nEpoch: 2919  | Training Loss: 0.15921 \nEpoch: 2919  | Validation balanced accuracy : 0.76304 \nEpoch: 2920  | Training Loss: 0.31344 \nEpoch: 2920  | Training Loss: 0.36604 \nEpoch: 2920  | Training Loss: 0.34032 \nEpoch: 2920  | Training Loss: 0.21564 \nEpoch: 2920  | Training Loss: 0.15918 \nEpoch: 2920  | Validation balanced accuracy : 0.76304 \nEpoch: 2921  | Training Loss: 0.31331 \nEpoch: 2921  | Training Loss: 0.36585 \nEpoch: 2921  | Training Loss: 0.34049 \nEpoch: 2921  | Training Loss: 0.21558 \nEpoch: 2921  | Training Loss: 0.15986 \nEpoch: 2921  | Validation balanced accuracy : 0.76304 \nEpoch: 2922  | Training Loss: 0.31278 \nEpoch: 2922  | Training Loss: 0.36549 \nEpoch: 2922  | Training Loss: 0.34064 \nEpoch: 2922  | Training Loss: 0.21556 \nEpoch: 2922  | Training Loss: 0.15984 \nEpoch: 2922  | Validation balanced accuracy : 0.76304 \nEpoch: 2923  | Training Loss: 0.31291 \nEpoch: 2923  | Training Loss: 0.36567 \nEpoch: 2923  | Training Loss: 0.34051 \nEpoch: 2923  | Training Loss: 0.21559 \nEpoch: 2923  | Training Loss: 0.15910 \nEpoch: 2923  | Validation balanced accuracy : 0.76304 \nEpoch: 2924  | Training Loss: 0.31346 \nEpoch: 2924  | Training Loss: 0.36605 \nEpoch: 2924  | Training Loss: 0.34040 \nEpoch: 2924  | Training Loss: 0.21560 \nEpoch: 2924  | Training Loss: 0.15906 \nEpoch: 2924  | Validation balanced accuracy : 0.76304 \nEpoch: 2925  | Training Loss: 0.31333 \nEpoch: 2925  | Training Loss: 0.36586 \nEpoch: 2925  | Training Loss: 0.34056 \nEpoch: 2925  | Training Loss: 0.21554 \nEpoch: 2925  | Training Loss: 0.15975 \nEpoch: 2925  | Validation balanced accuracy : 0.76304 \nEpoch: 2926  | Training Loss: 0.31280 \nEpoch: 2926  | Training Loss: 0.36550 \nEpoch: 2926  | Training Loss: 0.34071 \nEpoch: 2926  | Training Loss: 0.21551 \nEpoch: 2926  | Training Loss: 0.15972 \nEpoch: 2926  | Validation balanced accuracy : 0.76304 \nEpoch: 2927  | Training Loss: 0.31293 \nEpoch: 2927  | Training Loss: 0.36569 \nEpoch: 2927  | Training Loss: 0.34058 \nEpoch: 2927  | Training Loss: 0.21555 \nEpoch: 2927  | Training Loss: 0.15898 \nEpoch: 2927  | Validation balanced accuracy : 0.76304 \nEpoch: 2928  | Training Loss: 0.31348 \nEpoch: 2928  | Training Loss: 0.36606 \nEpoch: 2928  | Training Loss: 0.34047 \nEpoch: 2928  | Training Loss: 0.21556 \nEpoch: 2928  | Training Loss: 0.15894 \nEpoch: 2928  | Validation balanced accuracy : 0.76304 \nEpoch: 2929  | Training Loss: 0.31335 \nEpoch: 2929  | Training Loss: 0.36587 \nEpoch: 2929  | Training Loss: 0.34064 \nEpoch: 2929  | Training Loss: 0.21550 \nEpoch: 2929  | Training Loss: 0.15963 \nEpoch: 2929  | Validation balanced accuracy : 0.76304 \nEpoch: 2930  | Training Loss: 0.31282 \nEpoch: 2930  | Training Loss: 0.36552 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2930  | Training Loss: 0.34079 \nEpoch: 2930  | Training Loss: 0.21547 \nEpoch: 2930  | Training Loss: 0.15960 \nEpoch: 2930  | Validation balanced accuracy : 0.76304 \nEpoch: 2931  | Training Loss: 0.31295 \nEpoch: 2931  | Training Loss: 0.36570 \nEpoch: 2931  | Training Loss: 0.34066 \nEpoch: 2931  | Training Loss: 0.21551 \nEpoch: 2931  | Training Loss: 0.15886 \nEpoch: 2931  | Validation balanced accuracy : 0.76304 \nEpoch: 2932  | Training Loss: 0.31350 \nEpoch: 2932  | Training Loss: 0.36607 \nEpoch: 2932  | Training Loss: 0.34055 \nEpoch: 2932  | Training Loss: 0.21551 \nEpoch: 2932  | Training Loss: 0.15883 \nEpoch: 2932  | Validation balanced accuracy : 0.76304 \nEpoch: 2933  | Training Loss: 0.31337 \nEpoch: 2933  | Training Loss: 0.36588 \nEpoch: 2933  | Training Loss: 0.34071 \nEpoch: 2933  | Training Loss: 0.21545 \nEpoch: 2933  | Training Loss: 0.15951 \nEpoch: 2933  | Validation balanced accuracy : 0.76304 \nEpoch: 2934  | Training Loss: 0.31285 \nEpoch: 2934  | Training Loss: 0.36553 \nEpoch: 2934  | Training Loss: 0.34086 \nEpoch: 2934  | Training Loss: 0.21543 \nEpoch: 2934  | Training Loss: 0.15949 \nEpoch: 2934  | Validation balanced accuracy : 0.76304 \nEpoch: 2935  | Training Loss: 0.31297 \nEpoch: 2935  | Training Loss: 0.36571 \nEpoch: 2935  | Training Loss: 0.34073 \nEpoch: 2935  | Training Loss: 0.21546 \nEpoch: 2935  | Training Loss: 0.15875 \nEpoch: 2935  | Validation balanced accuracy : 0.76304 \nEpoch: 2936  | Training Loss: 0.31352 \nEpoch: 2936  | Training Loss: 0.36608 \nEpoch: 2936  | Training Loss: 0.34062 \nEpoch: 2936  | Training Loss: 0.21547 \nEpoch: 2936  | Training Loss: 0.15871 \nEpoch: 2936  | Validation balanced accuracy : 0.76304 \nEpoch: 2937  | Training Loss: 0.31339 \nEpoch: 2937  | Training Loss: 0.36589 \nEpoch: 2937  | Training Loss: 0.34074 \nEpoch: 2937  | Training Loss: 0.21543 \nEpoch: 2937  | Training Loss: 0.15901 \nEpoch: 2937  | Validation balanced accuracy : 0.76304 \nEpoch: 2938  | Training Loss: 0.31319 \nEpoch: 2938  | Training Loss: 0.36583 \nEpoch: 2938  | Training Loss: 0.34075 \nEpoch: 2938  | Training Loss: 0.21544 \nEpoch: 2938  | Training Loss: 0.15870 \nEpoch: 2938  | Validation balanced accuracy : 0.76304 \nEpoch: 2939  | Training Loss: 0.31346 \nEpoch: 2939  | Training Loss: 0.36601 \nEpoch: 2939  | Training Loss: 0.34073 \nEpoch: 2939  | Training Loss: 0.21542 \nEpoch: 2939  | Training Loss: 0.15890 \nEpoch: 2939  | Validation balanced accuracy : 0.76304 \nEpoch: 2940  | Training Loss: 0.31320 \nEpoch: 2940  | Training Loss: 0.36582 \nEpoch: 2940  | Training Loss: 0.34080 \nEpoch: 2940  | Training Loss: 0.21541 \nEpoch: 2940  | Training Loss: 0.15876 \nEpoch: 2940  | Validation balanced accuracy : 0.76304 \nEpoch: 2941  | Training Loss: 0.31337 \nEpoch: 2941  | Training Loss: 0.36593 \nEpoch: 2941  | Training Loss: 0.34081 \nEpoch: 2941  | Training Loss: 0.21539 \nEpoch: 2941  | Training Loss: 0.15902 \nEpoch: 2941  | Validation balanced accuracy : 0.76304 \nEpoch: 2942  | Training Loss: 0.31310 \nEpoch: 2942  | Training Loss: 0.36574 \nEpoch: 2942  | Training Loss: 0.34089 \nEpoch: 2942  | Training Loss: 0.21538 \nEpoch: 2942  | Training Loss: 0.15884 \nEpoch: 2942  | Validation balanced accuracy : 0.76304 \nEpoch: 2943  | Training Loss: 0.31329 \nEpoch: 2943  | Training Loss: 0.36588 \nEpoch: 2943  | Training Loss: 0.34084 \nEpoch: 2943  | Training Loss: 0.21538 \nEpoch: 2943  | Training Loss: 0.15864 \nEpoch: 2943  | Validation balanced accuracy : 0.76304 \nEpoch: 2944  | Training Loss: 0.31340 \nEpoch: 2944  | Training Loss: 0.36594 \nEpoch: 2944  | Training Loss: 0.34087 \nEpoch: 2944  | Training Loss: 0.21535 \nEpoch: 2944  | Training Loss: 0.15898 \nEpoch: 2944  | Validation balanced accuracy : 0.76304 \nEpoch: 2945  | Training Loss: 0.31308 \nEpoch: 2945  | Training Loss: 0.36572 \nEpoch: 2945  | Training Loss: 0.34096 \nEpoch: 2945  | Training Loss: 0.21534 \nEpoch: 2945  | Training Loss: 0.15883 \nEpoch: 2945  | Validation balanced accuracy : 0.76304 \nEpoch: 2946  | Training Loss: 0.31326 \nEpoch: 2946  | Training Loss: 0.36592 \nEpoch: 2946  | Training Loss: 0.34083 \nEpoch: 2946  | Training Loss: 0.21538 \nEpoch: 2946  | Training Loss: 0.15815 \nEpoch: 2946  | Validation balanced accuracy : 0.76304 \nEpoch: 2947  | Training Loss: 0.31376 \nEpoch: 2947  | Training Loss: 0.36625 \nEpoch: 2947  | Training Loss: 0.34075 \nEpoch: 2947  | Training Loss: 0.21537 \nEpoch: 2947  | Training Loss: 0.15825 \nEpoch: 2947  | Validation balanced accuracy : 0.76304 \nEpoch: 2948  | Training Loss: 0.31353 \nEpoch: 2948  | Training Loss: 0.36598 \nEpoch: 2948  | Training Loss: 0.34095 \nEpoch: 2948  | Training Loss: 0.21530 \nEpoch: 2948  | Training Loss: 0.15907 \nEpoch: 2948  | Validation balanced accuracy : 0.76304 \nEpoch: 2949  | Training Loss: 0.31292 \nEpoch: 2949  | Training Loss: 0.36557 \nEpoch: 2949  | Training Loss: 0.34114 \nEpoch: 2949  | Training Loss: 0.21527 \nEpoch: 2949  | Training Loss: 0.15914 \nEpoch: 2949  | Validation balanced accuracy : 0.76304 \nEpoch: 2950  | Training Loss: 0.31300 \nEpoch: 2950  | Training Loss: 0.36572 \nEpoch: 2950  | Training Loss: 0.34102 \nEpoch: 2950  | Training Loss: 0.21530 \nEpoch: 2950  | Training Loss: 0.15842 \nEpoch: 2950  | Validation balanced accuracy : 0.76304 \nEpoch: 2951  | Training Loss: 0.31352 \nEpoch: 2951  | Training Loss: 0.36608 \nEpoch: 2951  | Training Loss: 0.34091 \nEpoch: 2951  | Training Loss: 0.21531 \nEpoch: 2951  | Training Loss: 0.15837 \nEpoch: 2951  | Validation balanced accuracy : 0.76304 \nEpoch: 2952  | Training Loss: 0.31342 \nEpoch: 2952  | Training Loss: 0.36592 \nEpoch: 2952  | Training Loss: 0.34102 \nEpoch: 2952  | Training Loss: 0.21528 \nEpoch: 2952  | Training Loss: 0.15862 \nEpoch: 2952  | Validation balanced accuracy : 0.76304 \nEpoch: 2953  | Training Loss: 0.31325 \nEpoch: 2953  | Training Loss: 0.36587 \nEpoch: 2953  | Training Loss: 0.34102 \nEpoch: 2953  | Training Loss: 0.21528 \nEpoch: 2953  | Training Loss: 0.15827 \nEpoch: 2953  | Validation balanced accuracy : 0.76304 \nEpoch: 2954  | Training Loss: 0.31354 \nEpoch: 2954  | Training Loss: 0.36606 \nEpoch: 2954  | Training Loss: 0.34099 \nEpoch: 2954  | Training Loss: 0.21527 \nEpoch: 2954  | Training Loss: 0.15846 \nEpoch: 2954  | Validation balanced accuracy : 0.76304 \nEpoch: 2955  | Training Loss: 0.31330 \nEpoch: 2955  | Training Loss: 0.36588 \nEpoch: 2955  | Training Loss: 0.34106 \nEpoch: 2955  | Training Loss: 0.21526 \nEpoch: 2955  | Training Loss: 0.15831 \nEpoch: 2955  | Validation balanced accuracy : 0.76304 \nEpoch: 2956  | Training Loss: 0.31347 \nEpoch: 2956  | Training Loss: 0.36599 \nEpoch: 2956  | Training Loss: 0.34103 \nEpoch: 2956  | Training Loss: 0.21526 \nEpoch: 2956  | Training Loss: 0.15820 \nEpoch: 2956  | Validation balanced accuracy : 0.76304 \nEpoch: 2957  | Training Loss: 0.31351 \nEpoch: 2957  | Training Loss: 0.36601 \nEpoch: 2957  | Training Loss: 0.34104 \nEpoch: 2957  | Training Loss: 0.21525 \nEpoch: 2957  | Training Loss: 0.15823 \nEpoch: 2957  | Validation balanced accuracy : 0.76304 \nEpoch: 2958  | Training Loss: 0.31346 \nEpoch: 2958  | Training Loss: 0.36597 \nEpoch: 2958  | Training Loss: 0.34109 \nEpoch: 2958  | Training Loss: 0.21523 \nEpoch: 2958  | Training Loss: 0.15832 \nEpoch: 2958  | Validation balanced accuracy : 0.76304 \nEpoch: 2959  | Training Loss: 0.31338 \nEpoch: 2959  | Training Loss: 0.36598 \nEpoch: 2959  | Training Loss: 0.34106 \nEpoch: 2959  | Training Loss: 0.21524 \nEpoch: 2959  | Training Loss: 0.15793 \nEpoch: 2959  | Validation balanced accuracy : 0.76304 \nEpoch: 2960  | Training Loss: 0.31370 \nEpoch: 2960  | Training Loss: 0.36618 \nEpoch: 2960  | Training Loss: 0.34104 \nEpoch: 2960  | Training Loss: 0.21522 \nEpoch: 2960  | Training Loss: 0.15816 \nEpoch: 2960  | Validation balanced accuracy : 0.76304 \nEpoch: 2961  | Training Loss: 0.31341 \nEpoch: 2961  | Training Loss: 0.36597 \nEpoch: 2961  | Training Loss: 0.34113 \nEpoch: 2961  | Training Loss: 0.21520 \nEpoch: 2961  | Training Loss: 0.15809 \nEpoch: 2961  | Validation balanced accuracy : 0.76304 \nEpoch: 2962  | Training Loss: 0.31353 \nEpoch: 2962  | Training Loss: 0.36604 \nEpoch: 2962  | Training Loss: 0.34111 \nEpoch: 2962  | Training Loss: 0.21520 \nEpoch: 2962  | Training Loss: 0.15804 \nEpoch: 2962  | Validation balanced accuracy : 0.76304 \nEpoch: 2963  | Training Loss: 0.31353 \nEpoch: 2963  | Training Loss: 0.36602 \nEpoch: 2963  | Training Loss: 0.34115 \nEpoch: 2963  | Training Loss: 0.21518 \nEpoch: 2963  | Training Loss: 0.15811 \nEpoch: 2963  | Validation balanced accuracy : 0.76304 \nEpoch: 2964  | Training Loss: 0.31346 \nEpoch: 2964  | Training Loss: 0.36597 \nEpoch: 2964  | Training Loss: 0.34120 \nEpoch: 2964  | Training Loss: 0.21516 \nEpoch: 2964  | Training Loss: 0.15821 \nEpoch: 2964  | Validation balanced accuracy : 0.76304 \nEpoch: 2965  | Training Loss: 0.31338 \nEpoch: 2965  | Training Loss: 0.36599 \nEpoch: 2965  | Training Loss: 0.34117 \nEpoch: 2965  | Training Loss: 0.21518 \nEpoch: 2965  | Training Loss: 0.15781 \nEpoch: 2965  | Validation balanced accuracy : 0.76304 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 2966  | Training Loss: 0.31371 \nEpoch: 2966  | Training Loss: 0.36620 \nEpoch: 2966  | Training Loss: 0.34114 \nEpoch: 2966  | Training Loss: 0.21516 \nEpoch: 2966  | Training Loss: 0.15801 \nEpoch: 2966  | Validation balanced accuracy : 0.76304 \nEpoch: 2967  | Training Loss: 0.31344 \nEpoch: 2967  | Training Loss: 0.36599 \nEpoch: 2967  | Training Loss: 0.34122 \nEpoch: 2967  | Training Loss: 0.21515 \nEpoch: 2967  | Training Loss: 0.15793 \nEpoch: 2967  | Validation balanced accuracy : 0.76304 \nEpoch: 2968  | Training Loss: 0.31357 \nEpoch: 2968  | Training Loss: 0.36607 \nEpoch: 2968  | Training Loss: 0.34125 \nEpoch: 2968  | Training Loss: 0.21512 \nEpoch: 2968  | Training Loss: 0.15826 \nEpoch: 2968  | Validation balanced accuracy : 0.76304 \nEpoch: 2969  | Training Loss: 0.31325 \nEpoch: 2969  | Training Loss: 0.36585 \nEpoch: 2969  | Training Loss: 0.34133 \nEpoch: 2969  | Training Loss: 0.21511 \nEpoch: 2969  | Training Loss: 0.15806 \nEpoch: 2969  | Validation balanced accuracy : 0.76304 \nEpoch: 2970  | Training Loss: 0.31347 \nEpoch: 2970  | Training Loss: 0.36609 \nEpoch: 2970  | Training Loss: 0.34122 \nEpoch: 2970  | Training Loss: 0.21513 \nEpoch: 2970  | Training Loss: 0.15775 \nEpoch: 2970  | Validation balanced accuracy : 0.76304 \nEpoch: 2971  | Training Loss: 0.31364 \nEpoch: 2971  | Training Loss: 0.36611 \nEpoch: 2971  | Training Loss: 0.34129 \nEpoch: 2971  | Training Loss: 0.21509 \nEpoch: 2971  | Training Loss: 0.15818 \nEpoch: 2971  | Validation balanced accuracy : 0.76304 \nEpoch: 2972  | Training Loss: 0.31325 \nEpoch: 2972  | Training Loss: 0.36584 \nEpoch: 2972  | Training Loss: 0.34139 \nEpoch: 2972  | Training Loss: 0.21508 \nEpoch: 2972  | Training Loss: 0.15804 \nEpoch: 2972  | Validation balanced accuracy : 0.76304 \nEpoch: 2973  | Training Loss: 0.31344 \nEpoch: 2973  | Training Loss: 0.36606 \nEpoch: 2973  | Training Loss: 0.34125 \nEpoch: 2973  | Training Loss: 0.21512 \nEpoch: 2973  | Training Loss: 0.15736 \nEpoch: 2973  | Validation balanced accuracy : 0.76304 \nEpoch: 2974  | Training Loss: 0.31394 \nEpoch: 2974  | Training Loss: 0.36638 \nEpoch: 2974  | Training Loss: 0.34118 \nEpoch: 2974  | Training Loss: 0.21511 \nEpoch: 2974  | Training Loss: 0.15749 \nEpoch: 2974  | Validation balanced accuracy : 0.76304 \nEpoch: 2975  | Training Loss: 0.31369 \nEpoch: 2975  | Training Loss: 0.36610 \nEpoch: 2975  | Training Loss: 0.34135 \nEpoch: 2975  | Training Loss: 0.21506 \nEpoch: 2975  | Training Loss: 0.15795 \nEpoch: 2975  | Validation balanced accuracy : 0.76304 \nEpoch: 2976  | Training Loss: 0.31338 \nEpoch: 2976  | Training Loss: 0.36596 \nEpoch: 2976  | Training Loss: 0.34139 \nEpoch: 2976  | Training Loss: 0.21506 \nEpoch: 2976  | Training Loss: 0.15768 \nEpoch: 2976  | Validation balanced accuracy : 0.76304 \nEpoch: 2977  | Training Loss: 0.31365 \nEpoch: 2977  | Training Loss: 0.36614 \nEpoch: 2977  | Training Loss: 0.34136 \nEpoch: 2977  | Training Loss: 0.21505 \nEpoch: 2977  | Training Loss: 0.15787 \nEpoch: 2977  | Validation balanced accuracy : 0.76304 \nEpoch: 2978  | Training Loss: 0.31340 \nEpoch: 2978  | Training Loss: 0.36597 \nEpoch: 2978  | Training Loss: 0.34142 \nEpoch: 2978  | Training Loss: 0.21504 \nEpoch: 2978  | Training Loss: 0.15765 \nEpoch: 2978  | Validation balanced accuracy : 0.76304 \nEpoch: 2979  | Training Loss: 0.31363 \nEpoch: 2979  | Training Loss: 0.36613 \nEpoch: 2979  | Training Loss: 0.34136 \nEpoch: 2979  | Training Loss: 0.21505 \nEpoch: 2979  | Training Loss: 0.15748 \nEpoch: 2979  | Validation balanced accuracy : 0.76304 \nEpoch: 2980  | Training Loss: 0.31371 \nEpoch: 2980  | Training Loss: 0.36617 \nEpoch: 2980  | Training Loss: 0.34142 \nEpoch: 2980  | Training Loss: 0.21501 \nEpoch: 2980  | Training Loss: 0.15790 \nEpoch: 2980  | Validation balanced accuracy : 0.76304 \nEpoch: 2981  | Training Loss: 0.31333 \nEpoch: 2981  | Training Loss: 0.36591 \nEpoch: 2981  | Training Loss: 0.34151 \nEpoch: 2981  | Training Loss: 0.21500 \nEpoch: 2981  | Training Loss: 0.15769 \nEpoch: 2981  | Validation balanced accuracy : 0.76304 \nEpoch: 2982  | Training Loss: 0.31357 \nEpoch: 2982  | Training Loss: 0.36617 \nEpoch: 2982  | Training Loss: 0.34140 \nEpoch: 2982  | Training Loss: 0.21502 \nEpoch: 2982  | Training Loss: 0.15738 \nEpoch: 2982  | Validation balanced accuracy : 0.76304 \nEpoch: 2983  | Training Loss: 0.31374 \nEpoch: 2983  | Training Loss: 0.36618 \nEpoch: 2983  | Training Loss: 0.34147 \nEpoch: 2983  | Training Loss: 0.21499 \nEpoch: 2983  | Training Loss: 0.15783 \nEpoch: 2983  | Validation balanced accuracy : 0.76304 \nEpoch: 2984  | Training Loss: 0.31334 \nEpoch: 2984  | Training Loss: 0.36592 \nEpoch: 2984  | Training Loss: 0.34156 \nEpoch: 2984  | Training Loss: 0.21497 \nEpoch: 2984  | Training Loss: 0.15764 \nEpoch: 2984  | Validation balanced accuracy : 0.76304 \nEpoch: 2985  | Training Loss: 0.31357 \nEpoch: 2985  | Training Loss: 0.36616 \nEpoch: 2985  | Training Loss: 0.34141 \nEpoch: 2985  | Training Loss: 0.21501 \nEpoch: 2985  | Training Loss: 0.15694 \nEpoch: 2985  | Validation balanced accuracy : 0.76304 \nEpoch: 2986  | Training Loss: 0.31408 \nEpoch: 2986  | Training Loss: 0.36648 \nEpoch: 2986  | Training Loss: 0.34135 \nEpoch: 2986  | Training Loss: 0.21501 \nEpoch: 2986  | Training Loss: 0.15715 \nEpoch: 2986  | Validation balanced accuracy : 0.76304 \nEpoch: 2987  | Training Loss: 0.31377 \nEpoch: 2987  | Training Loss: 0.36615 \nEpoch: 2987  | Training Loss: 0.34154 \nEpoch: 2987  | Training Loss: 0.21495 \nEpoch: 2987  | Training Loss: 0.15767 \nEpoch: 2987  | Validation balanced accuracy : 0.76304 \nEpoch: 2988  | Training Loss: 0.31342 \nEpoch: 2988  | Training Loss: 0.36599 \nEpoch: 2988  | Training Loss: 0.34158 \nEpoch: 2988  | Training Loss: 0.21495 \nEpoch: 2988  | Training Loss: 0.15735 \nEpoch: 2988  | Validation balanced accuracy : 0.76304 \nEpoch: 2989  | Training Loss: 0.31373 \nEpoch: 2989  | Training Loss: 0.36621 \nEpoch: 2989  | Training Loss: 0.34149 \nEpoch: 2989  | Training Loss: 0.21496 \nEpoch: 2989  | Training Loss: 0.15712 \nEpoch: 2989  | Validation balanced accuracy : 0.76304 \nEpoch: 2990  | Training Loss: 0.31384 \nEpoch: 2990  | Training Loss: 0.36626 \nEpoch: 2990  | Training Loss: 0.34154 \nEpoch: 2990  | Training Loss: 0.21493 \nEpoch: 2990  | Training Loss: 0.15754 \nEpoch: 2990  | Validation balanced accuracy : 0.76304 \nEpoch: 2991  | Training Loss: 0.31344 \nEpoch: 2991  | Training Loss: 0.36600 \nEpoch: 2991  | Training Loss: 0.34164 \nEpoch: 2991  | Training Loss: 0.21492 \nEpoch: 2991  | Training Loss: 0.15738 \nEpoch: 2991  | Validation balanced accuracy : 0.76304 \nEpoch: 2992  | Training Loss: 0.31366 \nEpoch: 2992  | Training Loss: 0.36623 \nEpoch: 2992  | Training Loss: 0.34150 \nEpoch: 2992  | Training Loss: 0.21496 \nEpoch: 2992  | Training Loss: 0.15673 \nEpoch: 2992  | Validation balanced accuracy : 0.76304 \nEpoch: 2993  | Training Loss: 0.31413 \nEpoch: 2993  | Training Loss: 0.36652 \nEpoch: 2993  | Training Loss: 0.34144 \nEpoch: 2993  | Training Loss: 0.21495 \nEpoch: 2993  | Training Loss: 0.15693 \nEpoch: 2993  | Validation balanced accuracy : 0.76304 \nEpoch: 2994  | Training Loss: 0.31383 \nEpoch: 2994  | Training Loss: 0.36620 \nEpoch: 2994  | Training Loss: 0.34163 \nEpoch: 2994  | Training Loss: 0.21489 \nEpoch: 2994  | Training Loss: 0.15747 \nEpoch: 2994  | Validation balanced accuracy : 0.76304 \nEpoch: 2995  | Training Loss: 0.31347 \nEpoch: 2995  | Training Loss: 0.36604 \nEpoch: 2995  | Training Loss: 0.34167 \nEpoch: 2995  | Training Loss: 0.21489 \nEpoch: 2995  | Training Loss: 0.15716 \nEpoch: 2995  | Validation balanced accuracy : 0.76304 \nEpoch: 2996  | Training Loss: 0.31378 \nEpoch: 2996  | Training Loss: 0.36625 \nEpoch: 2996  | Training Loss: 0.34163 \nEpoch: 2996  | Training Loss: 0.21488 \nEpoch: 2996  | Training Loss: 0.15733 \nEpoch: 2996  | Validation balanced accuracy : 0.76304 \nEpoch: 2997  | Training Loss: 0.31355 \nEpoch: 2997  | Training Loss: 0.36610 \nEpoch: 2997  | Training Loss: 0.34168 \nEpoch: 2997  | Training Loss: 0.21488 \nEpoch: 2997  | Training Loss: 0.15703 \nEpoch: 2997  | Validation balanced accuracy : 0.76304 \nEpoch: 2998  | Training Loss: 0.31384 \nEpoch: 2998  | Training Loss: 0.36628 \nEpoch: 2998  | Training Loss: 0.34166 \nEpoch: 2998  | Training Loss: 0.21487 \nEpoch: 2998  | Training Loss: 0.15728 \nEpoch: 2998  | Validation balanced accuracy : 0.76304 \nEpoch: 2999  | Training Loss: 0.31354 \nEpoch: 2999  | Training Loss: 0.36609 \nEpoch: 2999  | Training Loss: 0.34172 \nEpoch: 2999  | Training Loss: 0.21486 \nEpoch: 2999  | Training Loss: 0.15704 \nEpoch: 2999  | Validation balanced accuracy : 0.76304 \nEpoch: 3000  | Training Loss: 0.31380 \nEpoch: 3000  | Training Loss: 0.36626 \nEpoch: 3000  | Training Loss: 0.34166 \nEpoch: 3000  | Training Loss: 0.21487 \nEpoch: 3000  | Training Loss: 0.15688 \nEpoch: 3000  | Validation balanced accuracy : 0.76304 \nEpoch: 3001  | Training Loss: 0.31387 \nEpoch: 3001  | Training Loss: 0.36628 \nEpoch: 3001  | Training Loss: 0.34162 \nEpoch: 3001  | Training Loss: 0.21487 \nEpoch: 3001  | Training Loss: 0.15662 \nEpoch: 3001  | Validation balanced accuracy : 0.76304 \nEpoch: 3002  | Training Loss: 0.31377 \nEpoch: 3002  | Training Loss: 0.36619 \nEpoch: 3002  | Training Loss: 0.34170 \nEpoch: 3002  | Training Loss: 0.21485 \nEpoch: 3002  | Training Loss: 0.15684 \nEpoch: 3002  | Validation balanced accuracy : 0.76304 \nEpoch: 3003  | Training Loss: 0.31361 \nEpoch: 3003  | Training Loss: 0.36613 \nEpoch: 3003  | Training Loss: 0.34170 \nEpoch: 3003  | Training Loss: 0.21485 \nEpoch: 3003  | Training Loss: 0.15657 \nEpoch: 3003  | Validation balanced accuracy : 0.76304 \nEpoch: 3004  | Training Loss: 0.31385 \nEpoch: 3004  | Training Loss: 0.36629 \nEpoch: 3004  | Training Loss: 0.34165 \nEpoch: 3004  | Training Loss: 0.21486 \nEpoch: 3004  | Training Loss: 0.15647 \nEpoch: 3004  | Validation balanced accuracy : 0.76304 \nEpoch: 3005  | Training Loss: 0.31386 \nEpoch: 3005  | Training Loss: 0.36627 \nEpoch: 3005  | Training Loss: 0.34169 \nEpoch: 3005  | Training Loss: 0.21484 \nEpoch: 3005  | Training Loss: 0.15662 \nEpoch: 3005  | Validation balanced accuracy : 0.76304 \nEpoch: 3006  | Training Loss: 0.31373 \nEpoch: 3006  | Training Loss: 0.36623 \nEpoch: 3006  | Training Loss: 0.34170 \nEpoch: 3006  | Training Loss: 0.21484 \nEpoch: 3006  | Training Loss: 0.15642 \nEpoch: 3006  | Validation balanced accuracy : 0.76304 \nEpoch: 3007  | Training Loss: 0.31391 \nEpoch: 3007  | Training Loss: 0.36632 \nEpoch: 3007  | Training Loss: 0.34172 \nEpoch: 3007  | Training Loss: 0.21481 \nEpoch: 3007  | Training Loss: 0.15677 \nEpoch: 3007  | Validation balanced accuracy : 0.76304 \nEpoch: 3008  | Training Loss: 0.31356 \nEpoch: 3008  | Training Loss: 0.36609 \nEpoch: 3008  | Training Loss: 0.34181 \nEpoch: 3008  | Training Loss: 0.21480 \nEpoch: 3008  | Training Loss: 0.15667 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3008  | Validation balanced accuracy : 0.76304 \nEpoch: 3009  | Training Loss: 0.31372 \nEpoch: 3009  | Training Loss: 0.36626 \nEpoch: 3009  | Training Loss: 0.34170 \nEpoch: 3009  | Training Loss: 0.21483 \nEpoch: 3009  | Training Loss: 0.15616 \nEpoch: 3009  | Validation balanced accuracy : 0.76304 \nEpoch: 3010  | Training Loss: 0.31409 \nEpoch: 3010  | Training Loss: 0.36648 \nEpoch: 3010  | Training Loss: 0.34167 \nEpoch: 3010  | Training Loss: 0.21481 \nEpoch: 3010  | Training Loss: 0.15643 \nEpoch: 3010  | Validation balanced accuracy : 0.76304 \nEpoch: 3011  | Training Loss: 0.31376 \nEpoch: 3011  | Training Loss: 0.36623 \nEpoch: 3011  | Training Loss: 0.34179 \nEpoch: 3011  | Training Loss: 0.21479 \nEpoch: 3011  | Training Loss: 0.15652 \nEpoch: 3011  | Validation balanced accuracy : 0.76304 \nEpoch: 3012  | Training Loss: 0.31376 \nEpoch: 3012  | Training Loss: 0.36627 \nEpoch: 3012  | Training Loss: 0.34175 \nEpoch: 3012  | Training Loss: 0.21480 \nEpoch: 3012  | Training Loss: 0.15620 \nEpoch: 3012  | Validation balanced accuracy : 0.76304 \nEpoch: 3013  | Training Loss: 0.31401 \nEpoch: 3013  | Training Loss: 0.36642 \nEpoch: 3013  | Training Loss: 0.34175 \nEpoch: 3013  | Training Loss: 0.21478 \nEpoch: 3013  | Training Loss: 0.15651 \nEpoch: 3013  | Validation balanced accuracy : 0.76304 \nEpoch: 3014  | Training Loss: 0.31368 \nEpoch: 3014  | Training Loss: 0.36617 \nEpoch: 3014  | Training Loss: 0.34185 \nEpoch: 3014  | Training Loss: 0.21476 \nEpoch: 3014  | Training Loss: 0.15651 \nEpoch: 3014  | Validation balanced accuracy : 0.76304 \nEpoch: 3015  | Training Loss: 0.31376 \nEpoch: 3015  | Training Loss: 0.36629 \nEpoch: 3015  | Training Loss: 0.34177 \nEpoch: 3015  | Training Loss: 0.21478 \nEpoch: 3015  | Training Loss: 0.15608 \nEpoch: 3015  | Validation balanced accuracy : 0.76304 \nEpoch: 3016  | Training Loss: 0.31408 \nEpoch: 3016  | Training Loss: 0.36648 \nEpoch: 3016  | Training Loss: 0.34175 \nEpoch: 3016  | Training Loss: 0.21476 \nEpoch: 3016  | Training Loss: 0.15635 \nEpoch: 3016  | Validation balanced accuracy : 0.76304 \nEpoch: 3017  | Training Loss: 0.31376 \nEpoch: 3017  | Training Loss: 0.36624 \nEpoch: 3017  | Training Loss: 0.34185 \nEpoch: 3017  | Training Loss: 0.21474 \nEpoch: 3017  | Training Loss: 0.15635 \nEpoch: 3017  | Validation balanced accuracy : 0.76304 \nEpoch: 3018  | Training Loss: 0.31383 \nEpoch: 3018  | Training Loss: 0.36627 \nEpoch: 3018  | Training Loss: 0.34186 \nEpoch: 3018  | Training Loss: 0.21473 \nEpoch: 3018  | Training Loss: 0.15643 \nEpoch: 3018  | Validation balanced accuracy : 0.76304 \nEpoch: 3019  | Training Loss: 0.31374 \nEpoch: 3019  | Training Loss: 0.36626 \nEpoch: 3019  | Training Loss: 0.34186 \nEpoch: 3019  | Training Loss: 0.21474 \nEpoch: 3019  | Training Loss: 0.15617 \nEpoch: 3019  | Validation balanced accuracy : 0.76304 \nEpoch: 3020  | Training Loss: 0.31396 \nEpoch: 3020  | Training Loss: 0.36639 \nEpoch: 3020  | Training Loss: 0.34186 \nEpoch: 3020  | Training Loss: 0.21472 \nEpoch: 3020  | Training Loss: 0.15648 \nEpoch: 3020  | Validation balanced accuracy : 0.76304 \nEpoch: 3021  | Training Loss: 0.31364 \nEpoch: 3021  | Training Loss: 0.36615 \nEpoch: 3021  | Training Loss: 0.34196 \nEpoch: 3021  | Training Loss: 0.21470 \nEpoch: 3021  | Training Loss: 0.15644 \nEpoch: 3021  | Validation balanced accuracy : 0.76304 \nEpoch: 3022  | Training Loss: 0.31375 \nEpoch: 3022  | Training Loss: 0.36629 \nEpoch: 3022  | Training Loss: 0.34187 \nEpoch: 3022  | Training Loss: 0.21473 \nEpoch: 3022  | Training Loss: 0.15597 \nEpoch: 3022  | Validation balanced accuracy : 0.76304 \nEpoch: 3023  | Training Loss: 0.31410 \nEpoch: 3023  | Training Loss: 0.36651 \nEpoch: 3023  | Training Loss: 0.34184 \nEpoch: 3023  | Training Loss: 0.21471 \nEpoch: 3023  | Training Loss: 0.15619 \nEpoch: 3023  | Validation balanced accuracy : 0.76304 \nEpoch: 3024  | Training Loss: 0.31380 \nEpoch: 3024  | Training Loss: 0.36621 \nEpoch: 3024  | Training Loss: 0.34200 \nEpoch: 3024  | Training Loss: 0.21467 \nEpoch: 3024  | Training Loss: 0.15660 \nEpoch: 3024  | Validation balanced accuracy : 0.76304 \nEpoch: 3025  | Training Loss: 0.31355 \nEpoch: 3025  | Training Loss: 0.36612 \nEpoch: 3025  | Training Loss: 0.34202 \nEpoch: 3025  | Training Loss: 0.21467 \nEpoch: 3025  | Training Loss: 0.15627 \nEpoch: 3025  | Validation balanced accuracy : 0.76304 \nEpoch: 3026  | Training Loss: 0.31385 \nEpoch: 3026  | Training Loss: 0.36633 \nEpoch: 3026  | Training Loss: 0.34193 \nEpoch: 3026  | Training Loss: 0.21469 \nEpoch: 3026  | Training Loss: 0.15606 \nEpoch: 3026  | Validation balanced accuracy : 0.76304 \nEpoch: 3027  | Training Loss: 0.31395 \nEpoch: 3027  | Training Loss: 0.36637 \nEpoch: 3027  | Training Loss: 0.34194 \nEpoch: 3027  | Training Loss: 0.21468 \nEpoch: 3027  | Training Loss: 0.15612 \nEpoch: 3027  | Validation balanced accuracy : 0.76304 \nEpoch: 3028  | Training Loss: 0.31386 \nEpoch: 3028  | Training Loss: 0.36628 \nEpoch: 3028  | Training Loss: 0.34201 \nEpoch: 3028  | Training Loss: 0.21465 \nEpoch: 3028  | Training Loss: 0.15630 \nEpoch: 3028  | Validation balanced accuracy : 0.76304 \nEpoch: 3029  | Training Loss: 0.31374 \nEpoch: 3029  | Training Loss: 0.36626 \nEpoch: 3029  | Training Loss: 0.34200 \nEpoch: 3029  | Training Loss: 0.21466 \nEpoch: 3029  | Training Loss: 0.15598 \nEpoch: 3029  | Validation balanced accuracy : 0.76304 \nEpoch: 3030  | Training Loss: 0.31401 \nEpoch: 3030  | Training Loss: 0.36644 \nEpoch: 3030  | Training Loss: 0.34198 \nEpoch: 3030  | Training Loss: 0.21465 \nEpoch: 3030  | Training Loss: 0.15621 \nEpoch: 3030  | Validation balanced accuracy : 0.76304 \nEpoch: 3031  | Training Loss: 0.31373 \nEpoch: 3031  | Training Loss: 0.36623 \nEpoch: 3031  | Training Loss: 0.34206 \nEpoch: 3031  | Training Loss: 0.21463 \nEpoch: 3031  | Training Loss: 0.15615 \nEpoch: 3031  | Validation balanced accuracy : 0.76304 \nEpoch: 3032  | Training Loss: 0.31385 \nEpoch: 3032  | Training Loss: 0.36637 \nEpoch: 3032  | Training Loss: 0.34197 \nEpoch: 3032  | Training Loss: 0.21466 \nEpoch: 3032  | Training Loss: 0.15569 \nEpoch: 3032  | Validation balanced accuracy : 0.76304 \nEpoch: 3033  | Training Loss: 0.31418 \nEpoch: 3033  | Training Loss: 0.36657 \nEpoch: 3033  | Training Loss: 0.34195 \nEpoch: 3033  | Training Loss: 0.21464 \nEpoch: 3033  | Training Loss: 0.15595 \nEpoch: 3033  | Validation balanced accuracy : 0.76304 \nEpoch: 3034  | Training Loss: 0.31387 \nEpoch: 3034  | Training Loss: 0.36633 \nEpoch: 3034  | Training Loss: 0.34206 \nEpoch: 3034  | Training Loss: 0.21462 \nEpoch: 3034  | Training Loss: 0.15604 \nEpoch: 3034  | Validation balanced accuracy : 0.76304 \nEpoch: 3035  | Training Loss: 0.31387 \nEpoch: 3035  | Training Loss: 0.36638 \nEpoch: 3035  | Training Loss: 0.34202 \nEpoch: 3035  | Training Loss: 0.21463 \nEpoch: 3035  | Training Loss: 0.15572 \nEpoch: 3035  | Validation balanced accuracy : 0.76304 \nEpoch: 3036  | Training Loss: 0.31412 \nEpoch: 3036  | Training Loss: 0.36652 \nEpoch: 3036  | Training Loss: 0.34202 \nEpoch: 3036  | Training Loss: 0.21461 \nEpoch: 3036  | Training Loss: 0.15603 \nEpoch: 3036  | Validation balanced accuracy : 0.76304 \nEpoch: 3037  | Training Loss: 0.31379 \nEpoch: 3037  | Training Loss: 0.36627 \nEpoch: 3037  | Training Loss: 0.34212 \nEpoch: 3037  | Training Loss: 0.21459 \nEpoch: 3037  | Training Loss: 0.15604 \nEpoch: 3037  | Validation balanced accuracy : 0.76304 \nEpoch: 3038  | Training Loss: 0.31386 \nEpoch: 3038  | Training Loss: 0.36638 \nEpoch: 3038  | Training Loss: 0.34206 \nEpoch: 3038  | Training Loss: 0.21461 \nEpoch: 3038  | Training Loss: 0.15566 \nEpoch: 3038  | Validation balanced accuracy : 0.76304 \nEpoch: 3039  | Training Loss: 0.31414 \nEpoch: 3039  | Training Loss: 0.36654 \nEpoch: 3039  | Training Loss: 0.34205 \nEpoch: 3039  | Training Loss: 0.21459 \nEpoch: 3039  | Training Loss: 0.15594 \nEpoch: 3039  | Validation balanced accuracy : 0.76304 \nEpoch: 3040  | Training Loss: 0.31382 \nEpoch: 3040  | Training Loss: 0.36630 \nEpoch: 3040  | Training Loss: 0.34215 \nEpoch: 3040  | Training Loss: 0.21457 \nEpoch: 3040  | Training Loss: 0.15594 \nEpoch: 3040  | Validation balanced accuracy : 0.76304 \nEpoch: 3041  | Training Loss: 0.31390 \nEpoch: 3041  | Training Loss: 0.36641 \nEpoch: 3041  | Training Loss: 0.34208 \nEpoch: 3041  | Training Loss: 0.21460 \nEpoch: 3041  | Training Loss: 0.15553 \nEpoch: 3041  | Validation balanced accuracy : 0.76304 \nEpoch: 3042  | Training Loss: 0.31420 \nEpoch: 3042  | Training Loss: 0.36659 \nEpoch: 3042  | Training Loss: 0.34206 \nEpoch: 3042  | Training Loss: 0.21458 \nEpoch: 3042  | Training Loss: 0.15582 \nEpoch: 3042  | Validation balanced accuracy : 0.76304 \nEpoch: 3043  | Training Loss: 0.31388 \nEpoch: 3043  | Training Loss: 0.36634 \nEpoch: 3043  | Training Loss: 0.34216 \nEpoch: 3043  | Training Loss: 0.21456 \nEpoch: 3043  | Training Loss: 0.15584 \nEpoch: 3043  | Validation balanced accuracy : 0.76304 \nEpoch: 3044  | Training Loss: 0.31394 \nEpoch: 3044  | Training Loss: 0.36638 \nEpoch: 3044  | Training Loss: 0.34217 \nEpoch: 3044  | Training Loss: 0.21455 \nEpoch: 3044  | Training Loss: 0.15588 \nEpoch: 3044  | Validation balanced accuracy : 0.76304 \nEpoch: 3045  | Training Loss: 0.31388 \nEpoch: 3045  | Training Loss: 0.36639 \nEpoch: 3045  | Training Loss: 0.34215 \nEpoch: 3045  | Training Loss: 0.21456 \nEpoch: 3045  | Training Loss: 0.15561 \nEpoch: 3045  | Validation balanced accuracy : 0.76304 \nEpoch: 3046  | Training Loss: 0.31410 \nEpoch: 3046  | Training Loss: 0.36651 \nEpoch: 3046  | Training Loss: 0.34217 \nEpoch: 3046  | Training Loss: 0.21453 \nEpoch: 3046  | Training Loss: 0.15596 \nEpoch: 3046  | Validation balanced accuracy : 0.76304 \nEpoch: 3047  | Training Loss: 0.31375 \nEpoch: 3047  | Training Loss: 0.36626 \nEpoch: 3047  | Training Loss: 0.34226 \nEpoch: 3047  | Training Loss: 0.21452 \nEpoch: 3047  | Training Loss: 0.15587 \nEpoch: 3047  | Validation balanced accuracy : 0.76304 \nEpoch: 3048  | Training Loss: 0.31389 \nEpoch: 3048  | Training Loss: 0.36642 \nEpoch: 3048  | Training Loss: 0.34216 \nEpoch: 3048  | Training Loss: 0.21455 \nEpoch: 3048  | Training Loss: 0.15538 \nEpoch: 3048  | Validation balanced accuracy : 0.76304 \nEpoch: 3049  | Training Loss: 0.31426 \nEpoch: 3049  | Training Loss: 0.36664 \nEpoch: 3049  | Training Loss: 0.34213 \nEpoch: 3049  | Training Loss: 0.21454 \nEpoch: 3049  | Training Loss: 0.15562 \nEpoch: 3049  | Validation balanced accuracy : 0.76304 \nEpoch: 3050  | Training Loss: 0.31396 \nEpoch: 3050  | Training Loss: 0.36634 \nEpoch: 3050  | Training Loss: 0.34230 \nEpoch: 3050  | Training Loss: 0.21449 \nEpoch: 3050  | Training Loss: 0.15605 \nEpoch: 3050  | Validation balanced accuracy : 0.76304 \nEpoch: 3051  | Training Loss: 0.31368 \nEpoch: 3051  | Training Loss: 0.36624 \nEpoch: 3051  | Training Loss: 0.34232 \nEpoch: 3051  | Training Loss: 0.21449 \nEpoch: 3051  | Training Loss: 0.15575 \nEpoch: 3051  | Validation balanced accuracy : 0.76304 \nEpoch: 3052  | Training Loss: 0.31397 \nEpoch: 3052  | Training Loss: 0.36649 \nEpoch: 3052  | Training Loss: 0.34217 \nEpoch: 3052  | Training Loss: 0.21453 \nEpoch: 3052  | Training Loss: 0.15514 \nEpoch: 3052  | Validation balanced accuracy : 0.76304 \nEpoch: 3053  | Training Loss: 0.31440 \nEpoch: 3053  | Training Loss: 0.36675 \nEpoch: 3053  | Training Loss: 0.34212 \nEpoch: 3053  | Training Loss: 0.21452 \nEpoch: 3053  | Training Loss: 0.15536 \nEpoch: 3053  | Validation balanced accuracy : 0.76304 \nEpoch: 3054  | Training Loss: 0.31409 \nEpoch: 3054  | Training Loss: 0.36643 \nEpoch: 3054  | Training Loss: 0.34231 \nEpoch: 3054  | Training Loss: 0.21447 \nEpoch: 3054  | Training Loss: 0.15592 \nEpoch: 3054  | Validation balanced accuracy : 0.76304 \nEpoch: 3055  | Training Loss: 0.31372 \nEpoch: 3055  | Training Loss: 0.36625 \nEpoch: 3055  | Training Loss: 0.34237 \nEpoch: 3055  | Training Loss: 0.21446 \nEpoch: 3055  | Training Loss: 0.15573 \nEpoch: 3055  | Validation balanced accuracy : 0.76304 \nEpoch: 3056  | Training Loss: 0.31393 \nEpoch: 3056  | Training Loss: 0.36646 \nEpoch: 3056  | Training Loss: 0.34225 \nEpoch: 3056  | Training Loss: 0.21450 \nEpoch: 3056  | Training Loss: 0.15518 \nEpoch: 3056  | Validation balanced accuracy : 0.76304 \nEpoch: 3057  | Training Loss: 0.31433 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3057  | Training Loss: 0.36670 \nEpoch: 3057  | Training Loss: 0.34221 \nEpoch: 3057  | Training Loss: 0.21449 \nEpoch: 3057  | Training Loss: 0.15543 \nEpoch: 3057  | Validation balanced accuracy : 0.76304 \nEpoch: 3058  | Training Loss: 0.31401 \nEpoch: 3058  | Training Loss: 0.36638 \nEpoch: 3058  | Training Loss: 0.34239 \nEpoch: 3058  | Training Loss: 0.21444 \nEpoch: 3058  | Training Loss: 0.15590 \nEpoch: 3058  | Validation balanced accuracy : 0.76304 \nEpoch: 3059  | Training Loss: 0.31371 \nEpoch: 3059  | Training Loss: 0.36626 \nEpoch: 3059  | Training Loss: 0.34242 \nEpoch: 3059  | Training Loss: 0.21444 \nEpoch: 3059  | Training Loss: 0.15561 \nEpoch: 3059  | Validation balanced accuracy : 0.76304 \nEpoch: 3060  | Training Loss: 0.31399 \nEpoch: 3060  | Training Loss: 0.36651 \nEpoch: 3060  | Training Loss: 0.34227 \nEpoch: 3060  | Training Loss: 0.21448 \nEpoch: 3060  | Training Loss: 0.15501 \nEpoch: 3060  | Validation balanced accuracy : 0.76304 \nEpoch: 3061  | Training Loss: 0.31441 \nEpoch: 3061  | Training Loss: 0.36677 \nEpoch: 3061  | Training Loss: 0.34222 \nEpoch: 3061  | Training Loss: 0.21447 \nEpoch: 3061  | Training Loss: 0.15523 \nEpoch: 3061  | Validation balanced accuracy : 0.76304 \nEpoch: 3062  | Training Loss: 0.31411 \nEpoch: 3062  | Training Loss: 0.36645 \nEpoch: 3062  | Training Loss: 0.34241 \nEpoch: 3062  | Training Loss: 0.21442 \nEpoch: 3062  | Training Loss: 0.15578 \nEpoch: 3062  | Validation balanced accuracy : 0.76304 \nEpoch: 3063  | Training Loss: 0.31375 \nEpoch: 3063  | Training Loss: 0.36628 \nEpoch: 3063  | Training Loss: 0.34247 \nEpoch: 3063  | Training Loss: 0.21441 \nEpoch: 3063  | Training Loss: 0.15558 \nEpoch: 3063  | Validation balanced accuracy : 0.76304 \nEpoch: 3064  | Training Loss: 0.31396 \nEpoch: 3064  | Training Loss: 0.36649 \nEpoch: 3064  | Training Loss: 0.34234 \nEpoch: 3064  | Training Loss: 0.21444 \nEpoch: 3064  | Training Loss: 0.15502 \nEpoch: 3064  | Validation balanced accuracy : 0.76304 \nEpoch: 3065  | Training Loss: 0.31436 \nEpoch: 3065  | Training Loss: 0.36673 \nEpoch: 3065  | Training Loss: 0.34230 \nEpoch: 3065  | Training Loss: 0.21444 \nEpoch: 3065  | Training Loss: 0.15524 \nEpoch: 3065  | Validation balanced accuracy : 0.76304 \nEpoch: 3066  | Training Loss: 0.31407 \nEpoch: 3066  | Training Loss: 0.36643 \nEpoch: 3066  | Training Loss: 0.34247 \nEpoch: 3066  | Training Loss: 0.21439 \nEpoch: 3066  | Training Loss: 0.15569 \nEpoch: 3066  | Validation balanced accuracy : 0.76304 \nEpoch: 3067  | Training Loss: 0.31379 \nEpoch: 3067  | Training Loss: 0.36632 \nEpoch: 3067  | Training Loss: 0.34250 \nEpoch: 3067  | Training Loss: 0.21439 \nEpoch: 3067  | Training Loss: 0.15541 \nEpoch: 3067  | Validation balanced accuracy : 0.76304 \nEpoch: 3068  | Training Loss: 0.31405 \nEpoch: 3068  | Training Loss: 0.36656 \nEpoch: 3068  | Training Loss: 0.34236 \nEpoch: 3068  | Training Loss: 0.21443 \nEpoch: 3068  | Training Loss: 0.15484 \nEpoch: 3068  | Validation balanced accuracy : 0.76304 \nEpoch: 3069  | Training Loss: 0.31446 \nEpoch: 3069  | Training Loss: 0.36680 \nEpoch: 3069  | Training Loss: 0.34232 \nEpoch: 3069  | Training Loss: 0.21442 \nEpoch: 3069  | Training Loss: 0.15512 \nEpoch: 3069  | Validation balanced accuracy : 0.76304 \nEpoch: 3070  | Training Loss: 0.31411 \nEpoch: 3070  | Training Loss: 0.36645 \nEpoch: 3070  | Training Loss: 0.34252 \nEpoch: 3070  | Training Loss: 0.21436 \nEpoch: 3070  | Training Loss: 0.15563 \nEpoch: 3070  | Validation balanced accuracy : 0.76304 \nEpoch: 3071  | Training Loss: 0.31379 \nEpoch: 3071  | Training Loss: 0.36631 \nEpoch: 3071  | Training Loss: 0.34256 \nEpoch: 3071  | Training Loss: 0.21436 \nEpoch: 3071  | Training Loss: 0.15539 \nEpoch: 3071  | Validation balanced accuracy : 0.76304 \nEpoch: 3072  | Training Loss: 0.31403 \nEpoch: 3072  | Training Loss: 0.36654 \nEpoch: 3072  | Training Loss: 0.34242 \nEpoch: 3072  | Training Loss: 0.21440 \nEpoch: 3072  | Training Loss: 0.15481 \nEpoch: 3072  | Validation balanced accuracy : 0.76304 \nEpoch: 3073  | Training Loss: 0.31444 \nEpoch: 3073  | Training Loss: 0.36679 \nEpoch: 3073  | Training Loss: 0.34237 \nEpoch: 3073  | Training Loss: 0.21439 \nEpoch: 3073  | Training Loss: 0.15504 \nEpoch: 3073  | Validation balanced accuracy : 0.76304 \nEpoch: 3074  | Training Loss: 0.31414 \nEpoch: 3074  | Training Loss: 0.36648 \nEpoch: 3074  | Training Loss: 0.34255 \nEpoch: 3074  | Training Loss: 0.21434 \nEpoch: 3074  | Training Loss: 0.15552 \nEpoch: 3074  | Validation balanced accuracy : 0.76304 \nEpoch: 3075  | Training Loss: 0.31383 \nEpoch: 3075  | Training Loss: 0.36635 \nEpoch: 3075  | Training Loss: 0.34259 \nEpoch: 3075  | Training Loss: 0.21434 \nEpoch: 3075  | Training Loss: 0.15526 \nEpoch: 3075  | Validation balanced accuracy : 0.76304 \nEpoch: 3076  | Training Loss: 0.31408 \nEpoch: 3076  | Training Loss: 0.36658 \nEpoch: 3076  | Training Loss: 0.34245 \nEpoch: 3076  | Training Loss: 0.21438 \nEpoch: 3076  | Training Loss: 0.15470 \nEpoch: 3076  | Validation balanced accuracy : 0.76304 \nEpoch: 3077  | Training Loss: 0.31448 \nEpoch: 3077  | Training Loss: 0.36682 \nEpoch: 3077  | Training Loss: 0.34241 \nEpoch: 3077  | Training Loss: 0.21437 \nEpoch: 3077  | Training Loss: 0.15495 \nEpoch: 3077  | Validation balanced accuracy : 0.76304 \nEpoch: 3078  | Training Loss: 0.31416 \nEpoch: 3078  | Training Loss: 0.36650 \nEpoch: 3078  | Training Loss: 0.34260 \nEpoch: 3078  | Training Loss: 0.21431 \nEpoch: 3078  | Training Loss: 0.15544 \nEpoch: 3078  | Validation balanced accuracy : 0.76304 \nEpoch: 3079  | Training Loss: 0.31385 \nEpoch: 3079  | Training Loss: 0.36636 \nEpoch: 3079  | Training Loss: 0.34264 \nEpoch: 3079  | Training Loss: 0.21431 \nEpoch: 3079  | Training Loss: 0.15520 \nEpoch: 3079  | Validation balanced accuracy : 0.76304 \nEpoch: 3080  | Training Loss: 0.31409 \nEpoch: 3080  | Training Loss: 0.36659 \nEpoch: 3080  | Training Loss: 0.34250 \nEpoch: 3080  | Training Loss: 0.21435 \nEpoch: 3080  | Training Loss: 0.15464 \nEpoch: 3080  | Validation balanced accuracy : 0.76304 \nEpoch: 3081  | Training Loss: 0.31449 \nEpoch: 3081  | Training Loss: 0.36682 \nEpoch: 3081  | Training Loss: 0.34246 \nEpoch: 3081  | Training Loss: 0.21434 \nEpoch: 3081  | Training Loss: 0.15491 \nEpoch: 3081  | Validation balanced accuracy : 0.76304 \nEpoch: 3082  | Training Loss: 0.31416 \nEpoch: 3082  | Training Loss: 0.36656 \nEpoch: 3082  | Training Loss: 0.34258 \nEpoch: 3082  | Training Loss: 0.21431 \nEpoch: 3082  | Training Loss: 0.15499 \nEpoch: 3082  | Validation balanced accuracy : 0.76304 \nEpoch: 3083  | Training Loss: 0.31417 \nEpoch: 3083  | Training Loss: 0.36656 \nEpoch: 3083  | Training Loss: 0.34260 \nEpoch: 3083  | Training Loss: 0.21430 \nEpoch: 3083  | Training Loss: 0.15504 \nEpoch: 3083  | Validation balanced accuracy : 0.76304 \nEpoch: 3084  | Training Loss: 0.31411 \nEpoch: 3084  | Training Loss: 0.36657 \nEpoch: 3084  | Training Loss: 0.34258 \nEpoch: 3084  | Training Loss: 0.21431 \nEpoch: 3084  | Training Loss: 0.15479 \nEpoch: 3084  | Validation balanced accuracy : 0.76304 \nEpoch: 3085  | Training Loss: 0.31432 \nEpoch: 3085  | Training Loss: 0.36668 \nEpoch: 3085  | Training Loss: 0.34259 \nEpoch: 3085  | Training Loss: 0.21429 \nEpoch: 3085  | Training Loss: 0.15514 \nEpoch: 3085  | Validation balanced accuracy : 0.76304 \nEpoch: 3086  | Training Loss: 0.31397 \nEpoch: 3086  | Training Loss: 0.36643 \nEpoch: 3086  | Training Loss: 0.34270 \nEpoch: 3086  | Training Loss: 0.21427 \nEpoch: 3086  | Training Loss: 0.15509 \nEpoch: 3086  | Validation balanced accuracy : 0.76304 \nEpoch: 3087  | Training Loss: 0.31409 \nEpoch: 3087  | Training Loss: 0.36658 \nEpoch: 3087  | Training Loss: 0.34260 \nEpoch: 3087  | Training Loss: 0.21430 \nEpoch: 3087  | Training Loss: 0.15457 \nEpoch: 3087  | Validation balanced accuracy : 0.76304 \nEpoch: 3088  | Training Loss: 0.31448 \nEpoch: 3088  | Training Loss: 0.36682 \nEpoch: 3088  | Training Loss: 0.34256 \nEpoch: 3088  | Training Loss: 0.21429 \nEpoch: 3088  | Training Loss: 0.15483 \nEpoch: 3088  | Validation balanced accuracy : 0.76304 \nEpoch: 3089  | Training Loss: 0.31415 \nEpoch: 3089  | Training Loss: 0.36656 \nEpoch: 3089  | Training Loss: 0.34267 \nEpoch: 3089  | Training Loss: 0.21427 \nEpoch: 3089  | Training Loss: 0.15490 \nEpoch: 3089  | Validation balanced accuracy : 0.76304 \nEpoch: 3090  | Training Loss: 0.31418 \nEpoch: 3090  | Training Loss: 0.36663 \nEpoch: 3090  | Training Loss: 0.34262 \nEpoch: 3090  | Training Loss: 0.21428 \nEpoch: 3090  | Training Loss: 0.15458 \nEpoch: 3090  | Validation balanced accuracy : 0.76304 \nEpoch: 3091  | Training Loss: 0.31442 \nEpoch: 3091  | Training Loss: 0.36676 \nEpoch: 3091  | Training Loss: 0.34263 \nEpoch: 3091  | Training Loss: 0.21426 \nEpoch: 3091  | Training Loss: 0.15493 \nEpoch: 3091  | Validation balanced accuracy : 0.76304 \nEpoch: 3092  | Training Loss: 0.31406 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3092  | Training Loss: 0.36649 \nEpoch: 3092  | Training Loss: 0.34275 \nEpoch: 3092  | Training Loss: 0.21424 \nEpoch: 3092  | Training Loss: 0.15499 \nEpoch: 3092  | Validation balanced accuracy : 0.76304 \nEpoch: 3093  | Training Loss: 0.31410 \nEpoch: 3093  | Training Loss: 0.36658 \nEpoch: 3093  | Training Loss: 0.34268 \nEpoch: 3093  | Training Loss: 0.21426 \nEpoch: 3093  | Training Loss: 0.15455 \nEpoch: 3093  | Validation balanced accuracy : 0.76304 \nEpoch: 3094  | Training Loss: 0.31443 \nEpoch: 3094  | Training Loss: 0.36679 \nEpoch: 3094  | Training Loss: 0.34264 \nEpoch: 3094  | Training Loss: 0.21425 \nEpoch: 3094  | Training Loss: 0.15479 \nEpoch: 3094  | Validation balanced accuracy : 0.76304 \nEpoch: 3095  | Training Loss: 0.31414 \nEpoch: 3095  | Training Loss: 0.36656 \nEpoch: 3095  | Training Loss: 0.34275 \nEpoch: 3095  | Training Loss: 0.21423 \nEpoch: 3095  | Training Loss: 0.15482 \nEpoch: 3095  | Validation balanced accuracy : 0.76304 \nEpoch: 3096  | Training Loss: 0.31419 \nEpoch: 3096  | Training Loss: 0.36665 \nEpoch: 3096  | Training Loss: 0.34268 \nEpoch: 3096  | Training Loss: 0.21425 \nEpoch: 3096  | Training Loss: 0.15447 \nEpoch: 3096  | Validation balanced accuracy : 0.76304 \nEpoch: 3097  | Training Loss: 0.31446 \nEpoch: 3097  | Training Loss: 0.36679 \nEpoch: 3097  | Training Loss: 0.34268 \nEpoch: 3097  | Training Loss: 0.21423 \nEpoch: 3097  | Training Loss: 0.15480 \nEpoch: 3097  | Validation balanced accuracy : 0.76304 \nEpoch: 3098  | Training Loss: 0.31410 \nEpoch: 3098  | Training Loss: 0.36654 \nEpoch: 3098  | Training Loss: 0.34279 \nEpoch: 3098  | Training Loss: 0.21421 \nEpoch: 3098  | Training Loss: 0.15478 \nEpoch: 3098  | Validation balanced accuracy : 0.76304 \nEpoch: 3099  | Training Loss: 0.31420 \nEpoch: 3099  | Training Loss: 0.36666 \nEpoch: 3099  | Training Loss: 0.34271 \nEpoch: 3099  | Training Loss: 0.21423 \nEpoch: 3099  | Training Loss: 0.15439 \nEpoch: 3099  | Validation balanced accuracy : 0.76304 \nEpoch: 3100  | Training Loss: 0.31450 \nEpoch: 3100  | Training Loss: 0.36682 \nEpoch: 3100  | Training Loss: 0.34271 \nEpoch: 3100  | Training Loss: 0.21421 \nEpoch: 3100  | Training Loss: 0.15474 \nEpoch: 3100  | Validation balanced accuracy : 0.76304 \nEpoch: 3101  | Training Loss: 0.31412 \nEpoch: 3101  | Training Loss: 0.36654 \nEpoch: 3101  | Training Loss: 0.34284 \nEpoch: 3101  | Training Loss: 0.21419 \nEpoch: 3101  | Training Loss: 0.15482 \nEpoch: 3101  | Validation balanced accuracy : 0.76304 \nEpoch: 3102  | Training Loss: 0.31414 \nEpoch: 3102  | Training Loss: 0.36661 \nEpoch: 3102  | Training Loss: 0.34278 \nEpoch: 3102  | Training Loss: 0.21421 \nEpoch: 3102  | Training Loss: 0.15441 \nEpoch: 3102  | Validation balanced accuracy : 0.76304 \nEpoch: 3103  | Training Loss: 0.31446 \nEpoch: 3103  | Training Loss: 0.36681 \nEpoch: 3103  | Training Loss: 0.34275 \nEpoch: 3103  | Training Loss: 0.21419 \nEpoch: 3103  | Training Loss: 0.15466 \nEpoch: 3103  | Validation balanced accuracy : 0.76304 \nEpoch: 3104  | Training Loss: 0.31416 \nEpoch: 3104  | Training Loss: 0.36658 \nEpoch: 3104  | Training Loss: 0.34285 \nEpoch: 3104  | Training Loss: 0.21418 \nEpoch: 3104  | Training Loss: 0.15468 \nEpoch: 3104  | Validation balanced accuracy : 0.76304 \nEpoch: 3105  | Training Loss: 0.31422 \nEpoch: 3105  | Training Loss: 0.36667 \nEpoch: 3105  | Training Loss: 0.34279 \nEpoch: 3105  | Training Loss: 0.21419 \nEpoch: 3105  | Training Loss: 0.15432 \nEpoch: 3105  | Validation balanced accuracy : 0.76304 \nEpoch: 3106  | Training Loss: 0.31448 \nEpoch: 3106  | Training Loss: 0.36682 \nEpoch: 3106  | Training Loss: 0.34278 \nEpoch: 3106  | Training Loss: 0.21417 \nEpoch: 3106  | Training Loss: 0.15465 \nEpoch: 3106  | Validation balanced accuracy : 0.76304 \nEpoch: 3107  | Training Loss: 0.31414 \nEpoch: 3107  | Training Loss: 0.36657 \nEpoch: 3107  | Training Loss: 0.34289 \nEpoch: 3107  | Training Loss: 0.21416 \nEpoch: 3107  | Training Loss: 0.15463 \nEpoch: 3107  | Validation balanced accuracy : 0.76304 \nEpoch: 3108  | Training Loss: 0.31424 \nEpoch: 3108  | Training Loss: 0.36669 \nEpoch: 3108  | Training Loss: 0.34280 \nEpoch: 3108  | Training Loss: 0.21418 \nEpoch: 3108  | Training Loss: 0.15417 \nEpoch: 3108  | Validation balanced accuracy : 0.76304 \nEpoch: 3109  | Training Loss: 0.31459 \nEpoch: 3109  | Training Loss: 0.36690 \nEpoch: 3109  | Training Loss: 0.34278 \nEpoch: 3109  | Training Loss: 0.21417 \nEpoch: 3109  | Training Loss: 0.15448 \nEpoch: 3109  | Validation balanced accuracy : 0.76304 \nEpoch: 3110  | Training Loss: 0.31423 \nEpoch: 3110  | Training Loss: 0.36662 \nEpoch: 3110  | Training Loss: 0.34290 \nEpoch: 3110  | Training Loss: 0.21414 \nEpoch: 3110  | Training Loss: 0.15457 \nEpoch: 3110  | Validation balanced accuracy : 0.76304 \nEpoch: 3111  | Training Loss: 0.31424 \nEpoch: 3111  | Training Loss: 0.36668 \nEpoch: 3111  | Training Loss: 0.34285 \nEpoch: 3111  | Training Loss: 0.21416 \nEpoch: 3111  | Training Loss: 0.15420 \nEpoch: 3111  | Validation balanced accuracy : 0.76304 \nEpoch: 3112  | Training Loss: 0.31453 \nEpoch: 3112  | Training Loss: 0.36686 \nEpoch: 3112  | Training Loss: 0.34283 \nEpoch: 3112  | Training Loss: 0.21415 \nEpoch: 3112  | Training Loss: 0.15449 \nEpoch: 3112  | Validation balanced accuracy : 0.76304 \nEpoch: 3113  | Training Loss: 0.31420 \nEpoch: 3113  | Training Loss: 0.36661 \nEpoch: 3113  | Training Loss: 0.34295 \nEpoch: 3113  | Training Loss: 0.21412 \nEpoch: 3113  | Training Loss: 0.15455 \nEpoch: 3113  | Validation balanced accuracy : 0.76304 \nEpoch: 3114  | Training Loss: 0.31424 \nEpoch: 3114  | Training Loss: 0.36669 \nEpoch: 3114  | Training Loss: 0.34288 \nEpoch: 3114  | Training Loss: 0.21414 \nEpoch: 3114  | Training Loss: 0.15414 \nEpoch: 3114  | Validation balanced accuracy : 0.76304 \nEpoch: 3115  | Training Loss: 0.31455 \nEpoch: 3115  | Training Loss: 0.36688 \nEpoch: 3115  | Training Loss: 0.34286 \nEpoch: 3115  | Training Loss: 0.21413 \nEpoch: 3115  | Training Loss: 0.15442 \nEpoch: 3115  | Validation balanced accuracy : 0.76304 \nEpoch: 3116  | Training Loss: 0.31423 \nEpoch: 3116  | Training Loss: 0.36663 \nEpoch: 3116  | Training Loss: 0.34297 \nEpoch: 3116  | Training Loss: 0.21411 \nEpoch: 3116  | Training Loss: 0.15447 \nEpoch: 3116  | Validation balanced accuracy : 0.76304 \nEpoch: 3117  | Training Loss: 0.31426 \nEpoch: 3117  | Training Loss: 0.36671 \nEpoch: 3117  | Training Loss: 0.34291 \nEpoch: 3117  | Training Loss: 0.21413 \nEpoch: 3117  | Training Loss: 0.15408 \nEpoch: 3117  | Validation balanced accuracy : 0.76304 \nEpoch: 3118  | Training Loss: 0.31457 \nEpoch: 3118  | Training Loss: 0.36689 \nEpoch: 3118  | Training Loss: 0.34289 \nEpoch: 3118  | Training Loss: 0.21411 \nEpoch: 3118  | Training Loss: 0.15436 \nEpoch: 3118  | Validation balanced accuracy : 0.76304 \nEpoch: 3119  | Training Loss: 0.31424 \nEpoch: 3119  | Training Loss: 0.36664 \nEpoch: 3119  | Training Loss: 0.34300 \nEpoch: 3119  | Training Loss: 0.21409 \nEpoch: 3119  | Training Loss: 0.15443 \nEpoch: 3119  | Validation balanced accuracy : 0.76304 \nEpoch: 3120  | Training Loss: 0.31427 \nEpoch: 3120  | Training Loss: 0.36671 \nEpoch: 3120  | Training Loss: 0.34294 \nEpoch: 3120  | Training Loss: 0.21411 \nEpoch: 3120  | Training Loss: 0.15403 \nEpoch: 3120  | Validation balanced accuracy : 0.76304 \nEpoch: 3121  | Training Loss: 0.31458 \nEpoch: 3121  | Training Loss: 0.36689 \nEpoch: 3121  | Training Loss: 0.34293 \nEpoch: 3121  | Training Loss: 0.21409 \nEpoch: 3121  | Training Loss: 0.15436 \nEpoch: 3121  | Validation balanced accuracy : 0.76304 \nEpoch: 3122  | Training Loss: 0.31422 \nEpoch: 3122  | Training Loss: 0.36663 \nEpoch: 3122  | Training Loss: 0.34304 \nEpoch: 3122  | Training Loss: 0.21407 \nEpoch: 3122  | Training Loss: 0.15436 \nEpoch: 3122  | Validation balanced accuracy : 0.76304 \nEpoch: 3123  | Training Loss: 0.31431 \nEpoch: 3123  | Training Loss: 0.36674 \nEpoch: 3123  | Training Loss: 0.34296 \nEpoch: 3123  | Training Loss: 0.21410 \nEpoch: 3123  | Training Loss: 0.15399 \nEpoch: 3123  | Validation balanced accuracy : 0.76304 \nEpoch: 3124  | Training Loss: 0.31458 \nEpoch: 3124  | Training Loss: 0.36689 \nEpoch: 3124  | Training Loss: 0.34296 \nEpoch: 3124  | Training Loss: 0.21408 \nEpoch: 3124  | Training Loss: 0.15432 \nEpoch: 3124  | Validation balanced accuracy : 0.76304 \nEpoch: 3125  | Training Loss: 0.31423 \nEpoch: 3125  | Training Loss: 0.36664 \nEpoch: 3125  | Training Loss: 0.34307 \nEpoch: 3125  | Training Loss: 0.21406 \nEpoch: 3125  | Training Loss: 0.15431 \nEpoch: 3125  | Validation balanced accuracy : 0.76304 \nEpoch: 3126  | Training Loss: 0.31432 \nEpoch: 3126  | Training Loss: 0.36676 \nEpoch: 3126  | Training Loss: 0.34299 \nEpoch: 3126  | Training Loss: 0.21408 \nEpoch: 3126  | Training Loss: 0.15387 \nEpoch: 3126  | Validation balanced accuracy : 0.76304 \nEpoch: 3127  | Training Loss: 0.31465 \nEpoch: 3127  | Training Loss: 0.36696 \nEpoch: 3127  | Training Loss: 0.34296 \nEpoch: 3127  | Training Loss: 0.21407 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3127  | Training Loss: 0.15415 \nEpoch: 3127  | Validation balanced accuracy : 0.76304 \nEpoch: 3128  | Training Loss: 0.31432 \nEpoch: 3128  | Training Loss: 0.36670 \nEpoch: 3128  | Training Loss: 0.34308 \nEpoch: 3128  | Training Loss: 0.21405 \nEpoch: 3128  | Training Loss: 0.15424 \nEpoch: 3128  | Validation balanced accuracy : 0.76304 \nEpoch: 3129  | Training Loss: 0.31433 \nEpoch: 3129  | Training Loss: 0.36676 \nEpoch: 3129  | Training Loss: 0.34302 \nEpoch: 3129  | Training Loss: 0.21406 \nEpoch: 3129  | Training Loss: 0.15387 \nEpoch: 3129  | Validation balanced accuracy : 0.76304 \nEpoch: 3130  | Training Loss: 0.31462 \nEpoch: 3130  | Training Loss: 0.36693 \nEpoch: 3130  | Training Loss: 0.34301 \nEpoch: 3130  | Training Loss: 0.21405 \nEpoch: 3130  | Training Loss: 0.15419 \nEpoch: 3130  | Validation balanced accuracy : 0.76304 \nEpoch: 3131  | Training Loss: 0.31428 \nEpoch: 3131  | Training Loss: 0.36668 \nEpoch: 3131  | Training Loss: 0.34312 \nEpoch: 3131  | Training Loss: 0.21403 \nEpoch: 3131  | Training Loss: 0.15418 \nEpoch: 3131  | Validation balanced accuracy : 0.76304 \nEpoch: 3132  | Training Loss: 0.31436 \nEpoch: 3132  | Training Loss: 0.36679 \nEpoch: 3132  | Training Loss: 0.34304 \nEpoch: 3132  | Training Loss: 0.21405 \nEpoch: 3132  | Training Loss: 0.15375 \nEpoch: 3132  | Validation balanced accuracy : 0.76304 \nEpoch: 3133  | Training Loss: 0.31469 \nEpoch: 3133  | Training Loss: 0.36698 \nEpoch: 3133  | Training Loss: 0.34302 \nEpoch: 3133  | Training Loss: 0.21404 \nEpoch: 3133  | Training Loss: 0.15409 \nEpoch: 3133  | Validation balanced accuracy : 0.76304 \nEpoch: 3134  | Training Loss: 0.31432 \nEpoch: 3134  | Training Loss: 0.36669 \nEpoch: 3134  | Training Loss: 0.34315 \nEpoch: 3134  | Training Loss: 0.21401 \nEpoch: 3134  | Training Loss: 0.15420 \nEpoch: 3134  | Validation balanced accuracy : 0.76304 \nEpoch: 3135  | Training Loss: 0.31432 \nEpoch: 3135  | Training Loss: 0.36675 \nEpoch: 3135  | Training Loss: 0.34310 \nEpoch: 3135  | Training Loss: 0.21403 \nEpoch: 3135  | Training Loss: 0.15384 \nEpoch: 3135  | Validation balanced accuracy : 0.76304 \nEpoch: 3136  | Training Loss: 0.31460 \nEpoch: 3136  | Training Loss: 0.36692 \nEpoch: 3136  | Training Loss: 0.34305 \nEpoch: 3136  | Training Loss: 0.21403 \nEpoch: 3136  | Training Loss: 0.15379 \nEpoch: 3136  | Validation balanced accuracy : 0.76304 \nEpoch: 3137  | Training Loss: 0.31457 \nEpoch: 3137  | Training Loss: 0.36686 \nEpoch: 3137  | Training Loss: 0.34311 \nEpoch: 3137  | Training Loss: 0.21401 \nEpoch: 3137  | Training Loss: 0.15406 \nEpoch: 3137  | Validation balanced accuracy : 0.76304 \nEpoch: 3138  | Training Loss: 0.31435 \nEpoch: 3138  | Training Loss: 0.36675 \nEpoch: 3138  | Training Loss: 0.34315 \nEpoch: 3138  | Training Loss: 0.21400 \nEpoch: 3138  | Training Loss: 0.15393 \nEpoch: 3138  | Validation balanced accuracy : 0.76304 \nEpoch: 3139  | Training Loss: 0.31449 \nEpoch: 3139  | Training Loss: 0.36689 \nEpoch: 3139  | Training Loss: 0.34307 \nEpoch: 3139  | Training Loss: 0.21402 \nEpoch: 3139  | Training Loss: 0.15357 \nEpoch: 3139  | Validation balanced accuracy : 0.76304 \nEpoch: 3140  | Training Loss: 0.31476 \nEpoch: 3140  | Training Loss: 0.36703 \nEpoch: 3140  | Training Loss: 0.34308 \nEpoch: 3140  | Training Loss: 0.21400 \nEpoch: 3140  | Training Loss: 0.15396 \nEpoch: 3140  | Validation balanced accuracy : 0.76304 \nEpoch: 3141  | Training Loss: 0.31435 \nEpoch: 3141  | Training Loss: 0.36672 \nEpoch: 3141  | Training Loss: 0.34322 \nEpoch: 3141  | Training Loss: 0.21397 \nEpoch: 3141  | Training Loss: 0.15410 \nEpoch: 3141  | Validation balanced accuracy : 0.76304 \nEpoch: 3142  | Training Loss: 0.31433 \nEpoch: 3142  | Training Loss: 0.36677 \nEpoch: 3142  | Training Loss: 0.34316 \nEpoch: 3142  | Training Loss: 0.21399 \nEpoch: 3142  | Training Loss: 0.15368 \nEpoch: 3142  | Validation balanced accuracy : 0.76304 \nEpoch: 3143  | Training Loss: 0.31467 \nEpoch: 3143  | Training Loss: 0.36698 \nEpoch: 3143  | Training Loss: 0.34313 \nEpoch: 3143  | Training Loss: 0.21398 \nEpoch: 3143  | Training Loss: 0.15395 \nEpoch: 3143  | Validation balanced accuracy : 0.76304 \nEpoch: 3144  | Training Loss: 0.31435 \nEpoch: 3144  | Training Loss: 0.36674 \nEpoch: 3144  | Training Loss: 0.34323 \nEpoch: 3144  | Training Loss: 0.21396 \nEpoch: 3144  | Training Loss: 0.15394 \nEpoch: 3144  | Validation balanced accuracy : 0.76304 \nEpoch: 3145  | Training Loss: 0.31444 \nEpoch: 3145  | Training Loss: 0.36685 \nEpoch: 3145  | Training Loss: 0.34315 \nEpoch: 3145  | Training Loss: 0.21399 \nEpoch: 3145  | Training Loss: 0.15353 \nEpoch: 3145  | Validation balanced accuracy : 0.76304 \nEpoch: 3146  | Training Loss: 0.31475 \nEpoch: 3146  | Training Loss: 0.36703 \nEpoch: 3146  | Training Loss: 0.34313 \nEpoch: 3146  | Training Loss: 0.21397 \nEpoch: 3146  | Training Loss: 0.15384 \nEpoch: 3146  | Validation balanced accuracy : 0.76304 \nEpoch: 3147  | Training Loss: 0.31440 \nEpoch: 3147  | Training Loss: 0.36676 \nEpoch: 3147  | Training Loss: 0.34326 \nEpoch: 3147  | Training Loss: 0.21395 \nEpoch: 3147  | Training Loss: 0.15395 \nEpoch: 3147  | Validation balanced accuracy : 0.76304 \nEpoch: 3148  | Training Loss: 0.31440 \nEpoch: 3148  | Training Loss: 0.36681 \nEpoch: 3148  | Training Loss: 0.34321 \nEpoch: 3148  | Training Loss: 0.21396 \nEpoch: 3148  | Training Loss: 0.15360 \nEpoch: 3148  | Validation balanced accuracy : 0.76304 \nEpoch: 3149  | Training Loss: 0.31467 \nEpoch: 3149  | Training Loss: 0.36697 \nEpoch: 3149  | Training Loss: 0.34320 \nEpoch: 3149  | Training Loss: 0.21395 \nEpoch: 3149  | Training Loss: 0.15392 \nEpoch: 3149  | Validation balanced accuracy : 0.76304 \nEpoch: 3150  | Training Loss: 0.31433 \nEpoch: 3150  | Training Loss: 0.36673 \nEpoch: 3150  | Training Loss: 0.34331 \nEpoch: 3150  | Training Loss: 0.21393 \nEpoch: 3150  | Training Loss: 0.15390 \nEpoch: 3150  | Validation balanced accuracy : 0.76304 \nEpoch: 3151  | Training Loss: 0.31442 \nEpoch: 3151  | Training Loss: 0.36684 \nEpoch: 3151  | Training Loss: 0.34322 \nEpoch: 3151  | Training Loss: 0.21395 \nEpoch: 3151  | Training Loss: 0.15347 \nEpoch: 3151  | Validation balanced accuracy : 0.76304 \nEpoch: 3152  | Training Loss: 0.31475 \nEpoch: 3152  | Training Loss: 0.36703 \nEpoch: 3152  | Training Loss: 0.34321 \nEpoch: 3152  | Training Loss: 0.21394 \nEpoch: 3152  | Training Loss: 0.15381 \nEpoch: 3152  | Validation balanced accuracy : 0.76304 \nEpoch: 3153  | Training Loss: 0.31438 \nEpoch: 3153  | Training Loss: 0.36676 \nEpoch: 3153  | Training Loss: 0.34332 \nEpoch: 3153  | Training Loss: 0.21392 \nEpoch: 3153  | Training Loss: 0.15384 \nEpoch: 3153  | Validation balanced accuracy : 0.76304 \nEpoch: 3154  | Training Loss: 0.31444 \nEpoch: 3154  | Training Loss: 0.36685 \nEpoch: 3154  | Training Loss: 0.34326 \nEpoch: 3154  | Training Loss: 0.21394 \nEpoch: 3154  | Training Loss: 0.15344 \nEpoch: 3154  | Validation balanced accuracy : 0.76304 \nEpoch: 3155  | Training Loss: 0.31474 \nEpoch: 3155  | Training Loss: 0.36703 \nEpoch: 3155  | Training Loss: 0.34324 \nEpoch: 3155  | Training Loss: 0.21392 \nEpoch: 3155  | Training Loss: 0.15376 \nEpoch: 3155  | Validation balanced accuracy : 0.76304 \nEpoch: 3156  | Training Loss: 0.31440 \nEpoch: 3156  | Training Loss: 0.36677 \nEpoch: 3156  | Training Loss: 0.34335 \nEpoch: 3156  | Training Loss: 0.21390 \nEpoch: 3156  | Training Loss: 0.15377 \nEpoch: 3156  | Validation balanced accuracy : 0.76304 \nEpoch: 3157  | Training Loss: 0.31447 \nEpoch: 3157  | Training Loss: 0.36687 \nEpoch: 3157  | Training Loss: 0.34328 \nEpoch: 3157  | Training Loss: 0.21392 \nEpoch: 3157  | Training Loss: 0.15338 \nEpoch: 3157  | Validation balanced accuracy : 0.76304 \nEpoch: 3158  | Training Loss: 0.31477 \nEpoch: 3158  | Training Loss: 0.36705 \nEpoch: 3158  | Training Loss: 0.34326 \nEpoch: 3158  | Training Loss: 0.21391 \nEpoch: 3158  | Training Loss: 0.15370 \nEpoch: 3158  | Validation balanced accuracy : 0.76304 \nEpoch: 3159  | Training Loss: 0.31442 \nEpoch: 3159  | Training Loss: 0.36678 \nEpoch: 3159  | Training Loss: 0.34339 \nEpoch: 3159  | Training Loss: 0.21388 \nEpoch: 3159  | Training Loss: 0.15380 \nEpoch: 3159  | Validation balanced accuracy : 0.76304 \nEpoch: 3160  | Training Loss: 0.31442 \nEpoch: 3160  | Training Loss: 0.36685 \nEpoch: 3160  | Training Loss: 0.34332 \nEpoch: 3160  | Training Loss: 0.21391 \nEpoch: 3160  | Training Loss: 0.15337 \nEpoch: 3160  | Validation balanced accuracy : 0.76304 \nEpoch: 3161  | Training Loss: 0.31476 \nEpoch: 3161  | Training Loss: 0.36705 \nEpoch: 3161  | Training Loss: 0.34329 \nEpoch: 3161  | Training Loss: 0.21389 \nEpoch: 3161  | Training Loss: 0.15364 \nEpoch: 3161  | Validation balanced accuracy : 0.76304 \nEpoch: 3162  | Training Loss: 0.31444 \nEpoch: 3162  | Training Loss: 0.36681 \nEpoch: 3162  | Training Loss: 0.34339 \nEpoch: 3162  | Training Loss: 0.21388 \nEpoch: 3162  | Training Loss: 0.15365 \nEpoch: 3162  | Validation balanced accuracy : 0.76304 \nEpoch: 3163  | Training Loss: 0.31452 \nEpoch: 3163  | Training Loss: 0.36691 \nEpoch: 3163  | Training Loss: 0.34332 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3163  | Training Loss: 0.21390 \nEpoch: 3163  | Training Loss: 0.15326 \nEpoch: 3163  | Validation balanced accuracy : 0.76304 \nEpoch: 3164  | Training Loss: 0.31481 \nEpoch: 3164  | Training Loss: 0.36708 \nEpoch: 3164  | Training Loss: 0.34331 \nEpoch: 3164  | Training Loss: 0.21388 \nEpoch: 3164  | Training Loss: 0.15360 \nEpoch: 3164  | Validation balanced accuracy : 0.76304 \nEpoch: 3165  | Training Loss: 0.31445 \nEpoch: 3165  | Training Loss: 0.36682 \nEpoch: 3165  | Training Loss: 0.34342 \nEpoch: 3165  | Training Loss: 0.21386 \nEpoch: 3165  | Training Loss: 0.15364 \nEpoch: 3165  | Validation balanced accuracy : 0.76304 \nEpoch: 3166  | Training Loss: 0.31450 \nEpoch: 3166  | Training Loss: 0.36690 \nEpoch: 3166  | Training Loss: 0.34336 \nEpoch: 3166  | Training Loss: 0.21388 \nEpoch: 3166  | Training Loss: 0.15327 \nEpoch: 3166  | Validation balanced accuracy : 0.76304 \nEpoch: 3167  | Training Loss: 0.31479 \nEpoch: 3167  | Training Loss: 0.36706 \nEpoch: 3167  | Training Loss: 0.34335 \nEpoch: 3167  | Training Loss: 0.21386 \nEpoch: 3167  | Training Loss: 0.15363 \nEpoch: 3167  | Validation balanced accuracy : 0.76304 \nEpoch: 3168  | Training Loss: 0.31440 \nEpoch: 3168  | Training Loss: 0.36678 \nEpoch: 3168  | Training Loss: 0.34347 \nEpoch: 3168  | Training Loss: 0.21384 \nEpoch: 3168  | Training Loss: 0.15367 \nEpoch: 3168  | Validation balanced accuracy : 0.76304 \nEpoch: 3169  | Training Loss: 0.31446 \nEpoch: 3169  | Training Loss: 0.36688 \nEpoch: 3169  | Training Loss: 0.34340 \nEpoch: 3169  | Training Loss: 0.21386 \nEpoch: 3169  | Training Loss: 0.15327 \nEpoch: 3169  | Validation balanced accuracy : 0.76304 \nEpoch: 3170  | Training Loss: 0.31477 \nEpoch: 3170  | Training Loss: 0.36706 \nEpoch: 3170  | Training Loss: 0.34338 \nEpoch: 3170  | Training Loss: 0.21385 \nEpoch: 3170  | Training Loss: 0.15356 \nEpoch: 3170  | Validation balanced accuracy : 0.76304 \nEpoch: 3171  | Training Loss: 0.31444 \nEpoch: 3171  | Training Loss: 0.36682 \nEpoch: 3171  | Training Loss: 0.34349 \nEpoch: 3171  | Training Loss: 0.21383 \nEpoch: 3171  | Training Loss: 0.15357 \nEpoch: 3171  | Validation balanced accuracy : 0.76304 \nEpoch: 3172  | Training Loss: 0.31452 \nEpoch: 3172  | Training Loss: 0.36692 \nEpoch: 3172  | Training Loss: 0.34341 \nEpoch: 3172  | Training Loss: 0.21385 \nEpoch: 3172  | Training Loss: 0.15316 \nEpoch: 3172  | Validation balanced accuracy : 0.76304 \nEpoch: 3173  | Training Loss: 0.31482 \nEpoch: 3173  | Training Loss: 0.36710 \nEpoch: 3173  | Training Loss: 0.34339 \nEpoch: 3173  | Training Loss: 0.21384 \nEpoch: 3173  | Training Loss: 0.15348 \nEpoch: 3173  | Validation balanced accuracy : 0.76304 \nEpoch: 3174  | Training Loss: 0.31447 \nEpoch: 3174  | Training Loss: 0.36684 \nEpoch: 3174  | Training Loss: 0.34350 \nEpoch: 3174  | Training Loss: 0.21382 \nEpoch: 3174  | Training Loss: 0.15351 \nEpoch: 3174  | Validation balanced accuracy : 0.76304 \nEpoch: 3175  | Training Loss: 0.31453 \nEpoch: 3175  | Training Loss: 0.36693 \nEpoch: 3175  | Training Loss: 0.34344 \nEpoch: 3175  | Training Loss: 0.21384 \nEpoch: 3175  | Training Loss: 0.15313 \nEpoch: 3175  | Validation balanced accuracy : 0.76304 \nEpoch: 3176  | Training Loss: 0.31483 \nEpoch: 3176  | Training Loss: 0.36710 \nEpoch: 3176  | Training Loss: 0.34342 \nEpoch: 3176  | Training Loss: 0.21382 \nEpoch: 3176  | Training Loss: 0.15345 \nEpoch: 3176  | Validation balanced accuracy : 0.76304 \nEpoch: 3177  | Training Loss: 0.31447 \nEpoch: 3177  | Training Loss: 0.36684 \nEpoch: 3177  | Training Loss: 0.34353 \nEpoch: 3177  | Training Loss: 0.21380 \nEpoch: 3177  | Training Loss: 0.15348 \nEpoch: 3177  | Validation balanced accuracy : 0.76304 \nEpoch: 3178  | Training Loss: 0.31453 \nEpoch: 3178  | Training Loss: 0.36693 \nEpoch: 3178  | Training Loss: 0.34347 \nEpoch: 3178  | Training Loss: 0.21382 \nEpoch: 3178  | Training Loss: 0.15310 \nEpoch: 3178  | Validation balanced accuracy : 0.76304 \nEpoch: 3179  | Training Loss: 0.31483 \nEpoch: 3179  | Training Loss: 0.36710 \nEpoch: 3179  | Training Loss: 0.34345 \nEpoch: 3179  | Training Loss: 0.21381 \nEpoch: 3179  | Training Loss: 0.15342 \nEpoch: 3179  | Validation balanced accuracy : 0.76304 \nEpoch: 3180  | Training Loss: 0.31448 \nEpoch: 3180  | Training Loss: 0.36685 \nEpoch: 3180  | Training Loss: 0.34356 \nEpoch: 3180  | Training Loss: 0.21379 \nEpoch: 3180  | Training Loss: 0.15344 \nEpoch: 3180  | Validation balanced accuracy : 0.76304 \nEpoch: 3181  | Training Loss: 0.31454 \nEpoch: 3181  | Training Loss: 0.36694 \nEpoch: 3181  | Training Loss: 0.34349 \nEpoch: 3181  | Training Loss: 0.21381 \nEpoch: 3181  | Training Loss: 0.15305 \nEpoch: 3181  | Validation balanced accuracy : 0.76304 \nEpoch: 3182  | Training Loss: 0.31484 \nEpoch: 3182  | Training Loss: 0.36711 \nEpoch: 3182  | Training Loss: 0.34348 \nEpoch: 3182  | Training Loss: 0.21379 \nEpoch: 3182  | Training Loss: 0.15341 \nEpoch: 3182  | Validation balanced accuracy : 0.76304 \nEpoch: 3183  | Training Loss: 0.31446 \nEpoch: 3183  | Training Loss: 0.36683 \nEpoch: 3183  | Training Loss: 0.34360 \nEpoch: 3183  | Training Loss: 0.21377 \nEpoch: 3183  | Training Loss: 0.15345 \nEpoch: 3183  | Validation balanced accuracy : 0.76304 \nEpoch: 3184  | Training Loss: 0.31452 \nEpoch: 3184  | Training Loss: 0.36694 \nEpoch: 3184  | Training Loss: 0.34352 \nEpoch: 3184  | Training Loss: 0.21380 \nEpoch: 3184  | Training Loss: 0.15298 \nEpoch: 3184  | Validation balanced accuracy : 0.76304 \nEpoch: 3185  | Training Loss: 0.31489 \nEpoch: 3185  | Training Loss: 0.36716 \nEpoch: 3185  | Training Loss: 0.34348 \nEpoch: 3185  | Training Loss: 0.21378 \nEpoch: 3185  | Training Loss: 0.15324 \nEpoch: 3185  | Validation balanced accuracy : 0.76304 \nEpoch: 3186  | Training Loss: 0.31456 \nEpoch: 3186  | Training Loss: 0.36690 \nEpoch: 3186  | Training Loss: 0.34360 \nEpoch: 3186  | Training Loss: 0.21376 \nEpoch: 3186  | Training Loss: 0.15335 \nEpoch: 3186  | Validation balanced accuracy : 0.76304 \nEpoch: 3187  | Training Loss: 0.31456 \nEpoch: 3187  | Training Loss: 0.36695 \nEpoch: 3187  | Training Loss: 0.34355 \nEpoch: 3187  | Training Loss: 0.21378 \nEpoch: 3187  | Training Loss: 0.15302 \nEpoch: 3187  | Validation balanced accuracy : 0.76304 \nEpoch: 3188  | Training Loss: 0.31482 \nEpoch: 3188  | Training Loss: 0.36710 \nEpoch: 3188  | Training Loss: 0.34351 \nEpoch: 3188  | Training Loss: 0.21378 \nEpoch: 3188  | Training Loss: 0.15303 \nEpoch: 3188  | Validation balanced accuracy : 0.76304 \nEpoch: 3189  | Training Loss: 0.31475 \nEpoch: 3189  | Training Loss: 0.36701 \nEpoch: 3189  | Training Loss: 0.34358 \nEpoch: 3189  | Training Loss: 0.21375 \nEpoch: 3189  | Training Loss: 0.15328 \nEpoch: 3189  | Validation balanced accuracy : 0.76304 \nEpoch: 3190  | Training Loss: 0.31456 \nEpoch: 3190  | Training Loss: 0.36693 \nEpoch: 3190  | Training Loss: 0.34361 \nEpoch: 3190  | Training Loss: 0.21375 \nEpoch: 3190  | Training Loss: 0.15313 \nEpoch: 3190  | Validation balanced accuracy : 0.76304 \nEpoch: 3191  | Training Loss: 0.31471 \nEpoch: 3191  | Training Loss: 0.36707 \nEpoch: 3191  | Training Loss: 0.34352 \nEpoch: 3191  | Training Loss: 0.21378 \nEpoch: 3191  | Training Loss: 0.15278 \nEpoch: 3191  | Validation balanced accuracy : 0.76304 \nEpoch: 3192  | Training Loss: 0.31496 \nEpoch: 3192  | Training Loss: 0.36720 \nEpoch: 3192  | Training Loss: 0.34354 \nEpoch: 3192  | Training Loss: 0.21375 \nEpoch: 3192  | Training Loss: 0.15320 \nEpoch: 3192  | Validation balanced accuracy : 0.76304 \nEpoch: 3193  | Training Loss: 0.31454 \nEpoch: 3193  | Training Loss: 0.36689 \nEpoch: 3193  | Training Loss: 0.34367 \nEpoch: 3193  | Training Loss: 0.21372 \nEpoch: 3193  | Training Loss: 0.15330 \nEpoch: 3193  | Validation balanced accuracy : 0.76304 \nEpoch: 3194  | Training Loss: 0.31456 \nEpoch: 3194  | Training Loss: 0.36697 \nEpoch: 3194  | Training Loss: 0.34360 \nEpoch: 3194  | Training Loss: 0.21375 \nEpoch: 3194  | Training Loss: 0.15287 \nEpoch: 3194  | Validation balanced accuracy : 0.76304 \nEpoch: 3195  | Training Loss: 0.31490 \nEpoch: 3195  | Training Loss: 0.36716 \nEpoch: 3195  | Training Loss: 0.34358 \nEpoch: 3195  | Training Loss: 0.21373 \nEpoch: 3195  | Training Loss: 0.15319 \nEpoch: 3195  | Validation balanced accuracy : 0.76304 \nEpoch: 3196  | Training Loss: 0.31454 \nEpoch: 3196  | Training Loss: 0.36690 \nEpoch: 3196  | Training Loss: 0.34370 \nEpoch: 3196  | Training Loss: 0.21371 \nEpoch: 3196  | Training Loss: 0.15323 \nEpoch: 3196  | Validation balanced accuracy : 0.76304 \nEpoch: 3197  | Training Loss: 0.31460 \nEpoch: 3197  | Training Loss: 0.36699 \nEpoch: 3197  | Training Loss: 0.34363 \nEpoch: 3197  | Training Loss: 0.21374 \nEpoch: 3197  | Training Loss: 0.15284 \nEpoch: 3197  | Validation balanced accuracy : 0.76304 \nEpoch: 3198  | Training Loss: 0.31489 \nEpoch: 3198  | Training Loss: 0.36716 \nEpoch: 3198  | Training Loss: 0.34357 \nEpoch: 3198  | Training Loss: 0.21374 \nEpoch: 3198  | Training Loss: 0.15283 \nEpoch: 3198  | Validation balanced accuracy : 0.76304 \nEpoch: 3199  | Training Loss: 0.31483 \nEpoch: 3199  | Training Loss: 0.36707 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3199  | Training Loss: 0.34365 \nEpoch: 3199  | Training Loss: 0.21371 \nEpoch: 3199  | Training Loss: 0.15316 \nEpoch: 3199  | Validation balanced accuracy : 0.76304 \nEpoch: 3200  | Training Loss: 0.31457 \nEpoch: 3200  | Training Loss: 0.36695 \nEpoch: 3200  | Training Loss: 0.34370 \nEpoch: 3200  | Training Loss: 0.21371 \nEpoch: 3200  | Training Loss: 0.15301 \nEpoch: 3200  | Validation balanced accuracy : 0.76304 \nEpoch: 3201  | Training Loss: 0.31474 \nEpoch: 3201  | Training Loss: 0.36711 \nEpoch: 3201  | Training Loss: 0.34360 \nEpoch: 3201  | Training Loss: 0.21373 \nEpoch: 3201  | Training Loss: 0.15264 \nEpoch: 3201  | Validation balanced accuracy : 0.76304 \nEpoch: 3202  | Training Loss: 0.31500 \nEpoch: 3202  | Training Loss: 0.36724 \nEpoch: 3202  | Training Loss: 0.34361 \nEpoch: 3202  | Training Loss: 0.21371 \nEpoch: 3202  | Training Loss: 0.15305 \nEpoch: 3202  | Validation balanced accuracy : 0.76304 \nEpoch: 3203  | Training Loss: 0.31458 \nEpoch: 3203  | Training Loss: 0.36693 \nEpoch: 3203  | Training Loss: 0.34375 \nEpoch: 3203  | Training Loss: 0.21368 \nEpoch: 3203  | Training Loss: 0.15316 \nEpoch: 3203  | Validation balanced accuracy : 0.76304 \nEpoch: 3204  | Training Loss: 0.31460 \nEpoch: 3204  | Training Loss: 0.36700 \nEpoch: 3204  | Training Loss: 0.34368 \nEpoch: 3204  | Training Loss: 0.21371 \nEpoch: 3204  | Training Loss: 0.15273 \nEpoch: 3204  | Validation balanced accuracy : 0.76304 \nEpoch: 3205  | Training Loss: 0.31494 \nEpoch: 3205  | Training Loss: 0.36720 \nEpoch: 3205  | Training Loss: 0.34365 \nEpoch: 3205  | Training Loss: 0.21369 \nEpoch: 3205  | Training Loss: 0.15302 \nEpoch: 3205  | Validation balanced accuracy : 0.76304 \nEpoch: 3206  | Training Loss: 0.31460 \nEpoch: 3206  | Training Loss: 0.36695 \nEpoch: 3206  | Training Loss: 0.34376 \nEpoch: 3206  | Training Loss: 0.21367 \nEpoch: 3206  | Training Loss: 0.15305 \nEpoch: 3206  | Validation balanced accuracy : 0.76304 \nEpoch: 3207  | Training Loss: 0.31466 \nEpoch: 3207  | Training Loss: 0.36704 \nEpoch: 3207  | Training Loss: 0.34369 \nEpoch: 3207  | Training Loss: 0.21370 \nEpoch: 3207  | Training Loss: 0.15268 \nEpoch: 3207  | Validation balanced accuracy : 0.76304 \nEpoch: 3208  | Training Loss: 0.31495 \nEpoch: 3208  | Training Loss: 0.36720 \nEpoch: 3208  | Training Loss: 0.34369 \nEpoch: 3208  | Training Loss: 0.21367 \nEpoch: 3208  | Training Loss: 0.15306 \nEpoch: 3208  | Validation balanced accuracy : 0.76304 \nEpoch: 3209  | Training Loss: 0.31455 \nEpoch: 3209  | Training Loss: 0.36691 \nEpoch: 3209  | Training Loss: 0.34382 \nEpoch: 3209  | Training Loss: 0.21365 \nEpoch: 3209  | Training Loss: 0.15312 \nEpoch: 3209  | Validation balanced accuracy : 0.76304 \nEpoch: 3210  | Training Loss: 0.31460 \nEpoch: 3210  | Training Loss: 0.36701 \nEpoch: 3210  | Training Loss: 0.34374 \nEpoch: 3210  | Training Loss: 0.21368 \nEpoch: 3210  | Training Loss: 0.15266 \nEpoch: 3210  | Validation balanced accuracy : 0.76304 \nEpoch: 3211  | Training Loss: 0.31496 \nEpoch: 3211  | Training Loss: 0.36722 \nEpoch: 3211  | Training Loss: 0.34370 \nEpoch: 3211  | Training Loss: 0.21367 \nEpoch: 3211  | Training Loss: 0.15292 \nEpoch: 3211  | Validation balanced accuracy : 0.76304 \nEpoch: 3212  | Training Loss: 0.31464 \nEpoch: 3212  | Training Loss: 0.36697 \nEpoch: 3212  | Training Loss: 0.34382 \nEpoch: 3212  | Training Loss: 0.21365 \nEpoch: 3212  | Training Loss: 0.15302 \nEpoch: 3212  | Validation balanced accuracy : 0.76304 \nEpoch: 3213  | Training Loss: 0.31464 \nEpoch: 3213  | Training Loss: 0.36702 \nEpoch: 3213  | Training Loss: 0.34377 \nEpoch: 3213  | Training Loss: 0.21366 \nEpoch: 3213  | Training Loss: 0.15269 \nEpoch: 3213  | Validation balanced accuracy : 0.76304 \nEpoch: 3214  | Training Loss: 0.31490 \nEpoch: 3214  | Training Loss: 0.36717 \nEpoch: 3214  | Training Loss: 0.34373 \nEpoch: 3214  | Training Loss: 0.21366 \nEpoch: 3214  | Training Loss: 0.15269 \nEpoch: 3214  | Validation balanced accuracy : 0.76304 \nEpoch: 3215  | Training Loss: 0.31483 \nEpoch: 3215  | Training Loss: 0.36715 \nEpoch: 3215  | Training Loss: 0.34373 \nEpoch: 3215  | Training Loss: 0.21366 \nEpoch: 3215  | Training Loss: 0.15259 \nEpoch: 3215  | Validation balanced accuracy : 0.76304 \nEpoch: 3216  | Training Loss: 0.31492 \nEpoch: 3216  | Training Loss: 0.36716 \nEpoch: 3216  | Training Loss: 0.34376 \nEpoch: 3216  | Training Loss: 0.21365 \nEpoch: 3216  | Training Loss: 0.15279 \nEpoch: 3216  | Validation balanced accuracy : 0.76304 \nEpoch: 3217  | Training Loss: 0.31474 \nEpoch: 3217  | Training Loss: 0.36707 \nEpoch: 3217  | Training Loss: 0.34379 \nEpoch: 3217  | Training Loss: 0.21364 \nEpoch: 3217  | Training Loss: 0.15269 \nEpoch: 3217  | Validation balanced accuracy : 0.76304 \nEpoch: 3218  | Training Loss: 0.31485 \nEpoch: 3218  | Training Loss: 0.36712 \nEpoch: 3218  | Training Loss: 0.34379 \nEpoch: 3218  | Training Loss: 0.21364 \nEpoch: 3218  | Training Loss: 0.15276 \nEpoch: 3218  | Validation balanced accuracy : 0.76304 \nEpoch: 3219  | Training Loss: 0.31477 \nEpoch: 3219  | Training Loss: 0.36711 \nEpoch: 3219  | Training Loss: 0.34378 \nEpoch: 3219  | Training Loss: 0.21364 \nEpoch: 3219  | Training Loss: 0.15255 \nEpoch: 3219  | Validation balanced accuracy : 0.76304 \nEpoch: 3220  | Training Loss: 0.31494 \nEpoch: 3220  | Training Loss: 0.36719 \nEpoch: 3220  | Training Loss: 0.34378 \nEpoch: 3220  | Training Loss: 0.21364 \nEpoch: 3220  | Training Loss: 0.15269 \nEpoch: 3220  | Validation balanced accuracy : 0.76304 \nEpoch: 3221  | Training Loss: 0.31479 \nEpoch: 3221  | Training Loss: 0.36711 \nEpoch: 3221  | Training Loss: 0.34381 \nEpoch: 3221  | Training Loss: 0.21363 \nEpoch: 3221  | Training Loss: 0.15259 \nEpoch: 3221  | Validation balanced accuracy : 0.76304 \nEpoch: 3222  | Training Loss: 0.31490 \nEpoch: 3222  | Training Loss: 0.36716 \nEpoch: 3222  | Training Loss: 0.34381 \nEpoch: 3222  | Training Loss: 0.21362 \nEpoch: 3222  | Training Loss: 0.15273 \nEpoch: 3222  | Validation balanced accuracy : 0.76304 \nEpoch: 3223  | Training Loss: 0.31475 \nEpoch: 3223  | Training Loss: 0.36709 \nEpoch: 3223  | Training Loss: 0.34383 \nEpoch: 3223  | Training Loss: 0.21362 \nEpoch: 3223  | Training Loss: 0.15260 \nEpoch: 3223  | Validation balanced accuracy : 0.76304 \nEpoch: 3224  | Training Loss: 0.31489 \nEpoch: 3224  | Training Loss: 0.36715 \nEpoch: 3224  | Training Loss: 0.34383 \nEpoch: 3224  | Training Loss: 0.21361 \nEpoch: 3224  | Training Loss: 0.15271 \nEpoch: 3224  | Validation balanced accuracy : 0.76304 \nEpoch: 3225  | Training Loss: 0.31476 \nEpoch: 3225  | Training Loss: 0.36710 \nEpoch: 3225  | Training Loss: 0.34385 \nEpoch: 3225  | Training Loss: 0.21361 \nEpoch: 3225  | Training Loss: 0.15256 \nEpoch: 3225  | Validation balanced accuracy : 0.76304 \nEpoch: 3226  | Training Loss: 0.31490 \nEpoch: 3226  | Training Loss: 0.36717 \nEpoch: 3226  | Training Loss: 0.34384 \nEpoch: 3226  | Training Loss: 0.21361 \nEpoch: 3226  | Training Loss: 0.15266 \nEpoch: 3226  | Validation balanced accuracy : 0.76304 \nEpoch: 3227  | Training Loss: 0.31478 \nEpoch: 3227  | Training Loss: 0.36711 \nEpoch: 3227  | Training Loss: 0.34386 \nEpoch: 3227  | Training Loss: 0.21361 \nEpoch: 3227  | Training Loss: 0.15252 \nEpoch: 3227  | Validation balanced accuracy : 0.76304 \nEpoch: 3228  | Training Loss: 0.31492 \nEpoch: 3228  | Training Loss: 0.36718 \nEpoch: 3228  | Training Loss: 0.34385 \nEpoch: 3228  | Training Loss: 0.21360 \nEpoch: 3228  | Training Loss: 0.15263 \nEpoch: 3228  | Validation balanced accuracy : 0.76304 \nEpoch: 3229  | Training Loss: 0.31479 \nEpoch: 3229  | Training Loss: 0.36712 \nEpoch: 3229  | Training Loss: 0.34388 \nEpoch: 3229  | Training Loss: 0.21360 \nEpoch: 3229  | Training Loss: 0.15253 \nEpoch: 3229  | Validation balanced accuracy : 0.76304 \nEpoch: 3230  | Training Loss: 0.31489 \nEpoch: 3230  | Training Loss: 0.36716 \nEpoch: 3230  | Training Loss: 0.34388 \nEpoch: 3230  | Training Loss: 0.21359 \nEpoch: 3230  | Training Loss: 0.15260 \nEpoch: 3230  | Validation balanced accuracy : 0.76304 \nEpoch: 3231  | Training Loss: 0.31481 \nEpoch: 3231  | Training Loss: 0.36714 \nEpoch: 3231  | Training Loss: 0.34387 \nEpoch: 3231  | Training Loss: 0.21360 \nEpoch: 3231  | Training Loss: 0.15241 \nEpoch: 3231  | Validation balanced accuracy : 0.76304 \nEpoch: 3232  | Training Loss: 0.31498 \nEpoch: 3232  | Training Loss: 0.36723 \nEpoch: 3232  | Training Loss: 0.34386 \nEpoch: 3232  | Training Loss: 0.21359 \nEpoch: 3232  | Training Loss: 0.15252 \nEpoch: 3232  | Validation balanced accuracy : 0.76304 \nEpoch: 3233  | Training Loss: 0.31485 \nEpoch: 3233  | Training Loss: 0.36716 \nEpoch: 3233  | Training Loss: 0.34388 \nEpoch: 3233  | Training Loss: 0.21359 \nEpoch: 3233  | Training Loss: 0.15240 \nEpoch: 3233  | Validation balanced accuracy : 0.76304 \nEpoch: 3234  | Training Loss: 0.31497 \nEpoch: 3234  | Training Loss: 0.36722 \nEpoch: 3234  | Training Loss: 0.34389 \nEpoch: 3234  | Training Loss: 0.21358 \nEpoch: 3234  | Training Loss: 0.15254 \nEpoch: 3234  | Validation balanced accuracy : 0.76304 \nEpoch: 3235  | Training Loss: 0.31481 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3235  | Training Loss: 0.36714 \nEpoch: 3235  | Training Loss: 0.34391 \nEpoch: 3235  | Training Loss: 0.21358 \nEpoch: 3235  | Training Loss: 0.15243 \nEpoch: 3235  | Validation balanced accuracy : 0.76304 \nEpoch: 3236  | Training Loss: 0.31493 \nEpoch: 3236  | Training Loss: 0.36719 \nEpoch: 3236  | Training Loss: 0.34392 \nEpoch: 3236  | Training Loss: 0.21357 \nEpoch: 3236  | Training Loss: 0.15256 \nEpoch: 3236  | Validation balanced accuracy : 0.76304 \nEpoch: 3237  | Training Loss: 0.31480 \nEpoch: 3237  | Training Loss: 0.36713 \nEpoch: 3237  | Training Loss: 0.34394 \nEpoch: 3237  | Training Loss: 0.21357 \nEpoch: 3237  | Training Loss: 0.15243 \nEpoch: 3237  | Validation balanced accuracy : 0.76304 \nEpoch: 3238  | Training Loss: 0.31493 \nEpoch: 3238  | Training Loss: 0.36719 \nEpoch: 3238  | Training Loss: 0.34394 \nEpoch: 3238  | Training Loss: 0.21356 \nEpoch: 3238  | Training Loss: 0.15251 \nEpoch: 3238  | Validation balanced accuracy : 0.76304 \nEpoch: 3239  | Training Loss: 0.31483 \nEpoch: 3239  | Training Loss: 0.36716 \nEpoch: 3239  | Training Loss: 0.34394 \nEpoch: 3239  | Training Loss: 0.21356 \nEpoch: 3239  | Training Loss: 0.15233 \nEpoch: 3239  | Validation balanced accuracy : 0.76304 \nEpoch: 3240  | Training Loss: 0.31499 \nEpoch: 3240  | Training Loss: 0.36724 \nEpoch: 3240  | Training Loss: 0.34393 \nEpoch: 3240  | Training Loss: 0.21356 \nEpoch: 3240  | Training Loss: 0.15244 \nEpoch: 3240  | Validation balanced accuracy : 0.76304 \nEpoch: 3241  | Training Loss: 0.31486 \nEpoch: 3241  | Training Loss: 0.36718 \nEpoch: 3241  | Training Loss: 0.34395 \nEpoch: 3241  | Training Loss: 0.21356 \nEpoch: 3241  | Training Loss: 0.15232 \nEpoch: 3241  | Validation balanced accuracy : 0.76304 \nEpoch: 3242  | Training Loss: 0.31498 \nEpoch: 3242  | Training Loss: 0.36723 \nEpoch: 3242  | Training Loss: 0.34395 \nEpoch: 3242  | Training Loss: 0.21354 \nEpoch: 3242  | Training Loss: 0.15246 \nEpoch: 3242  | Validation balanced accuracy : 0.76304 \nEpoch: 3243  | Training Loss: 0.31483 \nEpoch: 3243  | Training Loss: 0.36716 \nEpoch: 3243  | Training Loss: 0.34398 \nEpoch: 3243  | Training Loss: 0.21354 \nEpoch: 3243  | Training Loss: 0.15234 \nEpoch: 3243  | Validation balanced accuracy : 0.76304 \nEpoch: 3244  | Training Loss: 0.31496 \nEpoch: 3244  | Training Loss: 0.36722 \nEpoch: 3244  | Training Loss: 0.34398 \nEpoch: 3244  | Training Loss: 0.21353 \nEpoch: 3244  | Training Loss: 0.15247 \nEpoch: 3244  | Validation balanced accuracy : 0.76304 \nEpoch: 3245  | Training Loss: 0.31482 \nEpoch: 3245  | Training Loss: 0.36715 \nEpoch: 3245  | Training Loss: 0.34400 \nEpoch: 3245  | Training Loss: 0.21353 \nEpoch: 3245  | Training Loss: 0.15233 \nEpoch: 3245  | Validation balanced accuracy : 0.76304 \nEpoch: 3246  | Training Loss: 0.31496 \nEpoch: 3246  | Training Loss: 0.36722 \nEpoch: 3246  | Training Loss: 0.34399 \nEpoch: 3246  | Training Loss: 0.21353 \nEpoch: 3246  | Training Loss: 0.15238 \nEpoch: 3246  | Validation balanced accuracy : 0.76304 \nEpoch: 3247  | Training Loss: 0.31488 \nEpoch: 3247  | Training Loss: 0.36721 \nEpoch: 3247  | Training Loss: 0.34398 \nEpoch: 3247  | Training Loss: 0.21354 \nEpoch: 3247  | Training Loss: 0.15219 \nEpoch: 3247  | Validation balanced accuracy : 0.76304 \nEpoch: 3248  | Training Loss: 0.31505 \nEpoch: 3248  | Training Loss: 0.36728 \nEpoch: 3248  | Training Loss: 0.34398 \nEpoch: 3248  | Training Loss: 0.21353 \nEpoch: 3248  | Training Loss: 0.15234 \nEpoch: 3248  | Validation balanced accuracy : 0.76304 \nEpoch: 3249  | Training Loss: 0.31488 \nEpoch: 3249  | Training Loss: 0.36719 \nEpoch: 3249  | Training Loss: 0.34401 \nEpoch: 3249  | Training Loss: 0.21352 \nEpoch: 3249  | Training Loss: 0.15226 \nEpoch: 3249  | Validation balanced accuracy : 0.76304 \nEpoch: 3250  | Training Loss: 0.31498 \nEpoch: 3250  | Training Loss: 0.36723 \nEpoch: 3250  | Training Loss: 0.34402 \nEpoch: 3250  | Training Loss: 0.21351 \nEpoch: 3250  | Training Loss: 0.15241 \nEpoch: 3250  | Validation balanced accuracy : 0.76304 \nEpoch: 3251  | Training Loss: 0.31483 \nEpoch: 3251  | Training Loss: 0.36716 \nEpoch: 3251  | Training Loss: 0.34405 \nEpoch: 3251  | Training Loss: 0.21351 \nEpoch: 3251  | Training Loss: 0.15228 \nEpoch: 3251  | Validation balanced accuracy : 0.76304 \nEpoch: 3252  | Training Loss: 0.31496 \nEpoch: 3252  | Training Loss: 0.36722 \nEpoch: 3252  | Training Loss: 0.34404 \nEpoch: 3252  | Training Loss: 0.21351 \nEpoch: 3252  | Training Loss: 0.15233 \nEpoch: 3252  | Validation balanced accuracy : 0.76304 \nEpoch: 3253  | Training Loss: 0.31489 \nEpoch: 3253  | Training Loss: 0.36721 \nEpoch: 3253  | Training Loss: 0.34403 \nEpoch: 3253  | Training Loss: 0.21351 \nEpoch: 3253  | Training Loss: 0.15213 \nEpoch: 3253  | Validation balanced accuracy : 0.76304 \nEpoch: 3254  | Training Loss: 0.31506 \nEpoch: 3254  | Training Loss: 0.36730 \nEpoch: 3254  | Training Loss: 0.34402 \nEpoch: 3254  | Training Loss: 0.21351 \nEpoch: 3254  | Training Loss: 0.15224 \nEpoch: 3254  | Validation balanced accuracy : 0.76304 \nEpoch: 3255  | Training Loss: 0.31492 \nEpoch: 3255  | Training Loss: 0.36723 \nEpoch: 3255  | Training Loss: 0.34404 \nEpoch: 3255  | Training Loss: 0.21350 \nEpoch: 3255  | Training Loss: 0.15214 \nEpoch: 3255  | Validation balanced accuracy : 0.76304 \nEpoch: 3256  | Training Loss: 0.31504 \nEpoch: 3256  | Training Loss: 0.36727 \nEpoch: 3256  | Training Loss: 0.34405 \nEpoch: 3256  | Training Loss: 0.21349 \nEpoch: 3256  | Training Loss: 0.15231 \nEpoch: 3256  | Validation balanced accuracy : 0.76304 \nEpoch: 3257  | Training Loss: 0.31486 \nEpoch: 3257  | Training Loss: 0.36718 \nEpoch: 3257  | Training Loss: 0.34409 \nEpoch: 3257  | Training Loss: 0.21349 \nEpoch: 3257  | Training Loss: 0.15222 \nEpoch: 3257  | Validation balanced accuracy : 0.76304 \nEpoch: 3258  | Training Loss: 0.31497 \nEpoch: 3258  | Training Loss: 0.36730 \nEpoch: 3258  | Training Loss: 0.34402 \nEpoch: 3258  | Training Loss: 0.21351 \nEpoch: 3258  | Training Loss: 0.15193 \nEpoch: 3258  | Validation balanced accuracy : 0.76304 \nEpoch: 3259  | Training Loss: 0.31518 \nEpoch: 3259  | Training Loss: 0.36738 \nEpoch: 3259  | Training Loss: 0.34406 \nEpoch: 3259  | Training Loss: 0.21347 \nEpoch: 3259  | Training Loss: 0.15245 \nEpoch: 3259  | Validation balanced accuracy : 0.76304 \nEpoch: 3260  | Training Loss: 0.31469 \nEpoch: 3260  | Training Loss: 0.36703 \nEpoch: 3260  | Training Loss: 0.34422 \nEpoch: 3260  | Training Loss: 0.21345 \nEpoch: 3260  | Training Loss: 0.15259 \nEpoch: 3260  | Validation balanced accuracy : 0.76304 \nEpoch: 3261  | Training Loss: 0.31469 \nEpoch: 3261  | Training Loss: 0.36709 \nEpoch: 3261  | Training Loss: 0.34415 \nEpoch: 3261  | Training Loss: 0.21347 \nEpoch: 3261  | Training Loss: 0.15216 \nEpoch: 3261  | Validation balanced accuracy : 0.76304 \nEpoch: 3262  | Training Loss: 0.31503 \nEpoch: 3262  | Training Loss: 0.36730 \nEpoch: 3262  | Training Loss: 0.34407 \nEpoch: 3262  | Training Loss: 0.21348 \nEpoch: 3262  | Training Loss: 0.15207 \nEpoch: 3262  | Validation balanced accuracy : 0.76304 \nEpoch: 3263  | Training Loss: 0.31502 \nEpoch: 3263  | Training Loss: 0.36725 \nEpoch: 3263  | Training Loss: 0.34413 \nEpoch: 3263  | Training Loss: 0.21346 \nEpoch: 3263  | Training Loss: 0.15229 \nEpoch: 3263  | Validation balanced accuracy : 0.76304 \nEpoch: 3264  | Training Loss: 0.31485 \nEpoch: 3264  | Training Loss: 0.36717 \nEpoch: 3264  | Training Loss: 0.34415 \nEpoch: 3264  | Training Loss: 0.21346 \nEpoch: 3264  | Training Loss: 0.15216 \nEpoch: 3264  | Validation balanced accuracy : 0.76304 \nEpoch: 3265  | Training Loss: 0.31498 \nEpoch: 3265  | Training Loss: 0.36730 \nEpoch: 3265  | Training Loss: 0.34408 \nEpoch: 3265  | Training Loss: 0.21348 \nEpoch: 3265  | Training Loss: 0.15186 \nEpoch: 3265  | Validation balanced accuracy : 0.76304 \nEpoch: 3266  | Training Loss: 0.31520 \nEpoch: 3266  | Training Loss: 0.36740 \nEpoch: 3266  | Training Loss: 0.34411 \nEpoch: 3266  | Training Loss: 0.21345 \nEpoch: 3266  | Training Loss: 0.15232 \nEpoch: 3266  | Validation balanced accuracy : 0.76304 \nEpoch: 3267  | Training Loss: 0.31475 \nEpoch: 3267  | Training Loss: 0.36708 \nEpoch: 3267  | Training Loss: 0.34425 \nEpoch: 3267  | Training Loss: 0.21343 \nEpoch: 3267  | Training Loss: 0.15244 \nEpoch: 3267  | Validation balanced accuracy : 0.76304 \nEpoch: 3268  | Training Loss: 0.31476 \nEpoch: 3268  | Training Loss: 0.36714 \nEpoch: 3268  | Training Loss: 0.34419 \nEpoch: 3268  | Training Loss: 0.21345 \nEpoch: 3268  | Training Loss: 0.15202 \nEpoch: 3268  | Validation balanced accuracy : 0.76304 \nEpoch: 3269  | Training Loss: 0.31509 \nEpoch: 3269  | Training Loss: 0.36734 \nEpoch: 3269  | Training Loss: 0.34412 \nEpoch: 3269  | Training Loss: 0.21346 \nEpoch: 3269  | Training Loss: 0.15196 \nEpoch: 3269  | Validation balanced accuracy : 0.76304 \nEpoch: 3270  | Training Loss: 0.31506 \nEpoch: 3270  | Training Loss: 0.36734 \nEpoch: 3270  | Training Loss: 0.34412 \nEpoch: 3270  | Training Loss: 0.21346 \nEpoch: 3270  | Training Loss: 0.15186 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3270  | Validation balanced accuracy : 0.76304 \nEpoch: 3271  | Training Loss: 0.31514 \nEpoch: 3271  | Training Loss: 0.36734 \nEpoch: 3271  | Training Loss: 0.34415 \nEpoch: 3271  | Training Loss: 0.21344 \nEpoch: 3271  | Training Loss: 0.15209 \nEpoch: 3271  | Validation balanced accuracy : 0.76304 \nEpoch: 3272  | Training Loss: 0.31493 \nEpoch: 3272  | Training Loss: 0.36723 \nEpoch: 3272  | Training Loss: 0.34419 \nEpoch: 3272  | Training Loss: 0.21343 \nEpoch: 3272  | Training Loss: 0.15205 \nEpoch: 3272  | Validation balanced accuracy : 0.76304 \nEpoch: 3273  | Training Loss: 0.31501 \nEpoch: 3273  | Training Loss: 0.36731 \nEpoch: 3273  | Training Loss: 0.34414 \nEpoch: 3273  | Training Loss: 0.21345 \nEpoch: 3273  | Training Loss: 0.15177 \nEpoch: 3273  | Validation balanced accuracy : 0.76304 \nEpoch: 3274  | Training Loss: 0.31522 \nEpoch: 3274  | Training Loss: 0.36741 \nEpoch: 3274  | Training Loss: 0.34412 \nEpoch: 3274  | Training Loss: 0.21344 \nEpoch: 3274  | Training Loss: 0.15189 \nEpoch: 3274  | Validation balanced accuracy : 0.76304 \nEpoch: 3275  | Training Loss: 0.31506 \nEpoch: 3275  | Training Loss: 0.36733 \nEpoch: 3275  | Training Loss: 0.34416 \nEpoch: 3275  | Training Loss: 0.21343 \nEpoch: 3275  | Training Loss: 0.15190 \nEpoch: 3275  | Validation balanced accuracy : 0.76304 \nEpoch: 3276  | Training Loss: 0.31508 \nEpoch: 3276  | Training Loss: 0.36730 \nEpoch: 3276  | Training Loss: 0.34421 \nEpoch: 3276  | Training Loss: 0.21342 \nEpoch: 3276  | Training Loss: 0.15210 \nEpoch: 3276  | Validation balanced accuracy : 0.76304 \nEpoch: 3277  | Training Loss: 0.31491 \nEpoch: 3277  | Training Loss: 0.36723 \nEpoch: 3277  | Training Loss: 0.34423 \nEpoch: 3277  | Training Loss: 0.21342 \nEpoch: 3277  | Training Loss: 0.15199 \nEpoch: 3277  | Validation balanced accuracy : 0.76304 \nEpoch: 3278  | Training Loss: 0.31504 \nEpoch: 3278  | Training Loss: 0.36735 \nEpoch: 3278  | Training Loss: 0.34416 \nEpoch: 3278  | Training Loss: 0.21344 \nEpoch: 3278  | Training Loss: 0.15170 \nEpoch: 3278  | Validation balanced accuracy : 0.76304 \nEpoch: 3279  | Training Loss: 0.31524 \nEpoch: 3279  | Training Loss: 0.36743 \nEpoch: 3279  | Training Loss: 0.34419 \nEpoch: 3279  | Training Loss: 0.21341 \nEpoch: 3279  | Training Loss: 0.15219 \nEpoch: 3279  | Validation balanced accuracy : 0.76304 \nEpoch: 3280  | Training Loss: 0.31477 \nEpoch: 3280  | Training Loss: 0.36709 \nEpoch: 3280  | Training Loss: 0.34435 \nEpoch: 3280  | Training Loss: 0.21338 \nEpoch: 3280  | Training Loss: 0.15234 \nEpoch: 3280  | Validation balanced accuracy : 0.76304 \nEpoch: 3281  | Training Loss: 0.31477 \nEpoch: 3281  | Training Loss: 0.36716 \nEpoch: 3281  | Training Loss: 0.34429 \nEpoch: 3281  | Training Loss: 0.21340 \nEpoch: 3281  | Training Loss: 0.15192 \nEpoch: 3281  | Validation balanced accuracy : 0.76304 \nEpoch: 3282  | Training Loss: 0.31510 \nEpoch: 3282  | Training Loss: 0.36735 \nEpoch: 3282  | Training Loss: 0.34421 \nEpoch: 3282  | Training Loss: 0.21341 \nEpoch: 3282  | Training Loss: 0.15185 \nEpoch: 3282  | Validation balanced accuracy : 0.76304 \nEpoch: 3283  | Training Loss: 0.31508 \nEpoch: 3283  | Training Loss: 0.36736 \nEpoch: 3283  | Training Loss: 0.34421 \nEpoch: 3283  | Training Loss: 0.21341 \nEpoch: 3283  | Training Loss: 0.15174 \nEpoch: 3283  | Validation balanced accuracy : 0.76304 \nEpoch: 3284  | Training Loss: 0.31517 \nEpoch: 3284  | Training Loss: 0.36737 \nEpoch: 3284  | Training Loss: 0.34424 \nEpoch: 3284  | Training Loss: 0.21340 \nEpoch: 3284  | Training Loss: 0.15195 \nEpoch: 3284  | Validation balanced accuracy : 0.76304 \nEpoch: 3285  | Training Loss: 0.31497 \nEpoch: 3285  | Training Loss: 0.36726 \nEpoch: 3285  | Training Loss: 0.34428 \nEpoch: 3285  | Training Loss: 0.21339 \nEpoch: 3285  | Training Loss: 0.15190 \nEpoch: 3285  | Validation balanced accuracy : 0.76304 \nEpoch: 3286  | Training Loss: 0.31505 \nEpoch: 3286  | Training Loss: 0.36735 \nEpoch: 3286  | Training Loss: 0.34422 \nEpoch: 3286  | Training Loss: 0.21341 \nEpoch: 3286  | Training Loss: 0.15163 \nEpoch: 3286  | Validation balanced accuracy : 0.76304 \nEpoch: 3287  | Training Loss: 0.31526 \nEpoch: 3287  | Training Loss: 0.36745 \nEpoch: 3287  | Training Loss: 0.34421 \nEpoch: 3287  | Training Loss: 0.21340 \nEpoch: 3287  | Training Loss: 0.15175 \nEpoch: 3287  | Validation balanced accuracy : 0.76304 \nEpoch: 3288  | Training Loss: 0.31510 \nEpoch: 3288  | Training Loss: 0.36736 \nEpoch: 3288  | Training Loss: 0.34425 \nEpoch: 3288  | Training Loss: 0.21339 \nEpoch: 3288  | Training Loss: 0.15177 \nEpoch: 3288  | Validation balanced accuracy : 0.76304 \nEpoch: 3289  | Training Loss: 0.31511 \nEpoch: 3289  | Training Loss: 0.36739 \nEpoch: 3289  | Training Loss: 0.34423 \nEpoch: 3289  | Training Loss: 0.21340 \nEpoch: 3289  | Training Loss: 0.15163 \nEpoch: 3289  | Validation balanced accuracy : 0.76304 \nEpoch: 3290  | Training Loss: 0.31523 \nEpoch: 3290  | Training Loss: 0.36742 \nEpoch: 3290  | Training Loss: 0.34426 \nEpoch: 3290  | Training Loss: 0.21338 \nEpoch: 3290  | Training Loss: 0.15185 \nEpoch: 3290  | Validation balanced accuracy : 0.76304 \nEpoch: 3291  | Training Loss: 0.31502 \nEpoch: 3291  | Training Loss: 0.36730 \nEpoch: 3291  | Training Loss: 0.34430 \nEpoch: 3291  | Training Loss: 0.21337 \nEpoch: 3291  | Training Loss: 0.15181 \nEpoch: 3291  | Validation balanced accuracy : 0.76304 \nEpoch: 3292  | Training Loss: 0.31508 \nEpoch: 3292  | Training Loss: 0.36738 \nEpoch: 3292  | Training Loss: 0.34425 \nEpoch: 3292  | Training Loss: 0.21339 \nEpoch: 3292  | Training Loss: 0.15158 \nEpoch: 3292  | Validation balanced accuracy : 0.76304 \nEpoch: 3293  | Training Loss: 0.31526 \nEpoch: 3293  | Training Loss: 0.36744 \nEpoch: 3293  | Training Loss: 0.34426 \nEpoch: 3293  | Training Loss: 0.21337 \nEpoch: 3293  | Training Loss: 0.15179 \nEpoch: 3293  | Validation balanced accuracy : 0.76304 \nEpoch: 3294  | Training Loss: 0.31504 \nEpoch: 3294  | Training Loss: 0.36732 \nEpoch: 3294  | Training Loss: 0.34431 \nEpoch: 3294  | Training Loss: 0.21336 \nEpoch: 3294  | Training Loss: 0.15177 \nEpoch: 3294  | Validation balanced accuracy : 0.76304 \nEpoch: 3295  | Training Loss: 0.31510 \nEpoch: 3295  | Training Loss: 0.36740 \nEpoch: 3295  | Training Loss: 0.34427 \nEpoch: 3295  | Training Loss: 0.21338 \nEpoch: 3295  | Training Loss: 0.15155 \nEpoch: 3295  | Validation balanced accuracy : 0.76304 \nEpoch: 3296  | Training Loss: 0.31526 \nEpoch: 3296  | Training Loss: 0.36745 \nEpoch: 3296  | Training Loss: 0.34428 \nEpoch: 3296  | Training Loss: 0.21336 \nEpoch: 3296  | Training Loss: 0.15173 \nEpoch: 3296  | Validation balanced accuracy : 0.76304 \nEpoch: 3297  | Training Loss: 0.31507 \nEpoch: 3297  | Training Loss: 0.36735 \nEpoch: 3297  | Training Loss: 0.34432 \nEpoch: 3297  | Training Loss: 0.21336 \nEpoch: 3297  | Training Loss: 0.15169 \nEpoch: 3297  | Validation balanced accuracy : 0.76304 \nEpoch: 3298  | Training Loss: 0.31514 \nEpoch: 3298  | Training Loss: 0.36737 \nEpoch: 3298  | Training Loss: 0.34434 \nEpoch: 3298  | Training Loss: 0.21335 \nEpoch: 3298  | Training Loss: 0.15183 \nEpoch: 3298  | Validation balanced accuracy : 0.76304 \nEpoch: 3299  | Training Loss: 0.31501 \nEpoch: 3299  | Training Loss: 0.36732 \nEpoch: 3299  | Training Loss: 0.34435 \nEpoch: 3299  | Training Loss: 0.21335 \nEpoch: 3299  | Training Loss: 0.15169 \nEpoch: 3299  | Validation balanced accuracy : 0.76304 \nEpoch: 3300  | Training Loss: 0.31515 \nEpoch: 3300  | Training Loss: 0.36737 \nEpoch: 3300  | Training Loss: 0.34435 \nEpoch: 3300  | Training Loss: 0.21334 \nEpoch: 3300  | Training Loss: 0.15180 \nEpoch: 3300  | Validation balanced accuracy : 0.76304 \nEpoch: 3301  | Training Loss: 0.31502 \nEpoch: 3301  | Training Loss: 0.36732 \nEpoch: 3301  | Training Loss: 0.34431 \nEpoch: 3301  | Training Loss: 0.21336 \nEpoch: 3301  | Training Loss: 0.15139 \nEpoch: 3301  | Validation balanced accuracy : 0.76304 \nEpoch: 3302  | Training Loss: 0.31513 \nEpoch: 3302  | Training Loss: 0.36736 \nEpoch: 3302  | Training Loss: 0.34431 \nEpoch: 3302  | Training Loss: 0.21335 \nEpoch: 3302  | Training Loss: 0.15149 \nEpoch: 3302  | Validation balanced accuracy : 0.76304 \nEpoch: 3303  | Training Loss: 0.31502 \nEpoch: 3303  | Training Loss: 0.36732 \nEpoch: 3303  | Training Loss: 0.34433 \nEpoch: 3303  | Training Loss: 0.21335 \nEpoch: 3303  | Training Loss: 0.15140 \nEpoch: 3303  | Validation balanced accuracy : 0.76304 \nEpoch: 3304  | Training Loss: 0.31511 \nEpoch: 3304  | Training Loss: 0.36741 \nEpoch: 3304  | Training Loss: 0.34428 \nEpoch: 3304  | Training Loss: 0.21336 \nEpoch: 3304  | Training Loss: 0.15120 \nEpoch: 3304  | Validation balanced accuracy : 0.76304 \nEpoch: 3305  | Training Loss: 0.31526 \nEpoch: 3305  | Training Loss: 0.36745 \nEpoch: 3305  | Training Loss: 0.34429 \nEpoch: 3305  | Training Loss: 0.21335 \nEpoch: 3305  | Training Loss: 0.15140 \nEpoch: 3305  | Validation balanced accuracy : 0.76304 \nEpoch: 3306  | Training Loss: 0.31506 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3306  | Training Loss: 0.36734 \nEpoch: 3306  | Training Loss: 0.34434 \nEpoch: 3306  | Training Loss: 0.21334 \nEpoch: 3306  | Training Loss: 0.15141 \nEpoch: 3306  | Validation balanced accuracy : 0.76304 \nEpoch: 3307  | Training Loss: 0.31509 \nEpoch: 3307  | Training Loss: 0.36738 \nEpoch: 3307  | Training Loss: 0.34430 \nEpoch: 3307  | Training Loss: 0.21335 \nEpoch: 3307  | Training Loss: 0.15121 \nEpoch: 3307  | Validation balanced accuracy : 0.76304 \nEpoch: 3308  | Training Loss: 0.31525 \nEpoch: 3308  | Training Loss: 0.36745 \nEpoch: 3308  | Training Loss: 0.34430 \nEpoch: 3308  | Training Loss: 0.21334 \nEpoch: 3308  | Training Loss: 0.15136 \nEpoch: 3308  | Validation balanced accuracy : 0.76304 \nEpoch: 3309  | Training Loss: 0.31508 \nEpoch: 3309  | Training Loss: 0.36736 \nEpoch: 3309  | Training Loss: 0.34434 \nEpoch: 3309  | Training Loss: 0.21333 \nEpoch: 3309  | Training Loss: 0.15135 \nEpoch: 3309  | Validation balanced accuracy : 0.76304 \nEpoch: 3310  | Training Loss: 0.31512 \nEpoch: 3310  | Training Loss: 0.36735 \nEpoch: 3310  | Training Loss: 0.34438 \nEpoch: 3310  | Training Loss: 0.21332 \nEpoch: 3310  | Training Loss: 0.15155 \nEpoch: 3310  | Validation balanced accuracy : 0.76304 \nEpoch: 3311  | Training Loss: 0.31495 \nEpoch: 3311  | Training Loss: 0.36728 \nEpoch: 3311  | Training Loss: 0.34439 \nEpoch: 3311  | Training Loss: 0.21332 \nEpoch: 3311  | Training Loss: 0.15141 \nEpoch: 3311  | Validation balanced accuracy : 0.76304 \nEpoch: 3312  | Training Loss: 0.31509 \nEpoch: 3312  | Training Loss: 0.36741 \nEpoch: 3312  | Training Loss: 0.34432 \nEpoch: 3312  | Training Loss: 0.21334 \nEpoch: 3312  | Training Loss: 0.15115 \nEpoch: 3312  | Validation balanced accuracy : 0.76304 \nEpoch: 3313  | Training Loss: 0.31528 \nEpoch: 3313  | Training Loss: 0.36748 \nEpoch: 3313  | Training Loss: 0.34432 \nEpoch: 3313  | Training Loss: 0.21333 \nEpoch: 3313  | Training Loss: 0.15130 \nEpoch: 3313  | Validation balanced accuracy : 0.76304 \nEpoch: 3314  | Training Loss: 0.31510 \nEpoch: 3314  | Training Loss: 0.36738 \nEpoch: 3314  | Training Loss: 0.34437 \nEpoch: 3314  | Training Loss: 0.21332 \nEpoch: 3314  | Training Loss: 0.15135 \nEpoch: 3314  | Validation balanced accuracy : 0.76304 \nEpoch: 3315  | Training Loss: 0.31509 \nEpoch: 3315  | Training Loss: 0.36739 \nEpoch: 3315  | Training Loss: 0.34436 \nEpoch: 3315  | Training Loss: 0.21332 \nEpoch: 3315  | Training Loss: 0.15126 \nEpoch: 3315  | Validation balanced accuracy : 0.76304 \nEpoch: 3316  | Training Loss: 0.31517 \nEpoch: 3316  | Training Loss: 0.36740 \nEpoch: 3316  | Training Loss: 0.34439 \nEpoch: 3316  | Training Loss: 0.21331 \nEpoch: 3316  | Training Loss: 0.15147 \nEpoch: 3316  | Validation balanced accuracy : 0.76304 \nEpoch: 3317  | Training Loss: 0.31498 \nEpoch: 3317  | Training Loss: 0.36729 \nEpoch: 3317  | Training Loss: 0.34443 \nEpoch: 3317  | Training Loss: 0.21330 \nEpoch: 3317  | Training Loss: 0.15144 \nEpoch: 3317  | Validation balanced accuracy : 0.76304 \nEpoch: 3318  | Training Loss: 0.31504 \nEpoch: 3318  | Training Loss: 0.36736 \nEpoch: 3318  | Training Loss: 0.34438 \nEpoch: 3318  | Training Loss: 0.21331 \nEpoch: 3318  | Training Loss: 0.15121 \nEpoch: 3318  | Validation balanced accuracy : 0.76304 \nEpoch: 3319  | Training Loss: 0.31521 \nEpoch: 3319  | Training Loss: 0.36744 \nEpoch: 3319  | Training Loss: 0.34437 \nEpoch: 3319  | Training Loss: 0.21331 \nEpoch: 3319  | Training Loss: 0.15132 \nEpoch: 3319  | Validation balanced accuracy : 0.76304 \nEpoch: 3320  | Training Loss: 0.31507 \nEpoch: 3320  | Training Loss: 0.36737 \nEpoch: 3320  | Training Loss: 0.34440 \nEpoch: 3320  | Training Loss: 0.21330 \nEpoch: 3320  | Training Loss: 0.15128 \nEpoch: 3320  | Validation balanced accuracy : 0.76304 \nEpoch: 3321  | Training Loss: 0.31514 \nEpoch: 3321  | Training Loss: 0.36738 \nEpoch: 3321  | Training Loss: 0.34442 \nEpoch: 3321  | Training Loss: 0.21329 \nEpoch: 3321  | Training Loss: 0.15141 \nEpoch: 3321  | Validation balanced accuracy : 0.76304 \nEpoch: 3322  | Training Loss: 0.31501 \nEpoch: 3322  | Training Loss: 0.36733 \nEpoch: 3322  | Training Loss: 0.34444 \nEpoch: 3322  | Training Loss: 0.21329 \nEpoch: 3322  | Training Loss: 0.15131 \nEpoch: 3322  | Validation balanced accuracy : 0.76304 \nEpoch: 3323  | Training Loss: 0.31511 \nEpoch: 3323  | Training Loss: 0.36743 \nEpoch: 3323  | Training Loss: 0.34438 \nEpoch: 3323  | Training Loss: 0.21331 \nEpoch: 3323  | Training Loss: 0.15109 \nEpoch: 3323  | Validation balanced accuracy : 0.76304 \nEpoch: 3324  | Training Loss: 0.31527 \nEpoch: 3324  | Training Loss: 0.36748 \nEpoch: 3324  | Training Loss: 0.34438 \nEpoch: 3324  | Training Loss: 0.21329 \nEpoch: 3324  | Training Loss: 0.15126 \nEpoch: 3324  | Validation balanced accuracy : 0.76304 \nEpoch: 3325  | Training Loss: 0.31510 \nEpoch: 3325  | Training Loss: 0.36738 \nEpoch: 3325  | Training Loss: 0.34443 \nEpoch: 3325  | Training Loss: 0.21329 \nEpoch: 3325  | Training Loss: 0.15125 \nEpoch: 3325  | Validation balanced accuracy : 0.76304 \nEpoch: 3326  | Training Loss: 0.31514 \nEpoch: 3326  | Training Loss: 0.36738 \nEpoch: 3326  | Training Loss: 0.34446 \nEpoch: 3326  | Training Loss: 0.21327 \nEpoch: 3326  | Training Loss: 0.15143 \nEpoch: 3326  | Validation balanced accuracy : 0.76304 \nEpoch: 3327  | Training Loss: 0.31497 \nEpoch: 3327  | Training Loss: 0.36730 \nEpoch: 3327  | Training Loss: 0.34449 \nEpoch: 3327  | Training Loss: 0.21327 \nEpoch: 3327  | Training Loss: 0.15135 \nEpoch: 3327  | Validation balanced accuracy : 0.76304 \nEpoch: 3328  | Training Loss: 0.31507 \nEpoch: 3328  | Training Loss: 0.36740 \nEpoch: 3328  | Training Loss: 0.34442 \nEpoch: 3328  | Training Loss: 0.21329 \nEpoch: 3328  | Training Loss: 0.15106 \nEpoch: 3328  | Validation balanced accuracy : 0.76304 \nEpoch: 3329  | Training Loss: 0.31529 \nEpoch: 3329  | Training Loss: 0.36751 \nEpoch: 3329  | Training Loss: 0.34443 \nEpoch: 3329  | Training Loss: 0.21327 \nEpoch: 3329  | Training Loss: 0.15145 \nEpoch: 3329  | Validation balanced accuracy : 0.76304 \nEpoch: 3330  | Training Loss: 0.31490 \nEpoch: 3330  | Training Loss: 0.36722 \nEpoch: 3330  | Training Loss: 0.34457 \nEpoch: 3330  | Training Loss: 0.21324 \nEpoch: 3330  | Training Loss: 0.15158 \nEpoch: 3330  | Validation balanced accuracy : 0.76304 \nEpoch: 3331  | Training Loss: 0.31488 \nEpoch: 3331  | Training Loss: 0.36726 \nEpoch: 3331  | Training Loss: 0.34452 \nEpoch: 3331  | Training Loss: 0.21326 \nEpoch: 3331  | Training Loss: 0.15125 \nEpoch: 3331  | Validation balanced accuracy : 0.76304 \nEpoch: 3332  | Training Loss: 0.31515 \nEpoch: 3332  | Training Loss: 0.36742 \nEpoch: 3332  | Training Loss: 0.34447 \nEpoch: 3332  | Training Loss: 0.21327 \nEpoch: 3332  | Training Loss: 0.15124 \nEpoch: 3332  | Validation balanced accuracy : 0.76304 \nEpoch: 3333  | Training Loss: 0.31510 \nEpoch: 3333  | Training Loss: 0.36740 \nEpoch: 3333  | Training Loss: 0.34447 \nEpoch: 3333  | Training Loss: 0.21327 \nEpoch: 3333  | Training Loss: 0.15111 \nEpoch: 3333  | Validation balanced accuracy : 0.76304 \nEpoch: 3334  | Training Loss: 0.31521 \nEpoch: 3334  | Training Loss: 0.36744 \nEpoch: 3334  | Training Loss: 0.34448 \nEpoch: 3334  | Training Loss: 0.21326 \nEpoch: 3334  | Training Loss: 0.15127 \nEpoch: 3334  | Validation balanced accuracy : 0.76304 \nEpoch: 3335  | Training Loss: 0.31505 \nEpoch: 3335  | Training Loss: 0.36735 \nEpoch: 3335  | Training Loss: 0.34451 \nEpoch: 3335  | Training Loss: 0.21325 \nEpoch: 3335  | Training Loss: 0.15123 \nEpoch: 3335  | Validation balanced accuracy : 0.76304 \nEpoch: 3336  | Training Loss: 0.31512 \nEpoch: 3336  | Training Loss: 0.36743 \nEpoch: 3336  | Training Loss: 0.34446 \nEpoch: 3336  | Training Loss: 0.21327 \nEpoch: 3336  | Training Loss: 0.15097 \nEpoch: 3336  | Validation balanced accuracy : 0.76304 \nEpoch: 3337  | Training Loss: 0.31531 \nEpoch: 3337  | Training Loss: 0.36751 \nEpoch: 3337  | Training Loss: 0.34445 \nEpoch: 3337  | Training Loss: 0.21326 \nEpoch: 3337  | Training Loss: 0.15113 \nEpoch: 3337  | Validation balanced accuracy : 0.76304 \nEpoch: 3338  | Training Loss: 0.31514 \nEpoch: 3338  | Training Loss: 0.36741 \nEpoch: 3338  | Training Loss: 0.34450 \nEpoch: 3338  | Training Loss: 0.21325 \nEpoch: 3338  | Training Loss: 0.15113 \nEpoch: 3338  | Validation balanced accuracy : 0.76304 \nEpoch: 3339  | Training Loss: 0.31517 \nEpoch: 3339  | Training Loss: 0.36741 \nEpoch: 3339  | Training Loss: 0.34453 \nEpoch: 3339  | Training Loss: 0.21324 \nEpoch: 3339  | Training Loss: 0.15129 \nEpoch: 3339  | Validation balanced accuracy : 0.76304 \nEpoch: 3340  | Training Loss: 0.31503 \nEpoch: 3340  | Training Loss: 0.36734 \nEpoch: 3340  | Training Loss: 0.34455 \nEpoch: 3340  | Training Loss: 0.21324 \nEpoch: 3340  | Training Loss: 0.15120 \nEpoch: 3340  | Validation balanced accuracy : 0.76304 \nEpoch: 3341  | Training Loss: 0.31513 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3341  | Training Loss: 0.36744 \nEpoch: 3341  | Training Loss: 0.34449 \nEpoch: 3341  | Training Loss: 0.21325 \nEpoch: 3341  | Training Loss: 0.15097 \nEpoch: 3341  | Validation balanced accuracy : 0.76304 \nEpoch: 3342  | Training Loss: 0.31529 \nEpoch: 3342  | Training Loss: 0.36750 \nEpoch: 3342  | Training Loss: 0.34449 \nEpoch: 3342  | Training Loss: 0.21324 \nEpoch: 3342  | Training Loss: 0.15113 \nEpoch: 3342  | Validation balanced accuracy : 0.76304 \nEpoch: 3343  | Training Loss: 0.31512 \nEpoch: 3343  | Training Loss: 0.36741 \nEpoch: 3343  | Training Loss: 0.34453 \nEpoch: 3343  | Training Loss: 0.21324 \nEpoch: 3343  | Training Loss: 0.15110 \nEpoch: 3343  | Validation balanced accuracy : 0.76304 \nEpoch: 3344  | Training Loss: 0.31517 \nEpoch: 3344  | Training Loss: 0.36747 \nEpoch: 3344  | Training Loss: 0.34449 \nEpoch: 3344  | Training Loss: 0.21325 \nEpoch: 3344  | Training Loss: 0.15094 \nEpoch: 3344  | Validation balanced accuracy : 0.76304 \nEpoch: 3345  | Training Loss: 0.31530 \nEpoch: 3345  | Training Loss: 0.36750 \nEpoch: 3345  | Training Loss: 0.34452 \nEpoch: 3345  | Training Loss: 0.21323 \nEpoch: 3345  | Training Loss: 0.15117 \nEpoch: 3345  | Validation balanced accuracy : 0.76304 \nEpoch: 3346  | Training Loss: 0.31508 \nEpoch: 3346  | Training Loss: 0.36737 \nEpoch: 3346  | Training Loss: 0.34457 \nEpoch: 3346  | Training Loss: 0.21322 \nEpoch: 3346  | Training Loss: 0.15118 \nEpoch: 3346  | Validation balanced accuracy : 0.76304 \nEpoch: 3347  | Training Loss: 0.31511 \nEpoch: 3347  | Training Loss: 0.36743 \nEpoch: 3347  | Training Loss: 0.34453 \nEpoch: 3347  | Training Loss: 0.21324 \nEpoch: 3347  | Training Loss: 0.15094 \nEpoch: 3347  | Validation balanced accuracy : 0.76304 \nEpoch: 3348  | Training Loss: 0.31530 \nEpoch: 3348  | Training Loss: 0.36751 \nEpoch: 3348  | Training Loss: 0.34452 \nEpoch: 3348  | Training Loss: 0.21323 \nEpoch: 3348  | Training Loss: 0.15106 \nEpoch: 3348  | Validation balanced accuracy : 0.76304 \nEpoch: 3349  | Training Loss: 0.31515 \nEpoch: 3349  | Training Loss: 0.36744 \nEpoch: 3349  | Training Loss: 0.34455 \nEpoch: 3349  | Training Loss: 0.21322 \nEpoch: 3349  | Training Loss: 0.15102 \nEpoch: 3349  | Validation balanced accuracy : 0.76304 \nEpoch: 3350  | Training Loss: 0.31521 \nEpoch: 3350  | Training Loss: 0.36744 \nEpoch: 3350  | Training Loss: 0.34457 \nEpoch: 3350  | Training Loss: 0.21321 \nEpoch: 3350  | Training Loss: 0.15117 \nEpoch: 3350  | Validation balanced accuracy : 0.76304 \nEpoch: 3351  | Training Loss: 0.31508 \nEpoch: 3351  | Training Loss: 0.36738 \nEpoch: 3351  | Training Loss: 0.34459 \nEpoch: 3351  | Training Loss: 0.21321 \nEpoch: 3351  | Training Loss: 0.15108 \nEpoch: 3351  | Validation balanced accuracy : 0.76304 \nEpoch: 3352  | Training Loss: 0.31517 \nEpoch: 3352  | Training Loss: 0.36748 \nEpoch: 3352  | Training Loss: 0.34454 \nEpoch: 3352  | Training Loss: 0.21323 \nEpoch: 3352  | Training Loss: 0.15086 \nEpoch: 3352  | Validation balanced accuracy : 0.76304 \nEpoch: 3353  | Training Loss: 0.31533 \nEpoch: 3353  | Training Loss: 0.36753 \nEpoch: 3353  | Training Loss: 0.34455 \nEpoch: 3353  | Training Loss: 0.21321 \nEpoch: 3353  | Training Loss: 0.15107 \nEpoch: 3353  | Validation balanced accuracy : 0.76304 \nEpoch: 3354  | Training Loss: 0.31512 \nEpoch: 3354  | Training Loss: 0.36741 \nEpoch: 3354  | Training Loss: 0.34460 \nEpoch: 3354  | Training Loss: 0.21320 \nEpoch: 3354  | Training Loss: 0.15107 \nEpoch: 3354  | Validation balanced accuracy : 0.76304 \nEpoch: 3355  | Training Loss: 0.31516 \nEpoch: 3355  | Training Loss: 0.36746 \nEpoch: 3355  | Training Loss: 0.34457 \nEpoch: 3355  | Training Loss: 0.21321 \nEpoch: 3355  | Training Loss: 0.15090 \nEpoch: 3355  | Validation balanced accuracy : 0.76304 \nEpoch: 3356  | Training Loss: 0.31528 \nEpoch: 3356  | Training Loss: 0.36750 \nEpoch: 3356  | Training Loss: 0.34458 \nEpoch: 3356  | Training Loss: 0.21320 \nEpoch: 3356  | Training Loss: 0.15108 \nEpoch: 3356  | Validation balanced accuracy : 0.76304 \nEpoch: 3357  | Training Loss: 0.31511 \nEpoch: 3357  | Training Loss: 0.36740 \nEpoch: 3357  | Training Loss: 0.34462 \nEpoch: 3357  | Training Loss: 0.21320 \nEpoch: 3357  | Training Loss: 0.15106 \nEpoch: 3357  | Validation balanced accuracy : 0.76304 \nEpoch: 3358  | Training Loss: 0.31516 \nEpoch: 3358  | Training Loss: 0.36747 \nEpoch: 3358  | Training Loss: 0.34457 \nEpoch: 3358  | Training Loss: 0.21321 \nEpoch: 3358  | Training Loss: 0.15081 \nEpoch: 3358  | Validation balanced accuracy : 0.76304 \nEpoch: 3359  | Training Loss: 0.31535 \nEpoch: 3359  | Training Loss: 0.36756 \nEpoch: 3359  | Training Loss: 0.34456 \nEpoch: 3359  | Training Loss: 0.21320 \nEpoch: 3359  | Training Loss: 0.15094 \nEpoch: 3359  | Validation balanced accuracy : 0.76304 \nEpoch: 3360  | Training Loss: 0.31520 \nEpoch: 3360  | Training Loss: 0.36747 \nEpoch: 3360  | Training Loss: 0.34459 \nEpoch: 3360  | Training Loss: 0.21320 \nEpoch: 3360  | Training Loss: 0.15092 \nEpoch: 3360  | Validation balanced accuracy : 0.76304 \nEpoch: 3361  | Training Loss: 0.31524 \nEpoch: 3361  | Training Loss: 0.36747 \nEpoch: 3361  | Training Loss: 0.34463 \nEpoch: 3361  | Training Loss: 0.21318 \nEpoch: 3361  | Training Loss: 0.15111 \nEpoch: 3361  | Validation balanced accuracy : 0.76304 \nEpoch: 3362  | Training Loss: 0.31507 \nEpoch: 3362  | Training Loss: 0.36738 \nEpoch: 3362  | Training Loss: 0.34466 \nEpoch: 3362  | Training Loss: 0.21318 \nEpoch: 3362  | Training Loss: 0.15106 \nEpoch: 3362  | Validation balanced accuracy : 0.76304 \nEpoch: 3363  | Training Loss: 0.31515 \nEpoch: 3363  | Training Loss: 0.36747 \nEpoch: 3363  | Training Loss: 0.34460 \nEpoch: 3363  | Training Loss: 0.21320 \nEpoch: 3363  | Training Loss: 0.15078 \nEpoch: 3363  | Validation balanced accuracy : 0.76304 \nEpoch: 3364  | Training Loss: 0.31536 \nEpoch: 3364  | Training Loss: 0.36757 \nEpoch: 3364  | Training Loss: 0.34458 \nEpoch: 3364  | Training Loss: 0.21319 \nEpoch: 3364  | Training Loss: 0.15089 \nEpoch: 3364  | Validation balanced accuracy : 0.76304 \nEpoch: 3365  | Training Loss: 0.31522 \nEpoch: 3365  | Training Loss: 0.36749 \nEpoch: 3365  | Training Loss: 0.34462 \nEpoch: 3365  | Training Loss: 0.21318 \nEpoch: 3365  | Training Loss: 0.15091 \nEpoch: 3365  | Validation balanced accuracy : 0.76304 \nEpoch: 3366  | Training Loss: 0.31522 \nEpoch: 3366  | Training Loss: 0.36751 \nEpoch: 3366  | Training Loss: 0.34461 \nEpoch: 3366  | Training Loss: 0.21319 \nEpoch: 3366  | Training Loss: 0.15081 \nEpoch: 3366  | Validation balanced accuracy : 0.76304 \nEpoch: 3367  | Training Loss: 0.31530 \nEpoch: 3367  | Training Loss: 0.36751 \nEpoch: 3367  | Training Loss: 0.34464 \nEpoch: 3367  | Training Loss: 0.21317 \nEpoch: 3367  | Training Loss: 0.15103 \nEpoch: 3367  | Validation balanced accuracy : 0.76304 \nEpoch: 3368  | Training Loss: 0.31510 \nEpoch: 3368  | Training Loss: 0.36740 \nEpoch: 3368  | Training Loss: 0.34469 \nEpoch: 3368  | Training Loss: 0.21316 \nEpoch: 3368  | Training Loss: 0.15102 \nEpoch: 3368  | Validation balanced accuracy : 0.76304 \nEpoch: 3369  | Training Loss: 0.31515 \nEpoch: 3369  | Training Loss: 0.36747 \nEpoch: 3369  | Training Loss: 0.34464 \nEpoch: 3369  | Training Loss: 0.21318 \nEpoch: 3369  | Training Loss: 0.15077 \nEpoch: 3369  | Validation balanced accuracy : 0.76304 \nEpoch: 3370  | Training Loss: 0.31535 \nEpoch: 3370  | Training Loss: 0.36755 \nEpoch: 3370  | Training Loss: 0.34463 \nEpoch: 3370  | Training Loss: 0.21317 \nEpoch: 3370  | Training Loss: 0.15091 \nEpoch: 3370  | Validation balanced accuracy : 0.76304 \nEpoch: 3371  | Training Loss: 0.31518 \nEpoch: 3371  | Training Loss: 0.36746 \nEpoch: 3371  | Training Loss: 0.34467 \nEpoch: 3371  | Training Loss: 0.21317 \nEpoch: 3371  | Training Loss: 0.15089 \nEpoch: 3371  | Validation balanced accuracy : 0.76304 \nEpoch: 3372  | Training Loss: 0.31523 \nEpoch: 3372  | Training Loss: 0.36752 \nEpoch: 3372  | Training Loss: 0.34463 \nEpoch: 3372  | Training Loss: 0.21318 \nEpoch: 3372  | Training Loss: 0.15073 \nEpoch: 3372  | Validation balanced accuracy : 0.76304 \nEpoch: 3373  | Training Loss: 0.31535 \nEpoch: 3373  | Training Loss: 0.36755 \nEpoch: 3373  | Training Loss: 0.34465 \nEpoch: 3373  | Training Loss: 0.21316 \nEpoch: 3373  | Training Loss: 0.15092 \nEpoch: 3373  | Validation balanced accuracy : 0.76304 \nEpoch: 3374  | Training Loss: 0.31516 \nEpoch: 3374  | Training Loss: 0.36745 \nEpoch: 3374  | Training Loss: 0.34470 \nEpoch: 3374  | Training Loss: 0.21315 \nEpoch: 3374  | Training Loss: 0.15091 \nEpoch: 3374  | Validation balanced accuracy : 0.76304 \nEpoch: 3375  | Training Loss: 0.31520 \nEpoch: 3375  | Training Loss: 0.36750 \nEpoch: 3375  | Training Loss: 0.34465 \nEpoch: 3375  | Training Loss: 0.21317 \nEpoch: 3375  | Training Loss: 0.15069 \nEpoch: 3375  | Validation balanced accuracy : 0.76304 \nEpoch: 3376  | Training Loss: 0.31538 \nEpoch: 3376  | Training Loss: 0.36758 \nEpoch: 3376  | Training Loss: 0.34465 \nEpoch: 3376  | Training Loss: 0.21316 \nEpoch: 3376  | Training Loss: 0.15086 \nEpoch: 3376  | Validation balanced accuracy : 0.76304 \nEpoch: 3377  | Training Loss: 0.31519 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3377  | Training Loss: 0.36747 \nEpoch: 3377  | Training Loss: 0.34470 \nEpoch: 3377  | Training Loss: 0.21315 \nEpoch: 3377  | Training Loss: 0.15085 \nEpoch: 3377  | Validation balanced accuracy : 0.76304 \nEpoch: 3378  | Training Loss: 0.31523 \nEpoch: 3378  | Training Loss: 0.36753 \nEpoch: 3378  | Training Loss: 0.34466 \nEpoch: 3378  | Training Loss: 0.21316 \nEpoch: 3378  | Training Loss: 0.15070 \nEpoch: 3378  | Validation balanced accuracy : 0.76304 \nEpoch: 3379  | Training Loss: 0.31535 \nEpoch: 3379  | Training Loss: 0.36756 \nEpoch: 3379  | Training Loss: 0.34468 \nEpoch: 3379  | Training Loss: 0.21315 \nEpoch: 3379  | Training Loss: 0.15089 \nEpoch: 3379  | Validation balanced accuracy : 0.76304 \nEpoch: 3380  | Training Loss: 0.31516 \nEpoch: 3380  | Training Loss: 0.36745 \nEpoch: 3380  | Training Loss: 0.34473 \nEpoch: 3380  | Training Loss: 0.21314 \nEpoch: 3380  | Training Loss: 0.15088 \nEpoch: 3380  | Validation balanced accuracy : 0.76304 \nEpoch: 3381  | Training Loss: 0.31520 \nEpoch: 3381  | Training Loss: 0.36751 \nEpoch: 3381  | Training Loss: 0.34468 \nEpoch: 3381  | Training Loss: 0.21315 \nEpoch: 3381  | Training Loss: 0.15065 \nEpoch: 3381  | Validation balanced accuracy : 0.76304 \nEpoch: 3382  | Training Loss: 0.31539 \nEpoch: 3382  | Training Loss: 0.36759 \nEpoch: 3382  | Training Loss: 0.34467 \nEpoch: 3382  | Training Loss: 0.21315 \nEpoch: 3382  | Training Loss: 0.15078 \nEpoch: 3382  | Validation balanced accuracy : 0.76304 \nEpoch: 3383  | Training Loss: 0.31523 \nEpoch: 3383  | Training Loss: 0.36751 \nEpoch: 3383  | Training Loss: 0.34471 \nEpoch: 3383  | Training Loss: 0.21314 \nEpoch: 3383  | Training Loss: 0.15076 \nEpoch: 3383  | Validation balanced accuracy : 0.76304 \nEpoch: 3384  | Training Loss: 0.31528 \nEpoch: 3384  | Training Loss: 0.36751 \nEpoch: 3384  | Training Loss: 0.34473 \nEpoch: 3384  | Training Loss: 0.21313 \nEpoch: 3384  | Training Loss: 0.15092 \nEpoch: 3384  | Validation balanced accuracy : 0.76304 \nEpoch: 3385  | Training Loss: 0.31514 \nEpoch: 3385  | Training Loss: 0.36744 \nEpoch: 3385  | Training Loss: 0.34476 \nEpoch: 3385  | Training Loss: 0.21313 \nEpoch: 3385  | Training Loss: 0.15084 \nEpoch: 3385  | Validation balanced accuracy : 0.76304 \nEpoch: 3386  | Training Loss: 0.31523 \nEpoch: 3386  | Training Loss: 0.36753 \nEpoch: 3386  | Training Loss: 0.34470 \nEpoch: 3386  | Training Loss: 0.21314 \nEpoch: 3386  | Training Loss: 0.15060 \nEpoch: 3386  | Validation balanced accuracy : 0.76304 \nEpoch: 3387  | Training Loss: 0.31541 \nEpoch: 3387  | Training Loss: 0.36761 \nEpoch: 3387  | Training Loss: 0.34469 \nEpoch: 3387  | Training Loss: 0.21314 \nEpoch: 3387  | Training Loss: 0.15073 \nEpoch: 3387  | Validation balanced accuracy : 0.76304 \nEpoch: 3388  | Training Loss: 0.31525 \nEpoch: 3388  | Training Loss: 0.36752 \nEpoch: 3388  | Training Loss: 0.34473 \nEpoch: 3388  | Training Loss: 0.21313 \nEpoch: 3388  | Training Loss: 0.15072 \nEpoch: 3388  | Validation balanced accuracy : 0.76304 \nEpoch: 3389  | Training Loss: 0.31529 \nEpoch: 3389  | Training Loss: 0.36752 \nEpoch: 3389  | Training Loss: 0.34476 \nEpoch: 3389  | Training Loss: 0.21312 \nEpoch: 3389  | Training Loss: 0.15088 \nEpoch: 3389  | Validation balanced accuracy : 0.76304 \nEpoch: 3390  | Training Loss: 0.31515 \nEpoch: 3390  | Training Loss: 0.36745 \nEpoch: 3390  | Training Loss: 0.34478 \nEpoch: 3390  | Training Loss: 0.21311 \nEpoch: 3390  | Training Loss: 0.15080 \nEpoch: 3390  | Validation balanced accuracy : 0.76304 \nEpoch: 3391  | Training Loss: 0.31524 \nEpoch: 3391  | Training Loss: 0.36754 \nEpoch: 3391  | Training Loss: 0.34472 \nEpoch: 3391  | Training Loss: 0.21313 \nEpoch: 3391  | Training Loss: 0.15053 \nEpoch: 3391  | Validation balanced accuracy : 0.76304 \nEpoch: 3392  | Training Loss: 0.31544 \nEpoch: 3392  | Training Loss: 0.36764 \nEpoch: 3392  | Training Loss: 0.34471 \nEpoch: 3392  | Training Loss: 0.21313 \nEpoch: 3392  | Training Loss: 0.15065 \nEpoch: 3392  | Validation balanced accuracy : 0.76304 \nEpoch: 3393  | Training Loss: 0.31529 \nEpoch: 3393  | Training Loss: 0.36749 \nEpoch: 3393  | Training Loss: 0.34481 \nEpoch: 3393  | Training Loss: 0.21310 \nEpoch: 3393  | Training Loss: 0.15101 \nEpoch: 3393  | Validation balanced accuracy : 0.76304 \nEpoch: 3394  | Training Loss: 0.31503 \nEpoch: 3394  | Training Loss: 0.36736 \nEpoch: 3394  | Training Loss: 0.34486 \nEpoch: 3394  | Training Loss: 0.21309 \nEpoch: 3394  | Training Loss: 0.15092 \nEpoch: 3394  | Validation balanced accuracy : 0.76304 \nEpoch: 3395  | Training Loss: 0.31515 \nEpoch: 3395  | Training Loss: 0.36749 \nEpoch: 3395  | Training Loss: 0.34477 \nEpoch: 3395  | Training Loss: 0.21312 \nEpoch: 3395  | Training Loss: 0.15052 \nEpoch: 3395  | Validation balanced accuracy : 0.76304 \nEpoch: 3396  | Training Loss: 0.31545 \nEpoch: 3396  | Training Loss: 0.36765 \nEpoch: 3396  | Training Loss: 0.34472 \nEpoch: 3396  | Training Loss: 0.21312 \nEpoch: 3396  | Training Loss: 0.15058 \nEpoch: 3396  | Validation balanced accuracy : 0.76304 \nEpoch: 3397  | Training Loss: 0.31533 \nEpoch: 3397  | Training Loss: 0.36752 \nEpoch: 3397  | Training Loss: 0.34482 \nEpoch: 3397  | Training Loss: 0.21309 \nEpoch: 3397  | Training Loss: 0.15092 \nEpoch: 3397  | Validation balanced accuracy : 0.76304 \nEpoch: 3398  | Training Loss: 0.31508 \nEpoch: 3398  | Training Loss: 0.36740 \nEpoch: 3398  | Training Loss: 0.34487 \nEpoch: 3398  | Training Loss: 0.21309 \nEpoch: 3398  | Training Loss: 0.15085 \nEpoch: 3398  | Validation balanced accuracy : 0.76304 \nEpoch: 3399  | Training Loss: 0.31519 \nEpoch: 3399  | Training Loss: 0.36750 \nEpoch: 3399  | Training Loss: 0.34479 \nEpoch: 3399  | Training Loss: 0.21311 \nEpoch: 3399  | Training Loss: 0.15053 \nEpoch: 3399  | Validation balanced accuracy : 0.76304 \nEpoch: 3400  | Training Loss: 0.31542 \nEpoch: 3400  | Training Loss: 0.36762 \nEpoch: 3400  | Training Loss: 0.34476 \nEpoch: 3400  | Training Loss: 0.21311 \nEpoch: 3400  | Training Loss: 0.15061 \nEpoch: 3400  | Validation balanced accuracy : 0.76304 \nEpoch: 3401  | Training Loss: 0.31530 \nEpoch: 3401  | Training Loss: 0.36755 \nEpoch: 3401  | Training Loss: 0.34479 \nEpoch: 3401  | Training Loss: 0.21310 \nEpoch: 3401  | Training Loss: 0.15057 \nEpoch: 3401  | Validation balanced accuracy : 0.76304 \nEpoch: 3402  | Training Loss: 0.31535 \nEpoch: 3402  | Training Loss: 0.36761 \nEpoch: 3402  | Training Loss: 0.34476 \nEpoch: 3402  | Training Loss: 0.21311 \nEpoch: 3402  | Training Loss: 0.15042 \nEpoch: 3402  | Validation balanced accuracy : 0.76304 \nEpoch: 3403  | Training Loss: 0.31546 \nEpoch: 3403  | Training Loss: 0.36763 \nEpoch: 3403  | Training Loss: 0.34478 \nEpoch: 3403  | Training Loss: 0.21310 \nEpoch: 3403  | Training Loss: 0.15066 \nEpoch: 3403  | Validation balanced accuracy : 0.76304 \nEpoch: 3404  | Training Loss: 0.31524 \nEpoch: 3404  | Training Loss: 0.36750 \nEpoch: 3404  | Training Loss: 0.34484 \nEpoch: 3404  | Training Loss: 0.21308 \nEpoch: 3404  | Training Loss: 0.15069 \nEpoch: 3404  | Validation balanced accuracy : 0.76304 \nEpoch: 3405  | Training Loss: 0.31526 \nEpoch: 3405  | Training Loss: 0.36754 \nEpoch: 3405  | Training Loss: 0.34481 \nEpoch: 3405  | Training Loss: 0.21310 \nEpoch: 3405  | Training Loss: 0.15049 \nEpoch: 3405  | Validation balanced accuracy : 0.76304 \nEpoch: 3406  | Training Loss: 0.31542 \nEpoch: 3406  | Training Loss: 0.36761 \nEpoch: 3406  | Training Loss: 0.34480 \nEpoch: 3406  | Training Loss: 0.21309 \nEpoch: 3406  | Training Loss: 0.15061 \nEpoch: 3406  | Validation balanced accuracy : 0.76304 \nEpoch: 3407  | Training Loss: 0.31528 \nEpoch: 3407  | Training Loss: 0.36754 \nEpoch: 3407  | Training Loss: 0.34483 \nEpoch: 3407  | Training Loss: 0.21309 \nEpoch: 3407  | Training Loss: 0.15056 \nEpoch: 3407  | Validation balanced accuracy : 0.76304 \nEpoch: 3408  | Training Loss: 0.31535 \nEpoch: 3408  | Training Loss: 0.36761 \nEpoch: 3408  | Training Loss: 0.34479 \nEpoch: 3408  | Training Loss: 0.21310 \nEpoch: 3408  | Training Loss: 0.15040 \nEpoch: 3408  | Validation balanced accuracy : 0.76304 \nEpoch: 3409  | Training Loss: 0.31546 \nEpoch: 3409  | Training Loss: 0.36764 \nEpoch: 3409  | Training Loss: 0.34481 \nEpoch: 3409  | Training Loss: 0.21308 \nEpoch: 3409  | Training Loss: 0.15062 \nEpoch: 3409  | Validation balanced accuracy : 0.76304 \nEpoch: 3410  | Training Loss: 0.31525 \nEpoch: 3410  | Training Loss: 0.36751 \nEpoch: 3410  | Training Loss: 0.34487 \nEpoch: 3410  | Training Loss: 0.21307 \nEpoch: 3410  | Training Loss: 0.15064 \nEpoch: 3410  | Validation balanced accuracy : 0.76304 \nEpoch: 3411  | Training Loss: 0.31528 \nEpoch: 3411  | Training Loss: 0.36756 \nEpoch: 3411  | Training Loss: 0.34483 \nEpoch: 3411  | Training Loss: 0.21308 \nEpoch: 3411  | Training Loss: 0.15043 \nEpoch: 3411  | Validation balanced accuracy : 0.76304 \nEpoch: 3412  | Training Loss: 0.31544 \nEpoch: 3412  | Training Loss: 0.36763 \nEpoch: 3412  | Training Loss: 0.34483 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3412  | Training Loss: 0.21308 \nEpoch: 3412  | Training Loss: 0.15058 \nEpoch: 3412  | Validation balanced accuracy : 0.76304 \nEpoch: 3413  | Training Loss: 0.31528 \nEpoch: 3413  | Training Loss: 0.36754 \nEpoch: 3413  | Training Loss: 0.34487 \nEpoch: 3413  | Training Loss: 0.21307 \nEpoch: 3413  | Training Loss: 0.15056 \nEpoch: 3413  | Validation balanced accuracy : 0.76304 \nEpoch: 3414  | Training Loss: 0.31532 \nEpoch: 3414  | Training Loss: 0.36759 \nEpoch: 3414  | Training Loss: 0.34483 \nEpoch: 3414  | Training Loss: 0.21308 \nEpoch: 3414  | Training Loss: 0.15035 \nEpoch: 3414  | Validation balanced accuracy : 0.76304 \nEpoch: 3415  | Training Loss: 0.31549 \nEpoch: 3415  | Training Loss: 0.36766 \nEpoch: 3415  | Training Loss: 0.34483 \nEpoch: 3415  | Training Loss: 0.21307 \nEpoch: 3415  | Training Loss: 0.15055 \nEpoch: 3415  | Validation balanced accuracy : 0.76304 \nEpoch: 3416  | Training Loss: 0.31528 \nEpoch: 3416  | Training Loss: 0.36754 \nEpoch: 3416  | Training Loss: 0.34489 \nEpoch: 3416  | Training Loss: 0.21306 \nEpoch: 3416  | Training Loss: 0.15057 \nEpoch: 3416  | Validation balanced accuracy : 0.76304 \nEpoch: 3417  | Training Loss: 0.31530 \nEpoch: 3417  | Training Loss: 0.36758 \nEpoch: 3417  | Training Loss: 0.34485 \nEpoch: 3417  | Training Loss: 0.21307 \nEpoch: 3417  | Training Loss: 0.15038 \nEpoch: 3417  | Validation balanced accuracy : 0.76304 \nEpoch: 3418  | Training Loss: 0.31546 \nEpoch: 3418  | Training Loss: 0.36764 \nEpoch: 3418  | Training Loss: 0.34485 \nEpoch: 3418  | Training Loss: 0.21306 \nEpoch: 3418  | Training Loss: 0.15053 \nEpoch: 3418  | Validation balanced accuracy : 0.76304 \nEpoch: 3419  | Training Loss: 0.31529 \nEpoch: 3419  | Training Loss: 0.36755 \nEpoch: 3419  | Training Loss: 0.34490 \nEpoch: 3419  | Training Loss: 0.21306 \nEpoch: 3419  | Training Loss: 0.15053 \nEpoch: 3419  | Validation balanced accuracy : 0.76304 \nEpoch: 3420  | Training Loss: 0.31533 \nEpoch: 3420  | Training Loss: 0.36760 \nEpoch: 3420  | Training Loss: 0.34486 \nEpoch: 3420  | Training Loss: 0.21307 \nEpoch: 3420  | Training Loss: 0.15032 \nEpoch: 3420  | Validation balanced accuracy : 0.76304 \nEpoch: 3421  | Training Loss: 0.31549 \nEpoch: 3421  | Training Loss: 0.36767 \nEpoch: 3421  | Training Loss: 0.34486 \nEpoch: 3421  | Training Loss: 0.21306 \nEpoch: 3421  | Training Loss: 0.15048 \nEpoch: 3421  | Validation balanced accuracy : 0.76304 \nEpoch: 3422  | Training Loss: 0.31532 \nEpoch: 3422  | Training Loss: 0.36757 \nEpoch: 3422  | Training Loss: 0.34490 \nEpoch: 3422  | Training Loss: 0.21305 \nEpoch: 3422  | Training Loss: 0.15049 \nEpoch: 3422  | Validation balanced accuracy : 0.76304 \nEpoch: 3423  | Training Loss: 0.31534 \nEpoch: 3423  | Training Loss: 0.36761 \nEpoch: 3423  | Training Loss: 0.34487 \nEpoch: 3423  | Training Loss: 0.21306 \nEpoch: 3423  | Training Loss: 0.15030 \nEpoch: 3423  | Validation balanced accuracy : 0.76304 \nEpoch: 3424  | Training Loss: 0.31550 \nEpoch: 3424  | Training Loss: 0.36767 \nEpoch: 3424  | Training Loss: 0.34487 \nEpoch: 3424  | Training Loss: 0.21305 \nEpoch: 3424  | Training Loss: 0.15050 \nEpoch: 3424  | Validation balanced accuracy : 0.76304 \nEpoch: 3425  | Training Loss: 0.31529 \nEpoch: 3425  | Training Loss: 0.36755 \nEpoch: 3425  | Training Loss: 0.34493 \nEpoch: 3425  | Training Loss: 0.21304 \nEpoch: 3425  | Training Loss: 0.15053 \nEpoch: 3425  | Validation balanced accuracy : 0.76304 \nEpoch: 3426  | Training Loss: 0.31531 \nEpoch: 3426  | Training Loss: 0.36759 \nEpoch: 3426  | Training Loss: 0.34490 \nEpoch: 3426  | Training Loss: 0.21305 \nEpoch: 3426  | Training Loss: 0.15033 \nEpoch: 3426  | Validation balanced accuracy : 0.76304 \nEpoch: 3427  | Training Loss: 0.31547 \nEpoch: 3427  | Training Loss: 0.36765 \nEpoch: 3427  | Training Loss: 0.34490 \nEpoch: 3427  | Training Loss: 0.21304 \nEpoch: 3427  | Training Loss: 0.15048 \nEpoch: 3427  | Validation balanced accuracy : 0.76304 \nEpoch: 3428  | Training Loss: 0.31530 \nEpoch: 3428  | Training Loss: 0.36756 \nEpoch: 3428  | Training Loss: 0.34494 \nEpoch: 3428  | Training Loss: 0.21304 \nEpoch: 3428  | Training Loss: 0.15047 \nEpoch: 3428  | Validation balanced accuracy : 0.76304 \nEpoch: 3429  | Training Loss: 0.31534 \nEpoch: 3429  | Training Loss: 0.36761 \nEpoch: 3429  | Training Loss: 0.34490 \nEpoch: 3429  | Training Loss: 0.21305 \nEpoch: 3429  | Training Loss: 0.15026 \nEpoch: 3429  | Validation balanced accuracy : 0.76304 \nEpoch: 3430  | Training Loss: 0.31551 \nEpoch: 3430  | Training Loss: 0.36768 \nEpoch: 3430  | Training Loss: 0.34489 \nEpoch: 3430  | Training Loss: 0.21304 \nEpoch: 3430  | Training Loss: 0.15042 \nEpoch: 3430  | Validation balanced accuracy : 0.76304 \nEpoch: 3431  | Training Loss: 0.31533 \nEpoch: 3431  | Training Loss: 0.36758 \nEpoch: 3431  | Training Loss: 0.34494 \nEpoch: 3431  | Training Loss: 0.21303 \nEpoch: 3431  | Training Loss: 0.15043 \nEpoch: 3431  | Validation balanced accuracy : 0.76304 \nEpoch: 3432  | Training Loss: 0.31536 \nEpoch: 3432  | Training Loss: 0.36762 \nEpoch: 3432  | Training Loss: 0.34491 \nEpoch: 3432  | Training Loss: 0.21304 \nEpoch: 3432  | Training Loss: 0.15027 \nEpoch: 3432  | Validation balanced accuracy : 0.76304 \nEpoch: 3433  | Training Loss: 0.31548 \nEpoch: 3433  | Training Loss: 0.36766 \nEpoch: 3433  | Training Loss: 0.34492 \nEpoch: 3433  | Training Loss: 0.21303 \nEpoch: 3433  | Training Loss: 0.15046 \nEpoch: 3433  | Validation balanced accuracy : 0.76304 \nEpoch: 3434  | Training Loss: 0.31530 \nEpoch: 3434  | Training Loss: 0.36756 \nEpoch: 3434  | Training Loss: 0.34497 \nEpoch: 3434  | Training Loss: 0.21302 \nEpoch: 3434  | Training Loss: 0.15046 \nEpoch: 3434  | Validation balanced accuracy : 0.76304 \nEpoch: 3435  | Training Loss: 0.31533 \nEpoch: 3435  | Training Loss: 0.36760 \nEpoch: 3435  | Training Loss: 0.34493 \nEpoch: 3435  | Training Loss: 0.21303 \nEpoch: 3435  | Training Loss: 0.15025 \nEpoch: 3435  | Validation balanced accuracy : 0.76304 \nEpoch: 3436  | Training Loss: 0.31549 \nEpoch: 3436  | Training Loss: 0.36768 \nEpoch: 3436  | Training Loss: 0.34493 \nEpoch: 3436  | Training Loss: 0.21302 \nEpoch: 3436  | Training Loss: 0.15040 \nEpoch: 3436  | Validation balanced accuracy : 0.76304 \nEpoch: 3437  | Training Loss: 0.31533 \nEpoch: 3437  | Training Loss: 0.36758 \nEpoch: 3437  | Training Loss: 0.34497 \nEpoch: 3437  | Training Loss: 0.21302 \nEpoch: 3437  | Training Loss: 0.15040 \nEpoch: 3437  | Validation balanced accuracy : 0.76304 \nEpoch: 3438  | Training Loss: 0.31537 \nEpoch: 3438  | Training Loss: 0.36763 \nEpoch: 3438  | Training Loss: 0.34493 \nEpoch: 3438  | Training Loss: 0.21303 \nEpoch: 3438  | Training Loss: 0.15020 \nEpoch: 3438  | Validation balanced accuracy : 0.76304 \nEpoch: 3439  | Training Loss: 0.31552 \nEpoch: 3439  | Training Loss: 0.36770 \nEpoch: 3439  | Training Loss: 0.34493 \nEpoch: 3439  | Training Loss: 0.21302 \nEpoch: 3439  | Training Loss: 0.15036 \nEpoch: 3439  | Validation balanced accuracy : 0.76304 \nEpoch: 3440  | Training Loss: 0.31535 \nEpoch: 3440  | Training Loss: 0.36759 \nEpoch: 3440  | Training Loss: 0.34498 \nEpoch: 3440  | Training Loss: 0.21301 \nEpoch: 3440  | Training Loss: 0.15037 \nEpoch: 3440  | Validation balanced accuracy : 0.76304 \nEpoch: 3441  | Training Loss: 0.31537 \nEpoch: 3441  | Training Loss: 0.36763 \nEpoch: 3441  | Training Loss: 0.34495 \nEpoch: 3441  | Training Loss: 0.21302 \nEpoch: 3441  | Training Loss: 0.15022 \nEpoch: 3441  | Validation balanced accuracy : 0.76304 \nEpoch: 3442  | Training Loss: 0.31549 \nEpoch: 3442  | Training Loss: 0.36767 \nEpoch: 3442  | Training Loss: 0.34496 \nEpoch: 3442  | Training Loss: 0.21301 \nEpoch: 3442  | Training Loss: 0.15035 \nEpoch: 3442  | Validation balanced accuracy : 0.76304 \nEpoch: 3443  | Training Loss: 0.31536 \nEpoch: 3443  | Training Loss: 0.36761 \nEpoch: 3443  | Training Loss: 0.34499 \nEpoch: 3443  | Training Loss: 0.21301 \nEpoch: 3443  | Training Loss: 0.15031 \nEpoch: 3443  | Validation balanced accuracy : 0.76304 \nEpoch: 3444  | Training Loss: 0.31542 \nEpoch: 3444  | Training Loss: 0.36767 \nEpoch: 3444  | Training Loss: 0.34494 \nEpoch: 3444  | Training Loss: 0.21302 \nEpoch: 3444  | Training Loss: 0.15010 \nEpoch: 3444  | Validation balanced accuracy : 0.76304 \nEpoch: 3445  | Training Loss: 0.31557 \nEpoch: 3445  | Training Loss: 0.36773 \nEpoch: 3445  | Training Loss: 0.34494 \nEpoch: 3445  | Training Loss: 0.21301 \nEpoch: 3445  | Training Loss: 0.15028 \nEpoch: 3445  | Validation balanced accuracy : 0.76304 \nEpoch: 3446  | Training Loss: 0.31538 \nEpoch: 3446  | Training Loss: 0.36762 \nEpoch: 3446  | Training Loss: 0.34500 \nEpoch: 3446  | Training Loss: 0.21300 \nEpoch: 3446  | Training Loss: 0.15032 \nEpoch: 3446  | Validation balanced accuracy : 0.76304 \nEpoch: 3447  | Training Loss: 0.31539 \nEpoch: 3447  | Training Loss: 0.36765 \nEpoch: 3447  | Training Loss: 0.34497 \nEpoch: 3447  | Training Loss: 0.21301 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3447  | Training Loss: 0.15015 \nEpoch: 3447  | Validation balanced accuracy : 0.76304 \nEpoch: 3448  | Training Loss: 0.31553 \nEpoch: 3448  | Training Loss: 0.36770 \nEpoch: 3448  | Training Loss: 0.34498 \nEpoch: 3448  | Training Loss: 0.21300 \nEpoch: 3448  | Training Loss: 0.15033 \nEpoch: 3448  | Validation balanced accuracy : 0.76304 \nEpoch: 3449  | Training Loss: 0.31535 \nEpoch: 3449  | Training Loss: 0.36759 \nEpoch: 3449  | Training Loss: 0.34503 \nEpoch: 3449  | Training Loss: 0.21299 \nEpoch: 3449  | Training Loss: 0.15034 \nEpoch: 3449  | Validation balanced accuracy : 0.76304 \nEpoch: 3450  | Training Loss: 0.31537 \nEpoch: 3450  | Training Loss: 0.36763 \nEpoch: 3450  | Training Loss: 0.34500 \nEpoch: 3450  | Training Loss: 0.21300 \nEpoch: 3450  | Training Loss: 0.15018 \nEpoch: 3450  | Validation balanced accuracy : 0.76304 \nEpoch: 3451  | Training Loss: 0.31550 \nEpoch: 3451  | Training Loss: 0.36768 \nEpoch: 3451  | Training Loss: 0.34500 \nEpoch: 3451  | Training Loss: 0.21299 \nEpoch: 3451  | Training Loss: 0.15030 \nEpoch: 3451  | Validation balanced accuracy : 0.76304 \nEpoch: 3452  | Training Loss: 0.31537 \nEpoch: 3452  | Training Loss: 0.36762 \nEpoch: 3452  | Training Loss: 0.34502 \nEpoch: 3452  | Training Loss: 0.21299 \nEpoch: 3452  | Training Loss: 0.15025 \nEpoch: 3452  | Validation balanced accuracy : 0.76304 \nEpoch: 3453  | Training Loss: 0.31543 \nEpoch: 3453  | Training Loss: 0.36768 \nEpoch: 3453  | Training Loss: 0.34498 \nEpoch: 3453  | Training Loss: 0.21300 \nEpoch: 3453  | Training Loss: 0.15004 \nEpoch: 3453  | Validation balanced accuracy : 0.76304 \nEpoch: 3454  | Training Loss: 0.31559 \nEpoch: 3454  | Training Loss: 0.36775 \nEpoch: 3454  | Training Loss: 0.34498 \nEpoch: 3454  | Training Loss: 0.21299 \nEpoch: 3454  | Training Loss: 0.15022 \nEpoch: 3454  | Validation balanced accuracy : 0.76304 \nEpoch: 3455  | Training Loss: 0.31540 \nEpoch: 3455  | Training Loss: 0.36763 \nEpoch: 3455  | Training Loss: 0.34503 \nEpoch: 3455  | Training Loss: 0.21298 \nEpoch: 3455  | Training Loss: 0.15026 \nEpoch: 3455  | Validation balanced accuracy : 0.76304 \nEpoch: 3456  | Training Loss: 0.31541 \nEpoch: 3456  | Training Loss: 0.36767 \nEpoch: 3456  | Training Loss: 0.34501 \nEpoch: 3456  | Training Loss: 0.21299 \nEpoch: 3456  | Training Loss: 0.15009 \nEpoch: 3456  | Validation balanced accuracy : 0.76304 \nEpoch: 3457  | Training Loss: 0.31555 \nEpoch: 3457  | Training Loss: 0.36772 \nEpoch: 3457  | Training Loss: 0.34501 \nEpoch: 3457  | Training Loss: 0.21298 \nEpoch: 3457  | Training Loss: 0.15027 \nEpoch: 3457  | Validation balanced accuracy : 0.76304 \nEpoch: 3458  | Training Loss: 0.31536 \nEpoch: 3458  | Training Loss: 0.36761 \nEpoch: 3458  | Training Loss: 0.34506 \nEpoch: 3458  | Training Loss: 0.21297 \nEpoch: 3458  | Training Loss: 0.15029 \nEpoch: 3458  | Validation balanced accuracy : 0.76304 \nEpoch: 3459  | Training Loss: 0.31538 \nEpoch: 3459  | Training Loss: 0.36765 \nEpoch: 3459  | Training Loss: 0.34503 \nEpoch: 3459  | Training Loss: 0.21298 \nEpoch: 3459  | Training Loss: 0.15011 \nEpoch: 3459  | Validation balanced accuracy : 0.76304 \nEpoch: 3460  | Training Loss: 0.31552 \nEpoch: 3460  | Training Loss: 0.36770 \nEpoch: 3460  | Training Loss: 0.34503 \nEpoch: 3460  | Training Loss: 0.21298 \nEpoch: 3460  | Training Loss: 0.15022 \nEpoch: 3460  | Validation balanced accuracy : 0.76304 \nEpoch: 3461  | Training Loss: 0.31540 \nEpoch: 3461  | Training Loss: 0.36764 \nEpoch: 3461  | Training Loss: 0.34505 \nEpoch: 3461  | Training Loss: 0.21297 \nEpoch: 3461  | Training Loss: 0.15018 \nEpoch: 3461  | Validation balanced accuracy : 0.76304 \nEpoch: 3462  | Training Loss: 0.31546 \nEpoch: 3462  | Training Loss: 0.36771 \nEpoch: 3462  | Training Loss: 0.34501 \nEpoch: 3462  | Training Loss: 0.21299 \nEpoch: 3462  | Training Loss: 0.14998 \nEpoch: 3462  | Validation balanced accuracy : 0.76304 \nEpoch: 3463  | Training Loss: 0.31561 \nEpoch: 3463  | Training Loss: 0.36776 \nEpoch: 3463  | Training Loss: 0.34502 \nEpoch: 3463  | Training Loss: 0.21297 \nEpoch: 3463  | Training Loss: 0.15020 \nEpoch: 3463  | Validation balanced accuracy : 0.76304 \nEpoch: 3464  | Training Loss: 0.31539 \nEpoch: 3464  | Training Loss: 0.36762 \nEpoch: 3464  | Training Loss: 0.34508 \nEpoch: 3464  | Training Loss: 0.21296 \nEpoch: 3464  | Training Loss: 0.15025 \nEpoch: 3464  | Validation balanced accuracy : 0.76304 \nEpoch: 3465  | Training Loss: 0.31539 \nEpoch: 3465  | Training Loss: 0.36765 \nEpoch: 3465  | Training Loss: 0.34506 \nEpoch: 3465  | Training Loss: 0.21297 \nEpoch: 3465  | Training Loss: 0.15008 \nEpoch: 3465  | Validation balanced accuracy : 0.76304 \nEpoch: 3466  | Training Loss: 0.31553 \nEpoch: 3466  | Training Loss: 0.36771 \nEpoch: 3466  | Training Loss: 0.34506 \nEpoch: 3466  | Training Loss: 0.21296 \nEpoch: 3466  | Training Loss: 0.15020 \nEpoch: 3466  | Validation balanced accuracy : 0.76304 \nEpoch: 3467  | Training Loss: 0.31540 \nEpoch: 3467  | Training Loss: 0.36765 \nEpoch: 3467  | Training Loss: 0.34508 \nEpoch: 3467  | Training Loss: 0.21296 \nEpoch: 3467  | Training Loss: 0.15015 \nEpoch: 3467  | Validation balanced accuracy : 0.76304 \nEpoch: 3468  | Training Loss: 0.31547 \nEpoch: 3468  | Training Loss: 0.36771 \nEpoch: 3468  | Training Loss: 0.34503 \nEpoch: 3468  | Training Loss: 0.21298 \nEpoch: 3468  | Training Loss: 0.14994 \nEpoch: 3468  | Validation balanced accuracy : 0.76304 \nEpoch: 3469  | Training Loss: 0.31562 \nEpoch: 3469  | Training Loss: 0.36777 \nEpoch: 3469  | Training Loss: 0.34504 \nEpoch: 3469  | Training Loss: 0.21296 \nEpoch: 3469  | Training Loss: 0.15013 \nEpoch: 3469  | Validation balanced accuracy : 0.76304 \nEpoch: 3470  | Training Loss: 0.31543 \nEpoch: 3470  | Training Loss: 0.36766 \nEpoch: 3470  | Training Loss: 0.34509 \nEpoch: 3470  | Training Loss: 0.21295 \nEpoch: 3470  | Training Loss: 0.15017 \nEpoch: 3470  | Validation balanced accuracy : 0.76304 \nEpoch: 3471  | Training Loss: 0.31543 \nEpoch: 3471  | Training Loss: 0.36769 \nEpoch: 3471  | Training Loss: 0.34507 \nEpoch: 3471  | Training Loss: 0.21296 \nEpoch: 3471  | Training Loss: 0.15000 \nEpoch: 3471  | Validation balanced accuracy : 0.76304 \nEpoch: 3472  | Training Loss: 0.31557 \nEpoch: 3472  | Training Loss: 0.36773 \nEpoch: 3472  | Training Loss: 0.34507 \nEpoch: 3472  | Training Loss: 0.21296 \nEpoch: 3472  | Training Loss: 0.15013 \nEpoch: 3472  | Validation balanced accuracy : 0.76304 \nEpoch: 3473  | Training Loss: 0.31543 \nEpoch: 3473  | Training Loss: 0.36767 \nEpoch: 3473  | Training Loss: 0.34510 \nEpoch: 3473  | Training Loss: 0.21295 \nEpoch: 3473  | Training Loss: 0.15010 \nEpoch: 3473  | Validation balanced accuracy : 0.76304 \nEpoch: 3474  | Training Loss: 0.31548 \nEpoch: 3474  | Training Loss: 0.36772 \nEpoch: 3474  | Training Loss: 0.34506 \nEpoch: 3474  | Training Loss: 0.21296 \nEpoch: 3474  | Training Loss: 0.14995 \nEpoch: 3474  | Validation balanced accuracy : 0.76304 \nEpoch: 3475  | Training Loss: 0.31560 \nEpoch: 3475  | Training Loss: 0.36775 \nEpoch: 3475  | Training Loss: 0.34508 \nEpoch: 3475  | Training Loss: 0.21295 \nEpoch: 3475  | Training Loss: 0.15016 \nEpoch: 3475  | Validation balanced accuracy : 0.76304 \nEpoch: 3476  | Training Loss: 0.31539 \nEpoch: 3476  | Training Loss: 0.36763 \nEpoch: 3476  | Training Loss: 0.34513 \nEpoch: 3476  | Training Loss: 0.21294 \nEpoch: 3476  | Training Loss: 0.15019 \nEpoch: 3476  | Validation balanced accuracy : 0.76304 \nEpoch: 3477  | Training Loss: 0.31541 \nEpoch: 3477  | Training Loss: 0.36767 \nEpoch: 3477  | Training Loss: 0.34510 \nEpoch: 3477  | Training Loss: 0.21295 \nEpoch: 3477  | Training Loss: 0.15000 \nEpoch: 3477  | Validation balanced accuracy : 0.76304 \nEpoch: 3478  | Training Loss: 0.31555 \nEpoch: 3478  | Training Loss: 0.36773 \nEpoch: 3478  | Training Loss: 0.34510 \nEpoch: 3478  | Training Loss: 0.21294 \nEpoch: 3478  | Training Loss: 0.15011 \nEpoch: 3478  | Validation balanced accuracy : 0.76304 \nEpoch: 3479  | Training Loss: 0.31543 \nEpoch: 3479  | Training Loss: 0.36767 \nEpoch: 3479  | Training Loss: 0.34512 \nEpoch: 3479  | Training Loss: 0.21294 \nEpoch: 3479  | Training Loss: 0.15006 \nEpoch: 3479  | Validation balanced accuracy : 0.76304 \nEpoch: 3480  | Training Loss: 0.31549 \nEpoch: 3480  | Training Loss: 0.36773 \nEpoch: 3480  | Training Loss: 0.34508 \nEpoch: 3480  | Training Loss: 0.21295 \nEpoch: 3480  | Training Loss: 0.14986 \nEpoch: 3480  | Validation balanced accuracy : 0.76304 \nEpoch: 3481  | Training Loss: 0.31564 \nEpoch: 3481  | Training Loss: 0.36779 \nEpoch: 3481  | Training Loss: 0.34508 \nEpoch: 3481  | Training Loss: 0.21294 \nEpoch: 3481  | Training Loss: 0.15006 \nEpoch: 3481  | Validation balanced accuracy : 0.76304 \nEpoch: 3482  | Training Loss: 0.31545 \nEpoch: 3482  | Training Loss: 0.36767 \nEpoch: 3482  | Training Loss: 0.34514 \nEpoch: 3482  | Training Loss: 0.21293 \nEpoch: 3482  | Training Loss: 0.15010 \nEpoch: 3482  | Validation balanced accuracy : 0.76304 \nEpoch: 3483  | Training Loss: 0.31545 \nEpoch: 3483  | Training Loss: 0.36770 \nEpoch: 3483  | Training Loss: 0.34511 \nEpoch: 3483  | Training Loss: 0.21294 \nEpoch: 3483  | Training Loss: 0.14994 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3483  | Validation balanced accuracy : 0.76304 \nEpoch: 3484  | Training Loss: 0.31558 \nEpoch: 3484  | Training Loss: 0.36774 \nEpoch: 3484  | Training Loss: 0.34512 \nEpoch: 3484  | Training Loss: 0.21293 \nEpoch: 3484  | Training Loss: 0.15010 \nEpoch: 3484  | Validation balanced accuracy : 0.76304 \nEpoch: 3485  | Training Loss: 0.31542 \nEpoch: 3485  | Training Loss: 0.36766 \nEpoch: 3485  | Training Loss: 0.34516 \nEpoch: 3485  | Training Loss: 0.21292 \nEpoch: 3485  | Training Loss: 0.15009 \nEpoch: 3485  | Validation balanced accuracy : 0.76304 \nEpoch: 3486  | Training Loss: 0.31546 \nEpoch: 3486  | Training Loss: 0.36771 \nEpoch: 3486  | Training Loss: 0.34512 \nEpoch: 3486  | Training Loss: 0.21294 \nEpoch: 3486  | Training Loss: 0.14989 \nEpoch: 3486  | Validation balanced accuracy : 0.76304 \nEpoch: 3487  | Training Loss: 0.31561 \nEpoch: 3487  | Training Loss: 0.36777 \nEpoch: 3487  | Training Loss: 0.34512 \nEpoch: 3487  | Training Loss: 0.21293 \nEpoch: 3487  | Training Loss: 0.15006 \nEpoch: 3487  | Validation balanced accuracy : 0.76304 \nEpoch: 3488  | Training Loss: 0.31543 \nEpoch: 3488  | Training Loss: 0.36766 \nEpoch: 3488  | Training Loss: 0.34517 \nEpoch: 3488  | Training Loss: 0.21292 \nEpoch: 3488  | Training Loss: 0.15008 \nEpoch: 3488  | Validation balanced accuracy : 0.76304 \nEpoch: 3489  | Training Loss: 0.31545 \nEpoch: 3489  | Training Loss: 0.36770 \nEpoch: 3489  | Training Loss: 0.34514 \nEpoch: 3489  | Training Loss: 0.21293 \nEpoch: 3489  | Training Loss: 0.14990 \nEpoch: 3489  | Validation balanced accuracy : 0.76304 \nEpoch: 3490  | Training Loss: 0.31559 \nEpoch: 3490  | Training Loss: 0.36776 \nEpoch: 3490  | Training Loss: 0.34514 \nEpoch: 3490  | Training Loss: 0.21292 \nEpoch: 3490  | Training Loss: 0.15002 \nEpoch: 3490  | Validation balanced accuracy : 0.76304 \nEpoch: 3491  | Training Loss: 0.31546 \nEpoch: 3491  | Training Loss: 0.36769 \nEpoch: 3491  | Training Loss: 0.34516 \nEpoch: 3491  | Training Loss: 0.21292 \nEpoch: 3491  | Training Loss: 0.14999 \nEpoch: 3491  | Validation balanced accuracy : 0.76304 \nEpoch: 3492  | Training Loss: 0.31551 \nEpoch: 3492  | Training Loss: 0.36775 \nEpoch: 3492  | Training Loss: 0.34512 \nEpoch: 3492  | Training Loss: 0.21293 \nEpoch: 3492  | Training Loss: 0.14980 \nEpoch: 3492  | Validation balanced accuracy : 0.76304 \nEpoch: 3493  | Training Loss: 0.31566 \nEpoch: 3493  | Training Loss: 0.36780 \nEpoch: 3493  | Training Loss: 0.34514 \nEpoch: 3493  | Training Loss: 0.21292 \nEpoch: 3493  | Training Loss: 0.15003 \nEpoch: 3493  | Validation balanced accuracy : 0.76304 \nEpoch: 3494  | Training Loss: 0.31543 \nEpoch: 3494  | Training Loss: 0.36766 \nEpoch: 3494  | Training Loss: 0.34520 \nEpoch: 3494  | Training Loss: 0.21290 \nEpoch: 3494  | Training Loss: 0.15009 \nEpoch: 3494  | Validation balanced accuracy : 0.76304 \nEpoch: 3495  | Training Loss: 0.31543 \nEpoch: 3495  | Training Loss: 0.36768 \nEpoch: 3495  | Training Loss: 0.34518 \nEpoch: 3495  | Training Loss: 0.21291 \nEpoch: 3495  | Training Loss: 0.14992 \nEpoch: 3495  | Validation balanced accuracy : 0.76304 \nEpoch: 3496  | Training Loss: 0.31556 \nEpoch: 3496  | Training Loss: 0.36780 \nEpoch: 3496  | Training Loss: 0.34512 \nEpoch: 3496  | Training Loss: 0.21293 \nEpoch: 3496  | Training Loss: 0.14972 \nEpoch: 3496  | Validation balanced accuracy : 0.76304 \nEpoch: 3497  | Training Loss: 0.31570 \nEpoch: 3497  | Training Loss: 0.36783 \nEpoch: 3497  | Training Loss: 0.34514 \nEpoch: 3497  | Training Loss: 0.21291 \nEpoch: 3497  | Training Loss: 0.14996 \nEpoch: 3497  | Validation balanced accuracy : 0.76304 \nEpoch: 3498  | Training Loss: 0.31547 \nEpoch: 3498  | Training Loss: 0.36769 \nEpoch: 3498  | Training Loss: 0.34520 \nEpoch: 3498  | Training Loss: 0.21290 \nEpoch: 3498  | Training Loss: 0.15003 \nEpoch: 3498  | Validation balanced accuracy : 0.76304 \nEpoch: 3499  | Training Loss: 0.31546 \nEpoch: 3499  | Training Loss: 0.36770 \nEpoch: 3499  | Training Loss: 0.34519 \nEpoch: 3499  | Training Loss: 0.21291 \nEpoch: 3499  | Training Loss: 0.14988 \nEpoch: 3499  | Validation balanced accuracy : 0.76304 \nEpoch: 3500  | Training Loss: 0.31558 \nEpoch: 3500  | Training Loss: 0.36775 \nEpoch: 3500  | Training Loss: 0.34519 \nEpoch: 3500  | Training Loss: 0.21290 \nEpoch: 3500  | Training Loss: 0.15001 \nEpoch: 3500  | Validation balanced accuracy : 0.76304 \nEpoch: 3501  | Training Loss: 0.31545 \nEpoch: 3501  | Training Loss: 0.36769 \nEpoch: 3501  | Training Loss: 0.34521 \nEpoch: 3501  | Training Loss: 0.21290 \nEpoch: 3501  | Training Loss: 0.14997 \nEpoch: 3501  | Validation balanced accuracy : 0.76304 \nEpoch: 3502  | Training Loss: 0.31551 \nEpoch: 3502  | Training Loss: 0.36774 \nEpoch: 3502  | Training Loss: 0.34517 \nEpoch: 3502  | Training Loss: 0.21291 \nEpoch: 3502  | Training Loss: 0.14980 \nEpoch: 3502  | Validation balanced accuracy : 0.76304 \nEpoch: 3503  | Training Loss: 0.31563 \nEpoch: 3503  | Training Loss: 0.36779 \nEpoch: 3503  | Training Loss: 0.34518 \nEpoch: 3503  | Training Loss: 0.21290 \nEpoch: 3503  | Training Loss: 0.14994 \nEpoch: 3503  | Validation balanced accuracy : 0.76304 \nEpoch: 3504  | Training Loss: 0.31549 \nEpoch: 3504  | Training Loss: 0.36771 \nEpoch: 3504  | Training Loss: 0.34521 \nEpoch: 3504  | Training Loss: 0.21289 \nEpoch: 3504  | Training Loss: 0.14993 \nEpoch: 3504  | Validation balanced accuracy : 0.76304 \nEpoch: 3505  | Training Loss: 0.31552 \nEpoch: 3505  | Training Loss: 0.36776 \nEpoch: 3505  | Training Loss: 0.34518 \nEpoch: 3505  | Training Loss: 0.21291 \nEpoch: 3505  | Training Loss: 0.14975 \nEpoch: 3505  | Validation balanced accuracy : 0.76304 \nEpoch: 3506  | Training Loss: 0.31566 \nEpoch: 3506  | Training Loss: 0.36781 \nEpoch: 3506  | Training Loss: 0.34519 \nEpoch: 3506  | Training Loss: 0.21289 \nEpoch: 3506  | Training Loss: 0.14994 \nEpoch: 3506  | Validation balanced accuracy : 0.76304 \nEpoch: 3507  | Training Loss: 0.31547 \nEpoch: 3507  | Training Loss: 0.36769 \nEpoch: 3507  | Training Loss: 0.34524 \nEpoch: 3507  | Training Loss: 0.21288 \nEpoch: 3507  | Training Loss: 0.14998 \nEpoch: 3507  | Validation balanced accuracy : 0.76304 \nEpoch: 3508  | Training Loss: 0.31547 \nEpoch: 3508  | Training Loss: 0.36772 \nEpoch: 3508  | Training Loss: 0.34521 \nEpoch: 3508  | Training Loss: 0.21289 \nEpoch: 3508  | Training Loss: 0.14981 \nEpoch: 3508  | Validation balanced accuracy : 0.76304 \nEpoch: 3509  | Training Loss: 0.31561 \nEpoch: 3509  | Training Loss: 0.36777 \nEpoch: 3509  | Training Loss: 0.34521 \nEpoch: 3509  | Training Loss: 0.21289 \nEpoch: 3509  | Training Loss: 0.14994 \nEpoch: 3509  | Validation balanced accuracy : 0.76304 \nEpoch: 3510  | Training Loss: 0.31548 \nEpoch: 3510  | Training Loss: 0.36771 \nEpoch: 3510  | Training Loss: 0.34524 \nEpoch: 3510  | Training Loss: 0.21288 \nEpoch: 3510  | Training Loss: 0.14990 \nEpoch: 3510  | Validation balanced accuracy : 0.76304 \nEpoch: 3511  | Training Loss: 0.31553 \nEpoch: 3511  | Training Loss: 0.36777 \nEpoch: 3511  | Training Loss: 0.34520 \nEpoch: 3511  | Training Loss: 0.21290 \nEpoch: 3511  | Training Loss: 0.14970 \nEpoch: 3511  | Validation balanced accuracy : 0.76304 \nEpoch: 3512  | Training Loss: 0.31568 \nEpoch: 3512  | Training Loss: 0.36782 \nEpoch: 3512  | Training Loss: 0.34520 \nEpoch: 3512  | Training Loss: 0.21289 \nEpoch: 3512  | Training Loss: 0.14988 \nEpoch: 3512  | Validation balanced accuracy : 0.76304 \nEpoch: 3513  | Training Loss: 0.31550 \nEpoch: 3513  | Training Loss: 0.36772 \nEpoch: 3513  | Training Loss: 0.34525 \nEpoch: 3513  | Training Loss: 0.21288 \nEpoch: 3513  | Training Loss: 0.14989 \nEpoch: 3513  | Validation balanced accuracy : 0.76304 \nEpoch: 3514  | Training Loss: 0.31553 \nEpoch: 3514  | Training Loss: 0.36776 \nEpoch: 3514  | Training Loss: 0.34522 \nEpoch: 3514  | Training Loss: 0.21289 \nEpoch: 3514  | Training Loss: 0.14972 \nEpoch: 3514  | Validation balanced accuracy : 0.76304 \nEpoch: 3515  | Training Loss: 0.31566 \nEpoch: 3515  | Training Loss: 0.36781 \nEpoch: 3515  | Training Loss: 0.34523 \nEpoch: 3515  | Training Loss: 0.21288 \nEpoch: 3515  | Training Loss: 0.14992 \nEpoch: 3515  | Validation balanced accuracy : 0.76304 \nEpoch: 3516  | Training Loss: 0.31546 \nEpoch: 3516  | Training Loss: 0.36769 \nEpoch: 3516  | Training Loss: 0.34528 \nEpoch: 3516  | Training Loss: 0.21287 \nEpoch: 3516  | Training Loss: 0.14995 \nEpoch: 3516  | Validation balanced accuracy : 0.76304 \nEpoch: 3517  | Training Loss: 0.31547 \nEpoch: 3517  | Training Loss: 0.36772 \nEpoch: 3517  | Training Loss: 0.34525 \nEpoch: 3517  | Training Loss: 0.21288 \nEpoch: 3517  | Training Loss: 0.14977 \nEpoch: 3517  | Validation balanced accuracy : 0.76304 \nEpoch: 3518  | Training Loss: 0.31562 \nEpoch: 3518  | Training Loss: 0.36784 \nEpoch: 3518  | Training Loss: 0.34519 \nEpoch: 3518  | Training Loss: 0.21289 \nEpoch: 3518  | Training Loss: 0.14958 \nEpoch: 3518  | Validation balanced accuracy : 0.76304 \nEpoch: 3519  | Training Loss: 0.31575 \nEpoch: 3519  | Training Loss: 0.36786 \nEpoch: 3519  | Training Loss: 0.34521 \nEpoch: 3519  | Training Loss: 0.21288 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3519  | Training Loss: 0.14983 \nEpoch: 3519  | Validation balanced accuracy : 0.76304 \nEpoch: 3520  | Training Loss: 0.31551 \nEpoch: 3520  | Training Loss: 0.36772 \nEpoch: 3520  | Training Loss: 0.34528 \nEpoch: 3520  | Training Loss: 0.21286 \nEpoch: 3520  | Training Loss: 0.14991 \nEpoch: 3520  | Validation balanced accuracy : 0.76304 \nEpoch: 3521  | Training Loss: 0.31549 \nEpoch: 3521  | Training Loss: 0.36774 \nEpoch: 3521  | Training Loss: 0.34526 \nEpoch: 3521  | Training Loss: 0.21287 \nEpoch: 3521  | Training Loss: 0.14972 \nEpoch: 3521  | Validation balanced accuracy : 0.76304 \nEpoch: 3522  | Training Loss: 0.31565 \nEpoch: 3522  | Training Loss: 0.36781 \nEpoch: 3522  | Training Loss: 0.34525 \nEpoch: 3522  | Training Loss: 0.21287 \nEpoch: 3522  | Training Loss: 0.14982 \nEpoch: 3522  | Validation balanced accuracy : 0.76304 \nEpoch: 3523  | Training Loss: 0.31553 \nEpoch: 3523  | Training Loss: 0.36775 \nEpoch: 3523  | Training Loss: 0.34527 \nEpoch: 3523  | Training Loss: 0.21286 \nEpoch: 3523  | Training Loss: 0.14979 \nEpoch: 3523  | Validation balanced accuracy : 0.76304 \nEpoch: 3524  | Training Loss: 0.31557 \nEpoch: 3524  | Training Loss: 0.36780 \nEpoch: 3524  | Training Loss: 0.34523 \nEpoch: 3524  | Training Loss: 0.21288 \nEpoch: 3524  | Training Loss: 0.14961 \nEpoch: 3524  | Validation balanced accuracy : 0.76304 \nEpoch: 3525  | Training Loss: 0.31571 \nEpoch: 3525  | Training Loss: 0.36784 \nEpoch: 3525  | Training Loss: 0.34525 \nEpoch: 3525  | Training Loss: 0.21286 \nEpoch: 3525  | Training Loss: 0.14986 \nEpoch: 3525  | Validation balanced accuracy : 0.76304 \nEpoch: 3526  | Training Loss: 0.31548 \nEpoch: 3526  | Training Loss: 0.36770 \nEpoch: 3526  | Training Loss: 0.34532 \nEpoch: 3526  | Training Loss: 0.21285 \nEpoch: 3526  | Training Loss: 0.14993 \nEpoch: 3526  | Validation balanced accuracy : 0.76304 \nEpoch: 3527  | Training Loss: 0.31547 \nEpoch: 3527  | Training Loss: 0.36772 \nEpoch: 3527  | Training Loss: 0.34530 \nEpoch: 3527  | Training Loss: 0.21286 \nEpoch: 3527  | Training Loss: 0.14976 \nEpoch: 3527  | Validation balanced accuracy : 0.76304 \nEpoch: 3528  | Training Loss: 0.31560 \nEpoch: 3528  | Training Loss: 0.36783 \nEpoch: 3528  | Training Loss: 0.34524 \nEpoch: 3528  | Training Loss: 0.21287 \nEpoch: 3528  | Training Loss: 0.14956 \nEpoch: 3528  | Validation balanced accuracy : 0.76304 \nEpoch: 3529  | Training Loss: 0.31573 \nEpoch: 3529  | Training Loss: 0.36786 \nEpoch: 3529  | Training Loss: 0.34526 \nEpoch: 3529  | Training Loss: 0.21286 \nEpoch: 3529  | Training Loss: 0.14980 \nEpoch: 3529  | Validation balanced accuracy : 0.76304 \nEpoch: 3530  | Training Loss: 0.31551 \nEpoch: 3530  | Training Loss: 0.36772 \nEpoch: 3530  | Training Loss: 0.34532 \nEpoch: 3530  | Training Loss: 0.21284 \nEpoch: 3530  | Training Loss: 0.14987 \nEpoch: 3530  | Validation balanced accuracy : 0.76304 \nEpoch: 3531  | Training Loss: 0.31550 \nEpoch: 3531  | Training Loss: 0.36774 \nEpoch: 3531  | Training Loss: 0.34530 \nEpoch: 3531  | Training Loss: 0.21285 \nEpoch: 3531  | Training Loss: 0.14972 \nEpoch: 3531  | Validation balanced accuracy : 0.76304 \nEpoch: 3532  | Training Loss: 0.31562 \nEpoch: 3532  | Training Loss: 0.36784 \nEpoch: 3532  | Training Loss: 0.34524 \nEpoch: 3532  | Training Loss: 0.21287 \nEpoch: 3532  | Training Loss: 0.14948 \nEpoch: 3532  | Validation balanced accuracy : 0.76304 \nEpoch: 3533  | Training Loss: 0.31580 \nEpoch: 3533  | Training Loss: 0.36791 \nEpoch: 3533  | Training Loss: 0.34524 \nEpoch: 3533  | Training Loss: 0.21286 \nEpoch: 3533  | Training Loss: 0.14970 \nEpoch: 3533  | Validation balanced accuracy : 0.76304 \nEpoch: 3534  | Training Loss: 0.31557 \nEpoch: 3534  | Training Loss: 0.36777 \nEpoch: 3534  | Training Loss: 0.34531 \nEpoch: 3534  | Training Loss: 0.21284 \nEpoch: 3534  | Training Loss: 0.14979 \nEpoch: 3534  | Validation balanced accuracy : 0.76304 \nEpoch: 3535  | Training Loss: 0.31554 \nEpoch: 3535  | Training Loss: 0.36777 \nEpoch: 3535  | Training Loss: 0.34530 \nEpoch: 3535  | Training Loss: 0.21285 \nEpoch: 3535  | Training Loss: 0.14967 \nEpoch: 3535  | Validation balanced accuracy : 0.76304 \nEpoch: 3536  | Training Loss: 0.31564 \nEpoch: 3536  | Training Loss: 0.36780 \nEpoch: 3536  | Training Loss: 0.34531 \nEpoch: 3536  | Training Loss: 0.21284 \nEpoch: 3536  | Training Loss: 0.14982 \nEpoch: 3536  | Validation balanced accuracy : 0.76304 \nEpoch: 3537  | Training Loss: 0.31550 \nEpoch: 3537  | Training Loss: 0.36774 \nEpoch: 3537  | Training Loss: 0.34533 \nEpoch: 3537  | Training Loss: 0.21284 \nEpoch: 3537  | Training Loss: 0.14973 \nEpoch: 3537  | Validation balanced accuracy : 0.76304 \nEpoch: 3538  | Training Loss: 0.31560 \nEpoch: 3538  | Training Loss: 0.36783 \nEpoch: 3538  | Training Loss: 0.34527 \nEpoch: 3538  | Training Loss: 0.21286 \nEpoch: 3538  | Training Loss: 0.14950 \nEpoch: 3538  | Validation balanced accuracy : 0.76304 \nEpoch: 3539  | Training Loss: 0.31577 \nEpoch: 3539  | Training Loss: 0.36789 \nEpoch: 3539  | Training Loss: 0.34528 \nEpoch: 3539  | Training Loss: 0.21284 \nEpoch: 3539  | Training Loss: 0.14972 \nEpoch: 3539  | Validation balanced accuracy : 0.76304 \nEpoch: 3540  | Training Loss: 0.31554 \nEpoch: 3540  | Training Loss: 0.36775 \nEpoch: 3540  | Training Loss: 0.34535 \nEpoch: 3540  | Training Loss: 0.21283 \nEpoch: 3540  | Training Loss: 0.14980 \nEpoch: 3540  | Validation balanced accuracy : 0.76304 \nEpoch: 3541  | Training Loss: 0.31552 \nEpoch: 3541  | Training Loss: 0.36776 \nEpoch: 3541  | Training Loss: 0.34533 \nEpoch: 3541  | Training Loss: 0.21284 \nEpoch: 3541  | Training Loss: 0.14966 \nEpoch: 3541  | Validation balanced accuracy : 0.76304 \nEpoch: 3542  | Training Loss: 0.31564 \nEpoch: 3542  | Training Loss: 0.36786 \nEpoch: 3542  | Training Loss: 0.34528 \nEpoch: 3542  | Training Loss: 0.21285 \nEpoch: 3542  | Training Loss: 0.14949 \nEpoch: 3542  | Validation balanced accuracy : 0.76304 \nEpoch: 3543  | Training Loss: 0.31575 \nEpoch: 3543  | Training Loss: 0.36788 \nEpoch: 3543  | Training Loss: 0.34530 \nEpoch: 3543  | Training Loss: 0.21283 \nEpoch: 3543  | Training Loss: 0.14974 \nEpoch: 3543  | Validation balanced accuracy : 0.76304 \nEpoch: 3544  | Training Loss: 0.31552 \nEpoch: 3544  | Training Loss: 0.36773 \nEpoch: 3544  | Training Loss: 0.34537 \nEpoch: 3544  | Training Loss: 0.21282 \nEpoch: 3544  | Training Loss: 0.14982 \nEpoch: 3544  | Validation balanced accuracy : 0.76304 \nEpoch: 3545  | Training Loss: 0.31550 \nEpoch: 3545  | Training Loss: 0.36776 \nEpoch: 3545  | Training Loss: 0.34534 \nEpoch: 3545  | Training Loss: 0.21283 \nEpoch: 3545  | Training Loss: 0.14959 \nEpoch: 3545  | Validation balanced accuracy : 0.76304 \nEpoch: 3546  | Training Loss: 0.31569 \nEpoch: 3546  | Training Loss: 0.36784 \nEpoch: 3546  | Training Loss: 0.34532 \nEpoch: 3546  | Training Loss: 0.21283 \nEpoch: 3546  | Training Loss: 0.14968 \nEpoch: 3546  | Validation balanced accuracy : 0.76304 \nEpoch: 3547  | Training Loss: 0.31558 \nEpoch: 3547  | Training Loss: 0.36779 \nEpoch: 3547  | Training Loss: 0.34534 \nEpoch: 3547  | Training Loss: 0.21283 \nEpoch: 3547  | Training Loss: 0.14965 \nEpoch: 3547  | Validation balanced accuracy : 0.76304 \nEpoch: 3548  | Training Loss: 0.31562 \nEpoch: 3548  | Training Loss: 0.36784 \nEpoch: 3548  | Training Loss: 0.34531 \nEpoch: 3548  | Training Loss: 0.21284 \nEpoch: 3548  | Training Loss: 0.14947 \nEpoch: 3548  | Validation balanced accuracy : 0.76304 \nEpoch: 3549  | Training Loss: 0.31576 \nEpoch: 3549  | Training Loss: 0.36788 \nEpoch: 3549  | Training Loss: 0.34532 \nEpoch: 3549  | Training Loss: 0.21283 \nEpoch: 3549  | Training Loss: 0.14967 \nEpoch: 3549  | Validation balanced accuracy : 0.76304 \nEpoch: 3550  | Training Loss: 0.31556 \nEpoch: 3550  | Training Loss: 0.36777 \nEpoch: 3550  | Training Loss: 0.34537 \nEpoch: 3550  | Training Loss: 0.21282 \nEpoch: 3550  | Training Loss: 0.14971 \nEpoch: 3550  | Validation balanced accuracy : 0.76304 \nEpoch: 3551  | Training Loss: 0.31557 \nEpoch: 3551  | Training Loss: 0.36780 \nEpoch: 3551  | Training Loss: 0.34535 \nEpoch: 3551  | Training Loss: 0.21283 \nEpoch: 3551  | Training Loss: 0.14955 \nEpoch: 3551  | Validation balanced accuracy : 0.76304 \nEpoch: 3552  | Training Loss: 0.31569 \nEpoch: 3552  | Training Loss: 0.36784 \nEpoch: 3552  | Training Loss: 0.34535 \nEpoch: 3552  | Training Loss: 0.21282 \nEpoch: 3552  | Training Loss: 0.14970 \nEpoch: 3552  | Validation balanced accuracy : 0.76304 \nEpoch: 3553  | Training Loss: 0.31555 \nEpoch: 3553  | Training Loss: 0.36776 \nEpoch: 3553  | Training Loss: 0.34538 \nEpoch: 3553  | Training Loss: 0.21281 \nEpoch: 3553  | Training Loss: 0.14968 \nEpoch: 3553  | Validation balanced accuracy : 0.76304 \nEpoch: 3554  | Training Loss: 0.31558 \nEpoch: 3554  | Training Loss: 0.36781 \nEpoch: 3554  | Training Loss: 0.34535 \nEpoch: 3554  | Training Loss: 0.21282 \nEpoch: 3554  | Training Loss: 0.14950 \nEpoch: 3554  | Validation balanced accuracy : 0.76304 \nEpoch: 3555  | Training Loss: 0.31572 \nEpoch: 3555  | Training Loss: 0.36786 \nEpoch: 3555  | Training Loss: 0.34535 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3555  | Training Loss: 0.21282 \nEpoch: 3555  | Training Loss: 0.14965 \nEpoch: 3555  | Validation balanced accuracy : 0.76304 \nEpoch: 3556  | Training Loss: 0.31558 \nEpoch: 3556  | Training Loss: 0.36779 \nEpoch: 3556  | Training Loss: 0.34538 \nEpoch: 3556  | Training Loss: 0.21281 \nEpoch: 3556  | Training Loss: 0.14964 \nEpoch: 3556  | Validation balanced accuracy : 0.76304 \nEpoch: 3557  | Training Loss: 0.31561 \nEpoch: 3557  | Training Loss: 0.36783 \nEpoch: 3557  | Training Loss: 0.34535 \nEpoch: 3557  | Training Loss: 0.21282 \nEpoch: 3557  | Training Loss: 0.14947 \nEpoch: 3557  | Validation balanced accuracy : 0.76304 \nEpoch: 3558  | Training Loss: 0.31574 \nEpoch: 3558  | Training Loss: 0.36787 \nEpoch: 3558  | Training Loss: 0.34536 \nEpoch: 3558  | Training Loss: 0.21281 \nEpoch: 3558  | Training Loss: 0.14963 \nEpoch: 3558  | Validation balanced accuracy : 0.76304 \nEpoch: 3559  | Training Loss: 0.31558 \nEpoch: 3559  | Training Loss: 0.36779 \nEpoch: 3559  | Training Loss: 0.34539 \nEpoch: 3559  | Training Loss: 0.21281 \nEpoch: 3559  | Training Loss: 0.14963 \nEpoch: 3559  | Validation balanced accuracy : 0.76304 \nEpoch: 3560  | Training Loss: 0.31560 \nEpoch: 3560  | Training Loss: 0.36783 \nEpoch: 3560  | Training Loss: 0.34536 \nEpoch: 3560  | Training Loss: 0.21282 \nEpoch: 3560  | Training Loss: 0.14947 \nEpoch: 3560  | Validation balanced accuracy : 0.76304 \nEpoch: 3561  | Training Loss: 0.31573 \nEpoch: 3561  | Training Loss: 0.36786 \nEpoch: 3561  | Training Loss: 0.34537 \nEpoch: 3561  | Training Loss: 0.21280 \nEpoch: 3561  | Training Loss: 0.14966 \nEpoch: 3561  | Validation balanced accuracy : 0.76304 \nEpoch: 3562  | Training Loss: 0.31555 \nEpoch: 3562  | Training Loss: 0.36776 \nEpoch: 3562  | Training Loss: 0.34542 \nEpoch: 3562  | Training Loss: 0.21280 \nEpoch: 3562  | Training Loss: 0.14967 \nEpoch: 3562  | Validation balanced accuracy : 0.76304 \nEpoch: 3563  | Training Loss: 0.31557 \nEpoch: 3563  | Training Loss: 0.36780 \nEpoch: 3563  | Training Loss: 0.34539 \nEpoch: 3563  | Training Loss: 0.21281 \nEpoch: 3563  | Training Loss: 0.14950 \nEpoch: 3563  | Validation balanced accuracy : 0.76304 \nEpoch: 3564  | Training Loss: 0.31570 \nEpoch: 3564  | Training Loss: 0.36791 \nEpoch: 3564  | Training Loss: 0.34533 \nEpoch: 3564  | Training Loss: 0.21282 \nEpoch: 3564  | Training Loss: 0.14933 \nEpoch: 3564  | Validation balanced accuracy : 0.76304 \nEpoch: 3565  | Training Loss: 0.31582 \nEpoch: 3565  | Training Loss: 0.36793 \nEpoch: 3565  | Training Loss: 0.34536 \nEpoch: 3565  | Training Loss: 0.21280 \nEpoch: 3565  | Training Loss: 0.14960 \nEpoch: 3565  | Validation balanced accuracy : 0.76304 \nEpoch: 3566  | Training Loss: 0.31557 \nEpoch: 3566  | Training Loss: 0.36777 \nEpoch: 3566  | Training Loss: 0.34544 \nEpoch: 3566  | Training Loss: 0.21279 \nEpoch: 3566  | Training Loss: 0.14970 \nEpoch: 3566  | Validation balanced accuracy : 0.76304 \nEpoch: 3567  | Training Loss: 0.31554 \nEpoch: 3567  | Training Loss: 0.36778 \nEpoch: 3567  | Training Loss: 0.34541 \nEpoch: 3567  | Training Loss: 0.21280 \nEpoch: 3567  | Training Loss: 0.14949 \nEpoch: 3567  | Validation balanced accuracy : 0.76304 \nEpoch: 3568  | Training Loss: 0.31571 \nEpoch: 3568  | Training Loss: 0.36786 \nEpoch: 3568  | Training Loss: 0.34540 \nEpoch: 3568  | Training Loss: 0.21279 \nEpoch: 3568  | Training Loss: 0.14959 \nEpoch: 3568  | Validation balanced accuracy : 0.76304 \nEpoch: 3569  | Training Loss: 0.31559 \nEpoch: 3569  | Training Loss: 0.36780 \nEpoch: 3569  | Training Loss: 0.34542 \nEpoch: 3569  | Training Loss: 0.21279 \nEpoch: 3569  | Training Loss: 0.14956 \nEpoch: 3569  | Validation balanced accuracy : 0.76304 \nEpoch: 3570  | Training Loss: 0.31564 \nEpoch: 3570  | Training Loss: 0.36785 \nEpoch: 3570  | Training Loss: 0.34538 \nEpoch: 3570  | Training Loss: 0.21280 \nEpoch: 3570  | Training Loss: 0.14938 \nEpoch: 3570  | Validation balanced accuracy : 0.76304 \nEpoch: 3571  | Training Loss: 0.31577 \nEpoch: 3571  | Training Loss: 0.36789 \nEpoch: 3571  | Training Loss: 0.34539 \nEpoch: 3571  | Training Loss: 0.21279 \nEpoch: 3571  | Training Loss: 0.14958 \nEpoch: 3571  | Validation balanced accuracy : 0.76304 \nEpoch: 3572  | Training Loss: 0.31558 \nEpoch: 3572  | Training Loss: 0.36779 \nEpoch: 3572  | Training Loss: 0.34544 \nEpoch: 3572  | Training Loss: 0.21278 \nEpoch: 3572  | Training Loss: 0.14961 \nEpoch: 3572  | Validation balanced accuracy : 0.76304 \nEpoch: 3573  | Training Loss: 0.31560 \nEpoch: 3573  | Training Loss: 0.36782 \nEpoch: 3573  | Training Loss: 0.34542 \nEpoch: 3573  | Training Loss: 0.21279 \nEpoch: 3573  | Training Loss: 0.14945 \nEpoch: 3573  | Validation balanced accuracy : 0.76304 \nEpoch: 3574  | Training Loss: 0.31572 \nEpoch: 3574  | Training Loss: 0.36792 \nEpoch: 3574  | Training Loss: 0.34536 \nEpoch: 3574  | Training Loss: 0.21281 \nEpoch: 3574  | Training Loss: 0.14929 \nEpoch: 3574  | Validation balanced accuracy : 0.76304 \nEpoch: 3575  | Training Loss: 0.31583 \nEpoch: 3575  | Training Loss: 0.36793 \nEpoch: 3575  | Training Loss: 0.34539 \nEpoch: 3575  | Training Loss: 0.21279 \nEpoch: 3575  | Training Loss: 0.14956 \nEpoch: 3575  | Validation balanced accuracy : 0.76304 \nEpoch: 3576  | Training Loss: 0.31557 \nEpoch: 3576  | Training Loss: 0.36777 \nEpoch: 3576  | Training Loss: 0.34547 \nEpoch: 3576  | Training Loss: 0.21277 \nEpoch: 3576  | Training Loss: 0.14966 \nEpoch: 3576  | Validation balanced accuracy : 0.76304 \nEpoch: 3577  | Training Loss: 0.31554 \nEpoch: 3577  | Training Loss: 0.36779 \nEpoch: 3577  | Training Loss: 0.34544 \nEpoch: 3577  | Training Loss: 0.21278 \nEpoch: 3577  | Training Loss: 0.14946 \nEpoch: 3577  | Validation balanced accuracy : 0.76304 \nEpoch: 3578  | Training Loss: 0.31572 \nEpoch: 3578  | Training Loss: 0.36792 \nEpoch: 3578  | Training Loss: 0.34537 \nEpoch: 3578  | Training Loss: 0.21280 \nEpoch: 3578  | Training Loss: 0.14924 \nEpoch: 3578  | Validation balanced accuracy : 0.76304 \nEpoch: 3579  | Training Loss: 0.31586 \nEpoch: 3579  | Training Loss: 0.36795 \nEpoch: 3579  | Training Loss: 0.34540 \nEpoch: 3579  | Training Loss: 0.21278 \nEpoch: 3579  | Training Loss: 0.14953 \nEpoch: 3579  | Validation balanced accuracy : 0.76304 \nEpoch: 3580  | Training Loss: 0.31559 \nEpoch: 3580  | Training Loss: 0.36778 \nEpoch: 3580  | Training Loss: 0.34548 \nEpoch: 3580  | Training Loss: 0.21277 \nEpoch: 3580  | Training Loss: 0.14965 \nEpoch: 3580  | Validation balanced accuracy : 0.76304 \nEpoch: 3581  | Training Loss: 0.31554 \nEpoch: 3581  | Training Loss: 0.36779 \nEpoch: 3581  | Training Loss: 0.34546 \nEpoch: 3581  | Training Loss: 0.21278 \nEpoch: 3581  | Training Loss: 0.14945 \nEpoch: 3581  | Validation balanced accuracy : 0.76304 \nEpoch: 3582  | Training Loss: 0.31571 \nEpoch: 3582  | Training Loss: 0.36792 \nEpoch: 3582  | Training Loss: 0.34539 \nEpoch: 3582  | Training Loss: 0.21279 \nEpoch: 3582  | Training Loss: 0.14924 \nEpoch: 3582  | Validation balanced accuracy : 0.76304 \nEpoch: 3583  | Training Loss: 0.31585 \nEpoch: 3583  | Training Loss: 0.36795 \nEpoch: 3583  | Training Loss: 0.34541 \nEpoch: 3583  | Training Loss: 0.21278 \nEpoch: 3583  | Training Loss: 0.14949 \nEpoch: 3583  | Validation balanced accuracy : 0.76304 \nEpoch: 3584  | Training Loss: 0.31561 \nEpoch: 3584  | Training Loss: 0.36780 \nEpoch: 3584  | Training Loss: 0.34548 \nEpoch: 3584  | Training Loss: 0.21276 \nEpoch: 3584  | Training Loss: 0.14959 \nEpoch: 3584  | Validation balanced accuracy : 0.76304 \nEpoch: 3585  | Training Loss: 0.31558 \nEpoch: 3585  | Training Loss: 0.36782 \nEpoch: 3585  | Training Loss: 0.34546 \nEpoch: 3585  | Training Loss: 0.21277 \nEpoch: 3585  | Training Loss: 0.14939 \nEpoch: 3585  | Validation balanced accuracy : 0.76304 \nEpoch: 3586  | Training Loss: 0.31574 \nEpoch: 3586  | Training Loss: 0.36789 \nEpoch: 3586  | Training Loss: 0.34545 \nEpoch: 3586  | Training Loss: 0.21277 \nEpoch: 3586  | Training Loss: 0.14950 \nEpoch: 3586  | Validation balanced accuracy : 0.76304 \nEpoch: 3587  | Training Loss: 0.31562 \nEpoch: 3587  | Training Loss: 0.36782 \nEpoch: 3587  | Training Loss: 0.34547 \nEpoch: 3587  | Training Loss: 0.21277 \nEpoch: 3587  | Training Loss: 0.14948 \nEpoch: 3587  | Validation balanced accuracy : 0.76304 \nEpoch: 3588  | Training Loss: 0.31566 \nEpoch: 3588  | Training Loss: 0.36787 \nEpoch: 3588  | Training Loss: 0.34544 \nEpoch: 3588  | Training Loss: 0.21278 \nEpoch: 3588  | Training Loss: 0.14931 \nEpoch: 3588  | Validation balanced accuracy : 0.76304 \nEpoch: 3589  | Training Loss: 0.31579 \nEpoch: 3589  | Training Loss: 0.36791 \nEpoch: 3589  | Training Loss: 0.34545 \nEpoch: 3589  | Training Loss: 0.21276 \nEpoch: 3589  | Training Loss: 0.14951 \nEpoch: 3589  | Validation balanced accuracy : 0.76304 \nEpoch: 3590  | Training Loss: 0.31560 \nEpoch: 3590  | Training Loss: 0.36780 \nEpoch: 3590  | Training Loss: 0.34550 \nEpoch: 3590  | Training Loss: 0.21276 \nEpoch: 3590  | Training Loss: 0.14954 \nEpoch: 3590  | Validation balanced accuracy : 0.76304 \nEpoch: 3591  | Training Loss: 0.31561 \nEpoch: 3591  | Training Loss: 0.36783 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3591  | Training Loss: 0.34547 \nEpoch: 3591  | Training Loss: 0.21277 \nEpoch: 3591  | Training Loss: 0.14938 \nEpoch: 3591  | Validation balanced accuracy : 0.76304 \nEpoch: 3592  | Training Loss: 0.31574 \nEpoch: 3592  | Training Loss: 0.36794 \nEpoch: 3592  | Training Loss: 0.34542 \nEpoch: 3592  | Training Loss: 0.21278 \nEpoch: 3592  | Training Loss: 0.14921 \nEpoch: 3592  | Validation balanced accuracy : 0.76304 \nEpoch: 3593  | Training Loss: 0.31585 \nEpoch: 3593  | Training Loss: 0.36795 \nEpoch: 3593  | Training Loss: 0.34545 \nEpoch: 3593  | Training Loss: 0.21276 \nEpoch: 3593  | Training Loss: 0.14948 \nEpoch: 3593  | Validation balanced accuracy : 0.76304 \nEpoch: 3594  | Training Loss: 0.31560 \nEpoch: 3594  | Training Loss: 0.36779 \nEpoch: 3594  | Training Loss: 0.34552 \nEpoch: 3594  | Training Loss: 0.21275 \nEpoch: 3594  | Training Loss: 0.14958 \nEpoch: 3594  | Validation balanced accuracy : 0.76304 \nEpoch: 3595  | Training Loss: 0.31557 \nEpoch: 3595  | Training Loss: 0.36781 \nEpoch: 3595  | Training Loss: 0.34550 \nEpoch: 3595  | Training Loss: 0.21276 \nEpoch: 3595  | Training Loss: 0.14937 \nEpoch: 3595  | Validation balanced accuracy : 0.76304 \nEpoch: 3596  | Training Loss: 0.31574 \nEpoch: 3596  | Training Loss: 0.36794 \nEpoch: 3596  | Training Loss: 0.34542 \nEpoch: 3596  | Training Loss: 0.21278 \nEpoch: 3596  | Training Loss: 0.14916 \nEpoch: 3596  | Validation balanced accuracy : 0.76304 \nEpoch: 3597  | Training Loss: 0.31588 \nEpoch: 3597  | Training Loss: 0.36798 \nEpoch: 3597  | Training Loss: 0.34544 \nEpoch: 3597  | Training Loss: 0.21276 \nEpoch: 3597  | Training Loss: 0.14942 \nEpoch: 3597  | Validation balanced accuracy : 0.76304 \nEpoch: 3598  | Training Loss: 0.31564 \nEpoch: 3598  | Training Loss: 0.36782 \nEpoch: 3598  | Training Loss: 0.34552 \nEpoch: 3598  | Training Loss: 0.21274 \nEpoch: 3598  | Training Loss: 0.14952 \nEpoch: 3598  | Validation balanced accuracy : 0.76304 \nEpoch: 3599  | Training Loss: 0.31560 \nEpoch: 3599  | Training Loss: 0.36783 \nEpoch: 3599  | Training Loss: 0.34550 \nEpoch: 3599  | Training Loss: 0.21275 \nEpoch: 3599  | Training Loss: 0.14936 \nEpoch: 3599  | Validation balanced accuracy : 0.76304 \nEpoch: 3600  | Training Loss: 0.31574 \nEpoch: 3600  | Training Loss: 0.36794 \nEpoch: 3600  | Training Loss: 0.34544 \nEpoch: 3600  | Training Loss: 0.21277 \nEpoch: 3600  | Training Loss: 0.14912 \nEpoch: 3600  | Validation balanced accuracy : 0.76304 \nEpoch: 3601  | Training Loss: 0.31591 \nEpoch: 3601  | Training Loss: 0.36800 \nEpoch: 3601  | Training Loss: 0.34539 \nEpoch: 3601  | Training Loss: 0.21278 \nEpoch: 3601  | Training Loss: 0.14907 \nEpoch: 3601  | Validation balanced accuracy : 0.76304 \nEpoch: 3602  | Training Loss: 0.31569 \nEpoch: 3602  | Training Loss: 0.36786 \nEpoch: 3602  | Training Loss: 0.34547 \nEpoch: 3602  | Training Loss: 0.21276 \nEpoch: 3602  | Training Loss: 0.14920 \nEpoch: 3602  | Validation balanced accuracy : 0.76304 \nEpoch: 3603  | Training Loss: 0.31563 \nEpoch: 3603  | Training Loss: 0.36783 \nEpoch: 3603  | Training Loss: 0.34547 \nEpoch: 3603  | Training Loss: 0.21276 \nEpoch: 3603  | Training Loss: 0.14916 \nEpoch: 3603  | Validation balanced accuracy : 0.76304 \nEpoch: 3604  | Training Loss: 0.31567 \nEpoch: 3604  | Training Loss: 0.36787 \nEpoch: 3604  | Training Loss: 0.34544 \nEpoch: 3604  | Training Loss: 0.21277 \nEpoch: 3604  | Training Loss: 0.14903 \nEpoch: 3604  | Validation balanced accuracy : 0.76304 \nEpoch: 3605  | Training Loss: 0.31576 \nEpoch: 3605  | Training Loss: 0.36790 \nEpoch: 3605  | Training Loss: 0.34546 \nEpoch: 3605  | Training Loss: 0.21276 \nEpoch: 3605  | Training Loss: 0.14921 \nEpoch: 3605  | Validation balanced accuracy : 0.76304 \nEpoch: 3606  | Training Loss: 0.31560 \nEpoch: 3606  | Training Loss: 0.36781 \nEpoch: 3606  | Training Loss: 0.34549 \nEpoch: 3606  | Training Loss: 0.21275 \nEpoch: 3606  | Training Loss: 0.14920 \nEpoch: 3606  | Validation balanced accuracy : 0.76304 \nEpoch: 3607  | Training Loss: 0.31564 \nEpoch: 3607  | Training Loss: 0.36786 \nEpoch: 3607  | Training Loss: 0.34546 \nEpoch: 3607  | Training Loss: 0.21276 \nEpoch: 3607  | Training Loss: 0.14905 \nEpoch: 3607  | Validation balanced accuracy : 0.76304 \nEpoch: 3608  | Training Loss: 0.31575 \nEpoch: 3608  | Training Loss: 0.36789 \nEpoch: 3608  | Training Loss: 0.34547 \nEpoch: 3608  | Training Loss: 0.21275 \nEpoch: 3608  | Training Loss: 0.14921 \nEpoch: 3608  | Validation balanced accuracy : 0.76304 \nEpoch: 3609  | Training Loss: 0.31560 \nEpoch: 3609  | Training Loss: 0.36781 \nEpoch: 3609  | Training Loss: 0.34550 \nEpoch: 3609  | Training Loss: 0.21275 \nEpoch: 3609  | Training Loss: 0.14917 \nEpoch: 3609  | Validation balanced accuracy : 0.76304 \nEpoch: 3610  | Training Loss: 0.31565 \nEpoch: 3610  | Training Loss: 0.36786 \nEpoch: 3610  | Training Loss: 0.34547 \nEpoch: 3610  | Training Loss: 0.21276 \nEpoch: 3610  | Training Loss: 0.14905 \nEpoch: 3610  | Validation balanced accuracy : 0.76304 \nEpoch: 3611  | Training Loss: 0.31574 \nEpoch: 3611  | Training Loss: 0.36793 \nEpoch: 3611  | Training Loss: 0.34543 \nEpoch: 3611  | Training Loss: 0.21277 \nEpoch: 3611  | Training Loss: 0.14890 \nEpoch: 3611  | Validation balanced accuracy : 0.76304 \nEpoch: 3612  | Training Loss: 0.31585 \nEpoch: 3612  | Training Loss: 0.36796 \nEpoch: 3612  | Training Loss: 0.34545 \nEpoch: 3612  | Training Loss: 0.21275 \nEpoch: 3612  | Training Loss: 0.14915 \nEpoch: 3612  | Validation balanced accuracy : 0.76304 \nEpoch: 3613  | Training Loss: 0.31562 \nEpoch: 3613  | Training Loss: 0.36781 \nEpoch: 3613  | Training Loss: 0.34552 \nEpoch: 3613  | Training Loss: 0.21274 \nEpoch: 3613  | Training Loss: 0.14927 \nEpoch: 3613  | Validation balanced accuracy : 0.76304 \nEpoch: 3614  | Training Loss: 0.31557 \nEpoch: 3614  | Training Loss: 0.36781 \nEpoch: 3614  | Training Loss: 0.34551 \nEpoch: 3614  | Training Loss: 0.21274 \nEpoch: 3614  | Training Loss: 0.14912 \nEpoch: 3614  | Validation balanced accuracy : 0.76304 \nEpoch: 3615  | Training Loss: 0.31569 \nEpoch: 3615  | Training Loss: 0.36791 \nEpoch: 3615  | Training Loss: 0.34545 \nEpoch: 3615  | Training Loss: 0.21276 \nEpoch: 3615  | Training Loss: 0.14891 \nEpoch: 3615  | Validation balanced accuracy : 0.76304 \nEpoch: 3616  | Training Loss: 0.31584 \nEpoch: 3616  | Training Loss: 0.36796 \nEpoch: 3616  | Training Loss: 0.34546 \nEpoch: 3616  | Training Loss: 0.21275 \nEpoch: 3616  | Training Loss: 0.14912 \nEpoch: 3616  | Validation balanced accuracy : 0.76304 \nEpoch: 3617  | Training Loss: 0.31564 \nEpoch: 3617  | Training Loss: 0.36783 \nEpoch: 3617  | Training Loss: 0.34552 \nEpoch: 3617  | Training Loss: 0.21273 \nEpoch: 3617  | Training Loss: 0.14922 \nEpoch: 3617  | Validation balanced accuracy : 0.76304 \nEpoch: 3618  | Training Loss: 0.31560 \nEpoch: 3618  | Training Loss: 0.36783 \nEpoch: 3618  | Training Loss: 0.34551 \nEpoch: 3618  | Training Loss: 0.21274 \nEpoch: 3618  | Training Loss: 0.14907 \nEpoch: 3618  | Validation balanced accuracy : 0.76304 \nEpoch: 3619  | Training Loss: 0.31572 \nEpoch: 3619  | Training Loss: 0.36793 \nEpoch: 3619  | Training Loss: 0.34545 \nEpoch: 3619  | Training Loss: 0.21276 \nEpoch: 3619  | Training Loss: 0.14887 \nEpoch: 3619  | Validation balanced accuracy : 0.76304 \nEpoch: 3620  | Training Loss: 0.31586 \nEpoch: 3620  | Training Loss: 0.36797 \nEpoch: 3620  | Training Loss: 0.34546 \nEpoch: 3620  | Training Loss: 0.21274 \nEpoch: 3620  | Training Loss: 0.14912 \nEpoch: 3620  | Validation balanced accuracy : 0.76304 \nEpoch: 3621  | Training Loss: 0.31563 \nEpoch: 3621  | Training Loss: 0.36782 \nEpoch: 3621  | Training Loss: 0.34554 \nEpoch: 3621  | Training Loss: 0.21273 \nEpoch: 3621  | Training Loss: 0.14924 \nEpoch: 3621  | Validation balanced accuracy : 0.76304 \nEpoch: 3622  | Training Loss: 0.31557 \nEpoch: 3622  | Training Loss: 0.36781 \nEpoch: 3622  | Training Loss: 0.34553 \nEpoch: 3622  | Training Loss: 0.21273 \nEpoch: 3622  | Training Loss: 0.14910 \nEpoch: 3622  | Validation balanced accuracy : 0.76304 \nEpoch: 3623  | Training Loss: 0.31569 \nEpoch: 3623  | Training Loss: 0.36791 \nEpoch: 3623  | Training Loss: 0.34547 \nEpoch: 3623  | Training Loss: 0.21275 \nEpoch: 3623  | Training Loss: 0.14889 \nEpoch: 3623  | Validation balanced accuracy : 0.76304 \nEpoch: 3624  | Training Loss: 0.31584 \nEpoch: 3624  | Training Loss: 0.36796 \nEpoch: 3624  | Training Loss: 0.34548 \nEpoch: 3624  | Training Loss: 0.21274 \nEpoch: 3624  | Training Loss: 0.14909 \nEpoch: 3624  | Validation balanced accuracy : 0.76304 \nEpoch: 3625  | Training Loss: 0.31564 \nEpoch: 3625  | Training Loss: 0.36784 \nEpoch: 3625  | Training Loss: 0.34554 \nEpoch: 3625  | Training Loss: 0.21272 \nEpoch: 3625  | Training Loss: 0.14919 \nEpoch: 3625  | Validation balanced accuracy : 0.76304 \nEpoch: 3626  | Training Loss: 0.31561 \nEpoch: 3626  | Training Loss: 0.36783 \nEpoch: 3626  | Training Loss: 0.34554 \nEpoch: 3626  | Training Loss: 0.21273 \nEpoch: 3626  | Training Loss: 0.14910 \nEpoch: 3626  | Validation balanced accuracy : 0.76304 \nEpoch: 3627  | Training Loss: 0.31568 \nEpoch: 3627  | Training Loss: 0.36790 \nEpoch: 3627  | Training Loss: 0.34549 \nEpoch: 3627  | Training Loss: 0.21274 \nEpoch: 3627  | Training Loss: 0.14893 \nEpoch: 3627  | Validation balanced accuracy : 0.76304 \nEpoch: 3628  | Training Loss: 0.31580 \nEpoch: 3628  | Training Loss: 0.36793 \nEpoch: 3628  | Training Loss: 0.34550 \nEpoch: 3628  | Training Loss: 0.21273 \nEpoch: 3628  | Training Loss: 0.14909 \nEpoch: 3628  | Validation balanced accuracy : 0.76304 \nEpoch: 3629  | Training Loss: 0.31565 \nEpoch: 3629  | Training Loss: 0.36785 \nEpoch: 3629  | Training Loss: 0.34554 \nEpoch: 3629  | Training Loss: 0.21272 \nEpoch: 3629  | Training Loss: 0.14913 \nEpoch: 3629  | Validation balanced accuracy : 0.76304 \nEpoch: 3630  | Training Loss: 0.31564 \nEpoch: 3630  | Training Loss: 0.36786 \nEpoch: 3630  | Training Loss: 0.34553 \nEpoch: 3630  | Training Loss: 0.21273 \nEpoch: 3630  | Training Loss: 0.14903 \nEpoch: 3630  | Validation balanced accuracy : 0.76304 \nEpoch: 3631  | Training Loss: 0.31573 \nEpoch: 3631  | Training Loss: 0.36793 \nEpoch: 3631  | Training Loss: 0.34549 \nEpoch: 3631  | Training Loss: 0.21274 \nEpoch: 3631  | Training Loss: 0.14888 \nEpoch: 3631  | Validation balanced accuracy : 0.76304 \nEpoch: 3632  | Training Loss: 0.31583 \nEpoch: 3632  | Training Loss: 0.36795 \nEpoch: 3632  | Training Loss: 0.34550 \nEpoch: 3632  | Training Loss: 0.21273 \nEpoch: 3632  | Training Loss: 0.14906 \nEpoch: 3632  | Validation balanced accuracy : 0.76304 \nEpoch: 3633  | Training Loss: 0.31566 \nEpoch: 3633  | Training Loss: 0.36785 \nEpoch: 3633  | Training Loss: 0.34555 \nEpoch: 3633  | Training Loss: 0.21272 \nEpoch: 3633  | Training Loss: 0.14912 \nEpoch: 3633  | Validation balanced accuracy : 0.76304 \nEpoch: 3634  | Training Loss: 0.31564 \nEpoch: 3634  | Training Loss: 0.36786 \nEpoch: 3634  | Training Loss: 0.34554 \nEpoch: 3634  | Training Loss: 0.21272 \nEpoch: 3634  | Training Loss: 0.14903 \nEpoch: 3634  | Validation balanced accuracy : 0.76304 \nEpoch: 3635  | Training Loss: 0.31572 \nEpoch: 3635  | Training Loss: 0.36793 \nEpoch: 3635  | Training Loss: 0.34550 \nEpoch: 3635  | Training Loss: 0.21273 \nEpoch: 3635  | Training Loss: 0.14887 \nEpoch: 3635  | Validation balanced accuracy : 0.76304 \nEpoch: 3636  | Training Loss: 0.31584 \nEpoch: 3636  | Training Loss: 0.36795 \nEpoch: 3636  | Training Loss: 0.34552 \nEpoch: 3636  | Training Loss: 0.21272 \nEpoch: 3636  | Training Loss: 0.14907 \nEpoch: 3636  | Validation balanced accuracy : 0.76304 \nEpoch: 3637  | Training Loss: 0.31564 \nEpoch: 3637  | Training Loss: 0.36784 \nEpoch: 3637  | Training Loss: 0.34557 \nEpoch: 3637  | Training Loss: 0.21271 \nEpoch: 3637  | Training Loss: 0.14914 \nEpoch: 3637  | Validation balanced accuracy : 0.76304 \nEpoch: 3638  | Training Loss: 0.31562 \nEpoch: 3638  | Training Loss: 0.36784 \nEpoch: 3638  | Training Loss: 0.34556 \nEpoch: 3638  | Training Loss: 0.21272 \nEpoch: 3638  | Training Loss: 0.14904 \nEpoch: 3638  | Validation balanced accuracy : 0.76304 \nEpoch: 3639  | Training Loss: 0.31570 \nEpoch: 3639  | Training Loss: 0.36791 \nEpoch: 3639  | Training Loss: 0.34552 \nEpoch: 3639  | Training Loss: 0.21273 \nEpoch: 3639  | Training Loss: 0.14887 \nEpoch: 3639  | Validation balanced accuracy : 0.76304 \nEpoch: 3640  | Training Loss: 0.31583 \nEpoch: 3640  | Training Loss: 0.36795 \nEpoch: 3640  | Training Loss: 0.34553 \nEpoch: 3640  | Training Loss: 0.21272 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3640  | Training Loss: 0.14908 \nEpoch: 3640  | Validation balanced accuracy : 0.76304 \nEpoch: 3641  | Training Loss: 0.31562 \nEpoch: 3641  | Training Loss: 0.36782 \nEpoch: 3641  | Training Loss: 0.34559 \nEpoch: 3641  | Training Loss: 0.21270 \nEpoch: 3641  | Training Loss: 0.14917 \nEpoch: 3641  | Validation balanced accuracy : 0.76304 \nEpoch: 3642  | Training Loss: 0.31559 \nEpoch: 3642  | Training Loss: 0.36783 \nEpoch: 3642  | Training Loss: 0.34558 \nEpoch: 3642  | Training Loss: 0.21271 \nEpoch: 3642  | Training Loss: 0.14901 \nEpoch: 3642  | Validation balanced accuracy : 0.76304 \nEpoch: 3643  | Training Loss: 0.31573 \nEpoch: 3643  | Training Loss: 0.36794 \nEpoch: 3643  | Training Loss: 0.34551 \nEpoch: 3643  | Training Loss: 0.21273 \nEpoch: 3643  | Training Loss: 0.14879 \nEpoch: 3643  | Validation balanced accuracy : 0.76304 \nEpoch: 3644  | Training Loss: 0.31588 \nEpoch: 3644  | Training Loss: 0.36799 \nEpoch: 3644  | Training Loss: 0.34552 \nEpoch: 3644  | Training Loss: 0.21272 \nEpoch: 3644  | Training Loss: 0.14900 \nEpoch: 3644  | Validation balanced accuracy : 0.76304 \nEpoch: 3645  | Training Loss: 0.31568 \nEpoch: 3645  | Training Loss: 0.36786 \nEpoch: 3645  | Training Loss: 0.34558 \nEpoch: 3645  | Training Loss: 0.21270 \nEpoch: 3645  | Training Loss: 0.14910 \nEpoch: 3645  | Validation balanced accuracy : 0.76304 \nEpoch: 3646  | Training Loss: 0.31563 \nEpoch: 3646  | Training Loss: 0.36786 \nEpoch: 3646  | Training Loss: 0.34557 \nEpoch: 3646  | Training Loss: 0.21271 \nEpoch: 3646  | Training Loss: 0.14896 \nEpoch: 3646  | Validation balanced accuracy : 0.76304 \nEpoch: 3647  | Training Loss: 0.31575 \nEpoch: 3647  | Training Loss: 0.36795 \nEpoch: 3647  | Training Loss: 0.34552 \nEpoch: 3647  | Training Loss: 0.21272 \nEpoch: 3647  | Training Loss: 0.14879 \nEpoch: 3647  | Validation balanced accuracy : 0.76304 \nEpoch: 3648  | Training Loss: 0.31588 \nEpoch: 3648  | Training Loss: 0.36799 \nEpoch: 3648  | Training Loss: 0.34553 \nEpoch: 3648  | Training Loss: 0.21271 \nEpoch: 3648  | Training Loss: 0.14902 \nEpoch: 3648  | Validation balanced accuracy : 0.76304 \nEpoch: 3649  | Training Loss: 0.31566 \nEpoch: 3649  | Training Loss: 0.36785 \nEpoch: 3649  | Training Loss: 0.34560 \nEpoch: 3649  | Training Loss: 0.21269 \nEpoch: 3649  | Training Loss: 0.14913 \nEpoch: 3649  | Validation balanced accuracy : 0.76304 \nEpoch: 3650  | Training Loss: 0.31561 \nEpoch: 3650  | Training Loss: 0.36785 \nEpoch: 3650  | Training Loss: 0.34559 \nEpoch: 3650  | Training Loss: 0.21270 \nEpoch: 3650  | Training Loss: 0.14898 \nEpoch: 3650  | Validation balanced accuracy : 0.76304 \nEpoch: 3651  | Training Loss: 0.31574 \nEpoch: 3651  | Training Loss: 0.36794 \nEpoch: 3651  | Training Loss: 0.34553 \nEpoch: 3651  | Training Loss: 0.21272 \nEpoch: 3651  | Training Loss: 0.14878 \nEpoch: 3651  | Validation balanced accuracy : 0.76304 \nEpoch: 3652  | Training Loss: 0.31588 \nEpoch: 3652  | Training Loss: 0.36799 \nEpoch: 3652  | Training Loss: 0.34554 \nEpoch: 3652  | Training Loss: 0.21270 \nEpoch: 3652  | Training Loss: 0.14901 \nEpoch: 3652  | Validation balanced accuracy : 0.76304 \nEpoch: 3653  | Training Loss: 0.31565 \nEpoch: 3653  | Training Loss: 0.36784 \nEpoch: 3653  | Training Loss: 0.34562 \nEpoch: 3653  | Training Loss: 0.21269 \nEpoch: 3653  | Training Loss: 0.14913 \nEpoch: 3653  | Validation balanced accuracy : 0.76304 \nEpoch: 3654  | Training Loss: 0.31560 \nEpoch: 3654  | Training Loss: 0.36784 \nEpoch: 3654  | Training Loss: 0.34561 \nEpoch: 3654  | Training Loss: 0.21270 \nEpoch: 3654  | Training Loss: 0.14899 \nEpoch: 3654  | Validation balanced accuracy : 0.76304 \nEpoch: 3655  | Training Loss: 0.31573 \nEpoch: 3655  | Training Loss: 0.36794 \nEpoch: 3655  | Training Loss: 0.34555 \nEpoch: 3655  | Training Loss: 0.21271 \nEpoch: 3655  | Training Loss: 0.14878 \nEpoch: 3655  | Validation balanced accuracy : 0.76304 \nEpoch: 3656  | Training Loss: 0.31588 \nEpoch: 3656  | Training Loss: 0.36799 \nEpoch: 3656  | Training Loss: 0.34555 \nEpoch: 3656  | Training Loss: 0.21270 \nEpoch: 3656  | Training Loss: 0.14898 \nEpoch: 3656  | Validation balanced accuracy : 0.76304 \nEpoch: 3657  | Training Loss: 0.31568 \nEpoch: 3657  | Training Loss: 0.36786 \nEpoch: 3657  | Training Loss: 0.34562 \nEpoch: 3657  | Training Loss: 0.21269 \nEpoch: 3657  | Training Loss: 0.14907 \nEpoch: 3657  | Validation balanced accuracy : 0.76304 \nEpoch: 3658  | Training Loss: 0.31564 \nEpoch: 3658  | Training Loss: 0.36787 \nEpoch: 3658  | Training Loss: 0.34560 \nEpoch: 3658  | Training Loss: 0.21270 \nEpoch: 3658  | Training Loss: 0.14893 \nEpoch: 3658  | Validation balanced accuracy : 0.76304 \nEpoch: 3659  | Training Loss: 0.31576 \nEpoch: 3659  | Training Loss: 0.36796 \nEpoch: 3659  | Training Loss: 0.34554 \nEpoch: 3659  | Training Loss: 0.21271 \nEpoch: 3659  | Training Loss: 0.14873 \nEpoch: 3659  | Validation balanced accuracy : 0.76304 \nEpoch: 3660  | Training Loss: 0.31590 \nEpoch: 3660  | Training Loss: 0.36801 \nEpoch: 3660  | Training Loss: 0.34555 \nEpoch: 3660  | Training Loss: 0.21270 \nEpoch: 3660  | Training Loss: 0.14895 \nEpoch: 3660  | Validation balanced accuracy : 0.76304 \nEpoch: 3661  | Training Loss: 0.31569 \nEpoch: 3661  | Training Loss: 0.36787 \nEpoch: 3661  | Training Loss: 0.34562 \nEpoch: 3661  | Training Loss: 0.21268 \nEpoch: 3661  | Training Loss: 0.14906 \nEpoch: 3661  | Validation balanced accuracy : 0.76304 \nEpoch: 3662  | Training Loss: 0.31564 \nEpoch: 3662  | Training Loss: 0.36787 \nEpoch: 3662  | Training Loss: 0.34561 \nEpoch: 3662  | Training Loss: 0.21269 \nEpoch: 3662  | Training Loss: 0.14892 \nEpoch: 3662  | Validation balanced accuracy : 0.76304 \nEpoch: 3663  | Training Loss: 0.31576 \nEpoch: 3663  | Training Loss: 0.36796 \nEpoch: 3663  | Training Loss: 0.34555 \nEpoch: 3663  | Training Loss: 0.21271 \nEpoch: 3663  | Training Loss: 0.14873 \nEpoch: 3663  | Validation balanced accuracy : 0.76304 \nEpoch: 3664  | Training Loss: 0.31590 \nEpoch: 3664  | Training Loss: 0.36800 \nEpoch: 3664  | Training Loss: 0.34556 \nEpoch: 3664  | Training Loss: 0.21269 \nEpoch: 3664  | Training Loss: 0.14892 \nEpoch: 3664  | Validation balanced accuracy : 0.76304 \nEpoch: 3665  | Training Loss: 0.31570 \nEpoch: 3665  | Training Loss: 0.36789 \nEpoch: 3665  | Training Loss: 0.34562 \nEpoch: 3665  | Training Loss: 0.21268 \nEpoch: 3665  | Training Loss: 0.14901 \nEpoch: 3665  | Validation balanced accuracy : 0.76304 \nEpoch: 3666  | Training Loss: 0.31567 \nEpoch: 3666  | Training Loss: 0.36788 \nEpoch: 3666  | Training Loss: 0.34562 \nEpoch: 3666  | Training Loss: 0.21269 \nEpoch: 3666  | Training Loss: 0.14893 \nEpoch: 3666  | Validation balanced accuracy : 0.76304 \nEpoch: 3667  | Training Loss: 0.31574 \nEpoch: 3667  | Training Loss: 0.36795 \nEpoch: 3667  | Training Loss: 0.34558 \nEpoch: 3667  | Training Loss: 0.21270 \nEpoch: 3667  | Training Loss: 0.14877 \nEpoch: 3667  | Validation balanced accuracy : 0.76304 \nEpoch: 3668  | Training Loss: 0.31585 \nEpoch: 3668  | Training Loss: 0.36798 \nEpoch: 3668  | Training Loss: 0.34559 \nEpoch: 3668  | Training Loss: 0.21269 \nEpoch: 3668  | Training Loss: 0.14895 \nEpoch: 3668  | Validation balanced accuracy : 0.76304 \nEpoch: 3669  | Training Loss: 0.31569 \nEpoch: 3669  | Training Loss: 0.36788 \nEpoch: 3669  | Training Loss: 0.34564 \nEpoch: 3669  | Training Loss: 0.21268 \nEpoch: 3669  | Training Loss: 0.14900 \nEpoch: 3669  | Validation balanced accuracy : 0.76304 \nEpoch: 3670  | Training Loss: 0.31567 \nEpoch: 3670  | Training Loss: 0.36789 \nEpoch: 3670  | Training Loss: 0.34562 \nEpoch: 3670  | Training Loss: 0.21268 \nEpoch: 3670  | Training Loss: 0.14890 \nEpoch: 3670  | Validation balanced accuracy : 0.76304 \nEpoch: 3671  | Training Loss: 0.31576 \nEpoch: 3671  | Training Loss: 0.36796 \nEpoch: 3671  | Training Loss: 0.34558 \nEpoch: 3671  | Training Loss: 0.21269 \nEpoch: 3671  | Training Loss: 0.14874 \nEpoch: 3671  | Validation balanced accuracy : 0.76304 \nEpoch: 3672  | Training Loss: 0.31587 \nEpoch: 3672  | Training Loss: 0.36799 \nEpoch: 3672  | Training Loss: 0.34559 \nEpoch: 3672  | Training Loss: 0.21268 \nEpoch: 3672  | Training Loss: 0.14891 \nEpoch: 3672  | Validation balanced accuracy : 0.76304 \nEpoch: 3673  | Training Loss: 0.31570 \nEpoch: 3673  | Training Loss: 0.36789 \nEpoch: 3673  | Training Loss: 0.34564 \nEpoch: 3673  | Training Loss: 0.21267 \nEpoch: 3673  | Training Loss: 0.14897 \nEpoch: 3673  | Validation balanced accuracy : 0.76304 \nEpoch: 3674  | Training Loss: 0.31569 \nEpoch: 3674  | Training Loss: 0.36790 \nEpoch: 3674  | Training Loss: 0.34563 \nEpoch: 3674  | Training Loss: 0.21268 \nEpoch: 3674  | Training Loss: 0.14888 \nEpoch: 3674  | Validation balanced accuracy : 0.76304 \nEpoch: 3675  | Training Loss: 0.31576 \nEpoch: 3675  | Training Loss: 0.36796 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3675  | Training Loss: 0.34559 \nEpoch: 3675  | Training Loss: 0.21269 \nEpoch: 3675  | Training Loss: 0.14874 \nEpoch: 3675  | Validation balanced accuracy : 0.76304 \nEpoch: 3676  | Training Loss: 0.31586 \nEpoch: 3676  | Training Loss: 0.36798 \nEpoch: 3676  | Training Loss: 0.34561 \nEpoch: 3676  | Training Loss: 0.21268 \nEpoch: 3676  | Training Loss: 0.14893 \nEpoch: 3676  | Validation balanced accuracy : 0.76304 \nEpoch: 3677  | Training Loss: 0.31569 \nEpoch: 3677  | Training Loss: 0.36788 \nEpoch: 3677  | Training Loss: 0.34566 \nEpoch: 3677  | Training Loss: 0.21267 \nEpoch: 3677  | Training Loss: 0.14899 \nEpoch: 3677  | Validation balanced accuracy : 0.76304 \nEpoch: 3678  | Training Loss: 0.31567 \nEpoch: 3678  | Training Loss: 0.36790 \nEpoch: 3678  | Training Loss: 0.34563 \nEpoch: 3678  | Training Loss: 0.21268 \nEpoch: 3678  | Training Loss: 0.14882 \nEpoch: 3678  | Validation balanced accuracy : 0.76304 \nEpoch: 3679  | Training Loss: 0.31581 \nEpoch: 3679  | Training Loss: 0.36800 \nEpoch: 3679  | Training Loss: 0.34557 \nEpoch: 3679  | Training Loss: 0.21269 \nEpoch: 3679  | Training Loss: 0.14863 \nEpoch: 3679  | Validation balanced accuracy : 0.76304 \nEpoch: 3680  | Training Loss: 0.31595 \nEpoch: 3680  | Training Loss: 0.36804 \nEpoch: 3680  | Training Loss: 0.34559 \nEpoch: 3680  | Training Loss: 0.21268 \nEpoch: 3680  | Training Loss: 0.14889 \nEpoch: 3680  | Validation balanced accuracy : 0.76304 \nEpoch: 3681  | Training Loss: 0.31570 \nEpoch: 3681  | Training Loss: 0.36788 \nEpoch: 3681  | Training Loss: 0.34567 \nEpoch: 3681  | Training Loss: 0.21266 \nEpoch: 3681  | Training Loss: 0.14903 \nEpoch: 3681  | Validation balanced accuracy : 0.76304 \nEpoch: 3682  | Training Loss: 0.31563 \nEpoch: 3682  | Training Loss: 0.36786 \nEpoch: 3682  | Training Loss: 0.34567 \nEpoch: 3682  | Training Loss: 0.21266 \nEpoch: 3682  | Training Loss: 0.14890 \nEpoch: 3682  | Validation balanced accuracy : 0.76304 \nEpoch: 3683  | Training Loss: 0.31575 \nEpoch: 3683  | Training Loss: 0.36796 \nEpoch: 3683  | Training Loss: 0.34561 \nEpoch: 3683  | Training Loss: 0.21268 \nEpoch: 3683  | Training Loss: 0.14870 \nEpoch: 3683  | Validation balanced accuracy : 0.76304 \nEpoch: 3684  | Training Loss: 0.31589 \nEpoch: 3684  | Training Loss: 0.36801 \nEpoch: 3684  | Training Loss: 0.34562 \nEpoch: 3684  | Training Loss: 0.21267 \nEpoch: 3684  | Training Loss: 0.14890 \nEpoch: 3684  | Validation balanced accuracy : 0.76304 \nEpoch: 3685  | Training Loss: 0.31569 \nEpoch: 3685  | Training Loss: 0.36788 \nEpoch: 3685  | Training Loss: 0.34568 \nEpoch: 3685  | Training Loss: 0.21266 \nEpoch: 3685  | Training Loss: 0.14899 \nEpoch: 3685  | Validation balanced accuracy : 0.76304 \nEpoch: 3686  | Training Loss: 0.31565 \nEpoch: 3686  | Training Loss: 0.36788 \nEpoch: 3686  | Training Loss: 0.34567 \nEpoch: 3686  | Training Loss: 0.21266 \nEpoch: 3686  | Training Loss: 0.14884 \nEpoch: 3686  | Validation balanced accuracy : 0.76304 \nEpoch: 3687  | Training Loss: 0.31578 \nEpoch: 3687  | Training Loss: 0.36798 \nEpoch: 3687  | Training Loss: 0.34561 \nEpoch: 3687  | Training Loss: 0.21268 \nEpoch: 3687  | Training Loss: 0.14864 \nEpoch: 3687  | Validation balanced accuracy : 0.76304 \nEpoch: 3688  | Training Loss: 0.31592 \nEpoch: 3688  | Training Loss: 0.36803 \nEpoch: 3688  | Training Loss: 0.34561 \nEpoch: 3688  | Training Loss: 0.21267 \nEpoch: 3688  | Training Loss: 0.14886 \nEpoch: 3688  | Validation balanced accuracy : 0.76304 \nEpoch: 3689  | Training Loss: 0.31571 \nEpoch: 3689  | Training Loss: 0.36789 \nEpoch: 3689  | Training Loss: 0.34568 \nEpoch: 3689  | Training Loss: 0.21265 \nEpoch: 3689  | Training Loss: 0.14897 \nEpoch: 3689  | Validation balanced accuracy : 0.76304 \nEpoch: 3690  | Training Loss: 0.31566 \nEpoch: 3690  | Training Loss: 0.36789 \nEpoch: 3690  | Training Loss: 0.34567 \nEpoch: 3690  | Training Loss: 0.21266 \nEpoch: 3690  | Training Loss: 0.14883 \nEpoch: 3690  | Validation balanced accuracy : 0.76304 \nEpoch: 3691  | Training Loss: 0.31578 \nEpoch: 3691  | Training Loss: 0.36798 \nEpoch: 3691  | Training Loss: 0.34562 \nEpoch: 3691  | Training Loss: 0.21268 \nEpoch: 3691  | Training Loss: 0.14864 \nEpoch: 3691  | Validation balanced accuracy : 0.76304 \nEpoch: 3692  | Training Loss: 0.31592 \nEpoch: 3692  | Training Loss: 0.36802 \nEpoch: 3692  | Training Loss: 0.34563 \nEpoch: 3692  | Training Loss: 0.21266 \nEpoch: 3692  | Training Loss: 0.14883 \nEpoch: 3692  | Validation balanced accuracy : 0.76304 \nEpoch: 3693  | Training Loss: 0.31573 \nEpoch: 3693  | Training Loss: 0.36791 \nEpoch: 3693  | Training Loss: 0.34568 \nEpoch: 3693  | Training Loss: 0.21265 \nEpoch: 3693  | Training Loss: 0.14892 \nEpoch: 3693  | Validation balanced accuracy : 0.76304 \nEpoch: 3694  | Training Loss: 0.31569 \nEpoch: 3694  | Training Loss: 0.36790 \nEpoch: 3694  | Training Loss: 0.34568 \nEpoch: 3694  | Training Loss: 0.21266 \nEpoch: 3694  | Training Loss: 0.14884 \nEpoch: 3694  | Validation balanced accuracy : 0.76304 \nEpoch: 3695  | Training Loss: 0.31576 \nEpoch: 3695  | Training Loss: 0.36796 \nEpoch: 3695  | Training Loss: 0.34564 \nEpoch: 3695  | Training Loss: 0.21267 \nEpoch: 3695  | Training Loss: 0.14868 \nEpoch: 3695  | Validation balanced accuracy : 0.76304 \nEpoch: 3696  | Training Loss: 0.31588 \nEpoch: 3696  | Training Loss: 0.36800 \nEpoch: 3696  | Training Loss: 0.34565 \nEpoch: 3696  | Training Loss: 0.21266 \nEpoch: 3696  | Training Loss: 0.14886 \nEpoch: 3696  | Validation balanced accuracy : 0.76304 \nEpoch: 3697  | Training Loss: 0.31571 \nEpoch: 3697  | Training Loss: 0.36790 \nEpoch: 3697  | Training Loss: 0.34570 \nEpoch: 3697  | Training Loss: 0.21265 \nEpoch: 3697  | Training Loss: 0.14891 \nEpoch: 3697  | Validation balanced accuracy : 0.76304 \nEpoch: 3698  | Training Loss: 0.31570 \nEpoch: 3698  | Training Loss: 0.36791 \nEpoch: 3698  | Training Loss: 0.34569 \nEpoch: 3698  | Training Loss: 0.21265 \nEpoch: 3698  | Training Loss: 0.14881 \nEpoch: 3698  | Validation balanced accuracy : 0.76304 \nEpoch: 3699  | Training Loss: 0.31578 \nEpoch: 3699  | Training Loss: 0.36798 \nEpoch: 3699  | Training Loss: 0.34564 \nEpoch: 3699  | Training Loss: 0.21266 \nEpoch: 3699  | Training Loss: 0.14865 \nEpoch: 3699  | Validation balanced accuracy : 0.76304 \nEpoch: 3700  | Training Loss: 0.31590 \nEpoch: 3700  | Training Loss: 0.36801 \nEpoch: 3700  | Training Loss: 0.34565 \nEpoch: 3700  | Training Loss: 0.21265 \nEpoch: 3700  | Training Loss: 0.14883 \nEpoch: 3700  | Validation balanced accuracy : 0.76304 \nEpoch: 3701  | Training Loss: 0.31573 \nEpoch: 3701  | Training Loss: 0.36791 \nEpoch: 3701  | Training Loss: 0.34570 \nEpoch: 3701  | Training Loss: 0.21264 \nEpoch: 3701  | Training Loss: 0.14889 \nEpoch: 3701  | Validation balanced accuracy : 0.76304 \nEpoch: 3702  | Training Loss: 0.31571 \nEpoch: 3702  | Training Loss: 0.36793 \nEpoch: 3702  | Training Loss: 0.34568 \nEpoch: 3702  | Training Loss: 0.21265 \nEpoch: 3702  | Training Loss: 0.14873 \nEpoch: 3702  | Validation balanced accuracy : 0.76304 \nEpoch: 3703  | Training Loss: 0.31584 \nEpoch: 3703  | Training Loss: 0.36802 \nEpoch: 3703  | Training Loss: 0.34562 \nEpoch: 3703  | Training Loss: 0.21267 \nEpoch: 3703  | Training Loss: 0.14855 \nEpoch: 3703  | Validation balanced accuracy : 0.76304 \nEpoch: 3704  | Training Loss: 0.31597 \nEpoch: 3704  | Training Loss: 0.36806 \nEpoch: 3704  | Training Loss: 0.34564 \nEpoch: 3704  | Training Loss: 0.21265 \nEpoch: 3704  | Training Loss: 0.14881 \nEpoch: 3704  | Validation balanced accuracy : 0.76304 \nEpoch: 3705  | Training Loss: 0.31571 \nEpoch: 3705  | Training Loss: 0.36789 \nEpoch: 3705  | Training Loss: 0.34573 \nEpoch: 3705  | Training Loss: 0.21263 \nEpoch: 3705  | Training Loss: 0.14896 \nEpoch: 3705  | Validation balanced accuracy : 0.76304 \nEpoch: 3706  | Training Loss: 0.31565 \nEpoch: 3706  | Training Loss: 0.36788 \nEpoch: 3706  | Training Loss: 0.34572 \nEpoch: 3706  | Training Loss: 0.21264 \nEpoch: 3706  | Training Loss: 0.14883 \nEpoch: 3706  | Validation balanced accuracy : 0.76304 \nEpoch: 3707  | Training Loss: 0.31576 \nEpoch: 3707  | Training Loss: 0.36797 \nEpoch: 3707  | Training Loss: 0.34566 \nEpoch: 3707  | Training Loss: 0.21266 \nEpoch: 3707  | Training Loss: 0.14863 \nEpoch: 3707  | Validation balanced accuracy : 0.76304 \nEpoch: 3708  | Training Loss: 0.31590 \nEpoch: 3708  | Training Loss: 0.36802 \nEpoch: 3708  | Training Loss: 0.34567 \nEpoch: 3708  | Training Loss: 0.21265 \nEpoch: 3708  | Training Loss: 0.14878 \nEpoch: 3708  | Validation balanced accuracy : 0.76304 \nEpoch: 3709  | Training Loss: 0.31575 \nEpoch: 3709  | Training Loss: 0.36793 \nEpoch: 3709  | Training Loss: 0.34571 \nEpoch: 3709  | Training Loss: 0.21264 \nEpoch: 3709  | Training Loss: 0.14883 \nEpoch: 3709  | Validation balanced accuracy : 0.76304 \nEpoch: 3710  | Training Loss: 0.31574 \nEpoch: 3710  | Training Loss: 0.36794 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3710  | Training Loss: 0.34570 \nEpoch: 3710  | Training Loss: 0.21264 \nEpoch: 3710  | Training Loss: 0.14874 \nEpoch: 3710  | Validation balanced accuracy : 0.76304 \nEpoch: 3711  | Training Loss: 0.31581 \nEpoch: 3711  | Training Loss: 0.36800 \nEpoch: 3711  | Training Loss: 0.34566 \nEpoch: 3711  | Training Loss: 0.21265 \nEpoch: 3711  | Training Loss: 0.14860 \nEpoch: 3711  | Validation balanced accuracy : 0.76304 \nEpoch: 3712  | Training Loss: 0.31591 \nEpoch: 3712  | Training Loss: 0.36802 \nEpoch: 3712  | Training Loss: 0.34567 \nEpoch: 3712  | Training Loss: 0.21264 \nEpoch: 3712  | Training Loss: 0.14879 \nEpoch: 3712  | Validation balanced accuracy : 0.76304 \nEpoch: 3713  | Training Loss: 0.31574 \nEpoch: 3713  | Training Loss: 0.36792 \nEpoch: 3713  | Training Loss: 0.34573 \nEpoch: 3713  | Training Loss: 0.21263 \nEpoch: 3713  | Training Loss: 0.14886 \nEpoch: 3713  | Validation balanced accuracy : 0.76304 \nEpoch: 3714  | Training Loss: 0.31571 \nEpoch: 3714  | Training Loss: 0.36793 \nEpoch: 3714  | Training Loss: 0.34571 \nEpoch: 3714  | Training Loss: 0.21264 \nEpoch: 3714  | Training Loss: 0.14871 \nEpoch: 3714  | Validation balanced accuracy : 0.76304 \nEpoch: 3715  | Training Loss: 0.31584 \nEpoch: 3715  | Training Loss: 0.36803 \nEpoch: 3715  | Training Loss: 0.34565 \nEpoch: 3715  | Training Loss: 0.21266 \nEpoch: 3715  | Training Loss: 0.14852 \nEpoch: 3715  | Validation balanced accuracy : 0.76304 \nEpoch: 3716  | Training Loss: 0.31597 \nEpoch: 3716  | Training Loss: 0.36806 \nEpoch: 3716  | Training Loss: 0.34567 \nEpoch: 3716  | Training Loss: 0.21264 \nEpoch: 3716  | Training Loss: 0.14878 \nEpoch: 3716  | Validation balanced accuracy : 0.76304 \nEpoch: 3717  | Training Loss: 0.31572 \nEpoch: 3717  | Training Loss: 0.36790 \nEpoch: 3717  | Training Loss: 0.34575 \nEpoch: 3717  | Training Loss: 0.21262 \nEpoch: 3717  | Training Loss: 0.14893 \nEpoch: 3717  | Validation balanced accuracy : 0.76304 \nEpoch: 3718  | Training Loss: 0.31565 \nEpoch: 3718  | Training Loss: 0.36788 \nEpoch: 3718  | Training Loss: 0.34575 \nEpoch: 3718  | Training Loss: 0.21263 \nEpoch: 3718  | Training Loss: 0.14880 \nEpoch: 3718  | Validation balanced accuracy : 0.76304 \nEpoch: 3719  | Training Loss: 0.31577 \nEpoch: 3719  | Training Loss: 0.36798 \nEpoch: 3719  | Training Loss: 0.34569 \nEpoch: 3719  | Training Loss: 0.21264 \nEpoch: 3719  | Training Loss: 0.14859 \nEpoch: 3719  | Validation balanced accuracy : 0.76304 \nEpoch: 3720  | Training Loss: 0.31591 \nEpoch: 3720  | Training Loss: 0.36803 \nEpoch: 3720  | Training Loss: 0.34569 \nEpoch: 3720  | Training Loss: 0.21264 \nEpoch: 3720  | Training Loss: 0.14874 \nEpoch: 3720  | Validation balanced accuracy : 0.76304 \nEpoch: 3721  | Training Loss: 0.31576 \nEpoch: 3721  | Training Loss: 0.36794 \nEpoch: 3721  | Training Loss: 0.34573 \nEpoch: 3721  | Training Loss: 0.21263 \nEpoch: 3721  | Training Loss: 0.14879 \nEpoch: 3721  | Validation balanced accuracy : 0.76304 \nEpoch: 3722  | Training Loss: 0.31575 \nEpoch: 3722  | Training Loss: 0.36795 \nEpoch: 3722  | Training Loss: 0.34572 \nEpoch: 3722  | Training Loss: 0.21263 \nEpoch: 3722  | Training Loss: 0.14871 \nEpoch: 3722  | Validation balanced accuracy : 0.76304 \nEpoch: 3723  | Training Loss: 0.31582 \nEpoch: 3723  | Training Loss: 0.36801 \nEpoch: 3723  | Training Loss: 0.34568 \nEpoch: 3723  | Training Loss: 0.21264 \nEpoch: 3723  | Training Loss: 0.14856 \nEpoch: 3723  | Validation balanced accuracy : 0.76304 \nEpoch: 3724  | Training Loss: 0.31592 \nEpoch: 3724  | Training Loss: 0.36803 \nEpoch: 3724  | Training Loss: 0.34570 \nEpoch: 3724  | Training Loss: 0.21263 \nEpoch: 3724  | Training Loss: 0.14875 \nEpoch: 3724  | Validation balanced accuracy : 0.76304 \nEpoch: 3725  | Training Loss: 0.31574 \nEpoch: 3725  | Training Loss: 0.36793 \nEpoch: 3725  | Training Loss: 0.34575 \nEpoch: 3725  | Training Loss: 0.21262 \nEpoch: 3725  | Training Loss: 0.14882 \nEpoch: 3725  | Validation balanced accuracy : 0.76304 \nEpoch: 3726  | Training Loss: 0.31572 \nEpoch: 3726  | Training Loss: 0.36794 \nEpoch: 3726  | Training Loss: 0.34573 \nEpoch: 3726  | Training Loss: 0.21263 \nEpoch: 3726  | Training Loss: 0.14867 \nEpoch: 3726  | Validation balanced accuracy : 0.76304 \nEpoch: 3727  | Training Loss: 0.31585 \nEpoch: 3727  | Training Loss: 0.36803 \nEpoch: 3727  | Training Loss: 0.34567 \nEpoch: 3727  | Training Loss: 0.21264 \nEpoch: 3727  | Training Loss: 0.14849 \nEpoch: 3727  | Validation balanced accuracy : 0.76304 \nEpoch: 3728  | Training Loss: 0.31598 \nEpoch: 3728  | Training Loss: 0.36807 \nEpoch: 3728  | Training Loss: 0.34570 \nEpoch: 3728  | Training Loss: 0.21263 \nEpoch: 3728  | Training Loss: 0.14875 \nEpoch: 3728  | Validation balanced accuracy : 0.76304 \nEpoch: 3729  | Training Loss: 0.31573 \nEpoch: 3729  | Training Loss: 0.36792 \nEpoch: 3729  | Training Loss: 0.34577 \nEpoch: 3729  | Training Loss: 0.21261 \nEpoch: 3729  | Training Loss: 0.14883 \nEpoch: 3729  | Validation balanced accuracy : 0.76304 \nEpoch: 3730  | Training Loss: 0.31571 \nEpoch: 3730  | Training Loss: 0.36793 \nEpoch: 3730  | Training Loss: 0.34574 \nEpoch: 3730  | Training Loss: 0.21262 \nEpoch: 3730  | Training Loss: 0.14867 \nEpoch: 3730  | Validation balanced accuracy : 0.76304 \nEpoch: 3731  | Training Loss: 0.31585 \nEpoch: 3731  | Training Loss: 0.36803 \nEpoch: 3731  | Training Loss: 0.34568 \nEpoch: 3731  | Training Loss: 0.21264 \nEpoch: 3731  | Training Loss: 0.14847 \nEpoch: 3731  | Validation balanced accuracy : 0.76304 \nEpoch: 3732  | Training Loss: 0.31598 \nEpoch: 3732  | Training Loss: 0.36808 \nEpoch: 3732  | Training Loss: 0.34570 \nEpoch: 3732  | Training Loss: 0.21263 \nEpoch: 3732  | Training Loss: 0.14870 \nEpoch: 3732  | Validation balanced accuracy : 0.76304 \nEpoch: 3733  | Training Loss: 0.31576 \nEpoch: 3733  | Training Loss: 0.36793 \nEpoch: 3733  | Training Loss: 0.34577 \nEpoch: 3733  | Training Loss: 0.21261 \nEpoch: 3733  | Training Loss: 0.14883 \nEpoch: 3733  | Validation balanced accuracy : 0.76304 \nEpoch: 3734  | Training Loss: 0.31570 \nEpoch: 3734  | Training Loss: 0.36792 \nEpoch: 3734  | Training Loss: 0.34576 \nEpoch: 3734  | Training Loss: 0.21262 \nEpoch: 3734  | Training Loss: 0.14870 \nEpoch: 3734  | Validation balanced accuracy : 0.76304 \nEpoch: 3735  | Training Loss: 0.31581 \nEpoch: 3735  | Training Loss: 0.36801 \nEpoch: 3735  | Training Loss: 0.34571 \nEpoch: 3735  | Training Loss: 0.21263 \nEpoch: 3735  | Training Loss: 0.14852 \nEpoch: 3735  | Validation balanced accuracy : 0.76304 \nEpoch: 3736  | Training Loss: 0.31595 \nEpoch: 3736  | Training Loss: 0.36805 \nEpoch: 3736  | Training Loss: 0.34571 \nEpoch: 3736  | Training Loss: 0.21262 \nEpoch: 3736  | Training Loss: 0.14868 \nEpoch: 3736  | Validation balanced accuracy : 0.76304 \nEpoch: 3737  | Training Loss: 0.31578 \nEpoch: 3737  | Training Loss: 0.36795 \nEpoch: 3737  | Training Loss: 0.34576 \nEpoch: 3737  | Training Loss: 0.21261 \nEpoch: 3737  | Training Loss: 0.14875 \nEpoch: 3737  | Validation balanced accuracy : 0.76304 \nEpoch: 3738  | Training Loss: 0.31576 \nEpoch: 3738  | Training Loss: 0.36795 \nEpoch: 3738  | Training Loss: 0.34575 \nEpoch: 3738  | Training Loss: 0.21262 \nEpoch: 3738  | Training Loss: 0.14867 \nEpoch: 3738  | Validation balanced accuracy : 0.76304 \nEpoch: 3739  | Training Loss: 0.31582 \nEpoch: 3739  | Training Loss: 0.36801 \nEpoch: 3739  | Training Loss: 0.34572 \nEpoch: 3739  | Training Loss: 0.21263 \nEpoch: 3739  | Training Loss: 0.14853 \nEpoch: 3739  | Validation balanced accuracy : 0.76304 \nEpoch: 3740  | Training Loss: 0.31593 \nEpoch: 3740  | Training Loss: 0.36803 \nEpoch: 3740  | Training Loss: 0.34574 \nEpoch: 3740  | Training Loss: 0.21261 \nEpoch: 3740  | Training Loss: 0.14874 \nEpoch: 3740  | Validation balanced accuracy : 0.76304 \nEpoch: 3741  | Training Loss: 0.31573 \nEpoch: 3741  | Training Loss: 0.36792 \nEpoch: 3741  | Training Loss: 0.34579 \nEpoch: 3741  | Training Loss: 0.21261 \nEpoch: 3741  | Training Loss: 0.14876 \nEpoch: 3741  | Validation balanced accuracy : 0.76304 \nEpoch: 3742  | Training Loss: 0.31575 \nEpoch: 3742  | Training Loss: 0.36796 \nEpoch: 3742  | Training Loss: 0.34576 \nEpoch: 3742  | Training Loss: 0.21261 \nEpoch: 3742  | Training Loss: 0.14863 \nEpoch: 3742  | Validation balanced accuracy : 0.76304 \nEpoch: 3743  | Training Loss: 0.31585 \nEpoch: 3743  | Training Loss: 0.36803 \nEpoch: 3743  | Training Loss: 0.34571 \nEpoch: 3743  | Training Loss: 0.21263 \nEpoch: 3743  | Training Loss: 0.14847 \nEpoch: 3743  | Validation balanced accuracy : 0.76304 \nEpoch: 3744  | Training Loss: 0.31597 \nEpoch: 3744  | Training Loss: 0.36806 \nEpoch: 3744  | Training Loss: 0.34573 \nEpoch: 3744  | Training Loss: 0.21261 \nEpoch: 3744  | Training Loss: 0.14871 \nEpoch: 3744  | Validation balanced accuracy : 0.76304 \nEpoch: 3745  | Training Loss: 0.31574 \nEpoch: 3745  | Training Loss: 0.36792 \nEpoch: 3745  | Training Loss: 0.34581 \nEpoch: 3745  | Training Loss: 0.21260 \nEpoch: 3745  | Training Loss: 0.14883 \nEpoch: 3745  | Validation balanced accuracy : 0.76304 \nEpoch: 3746  | Training Loss: 0.31569 \nEpoch: 3746  | Training Loss: 0.36791 \nEpoch: 3746  | Training Loss: 0.34580 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3746  | Training Loss: 0.21260 \nEpoch: 3746  | Training Loss: 0.14869 \nEpoch: 3746  | Validation balanced accuracy : 0.76304 \nEpoch: 3747  | Training Loss: 0.31581 \nEpoch: 3747  | Training Loss: 0.36801 \nEpoch: 3747  | Training Loss: 0.34574 \nEpoch: 3747  | Training Loss: 0.21262 \nEpoch: 3747  | Training Loss: 0.14848 \nEpoch: 3747  | Validation balanced accuracy : 0.76304 \nEpoch: 3748  | Training Loss: 0.31595 \nEpoch: 3748  | Training Loss: 0.36806 \nEpoch: 3748  | Training Loss: 0.34574 \nEpoch: 3748  | Training Loss: 0.21261 \nEpoch: 3748  | Training Loss: 0.14864 \nEpoch: 3748  | Validation balanced accuracy : 0.76304 \nEpoch: 3749  | Training Loss: 0.31579 \nEpoch: 3749  | Training Loss: 0.36796 \nEpoch: 3749  | Training Loss: 0.34579 \nEpoch: 3749  | Training Loss: 0.21260 \nEpoch: 3749  | Training Loss: 0.14870 \nEpoch: 3749  | Validation balanced accuracy : 0.76304 \nEpoch: 3750  | Training Loss: 0.31577 \nEpoch: 3750  | Training Loss: 0.36797 \nEpoch: 3750  | Training Loss: 0.34577 \nEpoch: 3750  | Training Loss: 0.21261 \nEpoch: 3750  | Training Loss: 0.14856 \nEpoch: 3750  | Validation balanced accuracy : 0.76304 \nEpoch: 3751  | Training Loss: 0.31589 \nEpoch: 3751  | Training Loss: 0.36806 \nEpoch: 3751  | Training Loss: 0.34571 \nEpoch: 3751  | Training Loss: 0.21262 \nEpoch: 3751  | Training Loss: 0.14839 \nEpoch: 3751  | Validation balanced accuracy : 0.76304 \nEpoch: 3752  | Training Loss: 0.31601 \nEpoch: 3752  | Training Loss: 0.36809 \nEpoch: 3752  | Training Loss: 0.34573 \nEpoch: 3752  | Training Loss: 0.21261 \nEpoch: 3752  | Training Loss: 0.14862 \nEpoch: 3752  | Validation balanced accuracy : 0.76304 \nEpoch: 3753  | Training Loss: 0.31579 \nEpoch: 3753  | Training Loss: 0.36796 \nEpoch: 3753  | Training Loss: 0.34580 \nEpoch: 3753  | Training Loss: 0.21259 \nEpoch: 3753  | Training Loss: 0.14873 \nEpoch: 3753  | Validation balanced accuracy : 0.76304 \nEpoch: 3754  | Training Loss: 0.31574 \nEpoch: 3754  | Training Loss: 0.36795 \nEpoch: 3754  | Training Loss: 0.34579 \nEpoch: 3754  | Training Loss: 0.21260 \nEpoch: 3754  | Training Loss: 0.14861 \nEpoch: 3754  | Validation balanced accuracy : 0.76304 \nEpoch: 3755  | Training Loss: 0.31585 \nEpoch: 3755  | Training Loss: 0.36804 \nEpoch: 3755  | Training Loss: 0.34574 \nEpoch: 3755  | Training Loss: 0.21261 \nEpoch: 3755  | Training Loss: 0.14843 \nEpoch: 3755  | Validation balanced accuracy : 0.76304 \nEpoch: 3756  | Training Loss: 0.31598 \nEpoch: 3756  | Training Loss: 0.36807 \nEpoch: 3756  | Training Loss: 0.34576 \nEpoch: 3756  | Training Loss: 0.21260 \nEpoch: 3756  | Training Loss: 0.14866 \nEpoch: 3756  | Validation balanced accuracy : 0.76304 \nEpoch: 3757  | Training Loss: 0.31576 \nEpoch: 3757  | Training Loss: 0.36793 \nEpoch: 3757  | Training Loss: 0.34583 \nEpoch: 3757  | Training Loss: 0.21259 \nEpoch: 3757  | Training Loss: 0.14878 \nEpoch: 3757  | Validation balanced accuracy : 0.76304 \nEpoch: 3758  | Training Loss: 0.31571 \nEpoch: 3758  | Training Loss: 0.36792 \nEpoch: 3758  | Training Loss: 0.34582 \nEpoch: 3758  | Training Loss: 0.21259 \nEpoch: 3758  | Training Loss: 0.14864 \nEpoch: 3758  | Validation balanced accuracy : 0.76304 \nEpoch: 3759  | Training Loss: 0.31583 \nEpoch: 3759  | Training Loss: 0.36802 \nEpoch: 3759  | Training Loss: 0.34576 \nEpoch: 3759  | Training Loss: 0.21261 \nEpoch: 3759  | Training Loss: 0.14845 \nEpoch: 3759  | Validation balanced accuracy : 0.76304 \nEpoch: 3760  | Training Loss: 0.31596 \nEpoch: 3760  | Training Loss: 0.36807 \nEpoch: 3760  | Training Loss: 0.34576 \nEpoch: 3760  | Training Loss: 0.21260 \nEpoch: 3760  | Training Loss: 0.14861 \nEpoch: 3760  | Validation balanced accuracy : 0.76304 \nEpoch: 3761  | Training Loss: 0.31580 \nEpoch: 3761  | Training Loss: 0.36797 \nEpoch: 3761  | Training Loss: 0.34581 \nEpoch: 3761  | Training Loss: 0.21259 \nEpoch: 3761  | Training Loss: 0.14867 \nEpoch: 3761  | Validation balanced accuracy : 0.76304 \nEpoch: 3762  | Training Loss: 0.31578 \nEpoch: 3762  | Training Loss: 0.36798 \nEpoch: 3762  | Training Loss: 0.34579 \nEpoch: 3762  | Training Loss: 0.21260 \nEpoch: 3762  | Training Loss: 0.14853 \nEpoch: 3762  | Validation balanced accuracy : 0.76304 \nEpoch: 3763  | Training Loss: 0.31590 \nEpoch: 3763  | Training Loss: 0.36807 \nEpoch: 3763  | Training Loss: 0.34574 \nEpoch: 3763  | Training Loss: 0.21261 \nEpoch: 3763  | Training Loss: 0.14836 \nEpoch: 3763  | Validation balanced accuracy : 0.76304 \nEpoch: 3764  | Training Loss: 0.31602 \nEpoch: 3764  | Training Loss: 0.36810 \nEpoch: 3764  | Training Loss: 0.34575 \nEpoch: 3764  | Training Loss: 0.21260 \nEpoch: 3764  | Training Loss: 0.14856 \nEpoch: 3764  | Validation balanced accuracy : 0.76304 \nEpoch: 3765  | Training Loss: 0.31583 \nEpoch: 3765  | Training Loss: 0.36798 \nEpoch: 3765  | Training Loss: 0.34581 \nEpoch: 3765  | Training Loss: 0.21259 \nEpoch: 3765  | Training Loss: 0.14866 \nEpoch: 3765  | Validation balanced accuracy : 0.76304 \nEpoch: 3766  | Training Loss: 0.31578 \nEpoch: 3766  | Training Loss: 0.36798 \nEpoch: 3766  | Training Loss: 0.34580 \nEpoch: 3766  | Training Loss: 0.21259 \nEpoch: 3766  | Training Loss: 0.14854 \nEpoch: 3766  | Validation balanced accuracy : 0.76304 \nEpoch: 3767  | Training Loss: 0.31589 \nEpoch: 3767  | Training Loss: 0.36806 \nEpoch: 3767  | Training Loss: 0.34576 \nEpoch: 3767  | Training Loss: 0.21260 \nEpoch: 3767  | Training Loss: 0.14840 \nEpoch: 3767  | Validation balanced accuracy : 0.76304 \nEpoch: 3768  | Training Loss: 0.31598 \nEpoch: 3768  | Training Loss: 0.36807 \nEpoch: 3768  | Training Loss: 0.34578 \nEpoch: 3768  | Training Loss: 0.21259 \nEpoch: 3768  | Training Loss: 0.14862 \nEpoch: 3768  | Validation balanced accuracy : 0.76304 \nEpoch: 3769  | Training Loss: 0.31578 \nEpoch: 3769  | Training Loss: 0.36795 \nEpoch: 3769  | Training Loss: 0.34584 \nEpoch: 3769  | Training Loss: 0.21258 \nEpoch: 3769  | Training Loss: 0.14870 \nEpoch: 3769  | Validation balanced accuracy : 0.76304 \nEpoch: 3770  | Training Loss: 0.31575 \nEpoch: 3770  | Training Loss: 0.36796 \nEpoch: 3770  | Training Loss: 0.34582 \nEpoch: 3770  | Training Loss: 0.21259 \nEpoch: 3770  | Training Loss: 0.14856 \nEpoch: 3770  | Validation balanced accuracy : 0.76304 \nEpoch: 3771  | Training Loss: 0.31587 \nEpoch: 3771  | Training Loss: 0.36805 \nEpoch: 3771  | Training Loss: 0.34577 \nEpoch: 3771  | Training Loss: 0.21260 \nEpoch: 3771  | Training Loss: 0.14837 \nEpoch: 3771  | Validation balanced accuracy : 0.76304 \nEpoch: 3772  | Training Loss: 0.31600 \nEpoch: 3772  | Training Loss: 0.36809 \nEpoch: 3772  | Training Loss: 0.34578 \nEpoch: 3772  | Training Loss: 0.21259 \nEpoch: 3772  | Training Loss: 0.14855 \nEpoch: 3772  | Validation balanced accuracy : 0.76304 \nEpoch: 3773  | Training Loss: 0.31582 \nEpoch: 3773  | Training Loss: 0.36798 \nEpoch: 3773  | Training Loss: 0.34583 \nEpoch: 3773  | Training Loss: 0.21258 \nEpoch: 3773  | Training Loss: 0.14863 \nEpoch: 3773  | Validation balanced accuracy : 0.76304 \nEpoch: 3774  | Training Loss: 0.31579 \nEpoch: 3774  | Training Loss: 0.36799 \nEpoch: 3774  | Training Loss: 0.34582 \nEpoch: 3774  | Training Loss: 0.21259 \nEpoch: 3774  | Training Loss: 0.14851 \nEpoch: 3774  | Validation balanced accuracy : 0.76304 \nEpoch: 3775  | Training Loss: 0.31590 \nEpoch: 3775  | Training Loss: 0.36807 \nEpoch: 3775  | Training Loss: 0.34577 \nEpoch: 3775  | Training Loss: 0.21260 \nEpoch: 3775  | Training Loss: 0.14834 \nEpoch: 3775  | Validation balanced accuracy : 0.76304 \nEpoch: 3776  | Training Loss: 0.31602 \nEpoch: 3776  | Training Loss: 0.36810 \nEpoch: 3776  | Training Loss: 0.34578 \nEpoch: 3776  | Training Loss: 0.21259 \nEpoch: 3776  | Training Loss: 0.14854 \nEpoch: 3776  | Validation balanced accuracy : 0.76304 \nEpoch: 3777  | Training Loss: 0.31583 \nEpoch: 3777  | Training Loss: 0.36799 \nEpoch: 3777  | Training Loss: 0.34584 \nEpoch: 3777  | Training Loss: 0.21258 \nEpoch: 3777  | Training Loss: 0.14863 \nEpoch: 3777  | Validation balanced accuracy : 0.76304 \nEpoch: 3778  | Training Loss: 0.31579 \nEpoch: 3778  | Training Loss: 0.36798 \nEpoch: 3778  | Training Loss: 0.34583 \nEpoch: 3778  | Training Loss: 0.21258 \nEpoch: 3778  | Training Loss: 0.14851 \nEpoch: 3778  | Validation balanced accuracy : 0.76304 \nEpoch: 3779  | Training Loss: 0.31589 \nEpoch: 3779  | Training Loss: 0.36807 \nEpoch: 3779  | Training Loss: 0.34578 \nEpoch: 3779  | Training Loss: 0.21260 \nEpoch: 3779  | Training Loss: 0.14834 \nEpoch: 3779  | Validation balanced accuracy : 0.76304 \nEpoch: 3780  | Training Loss: 0.31601 \nEpoch: 3780  | Training Loss: 0.36809 \nEpoch: 3780  | Training Loss: 0.34579 \nEpoch: 3780  | Training Loss: 0.21258 \nEpoch: 3780  | Training Loss: 0.14857 \nEpoch: 3780  | Validation balanced accuracy : 0.76304 \nEpoch: 3781  | Training Loss: 0.31580 \nEpoch: 3781  | Training Loss: 0.36797 \nEpoch: 3781  | Training Loss: 0.34586 \nEpoch: 3781  | Training Loss: 0.21257 \nEpoch: 3781  | Training Loss: 0.14867 \nEpoch: 3781  | Validation balanced accuracy : 0.76304 \nEpoch: 3782  | Training Loss: 0.31576 \nEpoch: 3782  | Training Loss: 0.36796 \nEpoch: 3782  | Training Loss: 0.34585 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3782  | Training Loss: 0.21257 \nEpoch: 3782  | Training Loss: 0.14854 \nEpoch: 3782  | Validation balanced accuracy : 0.76304 \nEpoch: 3783  | Training Loss: 0.31587 \nEpoch: 3783  | Training Loss: 0.36805 \nEpoch: 3783  | Training Loss: 0.34579 \nEpoch: 3783  | Training Loss: 0.21259 \nEpoch: 3783  | Training Loss: 0.14836 \nEpoch: 3783  | Validation balanced accuracy : 0.76304 \nEpoch: 3784  | Training Loss: 0.31600 \nEpoch: 3784  | Training Loss: 0.36809 \nEpoch: 3784  | Training Loss: 0.34580 \nEpoch: 3784  | Training Loss: 0.21258 \nEpoch: 3784  | Training Loss: 0.14853 \nEpoch: 3784  | Validation balanced accuracy : 0.76304 \nEpoch: 3785  | Training Loss: 0.31582 \nEpoch: 3785  | Training Loss: 0.36799 \nEpoch: 3785  | Training Loss: 0.34585 \nEpoch: 3785  | Training Loss: 0.21257 \nEpoch: 3785  | Training Loss: 0.14861 \nEpoch: 3785  | Validation balanced accuracy : 0.76304 \nEpoch: 3786  | Training Loss: 0.31579 \nEpoch: 3786  | Training Loss: 0.36798 \nEpoch: 3786  | Training Loss: 0.34585 \nEpoch: 3786  | Training Loss: 0.21257 \nEpoch: 3786  | Training Loss: 0.14854 \nEpoch: 3786  | Validation balanced accuracy : 0.76304 \nEpoch: 3787  | Training Loss: 0.31586 \nEpoch: 3787  | Training Loss: 0.36804 \nEpoch: 3787  | Training Loss: 0.34582 \nEpoch: 3787  | Training Loss: 0.21258 \nEpoch: 3787  | Training Loss: 0.14840 \nEpoch: 3787  | Validation balanced accuracy : 0.76304 \nEpoch: 3788  | Training Loss: 0.31596 \nEpoch: 3788  | Training Loss: 0.36811 \nEpoch: 3788  | Training Loss: 0.34577 \nEpoch: 3788  | Training Loss: 0.21259 \nEpoch: 3788  | Training Loss: 0.14826 \nEpoch: 3788  | Validation balanced accuracy : 0.76304 \nEpoch: 3789  | Training Loss: 0.31605 \nEpoch: 3789  | Training Loss: 0.36813 \nEpoch: 3789  | Training Loss: 0.34580 \nEpoch: 3789  | Training Loss: 0.21258 \nEpoch: 3789  | Training Loss: 0.14854 \nEpoch: 3789  | Validation balanced accuracy : 0.76304 \nEpoch: 3790  | Training Loss: 0.31580 \nEpoch: 3790  | Training Loss: 0.36797 \nEpoch: 3790  | Training Loss: 0.34587 \nEpoch: 3790  | Training Loss: 0.21256 \nEpoch: 3790  | Training Loss: 0.14863 \nEpoch: 3790  | Validation balanced accuracy : 0.76304 \nEpoch: 3791  | Training Loss: 0.31577 \nEpoch: 3791  | Training Loss: 0.36798 \nEpoch: 3791  | Training Loss: 0.34586 \nEpoch: 3791  | Training Loss: 0.21257 \nEpoch: 3791  | Training Loss: 0.14849 \nEpoch: 3791  | Validation balanced accuracy : 0.76304 \nEpoch: 3792  | Training Loss: 0.31590 \nEpoch: 3792  | Training Loss: 0.36807 \nEpoch: 3792  | Training Loss: 0.34580 \nEpoch: 3792  | Training Loss: 0.21258 \nEpoch: 3792  | Training Loss: 0.14830 \nEpoch: 3792  | Validation balanced accuracy : 0.76304 \nEpoch: 3793  | Training Loss: 0.31603 \nEpoch: 3793  | Training Loss: 0.36810 \nEpoch: 3793  | Training Loss: 0.34582 \nEpoch: 3793  | Training Loss: 0.21257 \nEpoch: 3793  | Training Loss: 0.14852 \nEpoch: 3793  | Validation balanced accuracy : 0.76304 \nEpoch: 3794  | Training Loss: 0.31582 \nEpoch: 3794  | Training Loss: 0.36798 \nEpoch: 3794  | Training Loss: 0.34588 \nEpoch: 3794  | Training Loss: 0.21256 \nEpoch: 3794  | Training Loss: 0.14862 \nEpoch: 3794  | Validation balanced accuracy : 0.76304 \nEpoch: 3795  | Training Loss: 0.31577 \nEpoch: 3795  | Training Loss: 0.36798 \nEpoch: 3795  | Training Loss: 0.34587 \nEpoch: 3795  | Training Loss: 0.21256 \nEpoch: 3795  | Training Loss: 0.14850 \nEpoch: 3795  | Validation balanced accuracy : 0.76304 \nEpoch: 3796  | Training Loss: 0.31589 \nEpoch: 3796  | Training Loss: 0.36806 \nEpoch: 3796  | Training Loss: 0.34582 \nEpoch: 3796  | Training Loss: 0.21258 \nEpoch: 3796  | Training Loss: 0.14832 \nEpoch: 3796  | Validation balanced accuracy : 0.76304 \nEpoch: 3797  | Training Loss: 0.31601 \nEpoch: 3797  | Training Loss: 0.36810 \nEpoch: 3797  | Training Loss: 0.34582 \nEpoch: 3797  | Training Loss: 0.21257 \nEpoch: 3797  | Training Loss: 0.14850 \nEpoch: 3797  | Validation balanced accuracy : 0.76304 \nEpoch: 3798  | Training Loss: 0.31583 \nEpoch: 3798  | Training Loss: 0.36799 \nEpoch: 3798  | Training Loss: 0.34588 \nEpoch: 3798  | Training Loss: 0.21256 \nEpoch: 3798  | Training Loss: 0.14858 \nEpoch: 3798  | Validation balanced accuracy : 0.76304 \nEpoch: 3799  | Training Loss: 0.31580 \nEpoch: 3799  | Training Loss: 0.36800 \nEpoch: 3799  | Training Loss: 0.34586 \nEpoch: 3799  | Training Loss: 0.21256 \nEpoch: 3799  | Training Loss: 0.14845 \nEpoch: 3799  | Validation balanced accuracy : 0.76304 \nEpoch: 3800  | Training Loss: 0.31591 \nEpoch: 3800  | Training Loss: 0.36808 \nEpoch: 3800  | Training Loss: 0.34581 \nEpoch: 3800  | Training Loss: 0.21258 \nEpoch: 3800  | Training Loss: 0.14828 \nEpoch: 3800  | Validation balanced accuracy : 0.76304 \nEpoch: 3801  | Training Loss: 0.31603 \nEpoch: 3801  | Training Loss: 0.36811 \nEpoch: 3801  | Training Loss: 0.34582 \nEpoch: 3801  | Training Loss: 0.21257 \nEpoch: 3801  | Training Loss: 0.14847 \nEpoch: 3801  | Validation balanced accuracy : 0.76304 \nEpoch: 3802  | Training Loss: 0.31584 \nEpoch: 3802  | Training Loss: 0.36800 \nEpoch: 3802  | Training Loss: 0.34588 \nEpoch: 3802  | Training Loss: 0.21255 \nEpoch: 3802  | Training Loss: 0.14857 \nEpoch: 3802  | Validation balanced accuracy : 0.76304 \nEpoch: 3803  | Training Loss: 0.31580 \nEpoch: 3803  | Training Loss: 0.36800 \nEpoch: 3803  | Training Loss: 0.34587 \nEpoch: 3803  | Training Loss: 0.21256 \nEpoch: 3803  | Training Loss: 0.14844 \nEpoch: 3803  | Validation balanced accuracy : 0.76304 \nEpoch: 3804  | Training Loss: 0.31591 \nEpoch: 3804  | Training Loss: 0.36808 \nEpoch: 3804  | Training Loss: 0.34582 \nEpoch: 3804  | Training Loss: 0.21257 \nEpoch: 3804  | Training Loss: 0.14828 \nEpoch: 3804  | Validation balanced accuracy : 0.76304 \nEpoch: 3805  | Training Loss: 0.31603 \nEpoch: 3805  | Training Loss: 0.36811 \nEpoch: 3805  | Training Loss: 0.34583 \nEpoch: 3805  | Training Loss: 0.21256 \nEpoch: 3805  | Training Loss: 0.14847 \nEpoch: 3805  | Validation balanced accuracy : 0.76304 \nEpoch: 3806  | Training Loss: 0.31584 \nEpoch: 3806  | Training Loss: 0.36801 \nEpoch: 3806  | Training Loss: 0.34588 \nEpoch: 3806  | Training Loss: 0.21256 \nEpoch: 3806  | Training Loss: 0.14850 \nEpoch: 3806  | Validation balanced accuracy : 0.76304 \nEpoch: 3807  | Training Loss: 0.31585 \nEpoch: 3807  | Training Loss: 0.36803 \nEpoch: 3807  | Training Loss: 0.34586 \nEpoch: 3807  | Training Loss: 0.21256 \nEpoch: 3807  | Training Loss: 0.14840 \nEpoch: 3807  | Validation balanced accuracy : 0.76304 \nEpoch: 3808  | Training Loss: 0.31593 \nEpoch: 3808  | Training Loss: 0.36809 \nEpoch: 3808  | Training Loss: 0.34583 \nEpoch: 3808  | Training Loss: 0.21257 \nEpoch: 3808  | Training Loss: 0.14831 \nEpoch: 3808  | Validation balanced accuracy : 0.76304 \nEpoch: 3809  | Training Loss: 0.31599 \nEpoch: 3809  | Training Loss: 0.36808 \nEpoch: 3809  | Training Loss: 0.34586 \nEpoch: 3809  | Training Loss: 0.21255 \nEpoch: 3809  | Training Loss: 0.14854 \nEpoch: 3809  | Validation balanced accuracy : 0.76304 \nEpoch: 3810  | Training Loss: 0.31579 \nEpoch: 3810  | Training Loss: 0.36797 \nEpoch: 3810  | Training Loss: 0.34591 \nEpoch: 3810  | Training Loss: 0.21255 \nEpoch: 3810  | Training Loss: 0.14856 \nEpoch: 3810  | Validation balanced accuracy : 0.76304 \nEpoch: 3811  | Training Loss: 0.31581 \nEpoch: 3811  | Training Loss: 0.36801 \nEpoch: 3811  | Training Loss: 0.34588 \nEpoch: 3811  | Training Loss: 0.21256 \nEpoch: 3811  | Training Loss: 0.14838 \nEpoch: 3811  | Validation balanced accuracy : 0.76304 \nEpoch: 3812  | Training Loss: 0.31595 \nEpoch: 3812  | Training Loss: 0.36811 \nEpoch: 3812  | Training Loss: 0.34582 \nEpoch: 3812  | Training Loss: 0.21257 \nEpoch: 3812  | Training Loss: 0.14820 \nEpoch: 3812  | Validation balanced accuracy : 0.76304 \nEpoch: 3813  | Training Loss: 0.31608 \nEpoch: 3813  | Training Loss: 0.36815 \nEpoch: 3813  | Training Loss: 0.34583 \nEpoch: 3813  | Training Loss: 0.21256 \nEpoch: 3813  | Training Loss: 0.14845 \nEpoch: 3813  | Validation balanced accuracy : 0.76304 \nEpoch: 3814  | Training Loss: 0.31584 \nEpoch: 3814  | Training Loss: 0.36799 \nEpoch: 3814  | Training Loss: 0.34592 \nEpoch: 3814  | Training Loss: 0.21254 \nEpoch: 3814  | Training Loss: 0.14860 \nEpoch: 3814  | Validation balanced accuracy : 0.76304 \nEpoch: 3815  | Training Loss: 0.31577 \nEpoch: 3815  | Training Loss: 0.36797 \nEpoch: 3815  | Training Loss: 0.34591 \nEpoch: 3815  | Training Loss: 0.21254 \nEpoch: 3815  | Training Loss: 0.14849 \nEpoch: 3815  | Validation balanced accuracy : 0.76304 \nEpoch: 3816  | Training Loss: 0.31587 \nEpoch: 3816  | Training Loss: 0.36805 \nEpoch: 3816  | Training Loss: 0.34586 \nEpoch: 3816  | Training Loss: 0.21256 \nEpoch: 3816  | Training Loss: 0.14831 \nEpoch: 3816  | Validation balanced accuracy : 0.76304 \nEpoch: 3817  | Training Loss: 0.31599 \nEpoch: 3817  | Training Loss: 0.36809 \nEpoch: 3817  | Training Loss: 0.34587 \nEpoch: 3817  | Training Loss: 0.21255 \nEpoch: 3817  | Training Loss: 0.14848 \nEpoch: 3817  | Validation balanced accuracy : 0.76304 \nEpoch: 3818  | Training Loss: 0.31583 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3818  | Training Loss: 0.36800 \nEpoch: 3818  | Training Loss: 0.34591 \nEpoch: 3818  | Training Loss: 0.21254 \nEpoch: 3818  | Training Loss: 0.14848 \nEpoch: 3818  | Validation balanced accuracy : 0.76304 \nEpoch: 3819  | Training Loss: 0.31586 \nEpoch: 3819  | Training Loss: 0.36803 \nEpoch: 3819  | Training Loss: 0.34588 \nEpoch: 3819  | Training Loss: 0.21255 \nEpoch: 3819  | Training Loss: 0.14837 \nEpoch: 3819  | Validation balanced accuracy : 0.76304 \nEpoch: 3820  | Training Loss: 0.31594 \nEpoch: 3820  | Training Loss: 0.36810 \nEpoch: 3820  | Training Loss: 0.34584 \nEpoch: 3820  | Training Loss: 0.21256 \nEpoch: 3820  | Training Loss: 0.14823 \nEpoch: 3820  | Validation balanced accuracy : 0.76304 \nEpoch: 3821  | Training Loss: 0.31604 \nEpoch: 3821  | Training Loss: 0.36811 \nEpoch: 3821  | Training Loss: 0.34587 \nEpoch: 3821  | Training Loss: 0.21255 \nEpoch: 3821  | Training Loss: 0.14847 \nEpoch: 3821  | Validation balanced accuracy : 0.76304 \nEpoch: 3822  | Training Loss: 0.31582 \nEpoch: 3822  | Training Loss: 0.36799 \nEpoch: 3822  | Training Loss: 0.34593 \nEpoch: 3822  | Training Loss: 0.21254 \nEpoch: 3822  | Training Loss: 0.14853 \nEpoch: 3822  | Validation balanced accuracy : 0.76304 \nEpoch: 3823  | Training Loss: 0.31582 \nEpoch: 3823  | Training Loss: 0.36801 \nEpoch: 3823  | Training Loss: 0.34590 \nEpoch: 3823  | Training Loss: 0.21255 \nEpoch: 3823  | Training Loss: 0.14836 \nEpoch: 3823  | Validation balanced accuracy : 0.76304 \nEpoch: 3824  | Training Loss: 0.31595 \nEpoch: 3824  | Training Loss: 0.36811 \nEpoch: 3824  | Training Loss: 0.34584 \nEpoch: 3824  | Training Loss: 0.21256 \nEpoch: 3824  | Training Loss: 0.14818 \nEpoch: 3824  | Validation balanced accuracy : 0.76304 \nEpoch: 3825  | Training Loss: 0.31607 \nEpoch: 3825  | Training Loss: 0.36814 \nEpoch: 3825  | Training Loss: 0.34586 \nEpoch: 3825  | Training Loss: 0.21255 \nEpoch: 3825  | Training Loss: 0.14843 \nEpoch: 3825  | Validation balanced accuracy : 0.76304 \nEpoch: 3826  | Training Loss: 0.31584 \nEpoch: 3826  | Training Loss: 0.36799 \nEpoch: 3826  | Training Loss: 0.34594 \nEpoch: 3826  | Training Loss: 0.21253 \nEpoch: 3826  | Training Loss: 0.14858 \nEpoch: 3826  | Validation balanced accuracy : 0.76304 \nEpoch: 3827  | Training Loss: 0.31577 \nEpoch: 3827  | Training Loss: 0.36797 \nEpoch: 3827  | Training Loss: 0.34594 \nEpoch: 3827  | Training Loss: 0.21253 \nEpoch: 3827  | Training Loss: 0.14847 \nEpoch: 3827  | Validation balanced accuracy : 0.76304 \nEpoch: 3828  | Training Loss: 0.31587 \nEpoch: 3828  | Training Loss: 0.36805 \nEpoch: 3828  | Training Loss: 0.34589 \nEpoch: 3828  | Training Loss: 0.21255 \nEpoch: 3828  | Training Loss: 0.14828 \nEpoch: 3828  | Validation balanced accuracy : 0.76304 \nEpoch: 3829  | Training Loss: 0.31600 \nEpoch: 3829  | Training Loss: 0.36815 \nEpoch: 3829  | Training Loss: 0.34584 \nEpoch: 3829  | Training Loss: 0.21256 \nEpoch: 3829  | Training Loss: 0.14817 \nEpoch: 3829  | Validation balanced accuracy : 0.76304 \nEpoch: 3830  | Training Loss: 0.31606 \nEpoch: 3830  | Training Loss: 0.36813 \nEpoch: 3830  | Training Loss: 0.34588 \nEpoch: 3830  | Training Loss: 0.21254 \nEpoch: 3830  | Training Loss: 0.14844 \nEpoch: 3830  | Validation balanced accuracy : 0.76304 \nEpoch: 3831  | Training Loss: 0.31583 \nEpoch: 3831  | Training Loss: 0.36800 \nEpoch: 3831  | Training Loss: 0.34594 \nEpoch: 3831  | Training Loss: 0.21253 \nEpoch: 3831  | Training Loss: 0.14850 \nEpoch: 3831  | Validation balanced accuracy : 0.76304 \nEpoch: 3832  | Training Loss: 0.31582 \nEpoch: 3832  | Training Loss: 0.36802 \nEpoch: 3832  | Training Loss: 0.34592 \nEpoch: 3832  | Training Loss: 0.21254 \nEpoch: 3832  | Training Loss: 0.14835 \nEpoch: 3832  | Validation balanced accuracy : 0.76304 \nEpoch: 3833  | Training Loss: 0.31595 \nEpoch: 3833  | Training Loss: 0.36811 \nEpoch: 3833  | Training Loss: 0.34586 \nEpoch: 3833  | Training Loss: 0.21255 \nEpoch: 3833  | Training Loss: 0.14817 \nEpoch: 3833  | Validation balanced accuracy : 0.76304 \nEpoch: 3834  | Training Loss: 0.31607 \nEpoch: 3834  | Training Loss: 0.36814 \nEpoch: 3834  | Training Loss: 0.34588 \nEpoch: 3834  | Training Loss: 0.21254 \nEpoch: 3834  | Training Loss: 0.14840 \nEpoch: 3834  | Validation balanced accuracy : 0.76304 \nEpoch: 3835  | Training Loss: 0.31586 \nEpoch: 3835  | Training Loss: 0.36801 \nEpoch: 3835  | Training Loss: 0.34595 \nEpoch: 3835  | Training Loss: 0.21253 \nEpoch: 3835  | Training Loss: 0.14852 \nEpoch: 3835  | Validation balanced accuracy : 0.76304 \nEpoch: 3836  | Training Loss: 0.31580 \nEpoch: 3836  | Training Loss: 0.36800 \nEpoch: 3836  | Training Loss: 0.34594 \nEpoch: 3836  | Training Loss: 0.21253 \nEpoch: 3836  | Training Loss: 0.14840 \nEpoch: 3836  | Validation balanced accuracy : 0.76304 \nEpoch: 3837  | Training Loss: 0.31591 \nEpoch: 3837  | Training Loss: 0.36808 \nEpoch: 3837  | Training Loss: 0.34589 \nEpoch: 3837  | Training Loss: 0.21255 \nEpoch: 3837  | Training Loss: 0.14823 \nEpoch: 3837  | Validation balanced accuracy : 0.76304 \nEpoch: 3838  | Training Loss: 0.31603 \nEpoch: 3838  | Training Loss: 0.36811 \nEpoch: 3838  | Training Loss: 0.34590 \nEpoch: 3838  | Training Loss: 0.21253 \nEpoch: 3838  | Training Loss: 0.14841 \nEpoch: 3838  | Validation balanced accuracy : 0.76304 \nEpoch: 3839  | Training Loss: 0.31585 \nEpoch: 3839  | Training Loss: 0.36801 \nEpoch: 3839  | Training Loss: 0.34595 \nEpoch: 3839  | Training Loss: 0.21252 \nEpoch: 3839  | Training Loss: 0.14849 \nEpoch: 3839  | Validation balanced accuracy : 0.76304 \nEpoch: 3840  | Training Loss: 0.31582 \nEpoch: 3840  | Training Loss: 0.36801 \nEpoch: 3840  | Training Loss: 0.34594 \nEpoch: 3840  | Training Loss: 0.21253 \nEpoch: 3840  | Training Loss: 0.14835 \nEpoch: 3840  | Validation balanced accuracy : 0.76304 \nEpoch: 3841  | Training Loss: 0.31594 \nEpoch: 3841  | Training Loss: 0.36810 \nEpoch: 3841  | Training Loss: 0.34588 \nEpoch: 3841  | Training Loss: 0.21255 \nEpoch: 3841  | Training Loss: 0.14818 \nEpoch: 3841  | Validation balanced accuracy : 0.76304 \nEpoch: 3842  | Training Loss: 0.31606 \nEpoch: 3842  | Training Loss: 0.36813 \nEpoch: 3842  | Training Loss: 0.34590 \nEpoch: 3842  | Training Loss: 0.21253 \nEpoch: 3842  | Training Loss: 0.14838 \nEpoch: 3842  | Validation balanced accuracy : 0.76304 \nEpoch: 3843  | Training Loss: 0.31587 \nEpoch: 3843  | Training Loss: 0.36802 \nEpoch: 3843  | Training Loss: 0.34595 \nEpoch: 3843  | Training Loss: 0.21252 \nEpoch: 3843  | Training Loss: 0.14847 \nEpoch: 3843  | Validation balanced accuracy : 0.76304 \nEpoch: 3844  | Training Loss: 0.31583 \nEpoch: 3844  | Training Loss: 0.36802 \nEpoch: 3844  | Training Loss: 0.34594 \nEpoch: 3844  | Training Loss: 0.21253 \nEpoch: 3844  | Training Loss: 0.14834 \nEpoch: 3844  | Validation balanced accuracy : 0.76304 \nEpoch: 3845  | Training Loss: 0.31594 \nEpoch: 3845  | Training Loss: 0.36810 \nEpoch: 3845  | Training Loss: 0.34589 \nEpoch: 3845  | Training Loss: 0.21254 \nEpoch: 3845  | Training Loss: 0.14818 \nEpoch: 3845  | Validation balanced accuracy : 0.76304 \nEpoch: 3846  | Training Loss: 0.31605 \nEpoch: 3846  | Training Loss: 0.36813 \nEpoch: 3846  | Training Loss: 0.34590 \nEpoch: 3846  | Training Loss: 0.21253 \nEpoch: 3846  | Training Loss: 0.14838 \nEpoch: 3846  | Validation balanced accuracy : 0.76304 \nEpoch: 3847  | Training Loss: 0.31587 \nEpoch: 3847  | Training Loss: 0.36803 \nEpoch: 3847  | Training Loss: 0.34595 \nEpoch: 3847  | Training Loss: 0.21252 \nEpoch: 3847  | Training Loss: 0.14840 \nEpoch: 3847  | Validation balanced accuracy : 0.76304 \nEpoch: 3848  | Training Loss: 0.31588 \nEpoch: 3848  | Training Loss: 0.36806 \nEpoch: 3848  | Training Loss: 0.34592 \nEpoch: 3848  | Training Loss: 0.21253 \nEpoch: 3848  | Training Loss: 0.14825 \nEpoch: 3848  | Validation balanced accuracy : 0.76304 \nEpoch: 3849  | Training Loss: 0.31600 \nEpoch: 3849  | Training Loss: 0.36815 \nEpoch: 3849  | Training Loss: 0.34587 \nEpoch: 3849  | Training Loss: 0.21255 \nEpoch: 3849  | Training Loss: 0.14809 \nEpoch: 3849  | Validation balanced accuracy : 0.76304 \nEpoch: 3850  | Training Loss: 0.31611 \nEpoch: 3850  | Training Loss: 0.36817 \nEpoch: 3850  | Training Loss: 0.34589 \nEpoch: 3850  | Training Loss: 0.21253 \nEpoch: 3850  | Training Loss: 0.14834 \nEpoch: 3850  | Validation balanced accuracy : 0.76304 \nEpoch: 3851  | Training Loss: 0.31588 \nEpoch: 3851  | Training Loss: 0.36802 \nEpoch: 3851  | Training Loss: 0.34597 \nEpoch: 3851  | Training Loss: 0.21251 \nEpoch: 3851  | Training Loss: 0.14848 \nEpoch: 3851  | Validation balanced accuracy : 0.76304 \nEpoch: 3852  | Training Loss: 0.31581 \nEpoch: 3852  | Training Loss: 0.36800 \nEpoch: 3852  | Training Loss: 0.34597 \nEpoch: 3852  | Training Loss: 0.21252 \nEpoch: 3852  | Training Loss: 0.14837 \nEpoch: 3852  | Validation balanced accuracy : 0.76304 \nEpoch: 3853  | Training Loss: 0.31591 \nEpoch: 3853  | Training Loss: 0.36808 \nEpoch: 3853  | Training Loss: 0.34592 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3853  | Training Loss: 0.21253 \nEpoch: 3853  | Training Loss: 0.14821 \nEpoch: 3853  | Validation balanced accuracy : 0.76304 \nEpoch: 3854  | Training Loss: 0.31602 \nEpoch: 3854  | Training Loss: 0.36817 \nEpoch: 3854  | Training Loss: 0.34587 \nEpoch: 3854  | Training Loss: 0.21254 \nEpoch: 3854  | Training Loss: 0.14811 \nEpoch: 3854  | Validation balanced accuracy : 0.76304 \nEpoch: 3855  | Training Loss: 0.31608 \nEpoch: 3855  | Training Loss: 0.36814 \nEpoch: 3855  | Training Loss: 0.34592 \nEpoch: 3855  | Training Loss: 0.21252 \nEpoch: 3855  | Training Loss: 0.14839 \nEpoch: 3855  | Validation balanced accuracy : 0.76304 \nEpoch: 3856  | Training Loss: 0.31584 \nEpoch: 3856  | Training Loss: 0.36801 \nEpoch: 3856  | Training Loss: 0.34598 \nEpoch: 3856  | Training Loss: 0.21251 \nEpoch: 3856  | Training Loss: 0.14845 \nEpoch: 3856  | Validation balanced accuracy : 0.76304 \nEpoch: 3857  | Training Loss: 0.31583 \nEpoch: 3857  | Training Loss: 0.36803 \nEpoch: 3857  | Training Loss: 0.34596 \nEpoch: 3857  | Training Loss: 0.21252 \nEpoch: 3857  | Training Loss: 0.14830 \nEpoch: 3857  | Validation balanced accuracy : 0.76304 \nEpoch: 3858  | Training Loss: 0.31596 \nEpoch: 3858  | Training Loss: 0.36812 \nEpoch: 3858  | Training Loss: 0.34590 \nEpoch: 3858  | Training Loss: 0.21253 \nEpoch: 3858  | Training Loss: 0.14812 \nEpoch: 3858  | Validation balanced accuracy : 0.76304 \nEpoch: 3859  | Training Loss: 0.31608 \nEpoch: 3859  | Training Loss: 0.36816 \nEpoch: 3859  | Training Loss: 0.34591 \nEpoch: 3859  | Training Loss: 0.21252 \nEpoch: 3859  | Training Loss: 0.14832 \nEpoch: 3859  | Validation balanced accuracy : 0.76304 \nEpoch: 3860  | Training Loss: 0.31589 \nEpoch: 3860  | Training Loss: 0.36804 \nEpoch: 3860  | Training Loss: 0.34597 \nEpoch: 3860  | Training Loss: 0.21251 \nEpoch: 3860  | Training Loss: 0.14842 \nEpoch: 3860  | Validation balanced accuracy : 0.76304 \nEpoch: 3861  | Training Loss: 0.31585 \nEpoch: 3861  | Training Loss: 0.36803 \nEpoch: 3861  | Training Loss: 0.34596 \nEpoch: 3861  | Training Loss: 0.21252 \nEpoch: 3861  | Training Loss: 0.14830 \nEpoch: 3861  | Validation balanced accuracy : 0.76304 \nEpoch: 3862  | Training Loss: 0.31595 \nEpoch: 3862  | Training Loss: 0.36811 \nEpoch: 3862  | Training Loss: 0.34591 \nEpoch: 3862  | Training Loss: 0.21253 \nEpoch: 3862  | Training Loss: 0.14814 \nEpoch: 3862  | Validation balanced accuracy : 0.76304 \nEpoch: 3863  | Training Loss: 0.31606 \nEpoch: 3863  | Training Loss: 0.36814 \nEpoch: 3863  | Training Loss: 0.34593 \nEpoch: 3863  | Training Loss: 0.21252 \nEpoch: 3863  | Training Loss: 0.14836 \nEpoch: 3863  | Validation balanced accuracy : 0.76304 \nEpoch: 3864  | Training Loss: 0.31586 \nEpoch: 3864  | Training Loss: 0.36803 \nEpoch: 3864  | Training Loss: 0.34598 \nEpoch: 3864  | Training Loss: 0.21251 \nEpoch: 3864  | Training Loss: 0.14840 \nEpoch: 3864  | Validation balanced accuracy : 0.76304 \nEpoch: 3865  | Training Loss: 0.31587 \nEpoch: 3865  | Training Loss: 0.36805 \nEpoch: 3865  | Training Loss: 0.34595 \nEpoch: 3865  | Training Loss: 0.21252 \nEpoch: 3865  | Training Loss: 0.14824 \nEpoch: 3865  | Validation balanced accuracy : 0.76304 \nEpoch: 3866  | Training Loss: 0.31600 \nEpoch: 3866  | Training Loss: 0.36815 \nEpoch: 3866  | Training Loss: 0.34590 \nEpoch: 3866  | Training Loss: 0.21253 \nEpoch: 3866  | Training Loss: 0.14807 \nEpoch: 3866  | Validation balanced accuracy : 0.76304 \nEpoch: 3867  | Training Loss: 0.31611 \nEpoch: 3867  | Training Loss: 0.36818 \nEpoch: 3867  | Training Loss: 0.34591 \nEpoch: 3867  | Training Loss: 0.21252 \nEpoch: 3867  | Training Loss: 0.14828 \nEpoch: 3867  | Validation balanced accuracy : 0.76304 \nEpoch: 3868  | Training Loss: 0.31591 \nEpoch: 3868  | Training Loss: 0.36805 \nEpoch: 3868  | Training Loss: 0.34598 \nEpoch: 3868  | Training Loss: 0.21251 \nEpoch: 3868  | Training Loss: 0.14839 \nEpoch: 3868  | Validation balanced accuracy : 0.76304 \nEpoch: 3869  | Training Loss: 0.31585 \nEpoch: 3869  | Training Loss: 0.36804 \nEpoch: 3869  | Training Loss: 0.34597 \nEpoch: 3869  | Training Loss: 0.21251 \nEpoch: 3869  | Training Loss: 0.14829 \nEpoch: 3869  | Validation balanced accuracy : 0.76304 \nEpoch: 3870  | Training Loss: 0.31595 \nEpoch: 3870  | Training Loss: 0.36811 \nEpoch: 3870  | Training Loss: 0.34593 \nEpoch: 3870  | Training Loss: 0.21252 \nEpoch: 3870  | Training Loss: 0.14814 \nEpoch: 3870  | Validation balanced accuracy : 0.76304 \nEpoch: 3871  | Training Loss: 0.31606 \nEpoch: 3871  | Training Loss: 0.36814 \nEpoch: 3871  | Training Loss: 0.34594 \nEpoch: 3871  | Training Loss: 0.21251 \nEpoch: 3871  | Training Loss: 0.14834 \nEpoch: 3871  | Validation balanced accuracy : 0.76304 \nEpoch: 3872  | Training Loss: 0.31587 \nEpoch: 3872  | Training Loss: 0.36804 \nEpoch: 3872  | Training Loss: 0.34599 \nEpoch: 3872  | Training Loss: 0.21250 \nEpoch: 3872  | Training Loss: 0.14836 \nEpoch: 3872  | Validation balanced accuracy : 0.76304 \nEpoch: 3873  | Training Loss: 0.31588 \nEpoch: 3873  | Training Loss: 0.36807 \nEpoch: 3873  | Training Loss: 0.34596 \nEpoch: 3873  | Training Loss: 0.21251 \nEpoch: 3873  | Training Loss: 0.14820 \nEpoch: 3873  | Validation balanced accuracy : 0.76304 \nEpoch: 3874  | Training Loss: 0.31601 \nEpoch: 3874  | Training Loss: 0.36816 \nEpoch: 3874  | Training Loss: 0.34591 \nEpoch: 3874  | Training Loss: 0.21253 \nEpoch: 3874  | Training Loss: 0.14807 \nEpoch: 3874  | Validation balanced accuracy : 0.76304 \nEpoch: 3875  | Training Loss: 0.31610 \nEpoch: 3875  | Training Loss: 0.36816 \nEpoch: 3875  | Training Loss: 0.34594 \nEpoch: 3875  | Training Loss: 0.21251 \nEpoch: 3875  | Training Loss: 0.14830 \nEpoch: 3875  | Validation balanced accuracy : 0.76304 \nEpoch: 3876  | Training Loss: 0.31589 \nEpoch: 3876  | Training Loss: 0.36803 \nEpoch: 3876  | Training Loss: 0.34600 \nEpoch: 3876  | Training Loss: 0.21250 \nEpoch: 3876  | Training Loss: 0.14842 \nEpoch: 3876  | Validation balanced accuracy : 0.76304 \nEpoch: 3877  | Training Loss: 0.31583 \nEpoch: 3877  | Training Loss: 0.36802 \nEpoch: 3877  | Training Loss: 0.34600 \nEpoch: 3877  | Training Loss: 0.21250 \nEpoch: 3877  | Training Loss: 0.14830 \nEpoch: 3877  | Validation balanced accuracy : 0.76304 \nEpoch: 3878  | Training Loss: 0.31593 \nEpoch: 3878  | Training Loss: 0.36810 \nEpoch: 3878  | Training Loss: 0.34595 \nEpoch: 3878  | Training Loss: 0.21252 \nEpoch: 3878  | Training Loss: 0.14814 \nEpoch: 3878  | Validation balanced accuracy : 0.76304 \nEpoch: 3879  | Training Loss: 0.31605 \nEpoch: 3879  | Training Loss: 0.36814 \nEpoch: 3879  | Training Loss: 0.34596 \nEpoch: 3879  | Training Loss: 0.21250 \nEpoch: 3879  | Training Loss: 0.14832 \nEpoch: 3879  | Validation balanced accuracy : 0.76304 \nEpoch: 3880  | Training Loss: 0.31587 \nEpoch: 3880  | Training Loss: 0.36804 \nEpoch: 3880  | Training Loss: 0.34600 \nEpoch: 3880  | Training Loss: 0.21250 \nEpoch: 3880  | Training Loss: 0.14834 \nEpoch: 3880  | Validation balanced accuracy : 0.76304 \nEpoch: 3881  | Training Loss: 0.31589 \nEpoch: 3881  | Training Loss: 0.36807 \nEpoch: 3881  | Training Loss: 0.34598 \nEpoch: 3881  | Training Loss: 0.21250 \nEpoch: 3881  | Training Loss: 0.14824 \nEpoch: 3881  | Validation balanced accuracy : 0.76304 \nEpoch: 3882  | Training Loss: 0.31597 \nEpoch: 3882  | Training Loss: 0.36813 \nEpoch: 3882  | Training Loss: 0.34594 \nEpoch: 3882  | Training Loss: 0.21252 \nEpoch: 3882  | Training Loss: 0.14810 \nEpoch: 3882  | Validation balanced accuracy : 0.76304 \nEpoch: 3883  | Training Loss: 0.31607 \nEpoch: 3883  | Training Loss: 0.36814 \nEpoch: 3883  | Training Loss: 0.34596 \nEpoch: 3883  | Training Loss: 0.21250 \nEpoch: 3883  | Training Loss: 0.14832 \nEpoch: 3883  | Validation balanced accuracy : 0.76304 \nEpoch: 3884  | Training Loss: 0.31587 \nEpoch: 3884  | Training Loss: 0.36803 \nEpoch: 3884  | Training Loss: 0.34601 \nEpoch: 3884  | Training Loss: 0.21249 \nEpoch: 3884  | Training Loss: 0.14835 \nEpoch: 3884  | Validation balanced accuracy : 0.76304 \nEpoch: 3885  | Training Loss: 0.31588 \nEpoch: 3885  | Training Loss: 0.36806 \nEpoch: 3885  | Training Loss: 0.34598 \nEpoch: 3885  | Training Loss: 0.21250 \nEpoch: 3885  | Training Loss: 0.14819 \nEpoch: 3885  | Validation balanced accuracy : 0.76304 \nEpoch: 3886  | Training Loss: 0.31601 \nEpoch: 3886  | Training Loss: 0.36816 \nEpoch: 3886  | Training Loss: 0.34593 \nEpoch: 3886  | Training Loss: 0.21252 \nEpoch: 3886  | Training Loss: 0.14802 \nEpoch: 3886  | Validation balanced accuracy : 0.76304 \nEpoch: 3887  | Training Loss: 0.31613 \nEpoch: 3887  | Training Loss: 0.36819 \nEpoch: 3887  | Training Loss: 0.34594 \nEpoch: 3887  | Training Loss: 0.21251 \nEpoch: 3887  | Training Loss: 0.14824 \nEpoch: 3887  | Validation balanced accuracy : 0.76304 \nEpoch: 3888  | Training Loss: 0.31592 \nEpoch: 3888  | Training Loss: 0.36806 \nEpoch: 3888  | Training Loss: 0.34601 \nEpoch: 3888  | Training Loss: 0.21249 \nEpoch: 3888  | Training Loss: 0.14835 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3888  | Validation balanced accuracy : 0.76304 \nEpoch: 3889  | Training Loss: 0.31587 \nEpoch: 3889  | Training Loss: 0.36805 \nEpoch: 3889  | Training Loss: 0.34600 \nEpoch: 3889  | Training Loss: 0.21250 \nEpoch: 3889  | Training Loss: 0.14825 \nEpoch: 3889  | Validation balanced accuracy : 0.76304 \nEpoch: 3890  | Training Loss: 0.31596 \nEpoch: 3890  | Training Loss: 0.36812 \nEpoch: 3890  | Training Loss: 0.34596 \nEpoch: 3890  | Training Loss: 0.21251 \nEpoch: 3890  | Training Loss: 0.14813 \nEpoch: 3890  | Validation balanced accuracy : 0.76304 \nEpoch: 3891  | Training Loss: 0.31604 \nEpoch: 3891  | Training Loss: 0.36818 \nEpoch: 3891  | Training Loss: 0.34593 \nEpoch: 3891  | Training Loss: 0.21252 \nEpoch: 3891  | Training Loss: 0.14802 \nEpoch: 3891  | Validation balanced accuracy : 0.76304 \nEpoch: 3892  | Training Loss: 0.31612 \nEpoch: 3892  | Training Loss: 0.36818 \nEpoch: 3892  | Training Loss: 0.34596 \nEpoch: 3892  | Training Loss: 0.21250 \nEpoch: 3892  | Training Loss: 0.14826 \nEpoch: 3892  | Validation balanced accuracy : 0.76304 \nEpoch: 3893  | Training Loss: 0.31590 \nEpoch: 3893  | Training Loss: 0.36804 \nEpoch: 3893  | Training Loss: 0.34603 \nEpoch: 3893  | Training Loss: 0.21248 \nEpoch: 3893  | Training Loss: 0.14839 \nEpoch: 3893  | Validation balanced accuracy : 0.76304 \nEpoch: 3894  | Training Loss: 0.31584 \nEpoch: 3894  | Training Loss: 0.36803 \nEpoch: 3894  | Training Loss: 0.34602 \nEpoch: 3894  | Training Loss: 0.21249 \nEpoch: 3894  | Training Loss: 0.14828 \nEpoch: 3894  | Validation balanced accuracy : 0.76304 \nEpoch: 3895  | Training Loss: 0.31594 \nEpoch: 3895  | Training Loss: 0.36811 \nEpoch: 3895  | Training Loss: 0.34597 \nEpoch: 3895  | Training Loss: 0.21250 \nEpoch: 3895  | Training Loss: 0.14811 \nEpoch: 3895  | Validation balanced accuracy : 0.76304 \nEpoch: 3896  | Training Loss: 0.31605 \nEpoch: 3896  | Training Loss: 0.36814 \nEpoch: 3896  | Training Loss: 0.34598 \nEpoch: 3896  | Training Loss: 0.21249 \nEpoch: 3896  | Training Loss: 0.14829 \nEpoch: 3896  | Validation balanced accuracy : 0.76304 \nEpoch: 3897  | Training Loss: 0.31588 \nEpoch: 3897  | Training Loss: 0.36804 \nEpoch: 3897  | Training Loss: 0.34602 \nEpoch: 3897  | Training Loss: 0.21249 \nEpoch: 3897  | Training Loss: 0.14831 \nEpoch: 3897  | Validation balanced accuracy : 0.76304 \nEpoch: 3898  | Training Loss: 0.31590 \nEpoch: 3898  | Training Loss: 0.36808 \nEpoch: 3898  | Training Loss: 0.34599 \nEpoch: 3898  | Training Loss: 0.21250 \nEpoch: 3898  | Training Loss: 0.14814 \nEpoch: 3898  | Validation balanced accuracy : 0.76304 \nEpoch: 3899  | Training Loss: 0.31603 \nEpoch: 3899  | Training Loss: 0.36818 \nEpoch: 3899  | Training Loss: 0.34594 \nEpoch: 3899  | Training Loss: 0.21251 \nEpoch: 3899  | Training Loss: 0.14798 \nEpoch: 3899  | Validation balanced accuracy : 0.76304 \nEpoch: 3900  | Training Loss: 0.31615 \nEpoch: 3900  | Training Loss: 0.36820 \nEpoch: 3900  | Training Loss: 0.34596 \nEpoch: 3900  | Training Loss: 0.21250 \nEpoch: 3900  | Training Loss: 0.14825 \nEpoch: 3900  | Validation balanced accuracy : 0.76304 \nEpoch: 3901  | Training Loss: 0.31589 \nEpoch: 3901  | Training Loss: 0.36804 \nEpoch: 3901  | Training Loss: 0.34599 \nEpoch: 3901  | Training Loss: 0.21250 \nEpoch: 3901  | Training Loss: 0.14812 \nEpoch: 3901  | Validation balanced accuracy : 0.76304 \nEpoch: 3902  | Training Loss: 0.31585 \nEpoch: 3902  | Training Loss: 0.36804 \nEpoch: 3902  | Training Loss: 0.34599 \nEpoch: 3902  | Training Loss: 0.21250 \nEpoch: 3902  | Training Loss: 0.14803 \nEpoch: 3902  | Validation balanced accuracy : 0.76304 \nEpoch: 3903  | Training Loss: 0.31593 \nEpoch: 3903  | Training Loss: 0.36809 \nEpoch: 3903  | Training Loss: 0.34595 \nEpoch: 3903  | Training Loss: 0.21251 \nEpoch: 3903  | Training Loss: 0.14792 \nEpoch: 3903  | Validation balanced accuracy : 0.76304 \nEpoch: 3904  | Training Loss: 0.31601 \nEpoch: 3904  | Training Loss: 0.36815 \nEpoch: 3904  | Training Loss: 0.34592 \nEpoch: 3904  | Training Loss: 0.21252 \nEpoch: 3904  | Training Loss: 0.14784 \nEpoch: 3904  | Validation balanced accuracy : 0.76304 \nEpoch: 3905  | Training Loss: 0.31606 \nEpoch: 3905  | Training Loss: 0.36814 \nEpoch: 3905  | Training Loss: 0.34596 \nEpoch: 3905  | Training Loss: 0.21250 \nEpoch: 3905  | Training Loss: 0.14808 \nEpoch: 3905  | Validation balanced accuracy : 0.76304 \nEpoch: 3906  | Training Loss: 0.31585 \nEpoch: 3906  | Training Loss: 0.36801 \nEpoch: 3906  | Training Loss: 0.34601 \nEpoch: 3906  | Training Loss: 0.21249 \nEpoch: 3906  | Training Loss: 0.14816 \nEpoch: 3906  | Validation balanced accuracy : 0.76304 \nEpoch: 3907  | Training Loss: 0.31583 \nEpoch: 3907  | Training Loss: 0.36802 \nEpoch: 3907  | Training Loss: 0.34600 \nEpoch: 3907  | Training Loss: 0.21249 \nEpoch: 3907  | Training Loss: 0.14805 \nEpoch: 3907  | Validation balanced accuracy : 0.76304 \nEpoch: 3908  | Training Loss: 0.31592 \nEpoch: 3908  | Training Loss: 0.36809 \nEpoch: 3908  | Training Loss: 0.34596 \nEpoch: 3908  | Training Loss: 0.21251 \nEpoch: 3908  | Training Loss: 0.14791 \nEpoch: 3908  | Validation balanced accuracy : 0.76304 \nEpoch: 3909  | Training Loss: 0.31601 \nEpoch: 3909  | Training Loss: 0.36816 \nEpoch: 3909  | Training Loss: 0.34592 \nEpoch: 3909  | Training Loss: 0.21251 \nEpoch: 3909  | Training Loss: 0.14780 \nEpoch: 3909  | Validation balanced accuracy : 0.76304 \nEpoch: 3910  | Training Loss: 0.31609 \nEpoch: 3910  | Training Loss: 0.36816 \nEpoch: 3910  | Training Loss: 0.34595 \nEpoch: 3910  | Training Loss: 0.21250 \nEpoch: 3910  | Training Loss: 0.14805 \nEpoch: 3910  | Validation balanced accuracy : 0.76304 \nEpoch: 3911  | Training Loss: 0.31587 \nEpoch: 3911  | Training Loss: 0.36803 \nEpoch: 3911  | Training Loss: 0.34601 \nEpoch: 3911  | Training Loss: 0.21249 \nEpoch: 3911  | Training Loss: 0.14814 \nEpoch: 3911  | Validation balanced accuracy : 0.76304 \nEpoch: 3912  | Training Loss: 0.31584 \nEpoch: 3912  | Training Loss: 0.36803 \nEpoch: 3912  | Training Loss: 0.34600 \nEpoch: 3912  | Training Loss: 0.21249 \nEpoch: 3912  | Training Loss: 0.14804 \nEpoch: 3912  | Validation balanced accuracy : 0.76304 \nEpoch: 3913  | Training Loss: 0.31592 \nEpoch: 3913  | Training Loss: 0.36810 \nEpoch: 3913  | Training Loss: 0.34596 \nEpoch: 3913  | Training Loss: 0.21250 \nEpoch: 3913  | Training Loss: 0.14791 \nEpoch: 3913  | Validation balanced accuracy : 0.76304 \nEpoch: 3914  | Training Loss: 0.31601 \nEpoch: 3914  | Training Loss: 0.36816 \nEpoch: 3914  | Training Loss: 0.34592 \nEpoch: 3914  | Training Loss: 0.21251 \nEpoch: 3914  | Training Loss: 0.14780 \nEpoch: 3914  | Validation balanced accuracy : 0.76304 \nEpoch: 3915  | Training Loss: 0.31609 \nEpoch: 3915  | Training Loss: 0.36816 \nEpoch: 3915  | Training Loss: 0.34595 \nEpoch: 3915  | Training Loss: 0.21250 \nEpoch: 3915  | Training Loss: 0.14803 \nEpoch: 3915  | Validation balanced accuracy : 0.76304 \nEpoch: 3916  | Training Loss: 0.31588 \nEpoch: 3916  | Training Loss: 0.36804 \nEpoch: 3916  | Training Loss: 0.34601 \nEpoch: 3916  | Training Loss: 0.21248 \nEpoch: 3916  | Training Loss: 0.14811 \nEpoch: 3916  | Validation balanced accuracy : 0.76304 \nEpoch: 3917  | Training Loss: 0.31585 \nEpoch: 3917  | Training Loss: 0.36804 \nEpoch: 3917  | Training Loss: 0.34600 \nEpoch: 3917  | Training Loss: 0.21249 \nEpoch: 3917  | Training Loss: 0.14801 \nEpoch: 3917  | Validation balanced accuracy : 0.76304 \nEpoch: 3918  | Training Loss: 0.31594 \nEpoch: 3918  | Training Loss: 0.36811 \nEpoch: 3918  | Training Loss: 0.34596 \nEpoch: 3918  | Training Loss: 0.21250 \nEpoch: 3918  | Training Loss: 0.14788 \nEpoch: 3918  | Validation balanced accuracy : 0.76304 \nEpoch: 3919  | Training Loss: 0.31603 \nEpoch: 3919  | Training Loss: 0.36813 \nEpoch: 3919  | Training Loss: 0.34598 \nEpoch: 3919  | Training Loss: 0.21249 \nEpoch: 3919  | Training Loss: 0.14808 \nEpoch: 3919  | Validation balanced accuracy : 0.76304 \nEpoch: 3920  | Training Loss: 0.31585 \nEpoch: 3920  | Training Loss: 0.36802 \nEpoch: 3920  | Training Loss: 0.34602 \nEpoch: 3920  | Training Loss: 0.21248 \nEpoch: 3920  | Training Loss: 0.14812 \nEpoch: 3920  | Validation balanced accuracy : 0.76304 \nEpoch: 3921  | Training Loss: 0.31584 \nEpoch: 3921  | Training Loss: 0.36804 \nEpoch: 3921  | Training Loss: 0.34600 \nEpoch: 3921  | Training Loss: 0.21249 \nEpoch: 3921  | Training Loss: 0.14800 \nEpoch: 3921  | Validation balanced accuracy : 0.76304 \nEpoch: 3922  | Training Loss: 0.31595 \nEpoch: 3922  | Training Loss: 0.36812 \nEpoch: 3922  | Training Loss: 0.34596 \nEpoch: 3922  | Training Loss: 0.21250 \nEpoch: 3922  | Training Loss: 0.14788 \nEpoch: 3922  | Validation balanced accuracy : 0.76304 \nEpoch: 3923  | Training Loss: 0.31602 \nEpoch: 3923  | Training Loss: 0.36812 \nEpoch: 3923  | Training Loss: 0.34598 \nEpoch: 3923  | Training Loss: 0.21248 \nEpoch: 3923  | Training Loss: 0.14809 \nEpoch: 3923  | Validation balanced accuracy : 0.76304 \nEpoch: 3924  | Training Loss: 0.31583 \nEpoch: 3924  | Training Loss: 0.36801 \nEpoch: 3924  | Training Loss: 0.34603 \nEpoch: 3924  | Training Loss: 0.21248 \nEpoch: 3924  | Training Loss: 0.14814 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3924  | Validation balanced accuracy : 0.76304 \nEpoch: 3925  | Training Loss: 0.31583 \nEpoch: 3925  | Training Loss: 0.36803 \nEpoch: 3925  | Training Loss: 0.34601 \nEpoch: 3925  | Training Loss: 0.21248 \nEpoch: 3925  | Training Loss: 0.14801 \nEpoch: 3925  | Validation balanced accuracy : 0.76304 \nEpoch: 3926  | Training Loss: 0.31594 \nEpoch: 3926  | Training Loss: 0.36811 \nEpoch: 3926  | Training Loss: 0.34596 \nEpoch: 3926  | Training Loss: 0.21250 \nEpoch: 3926  | Training Loss: 0.14786 \nEpoch: 3926  | Validation balanced accuracy : 0.76304 \nEpoch: 3927  | Training Loss: 0.31604 \nEpoch: 3927  | Training Loss: 0.36814 \nEpoch: 3927  | Training Loss: 0.34598 \nEpoch: 3927  | Training Loss: 0.21249 \nEpoch: 3927  | Training Loss: 0.14805 \nEpoch: 3927  | Validation balanced accuracy : 0.76304 \nEpoch: 3928  | Training Loss: 0.31586 \nEpoch: 3928  | Training Loss: 0.36803 \nEpoch: 3928  | Training Loss: 0.34603 \nEpoch: 3928  | Training Loss: 0.21247 \nEpoch: 3928  | Training Loss: 0.14815 \nEpoch: 3928  | Validation balanced accuracy : 0.76304 \nEpoch: 3929  | Training Loss: 0.31582 \nEpoch: 3929  | Training Loss: 0.36802 \nEpoch: 3929  | Training Loss: 0.34603 \nEpoch: 3929  | Training Loss: 0.21248 \nEpoch: 3929  | Training Loss: 0.14805 \nEpoch: 3929  | Validation balanced accuracy : 0.76304 \nEpoch: 3930  | Training Loss: 0.31590 \nEpoch: 3930  | Training Loss: 0.36808 \nEpoch: 3930  | Training Loss: 0.34599 \nEpoch: 3930  | Training Loss: 0.21249 \nEpoch: 3930  | Training Loss: 0.14792 \nEpoch: 3930  | Validation balanced accuracy : 0.76304 \nEpoch: 3931  | Training Loss: 0.31600 \nEpoch: 3931  | Training Loss: 0.36815 \nEpoch: 3931  | Training Loss: 0.34595 \nEpoch: 3931  | Training Loss: 0.21250 \nEpoch: 3931  | Training Loss: 0.14780 \nEpoch: 3931  | Validation balanced accuracy : 0.76304 \nEpoch: 3932  | Training Loss: 0.31608 \nEpoch: 3932  | Training Loss: 0.36816 \nEpoch: 3932  | Training Loss: 0.34597 \nEpoch: 3932  | Training Loss: 0.21249 \nEpoch: 3932  | Training Loss: 0.14802 \nEpoch: 3932  | Validation balanced accuracy : 0.76304 \nEpoch: 3933  | Training Loss: 0.31588 \nEpoch: 3933  | Training Loss: 0.36805 \nEpoch: 3933  | Training Loss: 0.34603 \nEpoch: 3933  | Training Loss: 0.21247 \nEpoch: 3933  | Training Loss: 0.14808 \nEpoch: 3933  | Validation balanced accuracy : 0.76304 \nEpoch: 3934  | Training Loss: 0.31586 \nEpoch: 3934  | Training Loss: 0.36805 \nEpoch: 3934  | Training Loss: 0.34601 \nEpoch: 3934  | Training Loss: 0.21248 \nEpoch: 3934  | Training Loss: 0.14798 \nEpoch: 3934  | Validation balanced accuracy : 0.76304 \nEpoch: 3935  | Training Loss: 0.31595 \nEpoch: 3935  | Training Loss: 0.36812 \nEpoch: 3935  | Training Loss: 0.34597 \nEpoch: 3935  | Training Loss: 0.21249 \nEpoch: 3935  | Training Loss: 0.14785 \nEpoch: 3935  | Validation balanced accuracy : 0.76304 \nEpoch: 3936  | Training Loss: 0.31604 \nEpoch: 3936  | Training Loss: 0.36814 \nEpoch: 3936  | Training Loss: 0.34599 \nEpoch: 3936  | Training Loss: 0.21248 \nEpoch: 3936  | Training Loss: 0.14804 \nEpoch: 3936  | Validation balanced accuracy : 0.76304 \nEpoch: 3937  | Training Loss: 0.31586 \nEpoch: 3937  | Training Loss: 0.36804 \nEpoch: 3937  | Training Loss: 0.34604 \nEpoch: 3937  | Training Loss: 0.21247 \nEpoch: 3937  | Training Loss: 0.14809 \nEpoch: 3937  | Validation balanced accuracy : 0.76304 \nEpoch: 3938  | Training Loss: 0.31586 \nEpoch: 3938  | Training Loss: 0.36805 \nEpoch: 3938  | Training Loss: 0.34602 \nEpoch: 3938  | Training Loss: 0.21248 \nEpoch: 3938  | Training Loss: 0.14797 \nEpoch: 3938  | Validation balanced accuracy : 0.76304 \nEpoch: 3939  | Training Loss: 0.31596 \nEpoch: 3939  | Training Loss: 0.36812 \nEpoch: 3939  | Training Loss: 0.34598 \nEpoch: 3939  | Training Loss: 0.21249 \nEpoch: 3939  | Training Loss: 0.14786 \nEpoch: 3939  | Validation balanced accuracy : 0.76304 \nEpoch: 3940  | Training Loss: 0.31603 \nEpoch: 3940  | Training Loss: 0.36813 \nEpoch: 3940  | Training Loss: 0.34600 \nEpoch: 3940  | Training Loss: 0.21248 \nEpoch: 3940  | Training Loss: 0.14807 \nEpoch: 3940  | Validation balanced accuracy : 0.76304 \nEpoch: 3941  | Training Loss: 0.31584 \nEpoch: 3941  | Training Loss: 0.36802 \nEpoch: 3941  | Training Loss: 0.34605 \nEpoch: 3941  | Training Loss: 0.21247 \nEpoch: 3941  | Training Loss: 0.14811 \nEpoch: 3941  | Validation balanced accuracy : 0.76304 \nEpoch: 3942  | Training Loss: 0.31584 \nEpoch: 3942  | Training Loss: 0.36804 \nEpoch: 3942  | Training Loss: 0.34603 \nEpoch: 3942  | Training Loss: 0.21247 \nEpoch: 3942  | Training Loss: 0.14798 \nEpoch: 3942  | Validation balanced accuracy : 0.76304 \nEpoch: 3943  | Training Loss: 0.31595 \nEpoch: 3943  | Training Loss: 0.36812 \nEpoch: 3943  | Training Loss: 0.34598 \nEpoch: 3943  | Training Loss: 0.21249 \nEpoch: 3943  | Training Loss: 0.14783 \nEpoch: 3943  | Validation balanced accuracy : 0.76304 \nEpoch: 3944  | Training Loss: 0.31605 \nEpoch: 3944  | Training Loss: 0.36815 \nEpoch: 3944  | Training Loss: 0.34600 \nEpoch: 3944  | Training Loss: 0.21248 \nEpoch: 3944  | Training Loss: 0.14802 \nEpoch: 3944  | Validation balanced accuracy : 0.76304 \nEpoch: 3945  | Training Loss: 0.31587 \nEpoch: 3945  | Training Loss: 0.36804 \nEpoch: 3945  | Training Loss: 0.34605 \nEpoch: 3945  | Training Loss: 0.21246 \nEpoch: 3945  | Training Loss: 0.14812 \nEpoch: 3945  | Validation balanced accuracy : 0.76304 \nEpoch: 3946  | Training Loss: 0.31582 \nEpoch: 3946  | Training Loss: 0.36803 \nEpoch: 3946  | Training Loss: 0.34605 \nEpoch: 3946  | Training Loss: 0.21247 \nEpoch: 3946  | Training Loss: 0.14803 \nEpoch: 3946  | Validation balanced accuracy : 0.76304 \nEpoch: 3947  | Training Loss: 0.31591 \nEpoch: 3947  | Training Loss: 0.36809 \nEpoch: 3947  | Training Loss: 0.34600 \nEpoch: 3947  | Training Loss: 0.21248 \nEpoch: 3947  | Training Loss: 0.14789 \nEpoch: 3947  | Validation balanced accuracy : 0.76304 \nEpoch: 3948  | Training Loss: 0.31600 \nEpoch: 3948  | Training Loss: 0.36816 \nEpoch: 3948  | Training Loss: 0.34596 \nEpoch: 3948  | Training Loss: 0.21249 \nEpoch: 3948  | Training Loss: 0.14777 \nEpoch: 3948  | Validation balanced accuracy : 0.76304 \nEpoch: 3949  | Training Loss: 0.31609 \nEpoch: 3949  | Training Loss: 0.36817 \nEpoch: 3949  | Training Loss: 0.34599 \nEpoch: 3949  | Training Loss: 0.21248 \nEpoch: 3949  | Training Loss: 0.14799 \nEpoch: 3949  | Validation balanced accuracy : 0.76304 \nEpoch: 3950  | Training Loss: 0.31589 \nEpoch: 3950  | Training Loss: 0.36805 \nEpoch: 3950  | Training Loss: 0.34605 \nEpoch: 3950  | Training Loss: 0.21246 \nEpoch: 3950  | Training Loss: 0.14811 \nEpoch: 3950  | Validation balanced accuracy : 0.76304 \nEpoch: 3951  | Training Loss: 0.31582 \nEpoch: 3951  | Training Loss: 0.36802 \nEpoch: 3951  | Training Loss: 0.34605 \nEpoch: 3951  | Training Loss: 0.21246 \nEpoch: 3951  | Training Loss: 0.14803 \nEpoch: 3951  | Validation balanced accuracy : 0.76304 \nEpoch: 3952  | Training Loss: 0.31590 \nEpoch: 3952  | Training Loss: 0.36809 \nEpoch: 3952  | Training Loss: 0.34602 \nEpoch: 3952  | Training Loss: 0.21248 \nEpoch: 3952  | Training Loss: 0.14790 \nEpoch: 3952  | Validation balanced accuracy : 0.76304 \nEpoch: 3953  | Training Loss: 0.31599 \nEpoch: 3953  | Training Loss: 0.36815 \nEpoch: 3953  | Training Loss: 0.34598 \nEpoch: 3953  | Training Loss: 0.21249 \nEpoch: 3953  | Training Loss: 0.14778 \nEpoch: 3953  | Validation balanced accuracy : 0.76304 \nEpoch: 3954  | Training Loss: 0.31608 \nEpoch: 3954  | Training Loss: 0.36816 \nEpoch: 3954  | Training Loss: 0.34600 \nEpoch: 3954  | Training Loss: 0.21247 \nEpoch: 3954  | Training Loss: 0.14802 \nEpoch: 3954  | Validation balanced accuracy : 0.76304 \nEpoch: 3955  | Training Loss: 0.31586 \nEpoch: 3955  | Training Loss: 0.36803 \nEpoch: 3955  | Training Loss: 0.34606 \nEpoch: 3955  | Training Loss: 0.21246 \nEpoch: 3955  | Training Loss: 0.14810 \nEpoch: 3955  | Validation balanced accuracy : 0.76304 \nEpoch: 3956  | Training Loss: 0.31584 \nEpoch: 3956  | Training Loss: 0.36804 \nEpoch: 3956  | Training Loss: 0.34605 \nEpoch: 3956  | Training Loss: 0.21247 \nEpoch: 3956  | Training Loss: 0.14798 \nEpoch: 3956  | Validation balanced accuracy : 0.76304 \nEpoch: 3957  | Training Loss: 0.31594 \nEpoch: 3957  | Training Loss: 0.36811 \nEpoch: 3957  | Training Loss: 0.34600 \nEpoch: 3957  | Training Loss: 0.21248 \nEpoch: 3957  | Training Loss: 0.14784 \nEpoch: 3957  | Validation balanced accuracy : 0.76304 \nEpoch: 3958  | Training Loss: 0.31603 \nEpoch: 3958  | Training Loss: 0.36814 \nEpoch: 3958  | Training Loss: 0.34602 \nEpoch: 3958  | Training Loss: 0.21247 \nEpoch: 3958  | Training Loss: 0.14802 \nEpoch: 3958  | Validation balanced accuracy : 0.76304 \nEpoch: 3959  | Training Loss: 0.31586 \nEpoch: 3959  | Training Loss: 0.36803 \nEpoch: 3959  | Training Loss: 0.34607 \nEpoch: 3959  | Training Loss: 0.21245 \nEpoch: 3959  | Training Loss: 0.14811 \nEpoch: 3959  | Validation balanced accuracy : 0.76304 \nEpoch: 3960  | Training Loss: 0.31582 \nEpoch: 3960  | Training Loss: 0.36803 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3960  | Training Loss: 0.34606 \nEpoch: 3960  | Training Loss: 0.21246 \nEpoch: 3960  | Training Loss: 0.14801 \nEpoch: 3960  | Validation balanced accuracy : 0.76304 \nEpoch: 3961  | Training Loss: 0.31591 \nEpoch: 3961  | Training Loss: 0.36810 \nEpoch: 3961  | Training Loss: 0.34602 \nEpoch: 3961  | Training Loss: 0.21247 \nEpoch: 3961  | Training Loss: 0.14786 \nEpoch: 3961  | Validation balanced accuracy : 0.76304 \nEpoch: 3962  | Training Loss: 0.31601 \nEpoch: 3962  | Training Loss: 0.36817 \nEpoch: 3962  | Training Loss: 0.34598 \nEpoch: 3962  | Training Loss: 0.21248 \nEpoch: 3962  | Training Loss: 0.14774 \nEpoch: 3962  | Validation balanced accuracy : 0.76304 \nEpoch: 3963  | Training Loss: 0.31609 \nEpoch: 3963  | Training Loss: 0.36818 \nEpoch: 3963  | Training Loss: 0.34600 \nEpoch: 3963  | Training Loss: 0.21247 \nEpoch: 3963  | Training Loss: 0.14796 \nEpoch: 3963  | Validation balanced accuracy : 0.76304 \nEpoch: 3964  | Training Loss: 0.31590 \nEpoch: 3964  | Training Loss: 0.36805 \nEpoch: 3964  | Training Loss: 0.34607 \nEpoch: 3964  | Training Loss: 0.21245 \nEpoch: 3964  | Training Loss: 0.14808 \nEpoch: 3964  | Validation balanced accuracy : 0.76304 \nEpoch: 3965  | Training Loss: 0.31583 \nEpoch: 3965  | Training Loss: 0.36803 \nEpoch: 3965  | Training Loss: 0.34607 \nEpoch: 3965  | Training Loss: 0.21246 \nEpoch: 3965  | Training Loss: 0.14801 \nEpoch: 3965  | Validation balanced accuracy : 0.76304 \nEpoch: 3966  | Training Loss: 0.31591 \nEpoch: 3966  | Training Loss: 0.36809 \nEpoch: 3966  | Training Loss: 0.34603 \nEpoch: 3966  | Training Loss: 0.21247 \nEpoch: 3966  | Training Loss: 0.14788 \nEpoch: 3966  | Validation balanced accuracy : 0.76304 \nEpoch: 3967  | Training Loss: 0.31600 \nEpoch: 3967  | Training Loss: 0.36816 \nEpoch: 3967  | Training Loss: 0.34599 \nEpoch: 3967  | Training Loss: 0.21248 \nEpoch: 3967  | Training Loss: 0.14776 \nEpoch: 3967  | Validation balanced accuracy : 0.76304 \nEpoch: 3968  | Training Loss: 0.31608 \nEpoch: 3968  | Training Loss: 0.36816 \nEpoch: 3968  | Training Loss: 0.34602 \nEpoch: 3968  | Training Loss: 0.21246 \nEpoch: 3968  | Training Loss: 0.14800 \nEpoch: 3968  | Validation balanced accuracy : 0.76304 \nEpoch: 3969  | Training Loss: 0.31586 \nEpoch: 3969  | Training Loss: 0.36804 \nEpoch: 3969  | Training Loss: 0.34608 \nEpoch: 3969  | Training Loss: 0.21245 \nEpoch: 3969  | Training Loss: 0.14807 \nEpoch: 3969  | Validation balanced accuracy : 0.76304 \nEpoch: 3970  | Training Loss: 0.31584 \nEpoch: 3970  | Training Loss: 0.36804 \nEpoch: 3970  | Training Loss: 0.34606 \nEpoch: 3970  | Training Loss: 0.21246 \nEpoch: 3970  | Training Loss: 0.14796 \nEpoch: 3970  | Validation balanced accuracy : 0.76304 \nEpoch: 3971  | Training Loss: 0.31594 \nEpoch: 3971  | Training Loss: 0.36812 \nEpoch: 3971  | Training Loss: 0.34602 \nEpoch: 3971  | Training Loss: 0.21247 \nEpoch: 3971  | Training Loss: 0.14781 \nEpoch: 3971  | Validation balanced accuracy : 0.76304 \nEpoch: 3972  | Training Loss: 0.31604 \nEpoch: 3972  | Training Loss: 0.36814 \nEpoch: 3972  | Training Loss: 0.34603 \nEpoch: 3972  | Training Loss: 0.21246 \nEpoch: 3972  | Training Loss: 0.14800 \nEpoch: 3972  | Validation balanced accuracy : 0.76304 \nEpoch: 3973  | Training Loss: 0.31587 \nEpoch: 3973  | Training Loss: 0.36804 \nEpoch: 3973  | Training Loss: 0.34609 \nEpoch: 3973  | Training Loss: 0.21245 \nEpoch: 3973  | Training Loss: 0.14809 \nEpoch: 3973  | Validation balanced accuracy : 0.76304 \nEpoch: 3974  | Training Loss: 0.31583 \nEpoch: 3974  | Training Loss: 0.36803 \nEpoch: 3974  | Training Loss: 0.34608 \nEpoch: 3974  | Training Loss: 0.21245 \nEpoch: 3974  | Training Loss: 0.14799 \nEpoch: 3974  | Validation balanced accuracy : 0.76304 \nEpoch: 3975  | Training Loss: 0.31592 \nEpoch: 3975  | Training Loss: 0.36810 \nEpoch: 3975  | Training Loss: 0.34603 \nEpoch: 3975  | Training Loss: 0.21246 \nEpoch: 3975  | Training Loss: 0.14784 \nEpoch: 3975  | Validation balanced accuracy : 0.76304 \nEpoch: 3976  | Training Loss: 0.31602 \nEpoch: 3976  | Training Loss: 0.36817 \nEpoch: 3976  | Training Loss: 0.34599 \nEpoch: 3976  | Training Loss: 0.21247 \nEpoch: 3976  | Training Loss: 0.14772 \nEpoch: 3976  | Validation balanced accuracy : 0.76304 \nEpoch: 3977  | Training Loss: 0.31610 \nEpoch: 3977  | Training Loss: 0.36818 \nEpoch: 3977  | Training Loss: 0.34602 \nEpoch: 3977  | Training Loss: 0.21246 \nEpoch: 3977  | Training Loss: 0.14794 \nEpoch: 3977  | Validation balanced accuracy : 0.76304 \nEpoch: 3978  | Training Loss: 0.31590 \nEpoch: 3978  | Training Loss: 0.36806 \nEpoch: 3978  | Training Loss: 0.34608 \nEpoch: 3978  | Training Loss: 0.21245 \nEpoch: 3978  | Training Loss: 0.14806 \nEpoch: 3978  | Validation balanced accuracy : 0.76304 \nEpoch: 3979  | Training Loss: 0.31584 \nEpoch: 3979  | Training Loss: 0.36804 \nEpoch: 3979  | Training Loss: 0.34608 \nEpoch: 3979  | Training Loss: 0.21245 \nEpoch: 3979  | Training Loss: 0.14799 \nEpoch: 3979  | Validation balanced accuracy : 0.76304 \nEpoch: 3980  | Training Loss: 0.31591 \nEpoch: 3980  | Training Loss: 0.36810 \nEpoch: 3980  | Training Loss: 0.34604 \nEpoch: 3980  | Training Loss: 0.21246 \nEpoch: 3980  | Training Loss: 0.14785 \nEpoch: 3980  | Validation balanced accuracy : 0.76304 \nEpoch: 3981  | Training Loss: 0.31600 \nEpoch: 3981  | Training Loss: 0.36816 \nEpoch: 3981  | Training Loss: 0.34600 \nEpoch: 3981  | Training Loss: 0.21247 \nEpoch: 3981  | Training Loss: 0.14774 \nEpoch: 3981  | Validation balanced accuracy : 0.76304 \nEpoch: 3982  | Training Loss: 0.31609 \nEpoch: 3982  | Training Loss: 0.36817 \nEpoch: 3982  | Training Loss: 0.34603 \nEpoch: 3982  | Training Loss: 0.21246 \nEpoch: 3982  | Training Loss: 0.14796 \nEpoch: 3982  | Validation balanced accuracy : 0.76304 \nEpoch: 3983  | Training Loss: 0.31588 \nEpoch: 3983  | Training Loss: 0.36805 \nEpoch: 3983  | Training Loss: 0.34609 \nEpoch: 3983  | Training Loss: 0.21245 \nEpoch: 3983  | Training Loss: 0.14803 \nEpoch: 3983  | Validation balanced accuracy : 0.76304 \nEpoch: 3984  | Training Loss: 0.31586 \nEpoch: 3984  | Training Loss: 0.36806 \nEpoch: 3984  | Training Loss: 0.34607 \nEpoch: 3984  | Training Loss: 0.21245 \nEpoch: 3984  | Training Loss: 0.14792 \nEpoch: 3984  | Validation balanced accuracy : 0.76304 \nEpoch: 3985  | Training Loss: 0.31596 \nEpoch: 3985  | Training Loss: 0.36813 \nEpoch: 3985  | Training Loss: 0.34603 \nEpoch: 3985  | Training Loss: 0.21246 \nEpoch: 3985  | Training Loss: 0.14778 \nEpoch: 3985  | Validation balanced accuracy : 0.76304 \nEpoch: 3986  | Training Loss: 0.31605 \nEpoch: 3986  | Training Loss: 0.36815 \nEpoch: 3986  | Training Loss: 0.34604 \nEpoch: 3986  | Training Loss: 0.21245 \nEpoch: 3986  | Training Loss: 0.14797 \nEpoch: 3986  | Validation balanced accuracy : 0.76304 \nEpoch: 3987  | Training Loss: 0.31588 \nEpoch: 3987  | Training Loss: 0.36805 \nEpoch: 3987  | Training Loss: 0.34609 \nEpoch: 3987  | Training Loss: 0.21244 \nEpoch: 3987  | Training Loss: 0.14801 \nEpoch: 3987  | Validation balanced accuracy : 0.76304 \nEpoch: 3988  | Training Loss: 0.31588 \nEpoch: 3988  | Training Loss: 0.36807 \nEpoch: 3988  | Training Loss: 0.34607 \nEpoch: 3988  | Training Loss: 0.21245 \nEpoch: 3988  | Training Loss: 0.14788 \nEpoch: 3988  | Validation balanced accuracy : 0.76304 \nEpoch: 3989  | Training Loss: 0.31598 \nEpoch: 3989  | Training Loss: 0.36815 \nEpoch: 3989  | Training Loss: 0.34602 \nEpoch: 3989  | Training Loss: 0.21246 \nEpoch: 3989  | Training Loss: 0.14774 \nEpoch: 3989  | Validation balanced accuracy : 0.76304 \nEpoch: 3990  | Training Loss: 0.31608 \nEpoch: 3990  | Training Loss: 0.36817 \nEpoch: 3990  | Training Loss: 0.34604 \nEpoch: 3990  | Training Loss: 0.21245 \nEpoch: 3990  | Training Loss: 0.14794 \nEpoch: 3990  | Validation balanced accuracy : 0.76304 \nEpoch: 3991  | Training Loss: 0.31589 \nEpoch: 3991  | Training Loss: 0.36806 \nEpoch: 3991  | Training Loss: 0.34609 \nEpoch: 3991  | Training Loss: 0.21244 \nEpoch: 3991  | Training Loss: 0.14799 \nEpoch: 3991  | Validation balanced accuracy : 0.76304 \nEpoch: 3992  | Training Loss: 0.31589 \nEpoch: 3992  | Training Loss: 0.36808 \nEpoch: 3992  | Training Loss: 0.34607 \nEpoch: 3992  | Training Loss: 0.21245 \nEpoch: 3992  | Training Loss: 0.14787 \nEpoch: 3992  | Validation balanced accuracy : 0.76304 \nEpoch: 3993  | Training Loss: 0.31598 \nEpoch: 3993  | Training Loss: 0.36815 \nEpoch: 3993  | Training Loss: 0.34603 \nEpoch: 3993  | Training Loss: 0.21246 \nEpoch: 3993  | Training Loss: 0.14774 \nEpoch: 3993  | Validation balanced accuracy : 0.76304 \nEpoch: 3994  | Training Loss: 0.31607 \nEpoch: 3994  | Training Loss: 0.36816 \nEpoch: 3994  | Training Loss: 0.34605 \nEpoch: 3994  | Training Loss: 0.21245 \nEpoch: 3994  | Training Loss: 0.14797 \nEpoch: 3994  | Validation balanced accuracy : 0.76304 \nEpoch: 3995  | Training Loss: 0.31587 \nEpoch: 3995  | Training Loss: 0.36804 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 3995  | Training Loss: 0.34611 \nEpoch: 3995  | Training Loss: 0.21244 \nEpoch: 3995  | Training Loss: 0.14803 \nEpoch: 3995  | Validation balanced accuracy : 0.76304 \nEpoch: 3996  | Training Loss: 0.31585 \nEpoch: 3996  | Training Loss: 0.36806 \nEpoch: 3996  | Training Loss: 0.34609 \nEpoch: 3996  | Training Loss: 0.21244 \nEpoch: 3996  | Training Loss: 0.14791 \nEpoch: 3996  | Validation balanced accuracy : 0.76304 \nEpoch: 3997  | Training Loss: 0.31596 \nEpoch: 3997  | Training Loss: 0.36813 \nEpoch: 3997  | Training Loss: 0.34604 \nEpoch: 3997  | Training Loss: 0.21246 \nEpoch: 3997  | Training Loss: 0.14777 \nEpoch: 3997  | Validation balanced accuracy : 0.76304 \nEpoch: 3998  | Training Loss: 0.31605 \nEpoch: 3998  | Training Loss: 0.36816 \nEpoch: 3998  | Training Loss: 0.34606 \nEpoch: 3998  | Training Loss: 0.21245 \nEpoch: 3998  | Training Loss: 0.14795 \nEpoch: 3998  | Validation balanced accuracy : 0.76304 \nEpoch: 3999  | Training Loss: 0.31588 \nEpoch: 3999  | Training Loss: 0.36805 \nEpoch: 3999  | Training Loss: 0.34611 \nEpoch: 3999  | Training Loss: 0.21243 \nEpoch: 3999  | Training Loss: 0.14804 \nEpoch: 3999  | Validation balanced accuracy : 0.76304 \nEpoch: 4000  | Training Loss: 0.31584 \nEpoch: 4000  | Training Loss: 0.36804 \nEpoch: 4000  | Training Loss: 0.34610 \nEpoch: 4000  | Training Loss: 0.21244 \nEpoch: 4000  | Training Loss: 0.14795 \nEpoch: 4000  | Validation balanced accuracy : 0.76304 \nEpoch: 4001  | Training Loss: 0.31593 \nEpoch: 4001  | Training Loss: 0.36811 \nEpoch: 4001  | Training Loss: 0.34606 \nEpoch: 4001  | Training Loss: 0.21245 \nEpoch: 4001  | Training Loss: 0.14780 \nEpoch: 4001  | Validation balanced accuracy : 0.76304 \nEpoch: 4002  | Training Loss: 0.31603 \nEpoch: 4002  | Training Loss: 0.36818 \nEpoch: 4002  | Training Loss: 0.34602 \nEpoch: 4002  | Training Loss: 0.21246 \nEpoch: 4002  | Training Loss: 0.14768 \nEpoch: 4002  | Validation balanced accuracy : 0.76304 \nEpoch: 4003  | Training Loss: 0.31611 \nEpoch: 4003  | Training Loss: 0.36819 \nEpoch: 4003  | Training Loss: 0.34604 \nEpoch: 4003  | Training Loss: 0.21245 \nEpoch: 4003  | Training Loss: 0.14790 \nEpoch: 4003  | Validation balanced accuracy : 0.76304 \nEpoch: 4004  | Training Loss: 0.31591 \nEpoch: 4004  | Training Loss: 0.36807 \nEpoch: 4004  | Training Loss: 0.34611 \nEpoch: 4004  | Training Loss: 0.21243 \nEpoch: 4004  | Training Loss: 0.14803 \nEpoch: 4004  | Validation balanced accuracy : 0.76304 \nEpoch: 4005  | Training Loss: 0.31584 \nEpoch: 4005  | Training Loss: 0.36804 \nEpoch: 4005  | Training Loss: 0.34611 \nEpoch: 4005  | Training Loss: 0.21244 \nEpoch: 4005  | Training Loss: 0.14795 \nEpoch: 4005  | Validation balanced accuracy : 0.76304 \nEpoch: 4006  | Training Loss: 0.31592 \nEpoch: 4006  | Training Loss: 0.36810 \nEpoch: 4006  | Training Loss: 0.34607 \nEpoch: 4006  | Training Loss: 0.21245 \nEpoch: 4006  | Training Loss: 0.14782 \nEpoch: 4006  | Validation balanced accuracy : 0.76304 \nEpoch: 4007  | Training Loss: 0.31601 \nEpoch: 4007  | Training Loss: 0.36817 \nEpoch: 4007  | Training Loss: 0.34603 \nEpoch: 4007  | Training Loss: 0.21246 \nEpoch: 4007  | Training Loss: 0.14770 \nEpoch: 4007  | Validation balanced accuracy : 0.76304 \nEpoch: 4008  | Training Loss: 0.31610 \nEpoch: 4008  | Training Loss: 0.36818 \nEpoch: 4008  | Training Loss: 0.34606 \nEpoch: 4008  | Training Loss: 0.21244 \nEpoch: 4008  | Training Loss: 0.14794 \nEpoch: 4008  | Validation balanced accuracy : 0.76304 \nEpoch: 4009  | Training Loss: 0.31588 \nEpoch: 4009  | Training Loss: 0.36805 \nEpoch: 4009  | Training Loss: 0.34612 \nEpoch: 4009  | Training Loss: 0.21243 \nEpoch: 4009  | Training Loss: 0.14801 \nEpoch: 4009  | Validation balanced accuracy : 0.76304 \nEpoch: 4010  | Training Loss: 0.31586 \nEpoch: 4010  | Training Loss: 0.36806 \nEpoch: 4010  | Training Loss: 0.34610 \nEpoch: 4010  | Training Loss: 0.21244 \nEpoch: 4010  | Training Loss: 0.14790 \nEpoch: 4010  | Validation balanced accuracy : 0.76304 \nEpoch: 4011  | Training Loss: 0.31595 \nEpoch: 4011  | Training Loss: 0.36813 \nEpoch: 4011  | Training Loss: 0.34606 \nEpoch: 4011  | Training Loss: 0.21245 \nEpoch: 4011  | Training Loss: 0.14776 \nEpoch: 4011  | Validation balanced accuracy : 0.76304 \nEpoch: 4012  | Training Loss: 0.31605 \nEpoch: 4012  | Training Loss: 0.36820 \nEpoch: 4012  | Training Loss: 0.34603 \nEpoch: 4012  | Training Loss: 0.21246 \nEpoch: 4012  | Training Loss: 0.14769 \nEpoch: 4012  | Validation balanced accuracy : 0.76304 \nEpoch: 4013  | Training Loss: 0.31609 \nEpoch: 4013  | Training Loss: 0.36817 \nEpoch: 4013  | Training Loss: 0.34607 \nEpoch: 4013  | Training Loss: 0.21244 \nEpoch: 4013  | Training Loss: 0.14795 \nEpoch: 4013  | Validation balanced accuracy : 0.76304 \nEpoch: 4014  | Training Loss: 0.31586 \nEpoch: 4014  | Training Loss: 0.36804 \nEpoch: 4014  | Training Loss: 0.34613 \nEpoch: 4014  | Training Loss: 0.21243 \nEpoch: 4014  | Training Loss: 0.14804 \nEpoch: 4014  | Validation balanced accuracy : 0.76304 \nEpoch: 4015  | Training Loss: 0.31584 \nEpoch: 4015  | Training Loss: 0.36804 \nEpoch: 4015  | Training Loss: 0.34612 \nEpoch: 4015  | Training Loss: 0.21243 \nEpoch: 4015  | Training Loss: 0.14792 \nEpoch: 4015  | Validation balanced accuracy : 0.76304 \nEpoch: 4016  | Training Loss: 0.31594 \nEpoch: 4016  | Training Loss: 0.36812 \nEpoch: 4016  | Training Loss: 0.34607 \nEpoch: 4016  | Training Loss: 0.21245 \nEpoch: 4016  | Training Loss: 0.14776 \nEpoch: 4016  | Validation balanced accuracy : 0.76304 \nEpoch: 4017  | Training Loss: 0.31605 \nEpoch: 4017  | Training Loss: 0.36820 \nEpoch: 4017  | Training Loss: 0.34603 \nEpoch: 4017  | Training Loss: 0.21246 \nEpoch: 4017  | Training Loss: 0.14764 \nEpoch: 4017  | Validation balanced accuracy : 0.76304 \nEpoch: 4018  | Training Loss: 0.31613 \nEpoch: 4018  | Training Loss: 0.36820 \nEpoch: 4018  | Training Loss: 0.34605 \nEpoch: 4018  | Training Loss: 0.21244 \nEpoch: 4018  | Training Loss: 0.14786 \nEpoch: 4018  | Validation balanced accuracy : 0.76304 \nEpoch: 4019  | Training Loss: 0.31592 \nEpoch: 4019  | Training Loss: 0.36808 \nEpoch: 4019  | Training Loss: 0.34612 \nEpoch: 4019  | Training Loss: 0.21243 \nEpoch: 4019  | Training Loss: 0.14800 \nEpoch: 4019  | Validation balanced accuracy : 0.76304 \nEpoch: 4020  | Training Loss: 0.31586 \nEpoch: 4020  | Training Loss: 0.36805 \nEpoch: 4020  | Training Loss: 0.34612 \nEpoch: 4020  | Training Loss: 0.21243 \nEpoch: 4020  | Training Loss: 0.14792 \nEpoch: 4020  | Validation balanced accuracy : 0.76304 \nEpoch: 4021  | Training Loss: 0.31593 \nEpoch: 4021  | Training Loss: 0.36811 \nEpoch: 4021  | Training Loss: 0.34608 \nEpoch: 4021  | Training Loss: 0.21244 \nEpoch: 4021  | Training Loss: 0.14780 \nEpoch: 4021  | Validation balanced accuracy : 0.76304 \nEpoch: 4022  | Training Loss: 0.31602 \nEpoch: 4022  | Training Loss: 0.36818 \nEpoch: 4022  | Training Loss: 0.34605 \nEpoch: 4022  | Training Loss: 0.21245 \nEpoch: 4022  | Training Loss: 0.14768 \nEpoch: 4022  | Validation balanced accuracy : 0.76304 \nEpoch: 4023  | Training Loss: 0.31610 \nEpoch: 4023  | Training Loss: 0.36818 \nEpoch: 4023  | Training Loss: 0.34607 \nEpoch: 4023  | Training Loss: 0.21243 \nEpoch: 4023  | Training Loss: 0.14792 \nEpoch: 4023  | Validation balanced accuracy : 0.76304 \nEpoch: 4024  | Training Loss: 0.31588 \nEpoch: 4024  | Training Loss: 0.36805 \nEpoch: 4024  | Training Loss: 0.34613 \nEpoch: 4024  | Training Loss: 0.21242 \nEpoch: 4024  | Training Loss: 0.14800 \nEpoch: 4024  | Validation balanced accuracy : 0.76304 \nEpoch: 4025  | Training Loss: 0.31586 \nEpoch: 4025  | Training Loss: 0.36806 \nEpoch: 4025  | Training Loss: 0.34612 \nEpoch: 4025  | Training Loss: 0.21243 \nEpoch: 4025  | Training Loss: 0.14788 \nEpoch: 4025  | Validation balanced accuracy : 0.76304 \nEpoch: 4026  | Training Loss: 0.31596 \nEpoch: 4026  | Training Loss: 0.36814 \nEpoch: 4026  | Training Loss: 0.34607 \nEpoch: 4026  | Training Loss: 0.21244 \nEpoch: 4026  | Training Loss: 0.14773 \nEpoch: 4026  | Validation balanced accuracy : 0.76304 \nEpoch: 4027  | Training Loss: 0.31606 \nEpoch: 4027  | Training Loss: 0.36821 \nEpoch: 4027  | Training Loss: 0.34603 \nEpoch: 4027  | Training Loss: 0.21245 \nEpoch: 4027  | Training Loss: 0.14762 \nEpoch: 4027  | Validation balanced accuracy : 0.76304 \nEpoch: 4028  | Training Loss: 0.31614 \nEpoch: 4028  | Training Loss: 0.36821 \nEpoch: 4028  | Training Loss: 0.34607 \nEpoch: 4028  | Training Loss: 0.21243 \nEpoch: 4028  | Training Loss: 0.14790 \nEpoch: 4028  | Validation balanced accuracy : 0.76304 \nEpoch: 4029  | Training Loss: 0.31589 \nEpoch: 4029  | Training Loss: 0.36806 \nEpoch: 4029  | Training Loss: 0.34614 \nEpoch: 4029  | Training Loss: 0.21242 \nEpoch: 4029  | Training Loss: 0.14801 \nEpoch: 4029  | Validation balanced accuracy : 0.76304 \nEpoch: 4030  | Training Loss: 0.31584 \nEpoch: 4030  | Training Loss: 0.36805 \nEpoch: 4030  | Training Loss: 0.34613 \nEpoch: 4030  | Training Loss: 0.21242 \nEpoch: 4030  | Training Loss: 0.14791 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4030  | Validation balanced accuracy : 0.76304 \nEpoch: 4031  | Training Loss: 0.31593 \nEpoch: 4031  | Training Loss: 0.36812 \nEpoch: 4031  | Training Loss: 0.34609 \nEpoch: 4031  | Training Loss: 0.21244 \nEpoch: 4031  | Training Loss: 0.14777 \nEpoch: 4031  | Validation balanced accuracy : 0.76304 \nEpoch: 4032  | Training Loss: 0.31603 \nEpoch: 4032  | Training Loss: 0.36819 \nEpoch: 4032  | Training Loss: 0.34605 \nEpoch: 4032  | Training Loss: 0.21245 \nEpoch: 4032  | Training Loss: 0.14765 \nEpoch: 4032  | Validation balanced accuracy : 0.76304 \nEpoch: 4033  | Training Loss: 0.31612 \nEpoch: 4033  | Training Loss: 0.36820 \nEpoch: 4033  | Training Loss: 0.34607 \nEpoch: 4033  | Training Loss: 0.21243 \nEpoch: 4033  | Training Loss: 0.14786 \nEpoch: 4033  | Validation balanced accuracy : 0.76304 \nEpoch: 4034  | Training Loss: 0.31592 \nEpoch: 4034  | Training Loss: 0.36808 \nEpoch: 4034  | Training Loss: 0.34613 \nEpoch: 4034  | Training Loss: 0.21242 \nEpoch: 4034  | Training Loss: 0.14793 \nEpoch: 4034  | Validation balanced accuracy : 0.76304 \nEpoch: 4035  | Training Loss: 0.31590 \nEpoch: 4035  | Training Loss: 0.36809 \nEpoch: 4035  | Training Loss: 0.34611 \nEpoch: 4035  | Training Loss: 0.21243 \nEpoch: 4035  | Training Loss: 0.14782 \nEpoch: 4035  | Validation balanced accuracy : 0.76304 \nEpoch: 4036  | Training Loss: 0.31599 \nEpoch: 4036  | Training Loss: 0.36816 \nEpoch: 4036  | Training Loss: 0.34607 \nEpoch: 4036  | Training Loss: 0.21244 \nEpoch: 4036  | Training Loss: 0.14769 \nEpoch: 4036  | Validation balanced accuracy : 0.76304 \nEpoch: 4037  | Training Loss: 0.31608 \nEpoch: 4037  | Training Loss: 0.36817 \nEpoch: 4037  | Training Loss: 0.34609 \nEpoch: 4037  | Training Loss: 0.21243 \nEpoch: 4037  | Training Loss: 0.14791 \nEpoch: 4037  | Validation balanced accuracy : 0.76304 \nEpoch: 4038  | Training Loss: 0.31589 \nEpoch: 4038  | Training Loss: 0.36806 \nEpoch: 4038  | Training Loss: 0.34614 \nEpoch: 4038  | Training Loss: 0.21242 \nEpoch: 4038  | Training Loss: 0.14796 \nEpoch: 4038  | Validation balanced accuracy : 0.76304 \nEpoch: 4039  | Training Loss: 0.31588 \nEpoch: 4039  | Training Loss: 0.36808 \nEpoch: 4039  | Training Loss: 0.34612 \nEpoch: 4039  | Training Loss: 0.21242 \nEpoch: 4039  | Training Loss: 0.14784 \nEpoch: 4039  | Validation balanced accuracy : 0.76304 \nEpoch: 4040  | Training Loss: 0.31598 \nEpoch: 4040  | Training Loss: 0.36815 \nEpoch: 4040  | Training Loss: 0.34608 \nEpoch: 4040  | Training Loss: 0.21244 \nEpoch: 4040  | Training Loss: 0.14769 \nEpoch: 4040  | Validation balanced accuracy : 0.76304 \nEpoch: 4041  | Training Loss: 0.31608 \nEpoch: 4041  | Training Loss: 0.36818 \nEpoch: 4041  | Training Loss: 0.34609 \nEpoch: 4041  | Training Loss: 0.21243 \nEpoch: 4041  | Training Loss: 0.14788 \nEpoch: 4041  | Validation balanced accuracy : 0.76304 \nEpoch: 4042  | Training Loss: 0.31590 \nEpoch: 4042  | Training Loss: 0.36808 \nEpoch: 4042  | Training Loss: 0.34614 \nEpoch: 4042  | Training Loss: 0.21242 \nEpoch: 4042  | Training Loss: 0.14792 \nEpoch: 4042  | Validation balanced accuracy : 0.76304 \nEpoch: 4043  | Training Loss: 0.31590 \nEpoch: 4043  | Training Loss: 0.36809 \nEpoch: 4043  | Training Loss: 0.34612 \nEpoch: 4043  | Training Loss: 0.21243 \nEpoch: 4043  | Training Loss: 0.14780 \nEpoch: 4043  | Validation balanced accuracy : 0.76304 \nEpoch: 4044  | Training Loss: 0.31600 \nEpoch: 4044  | Training Loss: 0.36817 \nEpoch: 4044  | Training Loss: 0.34607 \nEpoch: 4044  | Training Loss: 0.21244 \nEpoch: 4044  | Training Loss: 0.14767 \nEpoch: 4044  | Validation balanced accuracy : 0.76304 \nEpoch: 4045  | Training Loss: 0.31609 \nEpoch: 4045  | Training Loss: 0.36819 \nEpoch: 4045  | Training Loss: 0.34609 \nEpoch: 4045  | Training Loss: 0.21243 \nEpoch: 4045  | Training Loss: 0.14786 \nEpoch: 4045  | Validation balanced accuracy : 0.76304 \nEpoch: 4046  | Training Loss: 0.31591 \nEpoch: 4046  | Training Loss: 0.36808 \nEpoch: 4046  | Training Loss: 0.34614 \nEpoch: 4046  | Training Loss: 0.21242 \nEpoch: 4046  | Training Loss: 0.14792 \nEpoch: 4046  | Validation balanced accuracy : 0.76304 \nEpoch: 4047  | Training Loss: 0.31590 \nEpoch: 4047  | Training Loss: 0.36809 \nEpoch: 4047  | Training Loss: 0.34612 \nEpoch: 4047  | Training Loss: 0.21242 \nEpoch: 4047  | Training Loss: 0.14780 \nEpoch: 4047  | Validation balanced accuracy : 0.76304 \nEpoch: 4048  | Training Loss: 0.31600 \nEpoch: 4048  | Training Loss: 0.36817 \nEpoch: 4048  | Training Loss: 0.34608 \nEpoch: 4048  | Training Loss: 0.21244 \nEpoch: 4048  | Training Loss: 0.14767 \nEpoch: 4048  | Validation balanced accuracy : 0.76304 \nEpoch: 4049  | Training Loss: 0.31609 \nEpoch: 4049  | Training Loss: 0.36818 \nEpoch: 4049  | Training Loss: 0.34610 \nEpoch: 4049  | Training Loss: 0.21242 \nEpoch: 4049  | Training Loss: 0.14789 \nEpoch: 4049  | Validation balanced accuracy : 0.76304 \nEpoch: 4050  | Training Loss: 0.31589 \nEpoch: 4050  | Training Loss: 0.36806 \nEpoch: 4050  | Training Loss: 0.34616 \nEpoch: 4050  | Training Loss: 0.21241 \nEpoch: 4050  | Training Loss: 0.14796 \nEpoch: 4050  | Validation balanced accuracy : 0.76304 \nEpoch: 4051  | Training Loss: 0.31587 \nEpoch: 4051  | Training Loss: 0.36807 \nEpoch: 4051  | Training Loss: 0.34614 \nEpoch: 4051  | Training Loss: 0.21242 \nEpoch: 4051  | Training Loss: 0.14784 \nEpoch: 4051  | Validation balanced accuracy : 0.76304 \nEpoch: 4052  | Training Loss: 0.31597 \nEpoch: 4052  | Training Loss: 0.36815 \nEpoch: 4052  | Training Loss: 0.34609 \nEpoch: 4052  | Training Loss: 0.21243 \nEpoch: 4052  | Training Loss: 0.14769 \nEpoch: 4052  | Validation balanced accuracy : 0.76304 \nEpoch: 4053  | Training Loss: 0.31607 \nEpoch: 4053  | Training Loss: 0.36817 \nEpoch: 4053  | Training Loss: 0.34611 \nEpoch: 4053  | Training Loss: 0.21242 \nEpoch: 4053  | Training Loss: 0.14787 \nEpoch: 4053  | Validation balanced accuracy : 0.76304 \nEpoch: 4054  | Training Loss: 0.31590 \nEpoch: 4054  | Training Loss: 0.36807 \nEpoch: 4054  | Training Loss: 0.34615 \nEpoch: 4054  | Training Loss: 0.21241 \nEpoch: 4054  | Training Loss: 0.14791 \nEpoch: 4054  | Validation balanced accuracy : 0.76304 \nEpoch: 4055  | Training Loss: 0.31590 \nEpoch: 4055  | Training Loss: 0.36810 \nEpoch: 4055  | Training Loss: 0.34613 \nEpoch: 4055  | Training Loss: 0.21242 \nEpoch: 4055  | Training Loss: 0.14778 \nEpoch: 4055  | Validation balanced accuracy : 0.76304 \nEpoch: 4056  | Training Loss: 0.31601 \nEpoch: 4056  | Training Loss: 0.36817 \nEpoch: 4056  | Training Loss: 0.34609 \nEpoch: 4056  | Training Loss: 0.21243 \nEpoch: 4056  | Training Loss: 0.14765 \nEpoch: 4056  | Validation balanced accuracy : 0.76304 \nEpoch: 4057  | Training Loss: 0.31610 \nEpoch: 4057  | Training Loss: 0.36819 \nEpoch: 4057  | Training Loss: 0.34610 \nEpoch: 4057  | Training Loss: 0.21242 \nEpoch: 4057  | Training Loss: 0.14785 \nEpoch: 4057  | Validation balanced accuracy : 0.76304 \nEpoch: 4058  | Training Loss: 0.31592 \nEpoch: 4058  | Training Loss: 0.36808 \nEpoch: 4058  | Training Loss: 0.34615 \nEpoch: 4058  | Training Loss: 0.21241 \nEpoch: 4058  | Training Loss: 0.14790 \nEpoch: 4058  | Validation balanced accuracy : 0.76304 \nEpoch: 4059  | Training Loss: 0.31591 \nEpoch: 4059  | Training Loss: 0.36810 \nEpoch: 4059  | Training Loss: 0.34613 \nEpoch: 4059  | Training Loss: 0.21242 \nEpoch: 4059  | Training Loss: 0.14778 \nEpoch: 4059  | Validation balanced accuracy : 0.76304 \nEpoch: 4060  | Training Loss: 0.31601 \nEpoch: 4060  | Training Loss: 0.36817 \nEpoch: 4060  | Training Loss: 0.34609 \nEpoch: 4060  | Training Loss: 0.21243 \nEpoch: 4060  | Training Loss: 0.14765 \nEpoch: 4060  | Validation balanced accuracy : 0.76304 \nEpoch: 4061  | Training Loss: 0.31609 \nEpoch: 4061  | Training Loss: 0.36819 \nEpoch: 4061  | Training Loss: 0.34611 \nEpoch: 4061  | Training Loss: 0.21242 \nEpoch: 4061  | Training Loss: 0.14785 \nEpoch: 4061  | Validation balanced accuracy : 0.76304 \nEpoch: 4062  | Training Loss: 0.31591 \nEpoch: 4062  | Training Loss: 0.36808 \nEpoch: 4062  | Training Loss: 0.34616 \nEpoch: 4062  | Training Loss: 0.21241 \nEpoch: 4062  | Training Loss: 0.14790 \nEpoch: 4062  | Validation balanced accuracy : 0.76304 \nEpoch: 4063  | Training Loss: 0.31590 \nEpoch: 4063  | Training Loss: 0.36810 \nEpoch: 4063  | Training Loss: 0.34614 \nEpoch: 4063  | Training Loss: 0.21242 \nEpoch: 4063  | Training Loss: 0.14778 \nEpoch: 4063  | Validation balanced accuracy : 0.76304 \nEpoch: 4064  | Training Loss: 0.31600 \nEpoch: 4064  | Training Loss: 0.36817 \nEpoch: 4064  | Training Loss: 0.34610 \nEpoch: 4064  | Training Loss: 0.21243 \nEpoch: 4064  | Training Loss: 0.14765 \nEpoch: 4064  | Validation balanced accuracy : 0.76304 \nEpoch: 4065  | Training Loss: 0.31610 \nEpoch: 4065  | Training Loss: 0.36819 \nEpoch: 4065  | Training Loss: 0.34611 \nEpoch: 4065  | Training Loss: 0.21242 \nEpoch: 4065  | Training Loss: 0.14784 \nEpoch: 4065  | Validation balanced accuracy : 0.76304 \nEpoch: 4066  | Training Loss: 0.31591 \nEpoch: 4066  | Training Loss: 0.36808 \nEpoch: 4066  | Training Loss: 0.34616 \nEpoch: 4066  | Training Loss: 0.21241 \nEpoch: 4066  | Training Loss: 0.14789 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4066  | Validation balanced accuracy : 0.76304 \nEpoch: 4067  | Training Loss: 0.31591 \nEpoch: 4067  | Training Loss: 0.36810 \nEpoch: 4067  | Training Loss: 0.34614 \nEpoch: 4067  | Training Loss: 0.21241 \nEpoch: 4067  | Training Loss: 0.14777 \nEpoch: 4067  | Validation balanced accuracy : 0.76304 \nEpoch: 4068  | Training Loss: 0.31601 \nEpoch: 4068  | Training Loss: 0.36817 \nEpoch: 4068  | Training Loss: 0.34610 \nEpoch: 4068  | Training Loss: 0.21243 \nEpoch: 4068  | Training Loss: 0.14764 \nEpoch: 4068  | Validation balanced accuracy : 0.76304 \nEpoch: 4069  | Training Loss: 0.31610 \nEpoch: 4069  | Training Loss: 0.36818 \nEpoch: 4069  | Training Loss: 0.34612 \nEpoch: 4069  | Training Loss: 0.21241 \nEpoch: 4069  | Training Loss: 0.14787 \nEpoch: 4069  | Validation balanced accuracy : 0.76304 \nEpoch: 4070  | Training Loss: 0.31589 \nEpoch: 4070  | Training Loss: 0.36806 \nEpoch: 4070  | Training Loss: 0.34618 \nEpoch: 4070  | Training Loss: 0.21240 \nEpoch: 4070  | Training Loss: 0.14793 \nEpoch: 4070  | Validation balanced accuracy : 0.76304 \nEpoch: 4071  | Training Loss: 0.31588 \nEpoch: 4071  | Training Loss: 0.36808 \nEpoch: 4071  | Training Loss: 0.34616 \nEpoch: 4071  | Training Loss: 0.21241 \nEpoch: 4071  | Training Loss: 0.14781 \nEpoch: 4071  | Validation balanced accuracy : 0.76304 \nEpoch: 4072  | Training Loss: 0.31598 \nEpoch: 4072  | Training Loss: 0.36815 \nEpoch: 4072  | Training Loss: 0.34611 \nEpoch: 4072  | Training Loss: 0.21242 \nEpoch: 4072  | Training Loss: 0.14766 \nEpoch: 4072  | Validation balanced accuracy : 0.76304 \nEpoch: 4073  | Training Loss: 0.31608 \nEpoch: 4073  | Training Loss: 0.36822 \nEpoch: 4073  | Training Loss: 0.34607 \nEpoch: 4073  | Training Loss: 0.21243 \nEpoch: 4073  | Training Loss: 0.14755 \nEpoch: 4073  | Validation balanced accuracy : 0.76304 \nEpoch: 4074  | Training Loss: 0.31615 \nEpoch: 4074  | Training Loss: 0.36822 \nEpoch: 4074  | Training Loss: 0.34610 \nEpoch: 4074  | Training Loss: 0.21242 \nEpoch: 4074  | Training Loss: 0.14779 \nEpoch: 4074  | Validation balanced accuracy : 0.76304 \nEpoch: 4075  | Training Loss: 0.31594 \nEpoch: 4075  | Training Loss: 0.36809 \nEpoch: 4075  | Training Loss: 0.34617 \nEpoch: 4075  | Training Loss: 0.21240 \nEpoch: 4075  | Training Loss: 0.14792 \nEpoch: 4075  | Validation balanced accuracy : 0.76304 \nEpoch: 4076  | Training Loss: 0.31587 \nEpoch: 4076  | Training Loss: 0.36806 \nEpoch: 4076  | Training Loss: 0.34618 \nEpoch: 4076  | Training Loss: 0.21240 \nEpoch: 4076  | Training Loss: 0.14786 \nEpoch: 4076  | Validation balanced accuracy : 0.76304 \nEpoch: 4077  | Training Loss: 0.31594 \nEpoch: 4077  | Training Loss: 0.36812 \nEpoch: 4077  | Training Loss: 0.34614 \nEpoch: 4077  | Training Loss: 0.21241 \nEpoch: 4077  | Training Loss: 0.14773 \nEpoch: 4077  | Validation balanced accuracy : 0.76304 \nEpoch: 4078  | Training Loss: 0.31603 \nEpoch: 4078  | Training Loss: 0.36819 \nEpoch: 4078  | Training Loss: 0.34610 \nEpoch: 4078  | Training Loss: 0.21242 \nEpoch: 4078  | Training Loss: 0.14761 \nEpoch: 4078  | Validation balanced accuracy : 0.76304 \nEpoch: 4079  | Training Loss: 0.31611 \nEpoch: 4079  | Training Loss: 0.36820 \nEpoch: 4079  | Training Loss: 0.34612 \nEpoch: 4079  | Training Loss: 0.21241 \nEpoch: 4079  | Training Loss: 0.14782 \nEpoch: 4079  | Validation balanced accuracy : 0.76304 \nEpoch: 4080  | Training Loss: 0.31592 \nEpoch: 4080  | Training Loss: 0.36809 \nEpoch: 4080  | Training Loss: 0.34617 \nEpoch: 4080  | Training Loss: 0.21240 \nEpoch: 4080  | Training Loss: 0.14788 \nEpoch: 4080  | Validation balanced accuracy : 0.76304 \nEpoch: 4081  | Training Loss: 0.31591 \nEpoch: 4081  | Training Loss: 0.36810 \nEpoch: 4081  | Training Loss: 0.34616 \nEpoch: 4081  | Training Loss: 0.21241 \nEpoch: 4081  | Training Loss: 0.14777 \nEpoch: 4081  | Validation balanced accuracy : 0.76304 \nEpoch: 4082  | Training Loss: 0.31600 \nEpoch: 4082  | Training Loss: 0.36817 \nEpoch: 4082  | Training Loss: 0.34611 \nEpoch: 4082  | Training Loss: 0.21242 \nEpoch: 4082  | Training Loss: 0.14763 \nEpoch: 4082  | Validation balanced accuracy : 0.76304 \nEpoch: 4083  | Training Loss: 0.31609 \nEpoch: 4083  | Training Loss: 0.36819 \nEpoch: 4083  | Training Loss: 0.34613 \nEpoch: 4083  | Training Loss: 0.21241 \nEpoch: 4083  | Training Loss: 0.14783 \nEpoch: 4083  | Validation balanced accuracy : 0.76304 \nEpoch: 4084  | Training Loss: 0.31591 \nEpoch: 4084  | Training Loss: 0.36808 \nEpoch: 4084  | Training Loss: 0.34618 \nEpoch: 4084  | Training Loss: 0.21240 \nEpoch: 4084  | Training Loss: 0.14788 \nEpoch: 4084  | Validation balanced accuracy : 0.76304 \nEpoch: 4085  | Training Loss: 0.31591 \nEpoch: 4085  | Training Loss: 0.36810 \nEpoch: 4085  | Training Loss: 0.34616 \nEpoch: 4085  | Training Loss: 0.21241 \nEpoch: 4085  | Training Loss: 0.14775 \nEpoch: 4085  | Validation balanced accuracy : 0.76304 \nEpoch: 4086  | Training Loss: 0.31601 \nEpoch: 4086  | Training Loss: 0.36818 \nEpoch: 4086  | Training Loss: 0.34611 \nEpoch: 4086  | Training Loss: 0.21242 \nEpoch: 4086  | Training Loss: 0.14762 \nEpoch: 4086  | Validation balanced accuracy : 0.76304 \nEpoch: 4087  | Training Loss: 0.31610 \nEpoch: 4087  | Training Loss: 0.36819 \nEpoch: 4087  | Training Loss: 0.34614 \nEpoch: 4087  | Training Loss: 0.21240 \nEpoch: 4087  | Training Loss: 0.14784 \nEpoch: 4087  | Validation balanced accuracy : 0.76304 \nEpoch: 4088  | Training Loss: 0.31590 \nEpoch: 4088  | Training Loss: 0.36807 \nEpoch: 4088  | Training Loss: 0.34619 \nEpoch: 4088  | Training Loss: 0.21239 \nEpoch: 4088  | Training Loss: 0.14791 \nEpoch: 4088  | Validation balanced accuracy : 0.76304 \nEpoch: 4089  | Training Loss: 0.31588 \nEpoch: 4089  | Training Loss: 0.36808 \nEpoch: 4089  | Training Loss: 0.34618 \nEpoch: 4089  | Training Loss: 0.21240 \nEpoch: 4089  | Training Loss: 0.14779 \nEpoch: 4089  | Validation balanced accuracy : 0.76304 \nEpoch: 4090  | Training Loss: 0.31599 \nEpoch: 4090  | Training Loss: 0.36816 \nEpoch: 4090  | Training Loss: 0.34613 \nEpoch: 4090  | Training Loss: 0.21241 \nEpoch: 4090  | Training Loss: 0.14764 \nEpoch: 4090  | Validation balanced accuracy : 0.76304 \nEpoch: 4091  | Training Loss: 0.31609 \nEpoch: 4091  | Training Loss: 0.36823 \nEpoch: 4091  | Training Loss: 0.34609 \nEpoch: 4091  | Training Loss: 0.21242 \nEpoch: 4091  | Training Loss: 0.14753 \nEpoch: 4091  | Validation balanced accuracy : 0.76304 \nEpoch: 4092  | Training Loss: 0.31616 \nEpoch: 4092  | Training Loss: 0.36823 \nEpoch: 4092  | Training Loss: 0.34612 \nEpoch: 4092  | Training Loss: 0.21241 \nEpoch: 4092  | Training Loss: 0.14776 \nEpoch: 4092  | Validation balanced accuracy : 0.76304 \nEpoch: 4093  | Training Loss: 0.31595 \nEpoch: 4093  | Training Loss: 0.36810 \nEpoch: 4093  | Training Loss: 0.34619 \nEpoch: 4093  | Training Loss: 0.21239 \nEpoch: 4093  | Training Loss: 0.14790 \nEpoch: 4093  | Validation balanced accuracy : 0.76304 \nEpoch: 4094  | Training Loss: 0.31588 \nEpoch: 4094  | Training Loss: 0.36807 \nEpoch: 4094  | Training Loss: 0.34619 \nEpoch: 4094  | Training Loss: 0.21240 \nEpoch: 4094  | Training Loss: 0.14784 \nEpoch: 4094  | Validation balanced accuracy : 0.76304 \nEpoch: 4095  | Training Loss: 0.31594 \nEpoch: 4095  | Training Loss: 0.36812 \nEpoch: 4095  | Training Loss: 0.34616 \nEpoch: 4095  | Training Loss: 0.21241 \nEpoch: 4095  | Training Loss: 0.14771 \nEpoch: 4095  | Validation balanced accuracy : 0.76304 \nEpoch: 4096  | Training Loss: 0.31603 \nEpoch: 4096  | Training Loss: 0.36819 \nEpoch: 4096  | Training Loss: 0.34612 \nEpoch: 4096  | Training Loss: 0.21242 \nEpoch: 4096  | Training Loss: 0.14759 \nEpoch: 4096  | Validation balanced accuracy : 0.76304 \nEpoch: 4097  | Training Loss: 0.31612 \nEpoch: 4097  | Training Loss: 0.36820 \nEpoch: 4097  | Training Loss: 0.34614 \nEpoch: 4097  | Training Loss: 0.21240 \nEpoch: 4097  | Training Loss: 0.14780 \nEpoch: 4097  | Validation balanced accuracy : 0.76304 \nEpoch: 4098  | Training Loss: 0.31592 \nEpoch: 4098  | Training Loss: 0.36809 \nEpoch: 4098  | Training Loss: 0.34619 \nEpoch: 4098  | Training Loss: 0.21239 \nEpoch: 4098  | Training Loss: 0.14786 \nEpoch: 4098  | Validation balanced accuracy : 0.76304 \nEpoch: 4099  | Training Loss: 0.31591 \nEpoch: 4099  | Training Loss: 0.36810 \nEpoch: 4099  | Training Loss: 0.34617 \nEpoch: 4099  | Training Loss: 0.21240 \nEpoch: 4099  | Training Loss: 0.14774 \nEpoch: 4099  | Validation balanced accuracy : 0.76304 \nEpoch: 4100  | Training Loss: 0.31601 \nEpoch: 4100  | Training Loss: 0.36817 \nEpoch: 4100  | Training Loss: 0.34613 \nEpoch: 4100  | Training Loss: 0.21241 \nEpoch: 4100  | Training Loss: 0.14761 \nEpoch: 4100  | Validation balanced accuracy : 0.76304 \nEpoch: 4101  | Training Loss: 0.31610 \nEpoch: 4101  | Training Loss: 0.36819 \nEpoch: 4101  | Training Loss: 0.34615 \nEpoch: 4101  | Training Loss: 0.21240 \nEpoch: 4101  | Training Loss: 0.14781 \nEpoch: 4101  | Validation balanced accuracy : 0.76304 \nEpoch: 4102  | Training Loss: 0.31592 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4102  | Training Loss: 0.36809 \nEpoch: 4102  | Training Loss: 0.34619 \nEpoch: 4102  | Training Loss: 0.21239 \nEpoch: 4102  | Training Loss: 0.14785 \nEpoch: 4102  | Validation balanced accuracy : 0.76304 \nEpoch: 4103  | Training Loss: 0.31592 \nEpoch: 4103  | Training Loss: 0.36810 \nEpoch: 4103  | Training Loss: 0.34617 \nEpoch: 4103  | Training Loss: 0.21240 \nEpoch: 4103  | Training Loss: 0.14773 \nEpoch: 4103  | Validation balanced accuracy : 0.76304 \nEpoch: 4104  | Training Loss: 0.31602 \nEpoch: 4104  | Training Loss: 0.36817 \nEpoch: 4104  | Training Loss: 0.34614 \nEpoch: 4104  | Training Loss: 0.21241 \nEpoch: 4104  | Training Loss: 0.14762 \nEpoch: 4104  | Validation balanced accuracy : 0.76304 \nEpoch: 4105  | Training Loss: 0.31608 \nEpoch: 4105  | Training Loss: 0.36822 \nEpoch: 4105  | Training Loss: 0.34611 \nEpoch: 4105  | Training Loss: 0.21242 \nEpoch: 4105  | Training Loss: 0.14754 \nEpoch: 4105  | Validation balanced accuracy : 0.76304 \nEpoch: 4106  | Training Loss: 0.31614 \nEpoch: 4106  | Training Loss: 0.36821 \nEpoch: 4106  | Training Loss: 0.34614 \nEpoch: 4106  | Training Loss: 0.21240 \nEpoch: 4106  | Training Loss: 0.14778 \nEpoch: 4106  | Validation balanced accuracy : 0.76304 \nEpoch: 4107  | Training Loss: 0.31593 \nEpoch: 4107  | Training Loss: 0.36809 \nEpoch: 4107  | Training Loss: 0.34620 \nEpoch: 4107  | Training Loss: 0.21239 \nEpoch: 4107  | Training Loss: 0.14786 \nEpoch: 4107  | Validation balanced accuracy : 0.76304 \nEpoch: 4108  | Training Loss: 0.31590 \nEpoch: 4108  | Training Loss: 0.36809 \nEpoch: 4108  | Training Loss: 0.34619 \nEpoch: 4108  | Training Loss: 0.21239 \nEpoch: 4108  | Training Loss: 0.14776 \nEpoch: 4108  | Validation balanced accuracy : 0.76304 \nEpoch: 4109  | Training Loss: 0.31600 \nEpoch: 4109  | Training Loss: 0.36816 \nEpoch: 4109  | Training Loss: 0.34614 \nEpoch: 4109  | Training Loss: 0.21241 \nEpoch: 4109  | Training Loss: 0.14762 \nEpoch: 4109  | Validation balanced accuracy : 0.76304 \nEpoch: 4110  | Training Loss: 0.31609 \nEpoch: 4110  | Training Loss: 0.36823 \nEpoch: 4110  | Training Loss: 0.34611 \nEpoch: 4110  | Training Loss: 0.21241 \nEpoch: 4110  | Training Loss: 0.14752 \nEpoch: 4110  | Validation balanced accuracy : 0.76304 \nEpoch: 4111  | Training Loss: 0.31616 \nEpoch: 4111  | Training Loss: 0.36823 \nEpoch: 4111  | Training Loss: 0.34614 \nEpoch: 4111  | Training Loss: 0.21240 \nEpoch: 4111  | Training Loss: 0.14775 \nEpoch: 4111  | Validation balanced accuracy : 0.76304 \nEpoch: 4112  | Training Loss: 0.31595 \nEpoch: 4112  | Training Loss: 0.36810 \nEpoch: 4112  | Training Loss: 0.34620 \nEpoch: 4112  | Training Loss: 0.21238 \nEpoch: 4112  | Training Loss: 0.14789 \nEpoch: 4112  | Validation balanced accuracy : 0.76304 \nEpoch: 4113  | Training Loss: 0.31588 \nEpoch: 4113  | Training Loss: 0.36807 \nEpoch: 4113  | Training Loss: 0.34621 \nEpoch: 4113  | Training Loss: 0.21239 \nEpoch: 4113  | Training Loss: 0.14782 \nEpoch: 4113  | Validation balanced accuracy : 0.76304 \nEpoch: 4114  | Training Loss: 0.31595 \nEpoch: 4114  | Training Loss: 0.36814 \nEpoch: 4114  | Training Loss: 0.34616 \nEpoch: 4114  | Training Loss: 0.21240 \nEpoch: 4114  | Training Loss: 0.14763 \nEpoch: 4114  | Validation balanced accuracy : 0.76304 \nEpoch: 4115  | Training Loss: 0.31609 \nEpoch: 4115  | Training Loss: 0.36823 \nEpoch: 4115  | Training Loss: 0.34610 \nEpoch: 4115  | Training Loss: 0.21241 \nEpoch: 4115  | Training Loss: 0.14748 \nEpoch: 4115  | Validation balanced accuracy : 0.76304 \nEpoch: 4116  | Training Loss: 0.31619 \nEpoch: 4116  | Training Loss: 0.36825 \nEpoch: 4116  | Training Loss: 0.34612 \nEpoch: 4116  | Training Loss: 0.21240 \nEpoch: 4116  | Training Loss: 0.14770 \nEpoch: 4116  | Validation balanced accuracy : 0.76304 \nEpoch: 4117  | Training Loss: 0.31598 \nEpoch: 4117  | Training Loss: 0.36813 \nEpoch: 4117  | Training Loss: 0.34619 \nEpoch: 4117  | Training Loss: 0.21239 \nEpoch: 4117  | Training Loss: 0.14783 \nEpoch: 4117  | Validation balanced accuracy : 0.76304 \nEpoch: 4118  | Training Loss: 0.31591 \nEpoch: 4118  | Training Loss: 0.36809 \nEpoch: 4118  | Training Loss: 0.34620 \nEpoch: 4118  | Training Loss: 0.21239 \nEpoch: 4118  | Training Loss: 0.14778 \nEpoch: 4118  | Validation balanced accuracy : 0.76304 \nEpoch: 4119  | Training Loss: 0.31597 \nEpoch: 4119  | Training Loss: 0.36815 \nEpoch: 4119  | Training Loss: 0.34615 \nEpoch: 4119  | Training Loss: 0.21240 \nEpoch: 4119  | Training Loss: 0.14761 \nEpoch: 4119  | Validation balanced accuracy : 0.76304 \nEpoch: 4120  | Training Loss: 0.31610 \nEpoch: 4120  | Training Loss: 0.36819 \nEpoch: 4120  | Training Loss: 0.34616 \nEpoch: 4120  | Training Loss: 0.21239 \nEpoch: 4120  | Training Loss: 0.14779 \nEpoch: 4120  | Validation balanced accuracy : 0.76304 \nEpoch: 4121  | Training Loss: 0.31592 \nEpoch: 4121  | Training Loss: 0.36809 \nEpoch: 4121  | Training Loss: 0.34621 \nEpoch: 4121  | Training Loss: 0.21238 \nEpoch: 4121  | Training Loss: 0.14784 \nEpoch: 4121  | Validation balanced accuracy : 0.76304 \nEpoch: 4122  | Training Loss: 0.31592 \nEpoch: 4122  | Training Loss: 0.36811 \nEpoch: 4122  | Training Loss: 0.34619 \nEpoch: 4122  | Training Loss: 0.21239 \nEpoch: 4122  | Training Loss: 0.14771 \nEpoch: 4122  | Validation balanced accuracy : 0.76304 \nEpoch: 4123  | Training Loss: 0.31602 \nEpoch: 4123  | Training Loss: 0.36818 \nEpoch: 4123  | Training Loss: 0.34614 \nEpoch: 4123  | Training Loss: 0.21240 \nEpoch: 4123  | Training Loss: 0.14757 \nEpoch: 4123  | Validation balanced accuracy : 0.76304 \nEpoch: 4124  | Training Loss: 0.31611 \nEpoch: 4124  | Training Loss: 0.36820 \nEpoch: 4124  | Training Loss: 0.34616 \nEpoch: 4124  | Training Loss: 0.21239 \nEpoch: 4124  | Training Loss: 0.14777 \nEpoch: 4124  | Validation balanced accuracy : 0.76304 \nEpoch: 4125  | Training Loss: 0.31593 \nEpoch: 4125  | Training Loss: 0.36810 \nEpoch: 4125  | Training Loss: 0.34621 \nEpoch: 4125  | Training Loss: 0.21238 \nEpoch: 4125  | Training Loss: 0.14782 \nEpoch: 4125  | Validation balanced accuracy : 0.76304 \nEpoch: 4126  | Training Loss: 0.31593 \nEpoch: 4126  | Training Loss: 0.36811 \nEpoch: 4126  | Training Loss: 0.34619 \nEpoch: 4126  | Training Loss: 0.21239 \nEpoch: 4126  | Training Loss: 0.14770 \nEpoch: 4126  | Validation balanced accuracy : 0.76304 \nEpoch: 4127  | Training Loss: 0.31602 \nEpoch: 4127  | Training Loss: 0.36819 \nEpoch: 4127  | Training Loss: 0.34615 \nEpoch: 4127  | Training Loss: 0.21240 \nEpoch: 4127  | Training Loss: 0.14757 \nEpoch: 4127  | Validation balanced accuracy : 0.76304 \nEpoch: 4128  | Training Loss: 0.31611 \nEpoch: 4128  | Training Loss: 0.36820 \nEpoch: 4128  | Training Loss: 0.34617 \nEpoch: 4128  | Training Loss: 0.21239 \nEpoch: 4128  | Training Loss: 0.14777 \nEpoch: 4128  | Validation balanced accuracy : 0.76304 \nEpoch: 4129  | Training Loss: 0.31593 \nEpoch: 4129  | Training Loss: 0.36810 \nEpoch: 4129  | Training Loss: 0.34621 \nEpoch: 4129  | Training Loss: 0.21238 \nEpoch: 4129  | Training Loss: 0.14782 \nEpoch: 4129  | Validation balanced accuracy : 0.76304 \nEpoch: 4130  | Training Loss: 0.31592 \nEpoch: 4130  | Training Loss: 0.36811 \nEpoch: 4130  | Training Loss: 0.34619 \nEpoch: 4130  | Training Loss: 0.21239 \nEpoch: 4130  | Training Loss: 0.14770 \nEpoch: 4130  | Validation balanced accuracy : 0.76304 \nEpoch: 4131  | Training Loss: 0.31602 \nEpoch: 4131  | Training Loss: 0.36818 \nEpoch: 4131  | Training Loss: 0.34615 \nEpoch: 4131  | Training Loss: 0.21240 \nEpoch: 4131  | Training Loss: 0.14757 \nEpoch: 4131  | Validation balanced accuracy : 0.76304 \nEpoch: 4132  | Training Loss: 0.31611 \nEpoch: 4132  | Training Loss: 0.36820 \nEpoch: 4132  | Training Loss: 0.34617 \nEpoch: 4132  | Training Loss: 0.21239 \nEpoch: 4132  | Training Loss: 0.14776 \nEpoch: 4132  | Validation balanced accuracy : 0.76304 \nEpoch: 4133  | Training Loss: 0.31593 \nEpoch: 4133  | Training Loss: 0.36810 \nEpoch: 4133  | Training Loss: 0.34622 \nEpoch: 4133  | Training Loss: 0.21238 \nEpoch: 4133  | Training Loss: 0.14782 \nEpoch: 4133  | Validation balanced accuracy : 0.76304 \nEpoch: 4134  | Training Loss: 0.31593 \nEpoch: 4134  | Training Loss: 0.36811 \nEpoch: 4134  | Training Loss: 0.34620 \nEpoch: 4134  | Training Loss: 0.21239 \nEpoch: 4134  | Training Loss: 0.14770 \nEpoch: 4134  | Validation balanced accuracy : 0.76304 \nEpoch: 4135  | Training Loss: 0.31602 \nEpoch: 4135  | Training Loss: 0.36819 \nEpoch: 4135  | Training Loss: 0.34615 \nEpoch: 4135  | Training Loss: 0.21240 \nEpoch: 4135  | Training Loss: 0.14756 \nEpoch: 4135  | Validation balanced accuracy : 0.76304 \nEpoch: 4136  | Training Loss: 0.31611 \nEpoch: 4136  | Training Loss: 0.36820 \nEpoch: 4136  | Training Loss: 0.34617 \nEpoch: 4136  | Training Loss: 0.21239 \nEpoch: 4136  | Training Loss: 0.14776 \nEpoch: 4136  | Validation balanced accuracy : 0.76304 \nEpoch: 4137  | Training Loss: 0.31593 \nEpoch: 4137  | Training Loss: 0.36810 \nEpoch: 4137  | Training Loss: 0.34622 \nEpoch: 4137  | Training Loss: 0.21238 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4137  | Training Loss: 0.14781 \nEpoch: 4137  | Validation balanced accuracy : 0.76304 \nEpoch: 4138  | Training Loss: 0.31593 \nEpoch: 4138  | Training Loss: 0.36811 \nEpoch: 4138  | Training Loss: 0.34620 \nEpoch: 4138  | Training Loss: 0.21238 \nEpoch: 4138  | Training Loss: 0.14769 \nEpoch: 4138  | Validation balanced accuracy : 0.76304 \nEpoch: 4139  | Training Loss: 0.31603 \nEpoch: 4139  | Training Loss: 0.36819 \nEpoch: 4139  | Training Loss: 0.34616 \nEpoch: 4139  | Training Loss: 0.21240 \nEpoch: 4139  | Training Loss: 0.14756 \nEpoch: 4139  | Validation balanced accuracy : 0.76304 \nEpoch: 4140  | Training Loss: 0.31612 \nEpoch: 4140  | Training Loss: 0.36820 \nEpoch: 4140  | Training Loss: 0.34618 \nEpoch: 4140  | Training Loss: 0.21238 \nEpoch: 4140  | Training Loss: 0.14777 \nEpoch: 4140  | Validation balanced accuracy : 0.76304 \nEpoch: 4141  | Training Loss: 0.31592 \nEpoch: 4141  | Training Loss: 0.36809 \nEpoch: 4141  | Training Loss: 0.34623 \nEpoch: 4141  | Training Loss: 0.21237 \nEpoch: 4141  | Training Loss: 0.14783 \nEpoch: 4141  | Validation balanced accuracy : 0.76304 \nEpoch: 4142  | Training Loss: 0.31591 \nEpoch: 4142  | Training Loss: 0.36810 \nEpoch: 4142  | Training Loss: 0.34621 \nEpoch: 4142  | Training Loss: 0.21238 \nEpoch: 4142  | Training Loss: 0.14771 \nEpoch: 4142  | Validation balanced accuracy : 0.76304 \nEpoch: 4143  | Training Loss: 0.31601 \nEpoch: 4143  | Training Loss: 0.36818 \nEpoch: 4143  | Training Loss: 0.34617 \nEpoch: 4143  | Training Loss: 0.21239 \nEpoch: 4143  | Training Loss: 0.14757 \nEpoch: 4143  | Validation balanced accuracy : 0.76304 \nEpoch: 4144  | Training Loss: 0.31611 \nEpoch: 4144  | Training Loss: 0.36824 \nEpoch: 4144  | Training Loss: 0.34613 \nEpoch: 4144  | Training Loss: 0.21240 \nEpoch: 4144  | Training Loss: 0.14746 \nEpoch: 4144  | Validation balanced accuracy : 0.76304 \nEpoch: 4145  | Training Loss: 0.31618 \nEpoch: 4145  | Training Loss: 0.36824 \nEpoch: 4145  | Training Loss: 0.34616 \nEpoch: 4145  | Training Loss: 0.21239 \nEpoch: 4145  | Training Loss: 0.14770 \nEpoch: 4145  | Validation balanced accuracy : 0.76304 \nEpoch: 4146  | Training Loss: 0.31596 \nEpoch: 4146  | Training Loss: 0.36812 \nEpoch: 4146  | Training Loss: 0.34622 \nEpoch: 4146  | Training Loss: 0.21238 \nEpoch: 4146  | Training Loss: 0.14779 \nEpoch: 4146  | Validation balanced accuracy : 0.76304 \nEpoch: 4147  | Training Loss: 0.31593 \nEpoch: 4147  | Training Loss: 0.36811 \nEpoch: 4147  | Training Loss: 0.34621 \nEpoch: 4147  | Training Loss: 0.21238 \nEpoch: 4147  | Training Loss: 0.14769 \nEpoch: 4147  | Validation balanced accuracy : 0.76304 \nEpoch: 4148  | Training Loss: 0.31602 \nEpoch: 4148  | Training Loss: 0.36818 \nEpoch: 4148  | Training Loss: 0.34617 \nEpoch: 4148  | Training Loss: 0.21239 \nEpoch: 4148  | Training Loss: 0.14757 \nEpoch: 4148  | Validation balanced accuracy : 0.76304 \nEpoch: 4149  | Training Loss: 0.31610 \nEpoch: 4149  | Training Loss: 0.36824 \nEpoch: 4149  | Training Loss: 0.34614 \nEpoch: 4149  | Training Loss: 0.21240 \nEpoch: 4149  | Training Loss: 0.14747 \nEpoch: 4149  | Validation balanced accuracy : 0.76304 \nEpoch: 4150  | Training Loss: 0.31617 \nEpoch: 4150  | Training Loss: 0.36823 \nEpoch: 4150  | Training Loss: 0.34617 \nEpoch: 4150  | Training Loss: 0.21238 \nEpoch: 4150  | Training Loss: 0.14774 \nEpoch: 4150  | Validation balanced accuracy : 0.76304 \nEpoch: 4151  | Training Loss: 0.31593 \nEpoch: 4151  | Training Loss: 0.36809 \nEpoch: 4151  | Training Loss: 0.34624 \nEpoch: 4151  | Training Loss: 0.21237 \nEpoch: 4151  | Training Loss: 0.14784 \nEpoch: 4151  | Validation balanced accuracy : 0.76304 \nEpoch: 4152  | Training Loss: 0.31590 \nEpoch: 4152  | Training Loss: 0.36809 \nEpoch: 4152  | Training Loss: 0.34623 \nEpoch: 4152  | Training Loss: 0.21237 \nEpoch: 4152  | Training Loss: 0.14774 \nEpoch: 4152  | Validation balanced accuracy : 0.76304 \nEpoch: 4153  | Training Loss: 0.31599 \nEpoch: 4153  | Training Loss: 0.36816 \nEpoch: 4153  | Training Loss: 0.34619 \nEpoch: 4153  | Training Loss: 0.21239 \nEpoch: 4153  | Training Loss: 0.14760 \nEpoch: 4153  | Validation balanced accuracy : 0.76304 \nEpoch: 4154  | Training Loss: 0.31608 \nEpoch: 4154  | Training Loss: 0.36823 \nEpoch: 4154  | Training Loss: 0.34615 \nEpoch: 4154  | Training Loss: 0.21240 \nEpoch: 4154  | Training Loss: 0.14748 \nEpoch: 4154  | Validation balanced accuracy : 0.76304 \nEpoch: 4155  | Training Loss: 0.31616 \nEpoch: 4155  | Training Loss: 0.36823 \nEpoch: 4155  | Training Loss: 0.34617 \nEpoch: 4155  | Training Loss: 0.21238 \nEpoch: 4155  | Training Loss: 0.14771 \nEpoch: 4155  | Validation balanced accuracy : 0.76304 \nEpoch: 4156  | Training Loss: 0.31596 \nEpoch: 4156  | Training Loss: 0.36811 \nEpoch: 4156  | Training Loss: 0.34623 \nEpoch: 4156  | Training Loss: 0.21237 \nEpoch: 4156  | Training Loss: 0.14778 \nEpoch: 4156  | Validation balanced accuracy : 0.76304 \nEpoch: 4157  | Training Loss: 0.31593 \nEpoch: 4157  | Training Loss: 0.36812 \nEpoch: 4157  | Training Loss: 0.34622 \nEpoch: 4157  | Training Loss: 0.21238 \nEpoch: 4157  | Training Loss: 0.14768 \nEpoch: 4157  | Validation balanced accuracy : 0.76304 \nEpoch: 4158  | Training Loss: 0.31602 \nEpoch: 4158  | Training Loss: 0.36818 \nEpoch: 4158  | Training Loss: 0.34617 \nEpoch: 4158  | Training Loss: 0.21239 \nEpoch: 4158  | Training Loss: 0.14755 \nEpoch: 4158  | Validation balanced accuracy : 0.76304 \nEpoch: 4159  | Training Loss: 0.31611 \nEpoch: 4159  | Training Loss: 0.36825 \nEpoch: 4159  | Training Loss: 0.34614 \nEpoch: 4159  | Training Loss: 0.21240 \nEpoch: 4159  | Training Loss: 0.14746 \nEpoch: 4159  | Validation balanced accuracy : 0.76304 \nEpoch: 4160  | Training Loss: 0.31617 \nEpoch: 4160  | Training Loss: 0.36824 \nEpoch: 4160  | Training Loss: 0.34617 \nEpoch: 4160  | Training Loss: 0.21238 \nEpoch: 4160  | Training Loss: 0.14770 \nEpoch: 4160  | Validation balanced accuracy : 0.76304 \nEpoch: 4161  | Training Loss: 0.31596 \nEpoch: 4161  | Training Loss: 0.36812 \nEpoch: 4161  | Training Loss: 0.34623 \nEpoch: 4161  | Training Loss: 0.21237 \nEpoch: 4161  | Training Loss: 0.14778 \nEpoch: 4161  | Validation balanced accuracy : 0.76304 \nEpoch: 4162  | Training Loss: 0.31593 \nEpoch: 4162  | Training Loss: 0.36812 \nEpoch: 4162  | Training Loss: 0.34622 \nEpoch: 4162  | Training Loss: 0.21237 \nEpoch: 4162  | Training Loss: 0.14768 \nEpoch: 4162  | Validation balanced accuracy : 0.76304 \nEpoch: 4163  | Training Loss: 0.31602 \nEpoch: 4163  | Training Loss: 0.36818 \nEpoch: 4163  | Training Loss: 0.34618 \nEpoch: 4163  | Training Loss: 0.21239 \nEpoch: 4163  | Training Loss: 0.14756 \nEpoch: 4163  | Validation balanced accuracy : 0.76304 \nEpoch: 4164  | Training Loss: 0.31610 \nEpoch: 4164  | Training Loss: 0.36824 \nEpoch: 4164  | Training Loss: 0.34614 \nEpoch: 4164  | Training Loss: 0.21239 \nEpoch: 4164  | Training Loss: 0.14746 \nEpoch: 4164  | Validation balanced accuracy : 0.76304 \nEpoch: 4165  | Training Loss: 0.31617 \nEpoch: 4165  | Training Loss: 0.36824 \nEpoch: 4165  | Training Loss: 0.34618 \nEpoch: 4165  | Training Loss: 0.21238 \nEpoch: 4165  | Training Loss: 0.14771 \nEpoch: 4165  | Validation balanced accuracy : 0.76304 \nEpoch: 4166  | Training Loss: 0.31595 \nEpoch: 4166  | Training Loss: 0.36811 \nEpoch: 4166  | Training Loss: 0.34624 \nEpoch: 4166  | Training Loss: 0.21237 \nEpoch: 4166  | Training Loss: 0.14780 \nEpoch: 4166  | Validation balanced accuracy : 0.76304 \nEpoch: 4167  | Training Loss: 0.31592 \nEpoch: 4167  | Training Loss: 0.36811 \nEpoch: 4167  | Training Loss: 0.34623 \nEpoch: 4167  | Training Loss: 0.21237 \nEpoch: 4167  | Training Loss: 0.14770 \nEpoch: 4167  | Validation balanced accuracy : 0.76304 \nEpoch: 4168  | Training Loss: 0.31601 \nEpoch: 4168  | Training Loss: 0.36817 \nEpoch: 4168  | Training Loss: 0.34619 \nEpoch: 4168  | Training Loss: 0.21238 \nEpoch: 4168  | Training Loss: 0.14757 \nEpoch: 4168  | Validation balanced accuracy : 0.76304 \nEpoch: 4169  | Training Loss: 0.31610 \nEpoch: 4169  | Training Loss: 0.36824 \nEpoch: 4169  | Training Loss: 0.34615 \nEpoch: 4169  | Training Loss: 0.21239 \nEpoch: 4169  | Training Loss: 0.14746 \nEpoch: 4169  | Validation balanced accuracy : 0.76304 \nEpoch: 4170  | Training Loss: 0.31617 \nEpoch: 4170  | Training Loss: 0.36824 \nEpoch: 4170  | Training Loss: 0.34618 \nEpoch: 4170  | Training Loss: 0.21238 \nEpoch: 4170  | Training Loss: 0.14769 \nEpoch: 4170  | Validation balanced accuracy : 0.76304 \nEpoch: 4171  | Training Loss: 0.31596 \nEpoch: 4171  | Training Loss: 0.36812 \nEpoch: 4171  | Training Loss: 0.34624 \nEpoch: 4171  | Training Loss: 0.21237 \nEpoch: 4171  | Training Loss: 0.14777 \nEpoch: 4171  | Validation balanced accuracy : 0.76304 \nEpoch: 4172  | Training Loss: 0.31594 \nEpoch: 4172  | Training Loss: 0.36812 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4172  | Training Loss: 0.34622 \nEpoch: 4172  | Training Loss: 0.21237 \nEpoch: 4172  | Training Loss: 0.14767 \nEpoch: 4172  | Validation balanced accuracy : 0.76304 \nEpoch: 4173  | Training Loss: 0.31602 \nEpoch: 4173  | Training Loss: 0.36819 \nEpoch: 4173  | Training Loss: 0.34618 \nEpoch: 4173  | Training Loss: 0.21238 \nEpoch: 4173  | Training Loss: 0.14754 \nEpoch: 4173  | Validation balanced accuracy : 0.76304 \nEpoch: 4174  | Training Loss: 0.31611 \nEpoch: 4174  | Training Loss: 0.36820 \nEpoch: 4174  | Training Loss: 0.34620 \nEpoch: 4174  | Training Loss: 0.21237 \nEpoch: 4174  | Training Loss: 0.14775 \nEpoch: 4174  | Validation balanced accuracy : 0.76304 \nEpoch: 4175  | Training Loss: 0.31592 \nEpoch: 4175  | Training Loss: 0.36809 \nEpoch: 4175  | Training Loss: 0.34626 \nEpoch: 4175  | Training Loss: 0.21236 \nEpoch: 4175  | Training Loss: 0.14781 \nEpoch: 4175  | Validation balanced accuracy : 0.76304 \nEpoch: 4176  | Training Loss: 0.31591 \nEpoch: 4176  | Training Loss: 0.36811 \nEpoch: 4176  | Training Loss: 0.34623 \nEpoch: 4176  | Training Loss: 0.21237 \nEpoch: 4176  | Training Loss: 0.14768 \nEpoch: 4176  | Validation balanced accuracy : 0.76304 \nEpoch: 4177  | Training Loss: 0.31602 \nEpoch: 4177  | Training Loss: 0.36818 \nEpoch: 4177  | Training Loss: 0.34619 \nEpoch: 4177  | Training Loss: 0.21238 \nEpoch: 4177  | Training Loss: 0.14753 \nEpoch: 4177  | Validation balanced accuracy : 0.76304 \nEpoch: 4178  | Training Loss: 0.31612 \nEpoch: 4178  | Training Loss: 0.36821 \nEpoch: 4178  | Training Loss: 0.34620 \nEpoch: 4178  | Training Loss: 0.21237 \nEpoch: 4178  | Training Loss: 0.14772 \nEpoch: 4178  | Validation balanced accuracy : 0.76304 \nEpoch: 4179  | Training Loss: 0.31594 \nEpoch: 4179  | Training Loss: 0.36811 \nEpoch: 4179  | Training Loss: 0.34625 \nEpoch: 4179  | Training Loss: 0.21236 \nEpoch: 4179  | Training Loss: 0.14776 \nEpoch: 4179  | Validation balanced accuracy : 0.76304 \nEpoch: 4180  | Training Loss: 0.31594 \nEpoch: 4180  | Training Loss: 0.36813 \nEpoch: 4180  | Training Loss: 0.34623 \nEpoch: 4180  | Training Loss: 0.21237 \nEpoch: 4180  | Training Loss: 0.14764 \nEpoch: 4180  | Validation balanced accuracy : 0.76304 \nEpoch: 4181  | Training Loss: 0.31604 \nEpoch: 4181  | Training Loss: 0.36820 \nEpoch: 4181  | Training Loss: 0.34618 \nEpoch: 4181  | Training Loss: 0.21238 \nEpoch: 4181  | Training Loss: 0.14751 \nEpoch: 4181  | Validation balanced accuracy : 0.76304 \nEpoch: 4182  | Training Loss: 0.31613 \nEpoch: 4182  | Training Loss: 0.36822 \nEpoch: 4182  | Training Loss: 0.34620 \nEpoch: 4182  | Training Loss: 0.21237 \nEpoch: 4182  | Training Loss: 0.14771 \nEpoch: 4182  | Validation balanced accuracy : 0.76304 \nEpoch: 4183  | Training Loss: 0.31595 \nEpoch: 4183  | Training Loss: 0.36811 \nEpoch: 4183  | Training Loss: 0.34625 \nEpoch: 4183  | Training Loss: 0.21236 \nEpoch: 4183  | Training Loss: 0.14776 \nEpoch: 4183  | Validation balanced accuracy : 0.76304 \nEpoch: 4184  | Training Loss: 0.31594 \nEpoch: 4184  | Training Loss: 0.36812 \nEpoch: 4184  | Training Loss: 0.34623 \nEpoch: 4184  | Training Loss: 0.21237 \nEpoch: 4184  | Training Loss: 0.14764 \nEpoch: 4184  | Validation balanced accuracy : 0.76304 \nEpoch: 4185  | Training Loss: 0.31604 \nEpoch: 4185  | Training Loss: 0.36820 \nEpoch: 4185  | Training Loss: 0.34619 \nEpoch: 4185  | Training Loss: 0.21238 \nEpoch: 4185  | Training Loss: 0.14751 \nEpoch: 4185  | Validation balanced accuracy : 0.76304 \nEpoch: 4186  | Training Loss: 0.31613 \nEpoch: 4186  | Training Loss: 0.36821 \nEpoch: 4186  | Training Loss: 0.34621 \nEpoch: 4186  | Training Loss: 0.21237 \nEpoch: 4186  | Training Loss: 0.14774 \nEpoch: 4186  | Validation balanced accuracy : 0.76304 \nEpoch: 4187  | Training Loss: 0.31592 \nEpoch: 4187  | Training Loss: 0.36809 \nEpoch: 4187  | Training Loss: 0.34627 \nEpoch: 4187  | Training Loss: 0.21235 \nEpoch: 4187  | Training Loss: 0.14780 \nEpoch: 4187  | Validation balanced accuracy : 0.76304 \nEpoch: 4188  | Training Loss: 0.31591 \nEpoch: 4188  | Training Loss: 0.36810 \nEpoch: 4188  | Training Loss: 0.34625 \nEpoch: 4188  | Training Loss: 0.21236 \nEpoch: 4188  | Training Loss: 0.14768 \nEpoch: 4188  | Validation balanced accuracy : 0.76304 \nEpoch: 4189  | Training Loss: 0.31601 \nEpoch: 4189  | Training Loss: 0.36818 \nEpoch: 4189  | Training Loss: 0.34621 \nEpoch: 4189  | Training Loss: 0.21237 \nEpoch: 4189  | Training Loss: 0.14753 \nEpoch: 4189  | Validation balanced accuracy : 0.76304 \nEpoch: 4190  | Training Loss: 0.31611 \nEpoch: 4190  | Training Loss: 0.36825 \nEpoch: 4190  | Training Loss: 0.34617 \nEpoch: 4190  | Training Loss: 0.21239 \nEpoch: 4190  | Training Loss: 0.14742 \nEpoch: 4190  | Validation balanced accuracy : 0.76304 \nEpoch: 4191  | Training Loss: 0.31618 \nEpoch: 4191  | Training Loss: 0.36825 \nEpoch: 4191  | Training Loss: 0.34619 \nEpoch: 4191  | Training Loss: 0.21237 \nEpoch: 4191  | Training Loss: 0.14766 \nEpoch: 4191  | Validation balanced accuracy : 0.76304 \nEpoch: 4192  | Training Loss: 0.31597 \nEpoch: 4192  | Training Loss: 0.36813 \nEpoch: 4192  | Training Loss: 0.34625 \nEpoch: 4192  | Training Loss: 0.21236 \nEpoch: 4192  | Training Loss: 0.14774 \nEpoch: 4192  | Validation balanced accuracy : 0.76304 \nEpoch: 4193  | Training Loss: 0.31595 \nEpoch: 4193  | Training Loss: 0.36813 \nEpoch: 4193  | Training Loss: 0.34624 \nEpoch: 4193  | Training Loss: 0.21236 \nEpoch: 4193  | Training Loss: 0.14764 \nEpoch: 4193  | Validation balanced accuracy : 0.76304 \nEpoch: 4194  | Training Loss: 0.31603 \nEpoch: 4194  | Training Loss: 0.36819 \nEpoch: 4194  | Training Loss: 0.34620 \nEpoch: 4194  | Training Loss: 0.21237 \nEpoch: 4194  | Training Loss: 0.14752 \nEpoch: 4194  | Validation balanced accuracy : 0.76304 \nEpoch: 4195  | Training Loss: 0.31611 \nEpoch: 4195  | Training Loss: 0.36825 \nEpoch: 4195  | Training Loss: 0.34617 \nEpoch: 4195  | Training Loss: 0.21238 \nEpoch: 4195  | Training Loss: 0.14742 \nEpoch: 4195  | Validation balanced accuracy : 0.76304 \nEpoch: 4196  | Training Loss: 0.31618 \nEpoch: 4196  | Training Loss: 0.36824 \nEpoch: 4196  | Training Loss: 0.34620 \nEpoch: 4196  | Training Loss: 0.21237 \nEpoch: 4196  | Training Loss: 0.14767 \nEpoch: 4196  | Validation balanced accuracy : 0.76304 \nEpoch: 4197  | Training Loss: 0.31596 \nEpoch: 4197  | Training Loss: 0.36812 \nEpoch: 4197  | Training Loss: 0.34626 \nEpoch: 4197  | Training Loss: 0.21236 \nEpoch: 4197  | Training Loss: 0.14775 \nEpoch: 4197  | Validation balanced accuracy : 0.76304 \nEpoch: 4198  | Training Loss: 0.31594 \nEpoch: 4198  | Training Loss: 0.36812 \nEpoch: 4198  | Training Loss: 0.34625 \nEpoch: 4198  | Training Loss: 0.21236 \nEpoch: 4198  | Training Loss: 0.14765 \nEpoch: 4198  | Validation balanced accuracy : 0.76304 \nEpoch: 4199  | Training Loss: 0.31602 \nEpoch: 4199  | Training Loss: 0.36819 \nEpoch: 4199  | Training Loss: 0.34621 \nEpoch: 4199  | Training Loss: 0.21237 \nEpoch: 4199  | Training Loss: 0.14752 \nEpoch: 4199  | Validation balanced accuracy : 0.76304 \nEpoch: 4200  | Training Loss: 0.31611 \nEpoch: 4200  | Training Loss: 0.36825 \nEpoch: 4200  | Training Loss: 0.34617 \nEpoch: 4200  | Training Loss: 0.21238 \nEpoch: 4200  | Training Loss: 0.14742 \nEpoch: 4200  | Validation balanced accuracy : 0.76304 \nEpoch: 4201  | Training Loss: 0.31618 \nEpoch: 4201  | Training Loss: 0.36825 \nEpoch: 4201  | Training Loss: 0.34616 \nEpoch: 4201  | Training Loss: 0.21238 \nEpoch: 4201  | Training Loss: 0.14743 \nEpoch: 4201  | Validation balanced accuracy : 0.76304 \nEpoch: 4202  | Training Loss: 0.31598 \nEpoch: 4202  | Training Loss: 0.36813 \nEpoch: 4202  | Training Loss: 0.34622 \nEpoch: 4202  | Training Loss: 0.21237 \nEpoch: 4202  | Training Loss: 0.14753 \nEpoch: 4202  | Validation balanced accuracy : 0.76304 \nEpoch: 4203  | Training Loss: 0.31593 \nEpoch: 4203  | Training Loss: 0.36811 \nEpoch: 4203  | Training Loss: 0.34622 \nEpoch: 4203  | Training Loss: 0.21237 \nEpoch: 4203  | Training Loss: 0.14748 \nEpoch: 4203  | Validation balanced accuracy : 0.76304 \nEpoch: 4204  | Training Loss: 0.31598 \nEpoch: 4204  | Training Loss: 0.36816 \nEpoch: 4204  | Training Loss: 0.34619 \nEpoch: 4204  | Training Loss: 0.21238 \nEpoch: 4204  | Training Loss: 0.14735 \nEpoch: 4204  | Validation balanced accuracy : 0.76304 \nEpoch: 4205  | Training Loss: 0.31608 \nEpoch: 4205  | Training Loss: 0.36822 \nEpoch: 4205  | Training Loss: 0.34615 \nEpoch: 4205  | Training Loss: 0.21239 \nEpoch: 4205  | Training Loss: 0.14728 \nEpoch: 4205  | Validation balanced accuracy : 0.76304 \nEpoch: 4206  | Training Loss: 0.31612 \nEpoch: 4206  | Training Loss: 0.36821 \nEpoch: 4206  | Training Loss: 0.34619 \nEpoch: 4206  | Training Loss: 0.21237 \nEpoch: 4206  | Training Loss: 0.14752 \nEpoch: 4206  | Validation balanced accuracy : 0.76304 \nEpoch: 4207  | Training Loss: 0.31592 \nEpoch: 4207  | Training Loss: 0.36808 \nEpoch: 4207  | Training Loss: 0.34625 \nEpoch: 4207  | Training Loss: 0.21236 \nEpoch: 4207  | Training Loss: 0.14761 \nEpoch: 4207  | Validation balanced accuracy : 0.76304 \nEpoch: 4208  | Training Loss: 0.31588 \nEpoch: 4208  | Training Loss: 0.36808 \nEpoch: 4208  | Training Loss: 0.34624 \nEpoch: 4208  | Training Loss: 0.21236 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4208  | Training Loss: 0.14753 \nEpoch: 4208  | Validation balanced accuracy : 0.76304 \nEpoch: 4209  | Training Loss: 0.31595 \nEpoch: 4209  | Training Loss: 0.36814 \nEpoch: 4209  | Training Loss: 0.34620 \nEpoch: 4209  | Training Loss: 0.21238 \nEpoch: 4209  | Training Loss: 0.14738 \nEpoch: 4209  | Validation balanced accuracy : 0.76304 \nEpoch: 4210  | Training Loss: 0.31607 \nEpoch: 4210  | Training Loss: 0.36822 \nEpoch: 4210  | Training Loss: 0.34615 \nEpoch: 4210  | Training Loss: 0.21239 \nEpoch: 4210  | Training Loss: 0.14726 \nEpoch: 4210  | Validation balanced accuracy : 0.76304 \nEpoch: 4211  | Training Loss: 0.31614 \nEpoch: 4211  | Training Loss: 0.36823 \nEpoch: 4211  | Training Loss: 0.34617 \nEpoch: 4211  | Training Loss: 0.21237 \nEpoch: 4211  | Training Loss: 0.14746 \nEpoch: 4211  | Validation balanced accuracy : 0.76304 \nEpoch: 4212  | Training Loss: 0.31595 \nEpoch: 4212  | Training Loss: 0.36811 \nEpoch: 4212  | Training Loss: 0.34623 \nEpoch: 4212  | Training Loss: 0.21236 \nEpoch: 4212  | Training Loss: 0.14755 \nEpoch: 4212  | Validation balanced accuracy : 0.76304 \nEpoch: 4213  | Training Loss: 0.31592 \nEpoch: 4213  | Training Loss: 0.36811 \nEpoch: 4213  | Training Loss: 0.34623 \nEpoch: 4213  | Training Loss: 0.21237 \nEpoch: 4213  | Training Loss: 0.14749 \nEpoch: 4213  | Validation balanced accuracy : 0.76304 \nEpoch: 4214  | Training Loss: 0.31598 \nEpoch: 4214  | Training Loss: 0.36815 \nEpoch: 4214  | Training Loss: 0.34620 \nEpoch: 4214  | Training Loss: 0.21237 \nEpoch: 4214  | Training Loss: 0.14739 \nEpoch: 4214  | Validation balanced accuracy : 0.76304 \nEpoch: 4215  | Training Loss: 0.31604 \nEpoch: 4215  | Training Loss: 0.36820 \nEpoch: 4215  | Training Loss: 0.34617 \nEpoch: 4215  | Training Loss: 0.21238 \nEpoch: 4215  | Training Loss: 0.14732 \nEpoch: 4215  | Validation balanced accuracy : 0.76304 \nEpoch: 4216  | Training Loss: 0.31609 \nEpoch: 4216  | Training Loss: 0.36823 \nEpoch: 4216  | Training Loss: 0.34615 \nEpoch: 4216  | Training Loss: 0.21238 \nEpoch: 4216  | Training Loss: 0.14727 \nEpoch: 4216  | Validation balanced accuracy : 0.76304 \nEpoch: 4217  | Training Loss: 0.31613 \nEpoch: 4217  | Training Loss: 0.36821 \nEpoch: 4217  | Training Loss: 0.34619 \nEpoch: 4217  | Training Loss: 0.21237 \nEpoch: 4217  | Training Loss: 0.14751 \nEpoch: 4217  | Validation balanced accuracy : 0.76304 \nEpoch: 4218  | Training Loss: 0.31592 \nEpoch: 4218  | Training Loss: 0.36809 \nEpoch: 4218  | Training Loss: 0.34625 \nEpoch: 4218  | Training Loss: 0.21236 \nEpoch: 4218  | Training Loss: 0.14761 \nEpoch: 4218  | Validation balanced accuracy : 0.76304 \nEpoch: 4219  | Training Loss: 0.31588 \nEpoch: 4219  | Training Loss: 0.36808 \nEpoch: 4219  | Training Loss: 0.34624 \nEpoch: 4219  | Training Loss: 0.21236 \nEpoch: 4219  | Training Loss: 0.14754 \nEpoch: 4219  | Validation balanced accuracy : 0.76304 \nEpoch: 4220  | Training Loss: 0.31595 \nEpoch: 4220  | Training Loss: 0.36814 \nEpoch: 4220  | Training Loss: 0.34620 \nEpoch: 4220  | Training Loss: 0.21237 \nEpoch: 4220  | Training Loss: 0.14738 \nEpoch: 4220  | Validation balanced accuracy : 0.76304 \nEpoch: 4221  | Training Loss: 0.31606 \nEpoch: 4221  | Training Loss: 0.36822 \nEpoch: 4221  | Training Loss: 0.34615 \nEpoch: 4221  | Training Loss: 0.21238 \nEpoch: 4221  | Training Loss: 0.14725 \nEpoch: 4221  | Validation balanced accuracy : 0.76304 \nEpoch: 4222  | Training Loss: 0.31614 \nEpoch: 4222  | Training Loss: 0.36823 \nEpoch: 4222  | Training Loss: 0.34618 \nEpoch: 4222  | Training Loss: 0.21237 \nEpoch: 4222  | Training Loss: 0.14748 \nEpoch: 4222  | Validation balanced accuracy : 0.76304 \nEpoch: 4223  | Training Loss: 0.31594 \nEpoch: 4223  | Training Loss: 0.36810 \nEpoch: 4223  | Training Loss: 0.34624 \nEpoch: 4223  | Training Loss: 0.21236 \nEpoch: 4223  | Training Loss: 0.14758 \nEpoch: 4223  | Validation balanced accuracy : 0.76304 \nEpoch: 4224  | Training Loss: 0.31589 \nEpoch: 4224  | Training Loss: 0.36809 \nEpoch: 4224  | Training Loss: 0.34624 \nEpoch: 4224  | Training Loss: 0.21236 \nEpoch: 4224  | Training Loss: 0.14751 \nEpoch: 4224  | Validation balanced accuracy : 0.76304 \nEpoch: 4225  | Training Loss: 0.31596 \nEpoch: 4225  | Training Loss: 0.36814 \nEpoch: 4225  | Training Loss: 0.34621 \nEpoch: 4225  | Training Loss: 0.21237 \nEpoch: 4225  | Training Loss: 0.14741 \nEpoch: 4225  | Validation balanced accuracy : 0.76304 \nEpoch: 4226  | Training Loss: 0.31603 \nEpoch: 4226  | Training Loss: 0.36819 \nEpoch: 4226  | Training Loss: 0.34618 \nEpoch: 4226  | Training Loss: 0.21238 \nEpoch: 4226  | Training Loss: 0.14732 \nEpoch: 4226  | Validation balanced accuracy : 0.76304 \nEpoch: 4227  | Training Loss: 0.31609 \nEpoch: 4227  | Training Loss: 0.36823 \nEpoch: 4227  | Training Loss: 0.34615 \nEpoch: 4227  | Training Loss: 0.21238 \nEpoch: 4227  | Training Loss: 0.14727 \nEpoch: 4227  | Validation balanced accuracy : 0.76304 \nEpoch: 4228  | Training Loss: 0.31613 \nEpoch: 4228  | Training Loss: 0.36822 \nEpoch: 4228  | Training Loss: 0.34619 \nEpoch: 4228  | Training Loss: 0.21236 \nEpoch: 4228  | Training Loss: 0.14750 \nEpoch: 4228  | Validation balanced accuracy : 0.76304 \nEpoch: 4229  | Training Loss: 0.31592 \nEpoch: 4229  | Training Loss: 0.36809 \nEpoch: 4229  | Training Loss: 0.34625 \nEpoch: 4229  | Training Loss: 0.21235 \nEpoch: 4229  | Training Loss: 0.14760 \nEpoch: 4229  | Validation balanced accuracy : 0.76304 \nEpoch: 4230  | Training Loss: 0.31588 \nEpoch: 4230  | Training Loss: 0.36809 \nEpoch: 4230  | Training Loss: 0.34624 \nEpoch: 4230  | Training Loss: 0.21236 \nEpoch: 4230  | Training Loss: 0.14752 \nEpoch: 4230  | Validation balanced accuracy : 0.76304 \nEpoch: 4231  | Training Loss: 0.31595 \nEpoch: 4231  | Training Loss: 0.36814 \nEpoch: 4231  | Training Loss: 0.34621 \nEpoch: 4231  | Training Loss: 0.21237 \nEpoch: 4231  | Training Loss: 0.14741 \nEpoch: 4231  | Validation balanced accuracy : 0.76304 \nEpoch: 4232  | Training Loss: 0.31603 \nEpoch: 4232  | Training Loss: 0.36819 \nEpoch: 4232  | Training Loss: 0.34618 \nEpoch: 4232  | Training Loss: 0.21237 \nEpoch: 4232  | Training Loss: 0.14732 \nEpoch: 4232  | Validation balanced accuracy : 0.76304 \nEpoch: 4233  | Training Loss: 0.31609 \nEpoch: 4233  | Training Loss: 0.36820 \nEpoch: 4233  | Training Loss: 0.34620 \nEpoch: 4233  | Training Loss: 0.21236 \nEpoch: 4233  | Training Loss: 0.14752 \nEpoch: 4233  | Validation balanced accuracy : 0.76304 \nEpoch: 4234  | Training Loss: 0.31591 \nEpoch: 4234  | Training Loss: 0.36809 \nEpoch: 4234  | Training Loss: 0.34625 \nEpoch: 4234  | Training Loss: 0.21235 \nEpoch: 4234  | Training Loss: 0.14759 \nEpoch: 4234  | Validation balanced accuracy : 0.76304 \nEpoch: 4235  | Training Loss: 0.31589 \nEpoch: 4235  | Training Loss: 0.36809 \nEpoch: 4235  | Training Loss: 0.34624 \nEpoch: 4235  | Training Loss: 0.21236 \nEpoch: 4235  | Training Loss: 0.14750 \nEpoch: 4235  | Validation balanced accuracy : 0.76304 \nEpoch: 4236  | Training Loss: 0.31597 \nEpoch: 4236  | Training Loss: 0.36815 \nEpoch: 4236  | Training Loss: 0.34621 \nEpoch: 4236  | Training Loss: 0.21237 \nEpoch: 4236  | Training Loss: 0.14739 \nEpoch: 4236  | Validation balanced accuracy : 0.76304 \nEpoch: 4237  | Training Loss: 0.31604 \nEpoch: 4237  | Training Loss: 0.36821 \nEpoch: 4237  | Training Loss: 0.34617 \nEpoch: 4237  | Training Loss: 0.21237 \nEpoch: 4237  | Training Loss: 0.14730 \nEpoch: 4237  | Validation balanced accuracy : 0.76304 \nEpoch: 4238  | Training Loss: 0.31611 \nEpoch: 4238  | Training Loss: 0.36820 \nEpoch: 4238  | Training Loss: 0.34620 \nEpoch: 4238  | Training Loss: 0.21236 \nEpoch: 4238  | Training Loss: 0.14752 \nEpoch: 4238  | Validation balanced accuracy : 0.76304 \nEpoch: 4239  | Training Loss: 0.31591 \nEpoch: 4239  | Training Loss: 0.36809 \nEpoch: 4239  | Training Loss: 0.34626 \nEpoch: 4239  | Training Loss: 0.21235 \nEpoch: 4239  | Training Loss: 0.14760 \nEpoch: 4239  | Validation balanced accuracy : 0.76304 \nEpoch: 4240  | Training Loss: 0.31588 \nEpoch: 4240  | Training Loss: 0.36809 \nEpoch: 4240  | Training Loss: 0.34625 \nEpoch: 4240  | Training Loss: 0.21235 \nEpoch: 4240  | Training Loss: 0.14751 \nEpoch: 4240  | Validation balanced accuracy : 0.76304 \nEpoch: 4241  | Training Loss: 0.31595 \nEpoch: 4241  | Training Loss: 0.36814 \nEpoch: 4241  | Training Loss: 0.34621 \nEpoch: 4241  | Training Loss: 0.21236 \nEpoch: 4241  | Training Loss: 0.14740 \nEpoch: 4241  | Validation balanced accuracy : 0.76304 \nEpoch: 4242  | Training Loss: 0.31603 \nEpoch: 4242  | Training Loss: 0.36820 \nEpoch: 4242  | Training Loss: 0.34618 \nEpoch: 4242  | Training Loss: 0.21237 \nEpoch: 4242  | Training Loss: 0.14730 \nEpoch: 4242  | Validation balanced accuracy : 0.76304 \nEpoch: 4243  | Training Loss: 0.31610 \nEpoch: 4243  | Training Loss: 0.36820 \nEpoch: 4243  | Training Loss: 0.34621 \nEpoch: 4243  | Training Loss: 0.21236 \nEpoch: 4243  | Training Loss: 0.14751 \nEpoch: 4243  | Validation balanced accuracy : 0.76304 \nEpoch: 4244  | Training Loss: 0.31592 \nEpoch: 4244  | Training Loss: 0.36809 \nEpoch: 4244  | Training Loss: 0.34626 \nEpoch: 4244  | Training Loss: 0.21235 \nEpoch: 4244  | Training Loss: 0.14758 \nEpoch: 4244  | Validation balanced accuracy : 0.76304 \nEpoch: 4245  | Training Loss: 0.31589 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4245  | Training Loss: 0.36810 \nEpoch: 4245  | Training Loss: 0.34625 \nEpoch: 4245  | Training Loss: 0.21235 \nEpoch: 4245  | Training Loss: 0.14749 \nEpoch: 4245  | Validation balanced accuracy : 0.76304 \nEpoch: 4246  | Training Loss: 0.31597 \nEpoch: 4246  | Training Loss: 0.36815 \nEpoch: 4246  | Training Loss: 0.34621 \nEpoch: 4246  | Training Loss: 0.21236 \nEpoch: 4246  | Training Loss: 0.14738 \nEpoch: 4246  | Validation balanced accuracy : 0.76304 \nEpoch: 4247  | Training Loss: 0.31605 \nEpoch: 4247  | Training Loss: 0.36821 \nEpoch: 4247  | Training Loss: 0.34618 \nEpoch: 4247  | Training Loss: 0.21237 \nEpoch: 4247  | Training Loss: 0.14729 \nEpoch: 4247  | Validation balanced accuracy : 0.76304 \nEpoch: 4248  | Training Loss: 0.31611 \nEpoch: 4248  | Training Loss: 0.36820 \nEpoch: 4248  | Training Loss: 0.34621 \nEpoch: 4248  | Training Loss: 0.21236 \nEpoch: 4248  | Training Loss: 0.14752 \nEpoch: 4248  | Validation balanced accuracy : 0.76304 \nEpoch: 4249  | Training Loss: 0.31590 \nEpoch: 4249  | Training Loss: 0.36808 \nEpoch: 4249  | Training Loss: 0.34627 \nEpoch: 4249  | Training Loss: 0.21234 \nEpoch: 4249  | Training Loss: 0.14761 \nEpoch: 4249  | Validation balanced accuracy : 0.76304 \nEpoch: 4250  | Training Loss: 0.31587 \nEpoch: 4250  | Training Loss: 0.36808 \nEpoch: 4250  | Training Loss: 0.34626 \nEpoch: 4250  | Training Loss: 0.21235 \nEpoch: 4250  | Training Loss: 0.14753 \nEpoch: 4250  | Validation balanced accuracy : 0.76304 \nEpoch: 4251  | Training Loss: 0.31594 \nEpoch: 4251  | Training Loss: 0.36813 \nEpoch: 4251  | Training Loss: 0.34623 \nEpoch: 4251  | Training Loss: 0.21236 \nEpoch: 4251  | Training Loss: 0.14741 \nEpoch: 4251  | Validation balanced accuracy : 0.76304 \nEpoch: 4252  | Training Loss: 0.31603 \nEpoch: 4252  | Training Loss: 0.36819 \nEpoch: 4252  | Training Loss: 0.34619 \nEpoch: 4252  | Training Loss: 0.21237 \nEpoch: 4252  | Training Loss: 0.14730 \nEpoch: 4252  | Validation balanced accuracy : 0.76304 \nEpoch: 4253  | Training Loss: 0.31609 \nEpoch: 4253  | Training Loss: 0.36820 \nEpoch: 4253  | Training Loss: 0.34621 \nEpoch: 4253  | Training Loss: 0.21235 \nEpoch: 4253  | Training Loss: 0.14750 \nEpoch: 4253  | Validation balanced accuracy : 0.76304 \nEpoch: 4254  | Training Loss: 0.31592 \nEpoch: 4254  | Training Loss: 0.36809 \nEpoch: 4254  | Training Loss: 0.34626 \nEpoch: 4254  | Training Loss: 0.21235 \nEpoch: 4254  | Training Loss: 0.14757 \nEpoch: 4254  | Validation balanced accuracy : 0.76304 \nEpoch: 4255  | Training Loss: 0.31590 \nEpoch: 4255  | Training Loss: 0.36810 \nEpoch: 4255  | Training Loss: 0.34625 \nEpoch: 4255  | Training Loss: 0.21235 \nEpoch: 4255  | Training Loss: 0.14748 \nEpoch: 4255  | Validation balanced accuracy : 0.76304 \nEpoch: 4256  | Training Loss: 0.31597 \nEpoch: 4256  | Training Loss: 0.36816 \nEpoch: 4256  | Training Loss: 0.34622 \nEpoch: 4256  | Training Loss: 0.21236 \nEpoch: 4256  | Training Loss: 0.14737 \nEpoch: 4256  | Validation balanced accuracy : 0.76304 \nEpoch: 4257  | Training Loss: 0.31605 \nEpoch: 4257  | Training Loss: 0.36821 \nEpoch: 4257  | Training Loss: 0.34618 \nEpoch: 4257  | Training Loss: 0.21237 \nEpoch: 4257  | Training Loss: 0.14728 \nEpoch: 4257  | Validation balanced accuracy : 0.76304 \nEpoch: 4258  | Training Loss: 0.31611 \nEpoch: 4258  | Training Loss: 0.36821 \nEpoch: 4258  | Training Loss: 0.34621 \nEpoch: 4258  | Training Loss: 0.21235 \nEpoch: 4258  | Training Loss: 0.14749 \nEpoch: 4258  | Validation balanced accuracy : 0.76304 \nEpoch: 4259  | Training Loss: 0.31592 \nEpoch: 4259  | Training Loss: 0.36810 \nEpoch: 4259  | Training Loss: 0.34626 \nEpoch: 4259  | Training Loss: 0.21234 \nEpoch: 4259  | Training Loss: 0.14756 \nEpoch: 4259  | Validation balanced accuracy : 0.76304 \nEpoch: 4260  | Training Loss: 0.31590 \nEpoch: 4260  | Training Loss: 0.36810 \nEpoch: 4260  | Training Loss: 0.34625 \nEpoch: 4260  | Training Loss: 0.21235 \nEpoch: 4260  | Training Loss: 0.14748 \nEpoch: 4260  | Validation balanced accuracy : 0.76304 \nEpoch: 4261  | Training Loss: 0.31597 \nEpoch: 4261  | Training Loss: 0.36815 \nEpoch: 4261  | Training Loss: 0.34622 \nEpoch: 4261  | Training Loss: 0.21236 \nEpoch: 4261  | Training Loss: 0.14737 \nEpoch: 4261  | Validation balanced accuracy : 0.76304 \nEpoch: 4262  | Training Loss: 0.31605 \nEpoch: 4262  | Training Loss: 0.36821 \nEpoch: 4262  | Training Loss: 0.34619 \nEpoch: 4262  | Training Loss: 0.21237 \nEpoch: 4262  | Training Loss: 0.14728 \nEpoch: 4262  | Validation balanced accuracy : 0.76304 \nEpoch: 4263  | Training Loss: 0.31611 \nEpoch: 4263  | Training Loss: 0.36821 \nEpoch: 4263  | Training Loss: 0.34621 \nEpoch: 4263  | Training Loss: 0.21235 \nEpoch: 4263  | Training Loss: 0.14749 \nEpoch: 4263  | Validation balanced accuracy : 0.76304 \nEpoch: 4264  | Training Loss: 0.31592 \nEpoch: 4264  | Training Loss: 0.36810 \nEpoch: 4264  | Training Loss: 0.34627 \nEpoch: 4264  | Training Loss: 0.21234 \nEpoch: 4264  | Training Loss: 0.14756 \nEpoch: 4264  | Validation balanced accuracy : 0.76304 \nEpoch: 4265  | Training Loss: 0.31590 \nEpoch: 4265  | Training Loss: 0.36810 \nEpoch: 4265  | Training Loss: 0.34626 \nEpoch: 4265  | Training Loss: 0.21235 \nEpoch: 4265  | Training Loss: 0.14748 \nEpoch: 4265  | Validation balanced accuracy : 0.76304 \nEpoch: 4266  | Training Loss: 0.31597 \nEpoch: 4266  | Training Loss: 0.36815 \nEpoch: 4266  | Training Loss: 0.34622 \nEpoch: 4266  | Training Loss: 0.21236 \nEpoch: 4266  | Training Loss: 0.14738 \nEpoch: 4266  | Validation balanced accuracy : 0.76304 \nEpoch: 4267  | Training Loss: 0.31604 \nEpoch: 4267  | Training Loss: 0.36820 \nEpoch: 4267  | Training Loss: 0.34620 \nEpoch: 4267  | Training Loss: 0.21236 \nEpoch: 4267  | Training Loss: 0.14729 \nEpoch: 4267  | Validation balanced accuracy : 0.76304 \nEpoch: 4268  | Training Loss: 0.31609 \nEpoch: 4268  | Training Loss: 0.36820 \nEpoch: 4268  | Training Loss: 0.34622 \nEpoch: 4268  | Training Loss: 0.21235 \nEpoch: 4268  | Training Loss: 0.14750 \nEpoch: 4268  | Validation balanced accuracy : 0.76304 \nEpoch: 4269  | Training Loss: 0.31591 \nEpoch: 4269  | Training Loss: 0.36809 \nEpoch: 4269  | Training Loss: 0.34627 \nEpoch: 4269  | Training Loss: 0.21234 \nEpoch: 4269  | Training Loss: 0.14757 \nEpoch: 4269  | Validation balanced accuracy : 0.76304 \nEpoch: 4270  | Training Loss: 0.31589 \nEpoch: 4270  | Training Loss: 0.36809 \nEpoch: 4270  | Training Loss: 0.34626 \nEpoch: 4270  | Training Loss: 0.21235 \nEpoch: 4270  | Training Loss: 0.14748 \nEpoch: 4270  | Validation balanced accuracy : 0.76304 \nEpoch: 4271  | Training Loss: 0.31597 \nEpoch: 4271  | Training Loss: 0.36815 \nEpoch: 4271  | Training Loss: 0.34623 \nEpoch: 4271  | Training Loss: 0.21235 \nEpoch: 4271  | Training Loss: 0.14736 \nEpoch: 4271  | Validation balanced accuracy : 0.76304 \nEpoch: 4272  | Training Loss: 0.31605 \nEpoch: 4272  | Training Loss: 0.36821 \nEpoch: 4272  | Training Loss: 0.34619 \nEpoch: 4272  | Training Loss: 0.21236 \nEpoch: 4272  | Training Loss: 0.14727 \nEpoch: 4272  | Validation balanced accuracy : 0.76304 \nEpoch: 4273  | Training Loss: 0.31611 \nEpoch: 4273  | Training Loss: 0.36821 \nEpoch: 4273  | Training Loss: 0.34622 \nEpoch: 4273  | Training Loss: 0.21235 \nEpoch: 4273  | Training Loss: 0.14750 \nEpoch: 4273  | Validation balanced accuracy : 0.76304 \nEpoch: 4274  | Training Loss: 0.31590 \nEpoch: 4274  | Training Loss: 0.36808 \nEpoch: 4274  | Training Loss: 0.34628 \nEpoch: 4274  | Training Loss: 0.21234 \nEpoch: 4274  | Training Loss: 0.14759 \nEpoch: 4274  | Validation balanced accuracy : 0.76304 \nEpoch: 4275  | Training Loss: 0.31587 \nEpoch: 4275  | Training Loss: 0.36808 \nEpoch: 4275  | Training Loss: 0.34627 \nEpoch: 4275  | Training Loss: 0.21234 \nEpoch: 4275  | Training Loss: 0.14750 \nEpoch: 4275  | Validation balanced accuracy : 0.76304 \nEpoch: 4276  | Training Loss: 0.31595 \nEpoch: 4276  | Training Loss: 0.36814 \nEpoch: 4276  | Training Loss: 0.34624 \nEpoch: 4276  | Training Loss: 0.21235 \nEpoch: 4276  | Training Loss: 0.14738 \nEpoch: 4276  | Validation balanced accuracy : 0.76304 \nEpoch: 4277  | Training Loss: 0.31603 \nEpoch: 4277  | Training Loss: 0.36820 \nEpoch: 4277  | Training Loss: 0.34620 \nEpoch: 4277  | Training Loss: 0.21236 \nEpoch: 4277  | Training Loss: 0.14728 \nEpoch: 4277  | Validation balanced accuracy : 0.76304 \nEpoch: 4278  | Training Loss: 0.31610 \nEpoch: 4278  | Training Loss: 0.36820 \nEpoch: 4278  | Training Loss: 0.34623 \nEpoch: 4278  | Training Loss: 0.21235 \nEpoch: 4278  | Training Loss: 0.14748 \nEpoch: 4278  | Validation balanced accuracy : 0.76304 \nEpoch: 4279  | Training Loss: 0.31592 \nEpoch: 4279  | Training Loss: 0.36810 \nEpoch: 4279  | Training Loss: 0.34628 \nEpoch: 4279  | Training Loss: 0.21234 \nEpoch: 4279  | Training Loss: 0.14755 \nEpoch: 4279  | Validation balanced accuracy : 0.76304 \nEpoch: 4280  | Training Loss: 0.31590 \nEpoch: 4280  | Training Loss: 0.36810 \nEpoch: 4280  | Training Loss: 0.34627 \nEpoch: 4280  | Training Loss: 0.21234 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4280  | Training Loss: 0.14746 \nEpoch: 4280  | Validation balanced accuracy : 0.76304 \nEpoch: 4281  | Training Loss: 0.31598 \nEpoch: 4281  | Training Loss: 0.36816 \nEpoch: 4281  | Training Loss: 0.34623 \nEpoch: 4281  | Training Loss: 0.21235 \nEpoch: 4281  | Training Loss: 0.14735 \nEpoch: 4281  | Validation balanced accuracy : 0.76304 \nEpoch: 4282  | Training Loss: 0.31605 \nEpoch: 4282  | Training Loss: 0.36821 \nEpoch: 4282  | Training Loss: 0.34620 \nEpoch: 4282  | Training Loss: 0.21236 \nEpoch: 4282  | Training Loss: 0.14726 \nEpoch: 4282  | Validation balanced accuracy : 0.76304 \nEpoch: 4283  | Training Loss: 0.31611 \nEpoch: 4283  | Training Loss: 0.36821 \nEpoch: 4283  | Training Loss: 0.34622 \nEpoch: 4283  | Training Loss: 0.21235 \nEpoch: 4283  | Training Loss: 0.14747 \nEpoch: 4283  | Validation balanced accuracy : 0.76304 \nEpoch: 4284  | Training Loss: 0.31593 \nEpoch: 4284  | Training Loss: 0.36810 \nEpoch: 4284  | Training Loss: 0.34628 \nEpoch: 4284  | Training Loss: 0.21234 \nEpoch: 4284  | Training Loss: 0.14754 \nEpoch: 4284  | Validation balanced accuracy : 0.76304 \nEpoch: 4285  | Training Loss: 0.31590 \nEpoch: 4285  | Training Loss: 0.36810 \nEpoch: 4285  | Training Loss: 0.34627 \nEpoch: 4285  | Training Loss: 0.21234 \nEpoch: 4285  | Training Loss: 0.14746 \nEpoch: 4285  | Validation balanced accuracy : 0.76304 \nEpoch: 4286  | Training Loss: 0.31597 \nEpoch: 4286  | Training Loss: 0.36816 \nEpoch: 4286  | Training Loss: 0.34623 \nEpoch: 4286  | Training Loss: 0.21235 \nEpoch: 4286  | Training Loss: 0.14735 \nEpoch: 4286  | Validation balanced accuracy : 0.76304 \nEpoch: 4287  | Training Loss: 0.31605 \nEpoch: 4287  | Training Loss: 0.36821 \nEpoch: 4287  | Training Loss: 0.34620 \nEpoch: 4287  | Training Loss: 0.21236 \nEpoch: 4287  | Training Loss: 0.14726 \nEpoch: 4287  | Validation balanced accuracy : 0.76304 \nEpoch: 4288  | Training Loss: 0.31611 \nEpoch: 4288  | Training Loss: 0.36821 \nEpoch: 4288  | Training Loss: 0.34623 \nEpoch: 4288  | Training Loss: 0.21235 \nEpoch: 4288  | Training Loss: 0.14747 \nEpoch: 4288  | Validation balanced accuracy : 0.76304 \nEpoch: 4289  | Training Loss: 0.31592 \nEpoch: 4289  | Training Loss: 0.36810 \nEpoch: 4289  | Training Loss: 0.34628 \nEpoch: 4289  | Training Loss: 0.21234 \nEpoch: 4289  | Training Loss: 0.14754 \nEpoch: 4289  | Validation balanced accuracy : 0.76304 \nEpoch: 4290  | Training Loss: 0.31590 \nEpoch: 4290  | Training Loss: 0.36810 \nEpoch: 4290  | Training Loss: 0.34627 \nEpoch: 4290  | Training Loss: 0.21234 \nEpoch: 4290  | Training Loss: 0.14746 \nEpoch: 4290  | Validation balanced accuracy : 0.76304 \nEpoch: 4291  | Training Loss: 0.31597 \nEpoch: 4291  | Training Loss: 0.36817 \nEpoch: 4291  | Training Loss: 0.34623 \nEpoch: 4291  | Training Loss: 0.21235 \nEpoch: 4291  | Training Loss: 0.14730 \nEpoch: 4291  | Validation balanced accuracy : 0.76304 \nEpoch: 4292  | Training Loss: 0.31609 \nEpoch: 4292  | Training Loss: 0.36820 \nEpoch: 4292  | Training Loss: 0.34623 \nEpoch: 4292  | Training Loss: 0.21234 \nEpoch: 4292  | Training Loss: 0.14747 \nEpoch: 4292  | Validation balanced accuracy : 0.76304 \nEpoch: 4293  | Training Loss: 0.31593 \nEpoch: 4293  | Training Loss: 0.36810 \nEpoch: 4293  | Training Loss: 0.34628 \nEpoch: 4293  | Training Loss: 0.21234 \nEpoch: 4293  | Training Loss: 0.14753 \nEpoch: 4293  | Validation balanced accuracy : 0.76304 \nEpoch: 4294  | Training Loss: 0.31591 \nEpoch: 4294  | Training Loss: 0.36811 \nEpoch: 4294  | Training Loss: 0.34627 \nEpoch: 4294  | Training Loss: 0.21234 \nEpoch: 4294  | Training Loss: 0.14743 \nEpoch: 4294  | Validation balanced accuracy : 0.76304 \nEpoch: 4295  | Training Loss: 0.31599 \nEpoch: 4295  | Training Loss: 0.36817 \nEpoch: 4295  | Training Loss: 0.34623 \nEpoch: 4295  | Training Loss: 0.21235 \nEpoch: 4295  | Training Loss: 0.14732 \nEpoch: 4295  | Validation balanced accuracy : 0.76304 \nEpoch: 4296  | Training Loss: 0.31607 \nEpoch: 4296  | Training Loss: 0.36822 \nEpoch: 4296  | Training Loss: 0.34620 \nEpoch: 4296  | Training Loss: 0.21236 \nEpoch: 4296  | Training Loss: 0.14724 \nEpoch: 4296  | Validation balanced accuracy : 0.76304 \nEpoch: 4297  | Training Loss: 0.31612 \nEpoch: 4297  | Training Loss: 0.36822 \nEpoch: 4297  | Training Loss: 0.34623 \nEpoch: 4297  | Training Loss: 0.21234 \nEpoch: 4297  | Training Loss: 0.14745 \nEpoch: 4297  | Validation balanced accuracy : 0.76304 \nEpoch: 4298  | Training Loss: 0.31593 \nEpoch: 4298  | Training Loss: 0.36811 \nEpoch: 4298  | Training Loss: 0.34628 \nEpoch: 4298  | Training Loss: 0.21233 \nEpoch: 4298  | Training Loss: 0.14753 \nEpoch: 4298  | Validation balanced accuracy : 0.76304 \nEpoch: 4299  | Training Loss: 0.31590 \nEpoch: 4299  | Training Loss: 0.36810 \nEpoch: 4299  | Training Loss: 0.34628 \nEpoch: 4299  | Training Loss: 0.21234 \nEpoch: 4299  | Training Loss: 0.14745 \nEpoch: 4299  | Validation balanced accuracy : 0.76304 \nEpoch: 4300  | Training Loss: 0.31598 \nEpoch: 4300  | Training Loss: 0.36816 \nEpoch: 4300  | Training Loss: 0.34624 \nEpoch: 4300  | Training Loss: 0.21235 \nEpoch: 4300  | Training Loss: 0.14734 \nEpoch: 4300  | Validation balanced accuracy : 0.76304 \nEpoch: 4301  | Training Loss: 0.31605 \nEpoch: 4301  | Training Loss: 0.36821 \nEpoch: 4301  | Training Loss: 0.34621 \nEpoch: 4301  | Training Loss: 0.21235 \nEpoch: 4301  | Training Loss: 0.14725 \nEpoch: 4301  | Validation balanced accuracy : 0.76304 \nEpoch: 4302  | Training Loss: 0.31611 \nEpoch: 4302  | Training Loss: 0.36821 \nEpoch: 4302  | Training Loss: 0.34624 \nEpoch: 4302  | Training Loss: 0.21234 \nEpoch: 4302  | Training Loss: 0.14746 \nEpoch: 4302  | Validation balanced accuracy : 0.76304 \nEpoch: 4303  | Training Loss: 0.31592 \nEpoch: 4303  | Training Loss: 0.36810 \nEpoch: 4303  | Training Loss: 0.34629 \nEpoch: 4303  | Training Loss: 0.21233 \nEpoch: 4303  | Training Loss: 0.14753 \nEpoch: 4303  | Validation balanced accuracy : 0.76304 \nEpoch: 4304  | Training Loss: 0.31590 \nEpoch: 4304  | Training Loss: 0.36810 \nEpoch: 4304  | Training Loss: 0.34628 \nEpoch: 4304  | Training Loss: 0.21234 \nEpoch: 4304  | Training Loss: 0.14745 \nEpoch: 4304  | Validation balanced accuracy : 0.76304 \nEpoch: 4305  | Training Loss: 0.31598 \nEpoch: 4305  | Training Loss: 0.36816 \nEpoch: 4305  | Training Loss: 0.34624 \nEpoch: 4305  | Training Loss: 0.21235 \nEpoch: 4305  | Training Loss: 0.14733 \nEpoch: 4305  | Validation balanced accuracy : 0.76304 \nEpoch: 4306  | Training Loss: 0.31605 \nEpoch: 4306  | Training Loss: 0.36822 \nEpoch: 4306  | Training Loss: 0.34621 \nEpoch: 4306  | Training Loss: 0.21235 \nEpoch: 4306  | Training Loss: 0.14724 \nEpoch: 4306  | Validation balanced accuracy : 0.76304 \nEpoch: 4307  | Training Loss: 0.31611 \nEpoch: 4307  | Training Loss: 0.36821 \nEpoch: 4307  | Training Loss: 0.34624 \nEpoch: 4307  | Training Loss: 0.21234 \nEpoch: 4307  | Training Loss: 0.14745 \nEpoch: 4307  | Validation balanced accuracy : 0.76304 \nEpoch: 4308  | Training Loss: 0.31593 \nEpoch: 4308  | Training Loss: 0.36810 \nEpoch: 4308  | Training Loss: 0.34629 \nEpoch: 4308  | Training Loss: 0.21233 \nEpoch: 4308  | Training Loss: 0.14753 \nEpoch: 4308  | Validation balanced accuracy : 0.76304 \nEpoch: 4309  | Training Loss: 0.31590 \nEpoch: 4309  | Training Loss: 0.36810 \nEpoch: 4309  | Training Loss: 0.34628 \nEpoch: 4309  | Training Loss: 0.21234 \nEpoch: 4309  | Training Loss: 0.14744 \nEpoch: 4309  | Validation balanced accuracy : 0.76304 \nEpoch: 4310  | Training Loss: 0.31598 \nEpoch: 4310  | Training Loss: 0.36817 \nEpoch: 4310  | Training Loss: 0.34624 \nEpoch: 4310  | Training Loss: 0.21235 \nEpoch: 4310  | Training Loss: 0.14728 \nEpoch: 4310  | Validation balanced accuracy : 0.76304 \nEpoch: 4311  | Training Loss: 0.31610 \nEpoch: 4311  | Training Loss: 0.36820 \nEpoch: 4311  | Training Loss: 0.34624 \nEpoch: 4311  | Training Loss: 0.21234 \nEpoch: 4311  | Training Loss: 0.14745 \nEpoch: 4311  | Validation balanced accuracy : 0.76304 \nEpoch: 4312  | Training Loss: 0.31593 \nEpoch: 4312  | Training Loss: 0.36811 \nEpoch: 4312  | Training Loss: 0.34629 \nEpoch: 4312  | Training Loss: 0.21233 \nEpoch: 4312  | Training Loss: 0.14751 \nEpoch: 4312  | Validation balanced accuracy : 0.76304 \nEpoch: 4313  | Training Loss: 0.31591 \nEpoch: 4313  | Training Loss: 0.36811 \nEpoch: 4313  | Training Loss: 0.34628 \nEpoch: 4313  | Training Loss: 0.21234 \nEpoch: 4313  | Training Loss: 0.14742 \nEpoch: 4313  | Validation balanced accuracy : 0.76304 \nEpoch: 4314  | Training Loss: 0.31599 \nEpoch: 4314  | Training Loss: 0.36817 \nEpoch: 4314  | Training Loss: 0.34624 \nEpoch: 4314  | Training Loss: 0.21235 \nEpoch: 4314  | Training Loss: 0.14731 \nEpoch: 4314  | Validation balanced accuracy : 0.76304 \nEpoch: 4315  | Training Loss: 0.31607 \nEpoch: 4315  | Training Loss: 0.36822 \nEpoch: 4315  | Training Loss: 0.34621 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4315  | Training Loss: 0.21235 \nEpoch: 4315  | Training Loss: 0.14722 \nEpoch: 4315  | Validation balanced accuracy : 0.76304 \nEpoch: 4316  | Training Loss: 0.31613 \nEpoch: 4316  | Training Loss: 0.36822 \nEpoch: 4316  | Training Loss: 0.34624 \nEpoch: 4316  | Training Loss: 0.21234 \nEpoch: 4316  | Training Loss: 0.14744 \nEpoch: 4316  | Validation balanced accuracy : 0.76304 \nEpoch: 4317  | Training Loss: 0.31593 \nEpoch: 4317  | Training Loss: 0.36811 \nEpoch: 4317  | Training Loss: 0.34629 \nEpoch: 4317  | Training Loss: 0.21233 \nEpoch: 4317  | Training Loss: 0.14752 \nEpoch: 4317  | Validation balanced accuracy : 0.76304 \nEpoch: 4318  | Training Loss: 0.31591 \nEpoch: 4318  | Training Loss: 0.36811 \nEpoch: 4318  | Training Loss: 0.34629 \nEpoch: 4318  | Training Loss: 0.21233 \nEpoch: 4318  | Training Loss: 0.14744 \nEpoch: 4318  | Validation balanced accuracy : 0.76304 \nEpoch: 4319  | Training Loss: 0.31598 \nEpoch: 4319  | Training Loss: 0.36816 \nEpoch: 4319  | Training Loss: 0.34625 \nEpoch: 4319  | Training Loss: 0.21234 \nEpoch: 4319  | Training Loss: 0.14733 \nEpoch: 4319  | Validation balanced accuracy : 0.76304 \nEpoch: 4320  | Training Loss: 0.31605 \nEpoch: 4320  | Training Loss: 0.36821 \nEpoch: 4320  | Training Loss: 0.34622 \nEpoch: 4320  | Training Loss: 0.21235 \nEpoch: 4320  | Training Loss: 0.14724 \nEpoch: 4320  | Validation balanced accuracy : 0.76304 \nEpoch: 4321  | Training Loss: 0.31611 \nEpoch: 4321  | Training Loss: 0.36821 \nEpoch: 4321  | Training Loss: 0.34625 \nEpoch: 4321  | Training Loss: 0.21234 \nEpoch: 4321  | Training Loss: 0.14745 \nEpoch: 4321  | Validation balanced accuracy : 0.76304 \nEpoch: 4322  | Training Loss: 0.31593 \nEpoch: 4322  | Training Loss: 0.36810 \nEpoch: 4322  | Training Loss: 0.34630 \nEpoch: 4322  | Training Loss: 0.21233 \nEpoch: 4322  | Training Loss: 0.14752 \nEpoch: 4322  | Validation balanced accuracy : 0.76304 \nEpoch: 4323  | Training Loss: 0.31590 \nEpoch: 4323  | Training Loss: 0.36810 \nEpoch: 4323  | Training Loss: 0.34629 \nEpoch: 4323  | Training Loss: 0.21233 \nEpoch: 4323  | Training Loss: 0.14743 \nEpoch: 4323  | Validation balanced accuracy : 0.76304 \nEpoch: 4324  | Training Loss: 0.31598 \nEpoch: 4324  | Training Loss: 0.36816 \nEpoch: 4324  | Training Loss: 0.34625 \nEpoch: 4324  | Training Loss: 0.21234 \nEpoch: 4324  | Training Loss: 0.14732 \nEpoch: 4324  | Validation balanced accuracy : 0.76304 \nEpoch: 4325  | Training Loss: 0.31606 \nEpoch: 4325  | Training Loss: 0.36822 \nEpoch: 4325  | Training Loss: 0.34622 \nEpoch: 4325  | Training Loss: 0.21235 \nEpoch: 4325  | Training Loss: 0.14723 \nEpoch: 4325  | Validation balanced accuracy : 0.76304 \nEpoch: 4326  | Training Loss: 0.31612 \nEpoch: 4326  | Training Loss: 0.36822 \nEpoch: 4326  | Training Loss: 0.34625 \nEpoch: 4326  | Training Loss: 0.21234 \nEpoch: 4326  | Training Loss: 0.14744 \nEpoch: 4326  | Validation balanced accuracy : 0.76304 \nEpoch: 4327  | Training Loss: 0.31593 \nEpoch: 4327  | Training Loss: 0.36811 \nEpoch: 4327  | Training Loss: 0.34630 \nEpoch: 4327  | Training Loss: 0.21233 \nEpoch: 4327  | Training Loss: 0.14751 \nEpoch: 4327  | Validation balanced accuracy : 0.76304 \nEpoch: 4328  | Training Loss: 0.31591 \nEpoch: 4328  | Training Loss: 0.36811 \nEpoch: 4328  | Training Loss: 0.34629 \nEpoch: 4328  | Training Loss: 0.21233 \nEpoch: 4328  | Training Loss: 0.14743 \nEpoch: 4328  | Validation balanced accuracy : 0.76304 \nEpoch: 4329  | Training Loss: 0.31598 \nEpoch: 4329  | Training Loss: 0.36817 \nEpoch: 4329  | Training Loss: 0.34625 \nEpoch: 4329  | Training Loss: 0.21234 \nEpoch: 4329  | Training Loss: 0.14727 \nEpoch: 4329  | Validation balanced accuracy : 0.76304 \nEpoch: 4330  | Training Loss: 0.31610 \nEpoch: 4330  | Training Loss: 0.36821 \nEpoch: 4330  | Training Loss: 0.34625 \nEpoch: 4330  | Training Loss: 0.21233 \nEpoch: 4330  | Training Loss: 0.14744 \nEpoch: 4330  | Validation balanced accuracy : 0.76304 \nEpoch: 4331  | Training Loss: 0.31593 \nEpoch: 4331  | Training Loss: 0.36811 \nEpoch: 4331  | Training Loss: 0.34630 \nEpoch: 4331  | Training Loss: 0.21232 \nEpoch: 4331  | Training Loss: 0.14750 \nEpoch: 4331  | Validation balanced accuracy : 0.76304 \nEpoch: 4332  | Training Loss: 0.31592 \nEpoch: 4332  | Training Loss: 0.36811 \nEpoch: 4332  | Training Loss: 0.34629 \nEpoch: 4332  | Training Loss: 0.21233 \nEpoch: 4332  | Training Loss: 0.14741 \nEpoch: 4332  | Validation balanced accuracy : 0.76304 \nEpoch: 4333  | Training Loss: 0.31600 \nEpoch: 4333  | Training Loss: 0.36817 \nEpoch: 4333  | Training Loss: 0.34625 \nEpoch: 4333  | Training Loss: 0.21234 \nEpoch: 4333  | Training Loss: 0.14729 \nEpoch: 4333  | Validation balanced accuracy : 0.76304 \nEpoch: 4334  | Training Loss: 0.31607 \nEpoch: 4334  | Training Loss: 0.36823 \nEpoch: 4334  | Training Loss: 0.34622 \nEpoch: 4334  | Training Loss: 0.21235 \nEpoch: 4334  | Training Loss: 0.14721 \nEpoch: 4334  | Validation balanced accuracy : 0.76304 \nEpoch: 4335  | Training Loss: 0.31613 \nEpoch: 4335  | Training Loss: 0.36822 \nEpoch: 4335  | Training Loss: 0.34625 \nEpoch: 4335  | Training Loss: 0.21233 \nEpoch: 4335  | Training Loss: 0.14743 \nEpoch: 4335  | Validation balanced accuracy : 0.76304 \nEpoch: 4336  | Training Loss: 0.31594 \nEpoch: 4336  | Training Loss: 0.36811 \nEpoch: 4336  | Training Loss: 0.34630 \nEpoch: 4336  | Training Loss: 0.21232 \nEpoch: 4336  | Training Loss: 0.14751 \nEpoch: 4336  | Validation balanced accuracy : 0.76304 \nEpoch: 4337  | Training Loss: 0.31591 \nEpoch: 4337  | Training Loss: 0.36811 \nEpoch: 4337  | Training Loss: 0.34629 \nEpoch: 4337  | Training Loss: 0.21233 \nEpoch: 4337  | Training Loss: 0.14742 \nEpoch: 4337  | Validation balanced accuracy : 0.76304 \nEpoch: 4338  | Training Loss: 0.31598 \nEpoch: 4338  | Training Loss: 0.36816 \nEpoch: 4338  | Training Loss: 0.34626 \nEpoch: 4338  | Training Loss: 0.21234 \nEpoch: 4338  | Training Loss: 0.14731 \nEpoch: 4338  | Validation balanced accuracy : 0.76304 \nEpoch: 4339  | Training Loss: 0.31606 \nEpoch: 4339  | Training Loss: 0.36822 \nEpoch: 4339  | Training Loss: 0.34623 \nEpoch: 4339  | Training Loss: 0.21234 \nEpoch: 4339  | Training Loss: 0.14722 \nEpoch: 4339  | Validation balanced accuracy : 0.76304 \nEpoch: 4340  | Training Loss: 0.31612 \nEpoch: 4340  | Training Loss: 0.36822 \nEpoch: 4340  | Training Loss: 0.34625 \nEpoch: 4340  | Training Loss: 0.21233 \nEpoch: 4340  | Training Loss: 0.14743 \nEpoch: 4340  | Validation balanced accuracy : 0.76304 \nEpoch: 4341  | Training Loss: 0.31593 \nEpoch: 4341  | Training Loss: 0.36811 \nEpoch: 4341  | Training Loss: 0.34631 \nEpoch: 4341  | Training Loss: 0.21232 \nEpoch: 4341  | Training Loss: 0.14751 \nEpoch: 4341  | Validation balanced accuracy : 0.76304 \nEpoch: 4342  | Training Loss: 0.31591 \nEpoch: 4342  | Training Loss: 0.36811 \nEpoch: 4342  | Training Loss: 0.34630 \nEpoch: 4342  | Training Loss: 0.21233 \nEpoch: 4342  | Training Loss: 0.14742 \nEpoch: 4342  | Validation balanced accuracy : 0.76304 \nEpoch: 4343  | Training Loss: 0.31598 \nEpoch: 4343  | Training Loss: 0.36816 \nEpoch: 4343  | Training Loss: 0.34626 \nEpoch: 4343  | Training Loss: 0.21234 \nEpoch: 4343  | Training Loss: 0.14731 \nEpoch: 4343  | Validation balanced accuracy : 0.76304 \nEpoch: 4344  | Training Loss: 0.31606 \nEpoch: 4344  | Training Loss: 0.36822 \nEpoch: 4344  | Training Loss: 0.34623 \nEpoch: 4344  | Training Loss: 0.21234 \nEpoch: 4344  | Training Loss: 0.14722 \nEpoch: 4344  | Validation balanced accuracy : 0.76304 \nEpoch: 4345  | Training Loss: 0.31612 \nEpoch: 4345  | Training Loss: 0.36822 \nEpoch: 4345  | Training Loss: 0.34626 \nEpoch: 4345  | Training Loss: 0.21233 \nEpoch: 4345  | Training Loss: 0.14743 \nEpoch: 4345  | Validation balanced accuracy : 0.76304 \nEpoch: 4346  | Training Loss: 0.31593 \nEpoch: 4346  | Training Loss: 0.36811 \nEpoch: 4346  | Training Loss: 0.34631 \nEpoch: 4346  | Training Loss: 0.21232 \nEpoch: 4346  | Training Loss: 0.14750 \nEpoch: 4346  | Validation balanced accuracy : 0.76304 \nEpoch: 4347  | Training Loss: 0.31591 \nEpoch: 4347  | Training Loss: 0.36811 \nEpoch: 4347  | Training Loss: 0.34630 \nEpoch: 4347  | Training Loss: 0.21233 \nEpoch: 4347  | Training Loss: 0.14741 \nEpoch: 4347  | Validation balanced accuracy : 0.76304 \nEpoch: 4348  | Training Loss: 0.31598 \nEpoch: 4348  | Training Loss: 0.36817 \nEpoch: 4348  | Training Loss: 0.34625 \nEpoch: 4348  | Training Loss: 0.21234 \nEpoch: 4348  | Training Loss: 0.14725 \nEpoch: 4348  | Validation balanced accuracy : 0.76304 \nEpoch: 4349  | Training Loss: 0.31610 \nEpoch: 4349  | Training Loss: 0.36821 \nEpoch: 4349  | Training Loss: 0.34626 \nEpoch: 4349  | Training Loss: 0.21233 \nEpoch: 4349  | Training Loss: 0.14743 \nEpoch: 4349  | Validation balanced accuracy : 0.76304 \nEpoch: 4350  | Training Loss: 0.31593 \nEpoch: 4350  | Training Loss: 0.36811 \nEpoch: 4350  | Training Loss: 0.34631 \nEpoch: 4350  | Training Loss: 0.21232 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4350  | Training Loss: 0.14748 \nEpoch: 4350  | Validation balanced accuracy : 0.76304 \nEpoch: 4351  | Training Loss: 0.31592 \nEpoch: 4351  | Training Loss: 0.36812 \nEpoch: 4351  | Training Loss: 0.34630 \nEpoch: 4351  | Training Loss: 0.21233 \nEpoch: 4351  | Training Loss: 0.14739 \nEpoch: 4351  | Validation balanced accuracy : 0.76304 \nEpoch: 4352  | Training Loss: 0.31600 \nEpoch: 4352  | Training Loss: 0.36818 \nEpoch: 4352  | Training Loss: 0.34626 \nEpoch: 4352  | Training Loss: 0.21234 \nEpoch: 4352  | Training Loss: 0.14728 \nEpoch: 4352  | Validation balanced accuracy : 0.76304 \nEpoch: 4353  | Training Loss: 0.31607 \nEpoch: 4353  | Training Loss: 0.36823 \nEpoch: 4353  | Training Loss: 0.34623 \nEpoch: 4353  | Training Loss: 0.21234 \nEpoch: 4353  | Training Loss: 0.14720 \nEpoch: 4353  | Validation balanced accuracy : 0.76304 \nEpoch: 4354  | Training Loss: 0.31613 \nEpoch: 4354  | Training Loss: 0.36822 \nEpoch: 4354  | Training Loss: 0.34626 \nEpoch: 4354  | Training Loss: 0.21233 \nEpoch: 4354  | Training Loss: 0.14741 \nEpoch: 4354  | Validation balanced accuracy : 0.76304 \nEpoch: 4355  | Training Loss: 0.31594 \nEpoch: 4355  | Training Loss: 0.36811 \nEpoch: 4355  | Training Loss: 0.34631 \nEpoch: 4355  | Training Loss: 0.21232 \nEpoch: 4355  | Training Loss: 0.14749 \nEpoch: 4355  | Validation balanced accuracy : 0.76304 \nEpoch: 4356  | Training Loss: 0.31591 \nEpoch: 4356  | Training Loss: 0.36811 \nEpoch: 4356  | Training Loss: 0.34630 \nEpoch: 4356  | Training Loss: 0.21232 \nEpoch: 4356  | Training Loss: 0.14741 \nEpoch: 4356  | Validation balanced accuracy : 0.76304 \nEpoch: 4357  | Training Loss: 0.31598 \nEpoch: 4357  | Training Loss: 0.36816 \nEpoch: 4357  | Training Loss: 0.34627 \nEpoch: 4357  | Training Loss: 0.21233 \nEpoch: 4357  | Training Loss: 0.14730 \nEpoch: 4357  | Validation balanced accuracy : 0.76304 \nEpoch: 4358  | Training Loss: 0.31606 \nEpoch: 4358  | Training Loss: 0.36822 \nEpoch: 4358  | Training Loss: 0.34624 \nEpoch: 4358  | Training Loss: 0.21234 \nEpoch: 4358  | Training Loss: 0.14721 \nEpoch: 4358  | Validation balanced accuracy : 0.76304 \nEpoch: 4359  | Training Loss: 0.31612 \nEpoch: 4359  | Training Loss: 0.36822 \nEpoch: 4359  | Training Loss: 0.34626 \nEpoch: 4359  | Training Loss: 0.21233 \nEpoch: 4359  | Training Loss: 0.14742 \nEpoch: 4359  | Validation balanced accuracy : 0.76304 \nEpoch: 4360  | Training Loss: 0.31593 \nEpoch: 4360  | Training Loss: 0.36811 \nEpoch: 4360  | Training Loss: 0.34632 \nEpoch: 4360  | Training Loss: 0.21232 \nEpoch: 4360  | Training Loss: 0.14749 \nEpoch: 4360  | Validation balanced accuracy : 0.76304 \nEpoch: 4361  | Training Loss: 0.31591 \nEpoch: 4361  | Training Loss: 0.36811 \nEpoch: 4361  | Training Loss: 0.34631 \nEpoch: 4361  | Training Loss: 0.21232 \nEpoch: 4361  | Training Loss: 0.14741 \nEpoch: 4361  | Validation balanced accuracy : 0.76304 \nEpoch: 4362  | Training Loss: 0.31599 \nEpoch: 4362  | Training Loss: 0.36817 \nEpoch: 4362  | Training Loss: 0.34627 \nEpoch: 4362  | Training Loss: 0.21233 \nEpoch: 4362  | Training Loss: 0.14729 \nEpoch: 4362  | Validation balanced accuracy : 0.76304 \nEpoch: 4363  | Training Loss: 0.31606 \nEpoch: 4363  | Training Loss: 0.36822 \nEpoch: 4363  | Training Loss: 0.34624 \nEpoch: 4363  | Training Loss: 0.21234 \nEpoch: 4363  | Training Loss: 0.14720 \nEpoch: 4363  | Validation balanced accuracy : 0.76304 \nEpoch: 4364  | Training Loss: 0.31612 \nEpoch: 4364  | Training Loss: 0.36822 \nEpoch: 4364  | Training Loss: 0.34627 \nEpoch: 4364  | Training Loss: 0.21233 \nEpoch: 4364  | Training Loss: 0.14741 \nEpoch: 4364  | Validation balanced accuracy : 0.76304 \nEpoch: 4365  | Training Loss: 0.31594 \nEpoch: 4365  | Training Loss: 0.36811 \nEpoch: 4365  | Training Loss: 0.34632 \nEpoch: 4365  | Training Loss: 0.21232 \nEpoch: 4365  | Training Loss: 0.14749 \nEpoch: 4365  | Validation balanced accuracy : 0.76304 \nEpoch: 4366  | Training Loss: 0.31591 \nEpoch: 4366  | Training Loss: 0.36811 \nEpoch: 4366  | Training Loss: 0.34631 \nEpoch: 4366  | Training Loss: 0.21232 \nEpoch: 4366  | Training Loss: 0.14740 \nEpoch: 4366  | Validation balanced accuracy : 0.76304 \nEpoch: 4367  | Training Loss: 0.31599 \nEpoch: 4367  | Training Loss: 0.36817 \nEpoch: 4367  | Training Loss: 0.34626 \nEpoch: 4367  | Training Loss: 0.21233 \nEpoch: 4367  | Training Loss: 0.14724 \nEpoch: 4367  | Validation balanced accuracy : 0.76304 \nEpoch: 4368  | Training Loss: 0.31610 \nEpoch: 4368  | Training Loss: 0.36825 \nEpoch: 4368  | Training Loss: 0.34622 \nEpoch: 4368  | Training Loss: 0.21234 \nEpoch: 4368  | Training Loss: 0.14715 \nEpoch: 4368  | Validation balanced accuracy : 0.76304 \nEpoch: 4369  | Training Loss: 0.31616 \nEpoch: 4369  | Training Loss: 0.36824 \nEpoch: 4369  | Training Loss: 0.34625 \nEpoch: 4369  | Training Loss: 0.21233 \nEpoch: 4369  | Training Loss: 0.14737 \nEpoch: 4369  | Validation balanced accuracy : 0.76304 \nEpoch: 4370  | Training Loss: 0.31596 \nEpoch: 4370  | Training Loss: 0.36813 \nEpoch: 4370  | Training Loss: 0.34631 \nEpoch: 4370  | Training Loss: 0.21232 \nEpoch: 4370  | Training Loss: 0.14747 \nEpoch: 4370  | Validation balanced accuracy : 0.76304 \nEpoch: 4371  | Training Loss: 0.31592 \nEpoch: 4371  | Training Loss: 0.36812 \nEpoch: 4371  | Training Loss: 0.34631 \nEpoch: 4371  | Training Loss: 0.21232 \nEpoch: 4371  | Training Loss: 0.14740 \nEpoch: 4371  | Validation balanced accuracy : 0.76304 \nEpoch: 4372  | Training Loss: 0.31599 \nEpoch: 4372  | Training Loss: 0.36817 \nEpoch: 4372  | Training Loss: 0.34628 \nEpoch: 4372  | Training Loss: 0.21233 \nEpoch: 4372  | Training Loss: 0.14729 \nEpoch: 4372  | Validation balanced accuracy : 0.76304 \nEpoch: 4373  | Training Loss: 0.31606 \nEpoch: 4373  | Training Loss: 0.36822 \nEpoch: 4373  | Training Loss: 0.34625 \nEpoch: 4373  | Training Loss: 0.21234 \nEpoch: 4373  | Training Loss: 0.14721 \nEpoch: 4373  | Validation balanced accuracy : 0.76304 \nEpoch: 4374  | Training Loss: 0.31612 \nEpoch: 4374  | Training Loss: 0.36822 \nEpoch: 4374  | Training Loss: 0.34627 \nEpoch: 4374  | Training Loss: 0.21232 \nEpoch: 4374  | Training Loss: 0.14742 \nEpoch: 4374  | Validation balanced accuracy : 0.76304 \nEpoch: 4375  | Training Loss: 0.31593 \nEpoch: 4375  | Training Loss: 0.36811 \nEpoch: 4375  | Training Loss: 0.34632 \nEpoch: 4375  | Training Loss: 0.21231 \nEpoch: 4375  | Training Loss: 0.14749 \nEpoch: 4375  | Validation balanced accuracy : 0.76304 \nEpoch: 4376  | Training Loss: 0.31591 \nEpoch: 4376  | Training Loss: 0.36811 \nEpoch: 4376  | Training Loss: 0.34631 \nEpoch: 4376  | Training Loss: 0.21232 \nEpoch: 4376  | Training Loss: 0.14740 \nEpoch: 4376  | Validation balanced accuracy : 0.76304 \nEpoch: 4377  | Training Loss: 0.31598 \nEpoch: 4377  | Training Loss: 0.36817 \nEpoch: 4377  | Training Loss: 0.34628 \nEpoch: 4377  | Training Loss: 0.21233 \nEpoch: 4377  | Training Loss: 0.14729 \nEpoch: 4377  | Validation balanced accuracy : 0.76304 \nEpoch: 4378  | Training Loss: 0.31606 \nEpoch: 4378  | Training Loss: 0.36822 \nEpoch: 4378  | Training Loss: 0.34625 \nEpoch: 4378  | Training Loss: 0.21234 \nEpoch: 4378  | Training Loss: 0.14719 \nEpoch: 4378  | Validation balanced accuracy : 0.76304 \nEpoch: 4379  | Training Loss: 0.31612 \nEpoch: 4379  | Training Loss: 0.36822 \nEpoch: 4379  | Training Loss: 0.34627 \nEpoch: 4379  | Training Loss: 0.21232 \nEpoch: 4379  | Training Loss: 0.14740 \nEpoch: 4379  | Validation balanced accuracy : 0.76304 \nEpoch: 4380  | Training Loss: 0.31594 \nEpoch: 4380  | Training Loss: 0.36811 \nEpoch: 4380  | Training Loss: 0.34632 \nEpoch: 4380  | Training Loss: 0.21231 \nEpoch: 4380  | Training Loss: 0.14748 \nEpoch: 4380  | Validation balanced accuracy : 0.76304 \nEpoch: 4381  | Training Loss: 0.31591 \nEpoch: 4381  | Training Loss: 0.36811 \nEpoch: 4381  | Training Loss: 0.34631 \nEpoch: 4381  | Training Loss: 0.21232 \nEpoch: 4381  | Training Loss: 0.14739 \nEpoch: 4381  | Validation balanced accuracy : 0.76304 \nEpoch: 4382  | Training Loss: 0.31599 \nEpoch: 4382  | Training Loss: 0.36817 \nEpoch: 4382  | Training Loss: 0.34628 \nEpoch: 4382  | Training Loss: 0.21233 \nEpoch: 4382  | Training Loss: 0.14728 \nEpoch: 4382  | Validation balanced accuracy : 0.76304 \nEpoch: 4383  | Training Loss: 0.31607 \nEpoch: 4383  | Training Loss: 0.36822 \nEpoch: 4383  | Training Loss: 0.34625 \nEpoch: 4383  | Training Loss: 0.21233 \nEpoch: 4383  | Training Loss: 0.14719 \nEpoch: 4383  | Validation balanced accuracy : 0.76304 \nEpoch: 4384  | Training Loss: 0.31612 \nEpoch: 4384  | Training Loss: 0.36822 \nEpoch: 4384  | Training Loss: 0.34627 \nEpoch: 4384  | Training Loss: 0.21232 \nEpoch: 4384  | Training Loss: 0.14740 \nEpoch: 4384  | Validation balanced accuracy : 0.76304 \nEpoch: 4385  | Training Loss: 0.31594 \nEpoch: 4385  | Training Loss: 0.36811 \nEpoch: 4385  | Training Loss: 0.34633 \nEpoch: 4385  | Training Loss: 0.21231 \nEpoch: 4385  | Training Loss: 0.14748 \nEpoch: 4385  | Validation balanced accuracy : 0.76304 \nEpoch: 4386  | Training Loss: 0.31591 \nEpoch: 4386  | Training Loss: 0.36811 \nEpoch: 4386  | Training Loss: 0.34632 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4386  | Training Loss: 0.21232 \nEpoch: 4386  | Training Loss: 0.14739 \nEpoch: 4386  | Validation balanced accuracy : 0.76304 \nEpoch: 4387  | Training Loss: 0.31599 \nEpoch: 4387  | Training Loss: 0.36817 \nEpoch: 4387  | Training Loss: 0.34627 \nEpoch: 4387  | Training Loss: 0.21233 \nEpoch: 4387  | Training Loss: 0.14724 \nEpoch: 4387  | Validation balanced accuracy : 0.76304 \nEpoch: 4388  | Training Loss: 0.31610 \nEpoch: 4388  | Training Loss: 0.36825 \nEpoch: 4388  | Training Loss: 0.34623 \nEpoch: 4388  | Training Loss: 0.21234 \nEpoch: 4388  | Training Loss: 0.14713 \nEpoch: 4388  | Validation balanced accuracy : 0.76304 \nEpoch: 4389  | Training Loss: 0.31617 \nEpoch: 4389  | Training Loss: 0.36825 \nEpoch: 4389  | Training Loss: 0.34626 \nEpoch: 4389  | Training Loss: 0.21232 \nEpoch: 4389  | Training Loss: 0.14734 \nEpoch: 4389  | Validation balanced accuracy : 0.76304 \nEpoch: 4390  | Training Loss: 0.31598 \nEpoch: 4390  | Training Loss: 0.36814 \nEpoch: 4390  | Training Loss: 0.34631 \nEpoch: 4390  | Training Loss: 0.21231 \nEpoch: 4390  | Training Loss: 0.14743 \nEpoch: 4390  | Validation balanced accuracy : 0.76304 \nEpoch: 4391  | Training Loss: 0.31594 \nEpoch: 4391  | Training Loss: 0.36813 \nEpoch: 4391  | Training Loss: 0.34631 \nEpoch: 4391  | Training Loss: 0.21232 \nEpoch: 4391  | Training Loss: 0.14736 \nEpoch: 4391  | Validation balanced accuracy : 0.76304 \nEpoch: 4392  | Training Loss: 0.31600 \nEpoch: 4392  | Training Loss: 0.36818 \nEpoch: 4392  | Training Loss: 0.34628 \nEpoch: 4392  | Training Loss: 0.21232 \nEpoch: 4392  | Training Loss: 0.14727 \nEpoch: 4392  | Validation balanced accuracy : 0.76304 \nEpoch: 4393  | Training Loss: 0.31607 \nEpoch: 4393  | Training Loss: 0.36823 \nEpoch: 4393  | Training Loss: 0.34625 \nEpoch: 4393  | Training Loss: 0.21233 \nEpoch: 4393  | Training Loss: 0.14719 \nEpoch: 4393  | Validation balanced accuracy : 0.76304 \nEpoch: 4394  | Training Loss: 0.31612 \nEpoch: 4394  | Training Loss: 0.36822 \nEpoch: 4394  | Training Loss: 0.34628 \nEpoch: 4394  | Training Loss: 0.21232 \nEpoch: 4394  | Training Loss: 0.14740 \nEpoch: 4394  | Validation balanced accuracy : 0.76304 \nEpoch: 4395  | Training Loss: 0.31593 \nEpoch: 4395  | Training Loss: 0.36811 \nEpoch: 4395  | Training Loss: 0.34633 \nEpoch: 4395  | Training Loss: 0.21231 \nEpoch: 4395  | Training Loss: 0.14748 \nEpoch: 4395  | Validation balanced accuracy : 0.76304 \nEpoch: 4396  | Training Loss: 0.31591 \nEpoch: 4396  | Training Loss: 0.36811 \nEpoch: 4396  | Training Loss: 0.34632 \nEpoch: 4396  | Training Loss: 0.21231 \nEpoch: 4396  | Training Loss: 0.14739 \nEpoch: 4396  | Validation balanced accuracy : 0.76304 \nEpoch: 4397  | Training Loss: 0.31598 \nEpoch: 4397  | Training Loss: 0.36817 \nEpoch: 4397  | Training Loss: 0.34628 \nEpoch: 4397  | Training Loss: 0.21232 \nEpoch: 4397  | Training Loss: 0.14724 \nEpoch: 4397  | Validation balanced accuracy : 0.76304 \nEpoch: 4398  | Training Loss: 0.31609 \nEpoch: 4398  | Training Loss: 0.36825 \nEpoch: 4398  | Training Loss: 0.34624 \nEpoch: 4398  | Training Loss: 0.21234 \nEpoch: 4398  | Training Loss: 0.14713 \nEpoch: 4398  | Validation balanced accuracy : 0.76304 \nEpoch: 4399  | Training Loss: 0.31617 \nEpoch: 4399  | Training Loss: 0.36825 \nEpoch: 4399  | Training Loss: 0.34626 \nEpoch: 4399  | Training Loss: 0.21232 \nEpoch: 4399  | Training Loss: 0.14734 \nEpoch: 4399  | Validation balanced accuracy : 0.76304 \nEpoch: 4400  | Training Loss: 0.31598 \nEpoch: 4400  | Training Loss: 0.36814 \nEpoch: 4400  | Training Loss: 0.34631 \nEpoch: 4400  | Training Loss: 0.21231 \nEpoch: 4400  | Training Loss: 0.14742 \nEpoch: 4400  | Validation balanced accuracy : 0.76304 \nEpoch: 4401  | Training Loss: 0.31594 \nEpoch: 4401  | Training Loss: 0.36813 \nEpoch: 4401  | Training Loss: 0.34631 \nEpoch: 4401  | Training Loss: 0.21231 \nEpoch: 4401  | Training Loss: 0.14735 \nEpoch: 4401  | Validation balanced accuracy : 0.76304 \nEpoch: 4402  | Training Loss: 0.31601 \nEpoch: 4402  | Training Loss: 0.36818 \nEpoch: 4402  | Training Loss: 0.34628 \nEpoch: 4402  | Training Loss: 0.21232 \nEpoch: 4402  | Training Loss: 0.14726 \nEpoch: 4402  | Validation balanced accuracy : 0.76304 \nEpoch: 4403  | Training Loss: 0.31607 \nEpoch: 4403  | Training Loss: 0.36823 \nEpoch: 4403  | Training Loss: 0.34625 \nEpoch: 4403  | Training Loss: 0.21233 \nEpoch: 4403  | Training Loss: 0.14718 \nEpoch: 4403  | Validation balanced accuracy : 0.76304 \nEpoch: 4404  | Training Loss: 0.31612 \nEpoch: 4404  | Training Loss: 0.36822 \nEpoch: 4404  | Training Loss: 0.34628 \nEpoch: 4404  | Training Loss: 0.21231 \nEpoch: 4404  | Training Loss: 0.14741 \nEpoch: 4404  | Validation balanced accuracy : 0.76304 \nEpoch: 4405  | Training Loss: 0.31592 \nEpoch: 4405  | Training Loss: 0.36810 \nEpoch: 4405  | Training Loss: 0.34634 \nEpoch: 4405  | Training Loss: 0.21230 \nEpoch: 4405  | Training Loss: 0.14749 \nEpoch: 4405  | Validation balanced accuracy : 0.76304 \nEpoch: 4406  | Training Loss: 0.31590 \nEpoch: 4406  | Training Loss: 0.36810 \nEpoch: 4406  | Training Loss: 0.34633 \nEpoch: 4406  | Training Loss: 0.21231 \nEpoch: 4406  | Training Loss: 0.14741 \nEpoch: 4406  | Validation balanced accuracy : 0.76304 \nEpoch: 4407  | Training Loss: 0.31597 \nEpoch: 4407  | Training Loss: 0.36817 \nEpoch: 4407  | Training Loss: 0.34629 \nEpoch: 4407  | Training Loss: 0.21232 \nEpoch: 4407  | Training Loss: 0.14724 \nEpoch: 4407  | Validation balanced accuracy : 0.76304 \nEpoch: 4408  | Training Loss: 0.31610 \nEpoch: 4408  | Training Loss: 0.36825 \nEpoch: 4408  | Training Loss: 0.34624 \nEpoch: 4408  | Training Loss: 0.21233 \nEpoch: 4408  | Training Loss: 0.14711 \nEpoch: 4408  | Validation balanced accuracy : 0.76304 \nEpoch: 4409  | Training Loss: 0.31618 \nEpoch: 4409  | Training Loss: 0.36826 \nEpoch: 4409  | Training Loss: 0.34626 \nEpoch: 4409  | Training Loss: 0.21232 \nEpoch: 4409  | Training Loss: 0.14731 \nEpoch: 4409  | Validation balanced accuracy : 0.76304 \nEpoch: 4410  | Training Loss: 0.31599 \nEpoch: 4410  | Training Loss: 0.36814 \nEpoch: 4410  | Training Loss: 0.34632 \nEpoch: 4410  | Training Loss: 0.21231 \nEpoch: 4410  | Training Loss: 0.14745 \nEpoch: 4410  | Validation balanced accuracy : 0.76304 \nEpoch: 4411  | Training Loss: 0.31591 \nEpoch: 4411  | Training Loss: 0.36811 \nEpoch: 4411  | Training Loss: 0.34633 \nEpoch: 4411  | Training Loss: 0.21231 \nEpoch: 4411  | Training Loss: 0.14741 \nEpoch: 4411  | Validation balanced accuracy : 0.76304 \nEpoch: 4412  | Training Loss: 0.31596 \nEpoch: 4412  | Training Loss: 0.36816 \nEpoch: 4412  | Training Loss: 0.34630 \nEpoch: 4412  | Training Loss: 0.21232 \nEpoch: 4412  | Training Loss: 0.14727 \nEpoch: 4412  | Validation balanced accuracy : 0.76304 \nEpoch: 4413  | Training Loss: 0.31607 \nEpoch: 4413  | Training Loss: 0.36823 \nEpoch: 4413  | Training Loss: 0.34625 \nEpoch: 4413  | Training Loss: 0.21233 \nEpoch: 4413  | Training Loss: 0.14715 \nEpoch: 4413  | Validation balanced accuracy : 0.76304 \nEpoch: 4414  | Training Loss: 0.31615 \nEpoch: 4414  | Training Loss: 0.36824 \nEpoch: 4414  | Training Loss: 0.34628 \nEpoch: 4414  | Training Loss: 0.21232 \nEpoch: 4414  | Training Loss: 0.14736 \nEpoch: 4414  | Validation balanced accuracy : 0.76304 \nEpoch: 4415  | Training Loss: 0.31596 \nEpoch: 4415  | Training Loss: 0.36813 \nEpoch: 4415  | Training Loss: 0.34633 \nEpoch: 4415  | Training Loss: 0.21230 \nEpoch: 4415  | Training Loss: 0.14744 \nEpoch: 4415  | Validation balanced accuracy : 0.76304 \nEpoch: 4416  | Training Loss: 0.31593 \nEpoch: 4416  | Training Loss: 0.36812 \nEpoch: 4416  | Training Loss: 0.34632 \nEpoch: 4416  | Training Loss: 0.21231 \nEpoch: 4416  | Training Loss: 0.14737 \nEpoch: 4416  | Validation balanced accuracy : 0.76304 \nEpoch: 4417  | Training Loss: 0.31600 \nEpoch: 4417  | Training Loss: 0.36818 \nEpoch: 4417  | Training Loss: 0.34629 \nEpoch: 4417  | Training Loss: 0.21232 \nEpoch: 4417  | Training Loss: 0.14726 \nEpoch: 4417  | Validation balanced accuracy : 0.76304 \nEpoch: 4418  | Training Loss: 0.31607 \nEpoch: 4418  | Training Loss: 0.36823 \nEpoch: 4418  | Training Loss: 0.34626 \nEpoch: 4418  | Training Loss: 0.21233 \nEpoch: 4418  | Training Loss: 0.14717 \nEpoch: 4418  | Validation balanced accuracy : 0.76304 \nEpoch: 4419  | Training Loss: 0.31613 \nEpoch: 4419  | Training Loss: 0.36823 \nEpoch: 4419  | Training Loss: 0.34629 \nEpoch: 4419  | Training Loss: 0.21231 \nEpoch: 4419  | Training Loss: 0.14738 \nEpoch: 4419  | Validation balanced accuracy : 0.76304 \nEpoch: 4420  | Training Loss: 0.31594 \nEpoch: 4420  | Training Loss: 0.36812 \nEpoch: 4420  | Training Loss: 0.34634 \nEpoch: 4420  | Training Loss: 0.21230 \nEpoch: 4420  | Training Loss: 0.14746 \nEpoch: 4420  | Validation balanced accuracy : 0.76304 \nEpoch: 4421  | Training Loss: 0.31592 \nEpoch: 4421  | Training Loss: 0.36812 \nEpoch: 4421  | Training Loss: 0.34633 \nEpoch: 4421  | Training Loss: 0.21231 \nEpoch: 4421  | Training Loss: 0.14737 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4421  | Validation balanced accuracy : 0.76304 \nEpoch: 4422  | Training Loss: 0.31599 \nEpoch: 4422  | Training Loss: 0.36817 \nEpoch: 4422  | Training Loss: 0.34629 \nEpoch: 4422  | Training Loss: 0.21232 \nEpoch: 4422  | Training Loss: 0.14726 \nEpoch: 4422  | Validation balanced accuracy : 0.76304 \nEpoch: 4423  | Training Loss: 0.31607 \nEpoch: 4423  | Training Loss: 0.36823 \nEpoch: 4423  | Training Loss: 0.34626 \nEpoch: 4423  | Training Loss: 0.21233 \nEpoch: 4423  | Training Loss: 0.14717 \nEpoch: 4423  | Validation balanced accuracy : 0.76304 \nEpoch: 4424  | Training Loss: 0.31613 \nEpoch: 4424  | Training Loss: 0.36822 \nEpoch: 4424  | Training Loss: 0.34629 \nEpoch: 4424  | Training Loss: 0.21231 \nEpoch: 4424  | Training Loss: 0.14740 \nEpoch: 4424  | Validation balanced accuracy : 0.76304 \nEpoch: 4425  | Training Loss: 0.31592 \nEpoch: 4425  | Training Loss: 0.36810 \nEpoch: 4425  | Training Loss: 0.34635 \nEpoch: 4425  | Training Loss: 0.21230 \nEpoch: 4425  | Training Loss: 0.14749 \nEpoch: 4425  | Validation balanced accuracy : 0.76304 \nEpoch: 4426  | Training Loss: 0.31589 \nEpoch: 4426  | Training Loss: 0.36810 \nEpoch: 4426  | Training Loss: 0.34634 \nEpoch: 4426  | Training Loss: 0.21230 \nEpoch: 4426  | Training Loss: 0.14740 \nEpoch: 4426  | Validation balanced accuracy : 0.76304 \nEpoch: 4427  | Training Loss: 0.31597 \nEpoch: 4427  | Training Loss: 0.36816 \nEpoch: 4427  | Training Loss: 0.34631 \nEpoch: 4427  | Training Loss: 0.21231 \nEpoch: 4427  | Training Loss: 0.14728 \nEpoch: 4427  | Validation balanced accuracy : 0.76304 \nEpoch: 4428  | Training Loss: 0.31605 \nEpoch: 4428  | Training Loss: 0.36822 \nEpoch: 4428  | Training Loss: 0.34627 \nEpoch: 4428  | Training Loss: 0.21232 \nEpoch: 4428  | Training Loss: 0.14718 \nEpoch: 4428  | Validation balanced accuracy : 0.76304 \nEpoch: 4429  | Training Loss: 0.31612 \nEpoch: 4429  | Training Loss: 0.36826 \nEpoch: 4429  | Training Loss: 0.34625 \nEpoch: 4429  | Training Loss: 0.21233 \nEpoch: 4429  | Training Loss: 0.14711 \nEpoch: 4429  | Validation balanced accuracy : 0.76304 \nEpoch: 4430  | Training Loss: 0.31616 \nEpoch: 4430  | Training Loss: 0.36825 \nEpoch: 4430  | Training Loss: 0.34628 \nEpoch: 4430  | Training Loss: 0.21231 \nEpoch: 4430  | Training Loss: 0.14735 \nEpoch: 4430  | Validation balanced accuracy : 0.76304 \nEpoch: 4431  | Training Loss: 0.31596 \nEpoch: 4431  | Training Loss: 0.36813 \nEpoch: 4431  | Training Loss: 0.34634 \nEpoch: 4431  | Training Loss: 0.21230 \nEpoch: 4431  | Training Loss: 0.14744 \nEpoch: 4431  | Validation balanced accuracy : 0.76304 \nEpoch: 4432  | Training Loss: 0.31592 \nEpoch: 4432  | Training Loss: 0.36812 \nEpoch: 4432  | Training Loss: 0.34633 \nEpoch: 4432  | Training Loss: 0.21230 \nEpoch: 4432  | Training Loss: 0.14737 \nEpoch: 4432  | Validation balanced accuracy : 0.76304 \nEpoch: 4433  | Training Loss: 0.31599 \nEpoch: 4433  | Training Loss: 0.36817 \nEpoch: 4433  | Training Loss: 0.34630 \nEpoch: 4433  | Training Loss: 0.21231 \nEpoch: 4433  | Training Loss: 0.14727 \nEpoch: 4433  | Validation balanced accuracy : 0.76304 \nEpoch: 4434  | Training Loss: 0.31606 \nEpoch: 4434  | Training Loss: 0.36822 \nEpoch: 4434  | Training Loss: 0.34627 \nEpoch: 4434  | Training Loss: 0.21232 \nEpoch: 4434  | Training Loss: 0.14718 \nEpoch: 4434  | Validation balanced accuracy : 0.76304 \nEpoch: 4435  | Training Loss: 0.31612 \nEpoch: 4435  | Training Loss: 0.36822 \nEpoch: 4435  | Training Loss: 0.34630 \nEpoch: 4435  | Training Loss: 0.21231 \nEpoch: 4435  | Training Loss: 0.14738 \nEpoch: 4435  | Validation balanced accuracy : 0.76304 \nEpoch: 4436  | Training Loss: 0.31594 \nEpoch: 4436  | Training Loss: 0.36811 \nEpoch: 4436  | Training Loss: 0.34635 \nEpoch: 4436  | Training Loss: 0.21230 \nEpoch: 4436  | Training Loss: 0.14745 \nEpoch: 4436  | Validation balanced accuracy : 0.76304 \nEpoch: 4437  | Training Loss: 0.31592 \nEpoch: 4437  | Training Loss: 0.36812 \nEpoch: 4437  | Training Loss: 0.34634 \nEpoch: 4437  | Training Loss: 0.21230 \nEpoch: 4437  | Training Loss: 0.14736 \nEpoch: 4437  | Validation balanced accuracy : 0.76304 \nEpoch: 4438  | Training Loss: 0.31599 \nEpoch: 4438  | Training Loss: 0.36818 \nEpoch: 4438  | Training Loss: 0.34629 \nEpoch: 4438  | Training Loss: 0.21232 \nEpoch: 4438  | Training Loss: 0.14720 \nEpoch: 4438  | Validation balanced accuracy : 0.76304 \nEpoch: 4439  | Training Loss: 0.31611 \nEpoch: 4439  | Training Loss: 0.36826 \nEpoch: 4439  | Training Loss: 0.34624 \nEpoch: 4439  | Training Loss: 0.21233 \nEpoch: 4439  | Training Loss: 0.14708 \nEpoch: 4439  | Validation balanced accuracy : 0.76304 \nEpoch: 4440  | Training Loss: 0.31619 \nEpoch: 4440  | Training Loss: 0.36827 \nEpoch: 4440  | Training Loss: 0.34627 \nEpoch: 4440  | Training Loss: 0.21231 \nEpoch: 4440  | Training Loss: 0.14732 \nEpoch: 4440  | Validation balanced accuracy : 0.76304 \nEpoch: 4441  | Training Loss: 0.31598 \nEpoch: 4441  | Training Loss: 0.36814 \nEpoch: 4441  | Training Loss: 0.34634 \nEpoch: 4441  | Training Loss: 0.21230 \nEpoch: 4441  | Training Loss: 0.14742 \nEpoch: 4441  | Validation balanced accuracy : 0.76304 \nEpoch: 4442  | Training Loss: 0.31593 \nEpoch: 4442  | Training Loss: 0.36812 \nEpoch: 4442  | Training Loss: 0.34634 \nEpoch: 4442  | Training Loss: 0.21230 \nEpoch: 4442  | Training Loss: 0.14736 \nEpoch: 4442  | Validation balanced accuracy : 0.76304 \nEpoch: 4443  | Training Loss: 0.31599 \nEpoch: 4443  | Training Loss: 0.36817 \nEpoch: 4443  | Training Loss: 0.34631 \nEpoch: 4443  | Training Loss: 0.21231 \nEpoch: 4443  | Training Loss: 0.14726 \nEpoch: 4443  | Validation balanced accuracy : 0.76304 \nEpoch: 4444  | Training Loss: 0.31606 \nEpoch: 4444  | Training Loss: 0.36822 \nEpoch: 4444  | Training Loss: 0.34628 \nEpoch: 4444  | Training Loss: 0.21232 \nEpoch: 4444  | Training Loss: 0.14718 \nEpoch: 4444  | Validation balanced accuracy : 0.76304 \nEpoch: 4445  | Training Loss: 0.31612 \nEpoch: 4445  | Training Loss: 0.36826 \nEpoch: 4445  | Training Loss: 0.34625 \nEpoch: 4445  | Training Loss: 0.21232 \nEpoch: 4445  | Training Loss: 0.14712 \nEpoch: 4445  | Validation balanced accuracy : 0.76304 \nEpoch: 4446  | Training Loss: 0.31616 \nEpoch: 4446  | Training Loss: 0.36824 \nEpoch: 4446  | Training Loss: 0.34629 \nEpoch: 4446  | Training Loss: 0.21231 \nEpoch: 4446  | Training Loss: 0.14735 \nEpoch: 4446  | Validation balanced accuracy : 0.76304 \nEpoch: 4447  | Training Loss: 0.31595 \nEpoch: 4447  | Training Loss: 0.36812 \nEpoch: 4447  | Training Loss: 0.34635 \nEpoch: 4447  | Training Loss: 0.21230 \nEpoch: 4447  | Training Loss: 0.14745 \nEpoch: 4447  | Validation balanced accuracy : 0.76304 \nEpoch: 4448  | Training Loss: 0.31591 \nEpoch: 4448  | Training Loss: 0.36811 \nEpoch: 4448  | Training Loss: 0.34634 \nEpoch: 4448  | Training Loss: 0.21230 \nEpoch: 4448  | Training Loss: 0.14737 \nEpoch: 4448  | Validation balanced accuracy : 0.76304 \nEpoch: 4449  | Training Loss: 0.31598 \nEpoch: 4449  | Training Loss: 0.36817 \nEpoch: 4449  | Training Loss: 0.34631 \nEpoch: 4449  | Training Loss: 0.21231 \nEpoch: 4449  | Training Loss: 0.14726 \nEpoch: 4449  | Validation balanced accuracy : 0.76304 \nEpoch: 4450  | Training Loss: 0.31606 \nEpoch: 4450  | Training Loss: 0.36822 \nEpoch: 4450  | Training Loss: 0.34628 \nEpoch: 4450  | Training Loss: 0.21232 \nEpoch: 4450  | Training Loss: 0.14717 \nEpoch: 4450  | Validation balanced accuracy : 0.76304 \nEpoch: 4451  | Training Loss: 0.31612 \nEpoch: 4451  | Training Loss: 0.36822 \nEpoch: 4451  | Training Loss: 0.34630 \nEpoch: 4451  | Training Loss: 0.21230 \nEpoch: 4451  | Training Loss: 0.14737 \nEpoch: 4451  | Validation balanced accuracy : 0.76304 \nEpoch: 4452  | Training Loss: 0.31594 \nEpoch: 4452  | Training Loss: 0.36812 \nEpoch: 4452  | Training Loss: 0.34635 \nEpoch: 4452  | Training Loss: 0.21230 \nEpoch: 4452  | Training Loss: 0.14744 \nEpoch: 4452  | Validation balanced accuracy : 0.76304 \nEpoch: 4453  | Training Loss: 0.31592 \nEpoch: 4453  | Training Loss: 0.36812 \nEpoch: 4453  | Training Loss: 0.34634 \nEpoch: 4453  | Training Loss: 0.21230 \nEpoch: 4453  | Training Loss: 0.14735 \nEpoch: 4453  | Validation balanced accuracy : 0.76304 \nEpoch: 4454  | Training Loss: 0.31600 \nEpoch: 4454  | Training Loss: 0.36818 \nEpoch: 4454  | Training Loss: 0.34630 \nEpoch: 4454  | Training Loss: 0.21231 \nEpoch: 4454  | Training Loss: 0.14724 \nEpoch: 4454  | Validation balanced accuracy : 0.76304 \nEpoch: 4455  | Training Loss: 0.31608 \nEpoch: 4455  | Training Loss: 0.36823 \nEpoch: 4455  | Training Loss: 0.34627 \nEpoch: 4455  | Training Loss: 0.21232 \nEpoch: 4455  | Training Loss: 0.14715 \nEpoch: 4455  | Validation balanced accuracy : 0.76304 \nEpoch: 4456  | Training Loss: 0.31614 \nEpoch: 4456  | Training Loss: 0.36823 \nEpoch: 4456  | Training Loss: 0.34630 \nEpoch: 4456  | Training Loss: 0.21231 \nEpoch: 4456  | Training Loss: 0.14736 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4456  | Validation balanced accuracy : 0.76304 \nEpoch: 4457  | Training Loss: 0.31595 \nEpoch: 4457  | Training Loss: 0.36812 \nEpoch: 4457  | Training Loss: 0.34635 \nEpoch: 4457  | Training Loss: 0.21229 \nEpoch: 4457  | Training Loss: 0.14743 \nEpoch: 4457  | Validation balanced accuracy : 0.76304 \nEpoch: 4458  | Training Loss: 0.31592 \nEpoch: 4458  | Training Loss: 0.36812 \nEpoch: 4458  | Training Loss: 0.34634 \nEpoch: 4458  | Training Loss: 0.21230 \nEpoch: 4458  | Training Loss: 0.14735 \nEpoch: 4458  | Validation balanced accuracy : 0.76304 \nEpoch: 4459  | Training Loss: 0.31600 \nEpoch: 4459  | Training Loss: 0.36818 \nEpoch: 4459  | Training Loss: 0.34630 \nEpoch: 4459  | Training Loss: 0.21231 \nEpoch: 4459  | Training Loss: 0.14720 \nEpoch: 4459  | Validation balanced accuracy : 0.76304 \nEpoch: 4460  | Training Loss: 0.31610 \nEpoch: 4460  | Training Loss: 0.36826 \nEpoch: 4460  | Training Loss: 0.34626 \nEpoch: 4460  | Training Loss: 0.21232 \nEpoch: 4460  | Training Loss: 0.14709 \nEpoch: 4460  | Validation balanced accuracy : 0.76304 \nEpoch: 4461  | Training Loss: 0.31618 \nEpoch: 4461  | Training Loss: 0.36826 \nEpoch: 4461  | Training Loss: 0.34628 \nEpoch: 4461  | Training Loss: 0.21231 \nEpoch: 4461  | Training Loss: 0.14730 \nEpoch: 4461  | Validation balanced accuracy : 0.76304 \nEpoch: 4462  | Training Loss: 0.31598 \nEpoch: 4462  | Training Loss: 0.36815 \nEpoch: 4462  | Training Loss: 0.34634 \nEpoch: 4462  | Training Loss: 0.21230 \nEpoch: 4462  | Training Loss: 0.14739 \nEpoch: 4462  | Validation balanced accuracy : 0.76304 \nEpoch: 4463  | Training Loss: 0.31595 \nEpoch: 4463  | Training Loss: 0.36814 \nEpoch: 4463  | Training Loss: 0.34633 \nEpoch: 4463  | Training Loss: 0.21230 \nEpoch: 4463  | Training Loss: 0.14732 \nEpoch: 4463  | Validation balanced accuracy : 0.76304 \nEpoch: 4464  | Training Loss: 0.31601 \nEpoch: 4464  | Training Loss: 0.36819 \nEpoch: 4464  | Training Loss: 0.34630 \nEpoch: 4464  | Training Loss: 0.21231 \nEpoch: 4464  | Training Loss: 0.14723 \nEpoch: 4464  | Validation balanced accuracy : 0.76304 \nEpoch: 4465  | Training Loss: 0.31608 \nEpoch: 4465  | Training Loss: 0.36823 \nEpoch: 4465  | Training Loss: 0.34628 \nEpoch: 4465  | Training Loss: 0.21232 \nEpoch: 4465  | Training Loss: 0.14715 \nEpoch: 4465  | Validation balanced accuracy : 0.76304 \nEpoch: 4466  | Training Loss: 0.31613 \nEpoch: 4466  | Training Loss: 0.36823 \nEpoch: 4466  | Training Loss: 0.34630 \nEpoch: 4466  | Training Loss: 0.21230 \nEpoch: 4466  | Training Loss: 0.14736 \nEpoch: 4466  | Validation balanced accuracy : 0.76304 \nEpoch: 4467  | Training Loss: 0.31594 \nEpoch: 4467  | Training Loss: 0.36812 \nEpoch: 4467  | Training Loss: 0.34636 \nEpoch: 4467  | Training Loss: 0.21229 \nEpoch: 4467  | Training Loss: 0.14744 \nEpoch: 4467  | Validation balanced accuracy : 0.76304 \nEpoch: 4468  | Training Loss: 0.31592 \nEpoch: 4468  | Training Loss: 0.36812 \nEpoch: 4468  | Training Loss: 0.34635 \nEpoch: 4468  | Training Loss: 0.21230 \nEpoch: 4468  | Training Loss: 0.14735 \nEpoch: 4468  | Validation balanced accuracy : 0.76304 \nEpoch: 4469  | Training Loss: 0.31599 \nEpoch: 4469  | Training Loss: 0.36818 \nEpoch: 4469  | Training Loss: 0.34631 \nEpoch: 4469  | Training Loss: 0.21231 \nEpoch: 4469  | Training Loss: 0.14720 \nEpoch: 4469  | Validation balanced accuracy : 0.76304 \nEpoch: 4470  | Training Loss: 0.31610 \nEpoch: 4470  | Training Loss: 0.36826 \nEpoch: 4470  | Training Loss: 0.34626 \nEpoch: 4470  | Training Loss: 0.21232 \nEpoch: 4470  | Training Loss: 0.14709 \nEpoch: 4470  | Validation balanced accuracy : 0.76304 \nEpoch: 4471  | Training Loss: 0.31618 \nEpoch: 4471  | Training Loss: 0.36826 \nEpoch: 4471  | Training Loss: 0.34629 \nEpoch: 4471  | Training Loss: 0.21231 \nEpoch: 4471  | Training Loss: 0.14729 \nEpoch: 4471  | Validation balanced accuracy : 0.76304 \nEpoch: 4472  | Training Loss: 0.31599 \nEpoch: 4472  | Training Loss: 0.36815 \nEpoch: 4472  | Training Loss: 0.34634 \nEpoch: 4472  | Training Loss: 0.21230 \nEpoch: 4472  | Training Loss: 0.14738 \nEpoch: 4472  | Validation balanced accuracy : 0.76304 \nEpoch: 4473  | Training Loss: 0.31595 \nEpoch: 4473  | Training Loss: 0.36814 \nEpoch: 4473  | Training Loss: 0.34634 \nEpoch: 4473  | Training Loss: 0.21230 \nEpoch: 4473  | Training Loss: 0.14731 \nEpoch: 4473  | Validation balanced accuracy : 0.76304 \nEpoch: 4474  | Training Loss: 0.31601 \nEpoch: 4474  | Training Loss: 0.36819 \nEpoch: 4474  | Training Loss: 0.34631 \nEpoch: 4474  | Training Loss: 0.21231 \nEpoch: 4474  | Training Loss: 0.14722 \nEpoch: 4474  | Validation balanced accuracy : 0.76304 \nEpoch: 4475  | Training Loss: 0.31608 \nEpoch: 4475  | Training Loss: 0.36824 \nEpoch: 4475  | Training Loss: 0.34628 \nEpoch: 4475  | Training Loss: 0.21231 \nEpoch: 4475  | Training Loss: 0.14714 \nEpoch: 4475  | Validation balanced accuracy : 0.76304 \nEpoch: 4476  | Training Loss: 0.31613 \nEpoch: 4476  | Training Loss: 0.36823 \nEpoch: 4476  | Training Loss: 0.34631 \nEpoch: 4476  | Training Loss: 0.21230 \nEpoch: 4476  | Training Loss: 0.14736 \nEpoch: 4476  | Validation balanced accuracy : 0.76304 \nEpoch: 4477  | Training Loss: 0.31594 \nEpoch: 4477  | Training Loss: 0.36812 \nEpoch: 4477  | Training Loss: 0.34636 \nEpoch: 4477  | Training Loss: 0.21229 \nEpoch: 4477  | Training Loss: 0.14743 \nEpoch: 4477  | Validation balanced accuracy : 0.76304 \nEpoch: 4478  | Training Loss: 0.31592 \nEpoch: 4478  | Training Loss: 0.36812 \nEpoch: 4478  | Training Loss: 0.34635 \nEpoch: 4478  | Training Loss: 0.21229 \nEpoch: 4478  | Training Loss: 0.14735 \nEpoch: 4478  | Validation balanced accuracy : 0.76304 \nEpoch: 4479  | Training Loss: 0.31599 \nEpoch: 4479  | Training Loss: 0.36818 \nEpoch: 4479  | Training Loss: 0.34631 \nEpoch: 4479  | Training Loss: 0.21231 \nEpoch: 4479  | Training Loss: 0.14719 \nEpoch: 4479  | Validation balanced accuracy : 0.76304 \nEpoch: 4480  | Training Loss: 0.31610 \nEpoch: 4480  | Training Loss: 0.36826 \nEpoch: 4480  | Training Loss: 0.34627 \nEpoch: 4480  | Training Loss: 0.21232 \nEpoch: 4480  | Training Loss: 0.14708 \nEpoch: 4480  | Validation balanced accuracy : 0.76304 \nEpoch: 4481  | Training Loss: 0.31618 \nEpoch: 4481  | Training Loss: 0.36826 \nEpoch: 4481  | Training Loss: 0.34629 \nEpoch: 4481  | Training Loss: 0.21230 \nEpoch: 4481  | Training Loss: 0.14729 \nEpoch: 4481  | Validation balanced accuracy : 0.76304 \nEpoch: 4482  | Training Loss: 0.31599 \nEpoch: 4482  | Training Loss: 0.36815 \nEpoch: 4482  | Training Loss: 0.34634 \nEpoch: 4482  | Training Loss: 0.21229 \nEpoch: 4482  | Training Loss: 0.14738 \nEpoch: 4482  | Validation balanced accuracy : 0.76304 \nEpoch: 4483  | Training Loss: 0.31595 \nEpoch: 4483  | Training Loss: 0.36814 \nEpoch: 4483  | Training Loss: 0.34634 \nEpoch: 4483  | Training Loss: 0.21230 \nEpoch: 4483  | Training Loss: 0.14731 \nEpoch: 4483  | Validation balanced accuracy : 0.76304 \nEpoch: 4484  | Training Loss: 0.31602 \nEpoch: 4484  | Training Loss: 0.36819 \nEpoch: 4484  | Training Loss: 0.34631 \nEpoch: 4484  | Training Loss: 0.21230 \nEpoch: 4484  | Training Loss: 0.14721 \nEpoch: 4484  | Validation balanced accuracy : 0.76304 \nEpoch: 4485  | Training Loss: 0.31608 \nEpoch: 4485  | Training Loss: 0.36824 \nEpoch: 4485  | Training Loss: 0.34628 \nEpoch: 4485  | Training Loss: 0.21231 \nEpoch: 4485  | Training Loss: 0.14714 \nEpoch: 4485  | Validation balanced accuracy : 0.76304 \nEpoch: 4486  | Training Loss: 0.31613 \nEpoch: 4486  | Training Loss: 0.36823 \nEpoch: 4486  | Training Loss: 0.34631 \nEpoch: 4486  | Training Loss: 0.21230 \nEpoch: 4486  | Training Loss: 0.14735 \nEpoch: 4486  | Validation balanced accuracy : 0.76304 \nEpoch: 4487  | Training Loss: 0.31594 \nEpoch: 4487  | Training Loss: 0.36812 \nEpoch: 4487  | Training Loss: 0.34636 \nEpoch: 4487  | Training Loss: 0.21229 \nEpoch: 4487  | Training Loss: 0.14743 \nEpoch: 4487  | Validation balanced accuracy : 0.76304 \nEpoch: 4488  | Training Loss: 0.31592 \nEpoch: 4488  | Training Loss: 0.36812 \nEpoch: 4488  | Training Loss: 0.34635 \nEpoch: 4488  | Training Loss: 0.21229 \nEpoch: 4488  | Training Loss: 0.14734 \nEpoch: 4488  | Validation balanced accuracy : 0.76304 \nEpoch: 4489  | Training Loss: 0.31599 \nEpoch: 4489  | Training Loss: 0.36818 \nEpoch: 4489  | Training Loss: 0.34631 \nEpoch: 4489  | Training Loss: 0.21230 \nEpoch: 4489  | Training Loss: 0.14719 \nEpoch: 4489  | Validation balanced accuracy : 0.76304 \nEpoch: 4490  | Training Loss: 0.31610 \nEpoch: 4490  | Training Loss: 0.36826 \nEpoch: 4490  | Training Loss: 0.34627 \nEpoch: 4490  | Training Loss: 0.21232 \nEpoch: 4490  | Training Loss: 0.14708 \nEpoch: 4490  | Validation balanced accuracy : 0.76304 \nEpoch: 4491  | Training Loss: 0.31618 \nEpoch: 4491  | Training Loss: 0.36826 \nEpoch: 4491  | Training Loss: 0.34629 \nEpoch: 4491  | Training Loss: 0.21230 \nEpoch: 4491  | Training Loss: 0.14728 \nEpoch: 4491  | Validation balanced accuracy : 0.76304 \nEpoch: 4492  | Training Loss: 0.31599 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4492  | Training Loss: 0.36815 \nEpoch: 4492  | Training Loss: 0.34635 \nEpoch: 4492  | Training Loss: 0.21229 \nEpoch: 4492  | Training Loss: 0.14737 \nEpoch: 4492  | Validation balanced accuracy : 0.76304 \nEpoch: 4493  | Training Loss: 0.31595 \nEpoch: 4493  | Training Loss: 0.36814 \nEpoch: 4493  | Training Loss: 0.34634 \nEpoch: 4493  | Training Loss: 0.21229 \nEpoch: 4493  | Training Loss: 0.14730 \nEpoch: 4493  | Validation balanced accuracy : 0.76304 \nEpoch: 4494  | Training Loss: 0.31602 \nEpoch: 4494  | Training Loss: 0.36819 \nEpoch: 4494  | Training Loss: 0.34631 \nEpoch: 4494  | Training Loss: 0.21230 \nEpoch: 4494  | Training Loss: 0.14721 \nEpoch: 4494  | Validation balanced accuracy : 0.76304 \nEpoch: 4495  | Training Loss: 0.31608 \nEpoch: 4495  | Training Loss: 0.36824 \nEpoch: 4495  | Training Loss: 0.34628 \nEpoch: 4495  | Training Loss: 0.21231 \nEpoch: 4495  | Training Loss: 0.14713 \nEpoch: 4495  | Validation balanced accuracy : 0.76304 \nEpoch: 4496  | Training Loss: 0.31613 \nEpoch: 4496  | Training Loss: 0.36823 \nEpoch: 4496  | Training Loss: 0.34631 \nEpoch: 4496  | Training Loss: 0.21230 \nEpoch: 4496  | Training Loss: 0.14735 \nEpoch: 4496  | Validation balanced accuracy : 0.76304 \nEpoch: 4497  | Training Loss: 0.31594 \nEpoch: 4497  | Training Loss: 0.36812 \nEpoch: 4497  | Training Loss: 0.34637 \nEpoch: 4497  | Training Loss: 0.21229 \nEpoch: 4497  | Training Loss: 0.14742 \nEpoch: 4497  | Validation balanced accuracy : 0.76304 \nEpoch: 4498  | Training Loss: 0.31592 \nEpoch: 4498  | Training Loss: 0.36812 \nEpoch: 4498  | Training Loss: 0.34636 \nEpoch: 4498  | Training Loss: 0.21229 \nEpoch: 4498  | Training Loss: 0.14734 \nEpoch: 4498  | Validation balanced accuracy : 0.76304 \nEpoch: 4499  | Training Loss: 0.31600 \nEpoch: 4499  | Training Loss: 0.36818 \nEpoch: 4499  | Training Loss: 0.34631 \nEpoch: 4499  | Training Loss: 0.21230 \nEpoch: 4499  | Training Loss: 0.14718 \nEpoch: 4499  | Validation balanced accuracy : 0.76304 \nEpoch: 4500  | Training Loss: 0.31610 \nEpoch: 4500  | Training Loss: 0.36826 \nEpoch: 4500  | Training Loss: 0.34627 \nEpoch: 4500  | Training Loss: 0.21231 \nEpoch: 4500  | Training Loss: 0.14707 \nEpoch: 4500  | Validation balanced accuracy : 0.76304 \nEpoch: 4501  | Training Loss: 0.31618 \nEpoch: 4501  | Training Loss: 0.36827 \nEpoch: 4501  | Training Loss: 0.34626 \nEpoch: 4501  | Training Loss: 0.21231 \nEpoch: 4501  | Training Loss: 0.14707 \nEpoch: 4501  | Validation balanced accuracy : 0.76304 \nEpoch: 4502  | Training Loss: 0.31600 \nEpoch: 4502  | Training Loss: 0.36815 \nEpoch: 4502  | Training Loss: 0.34632 \nEpoch: 4502  | Training Loss: 0.21230 \nEpoch: 4502  | Training Loss: 0.14722 \nEpoch: 4502  | Validation balanced accuracy : 0.76304 \nEpoch: 4503  | Training Loss: 0.31591 \nEpoch: 4503  | Training Loss: 0.36810 \nEpoch: 4503  | Training Loss: 0.34634 \nEpoch: 4503  | Training Loss: 0.21230 \nEpoch: 4503  | Training Loss: 0.14722 \nEpoch: 4503  | Validation balanced accuracy : 0.76304 \nEpoch: 4504  | Training Loss: 0.31593 \nEpoch: 4504  | Training Loss: 0.36813 \nEpoch: 4504  | Training Loss: 0.34632 \nEpoch: 4504  | Training Loss: 0.21230 \nEpoch: 4504  | Training Loss: 0.14712 \nEpoch: 4504  | Validation balanced accuracy : 0.76304 \nEpoch: 4505  | Training Loss: 0.31601 \nEpoch: 4505  | Training Loss: 0.36819 \nEpoch: 4505  | Training Loss: 0.34628 \nEpoch: 4505  | Training Loss: 0.21231 \nEpoch: 4505  | Training Loss: 0.14703 \nEpoch: 4505  | Validation balanced accuracy : 0.76304 \nEpoch: 4506  | Training Loss: 0.31607 \nEpoch: 4506  | Training Loss: 0.36823 \nEpoch: 4506  | Training Loss: 0.34626 \nEpoch: 4506  | Training Loss: 0.21232 \nEpoch: 4506  | Training Loss: 0.14697 \nEpoch: 4506  | Validation balanced accuracy : 0.76304 \nEpoch: 4507  | Training Loss: 0.31611 \nEpoch: 4507  | Training Loss: 0.36821 \nEpoch: 4507  | Training Loss: 0.34630 \nEpoch: 4507  | Training Loss: 0.21230 \nEpoch: 4507  | Training Loss: 0.14721 \nEpoch: 4507  | Validation balanced accuracy : 0.76304 \nEpoch: 4508  | Training Loss: 0.31590 \nEpoch: 4508  | Training Loss: 0.36809 \nEpoch: 4508  | Training Loss: 0.34636 \nEpoch: 4508  | Training Loss: 0.21229 \nEpoch: 4508  | Training Loss: 0.14731 \nEpoch: 4508  | Validation balanced accuracy : 0.76304 \nEpoch: 4509  | Training Loss: 0.31586 \nEpoch: 4509  | Training Loss: 0.36807 \nEpoch: 4509  | Training Loss: 0.34636 \nEpoch: 4509  | Training Loss: 0.21229 \nEpoch: 4509  | Training Loss: 0.14726 \nEpoch: 4509  | Validation balanced accuracy : 0.76304 \nEpoch: 4510  | Training Loss: 0.31591 \nEpoch: 4510  | Training Loss: 0.36812 \nEpoch: 4510  | Training Loss: 0.34632 \nEpoch: 4510  | Training Loss: 0.21230 \nEpoch: 4510  | Training Loss: 0.14712 \nEpoch: 4510  | Validation balanced accuracy : 0.76304 \nEpoch: 4511  | Training Loss: 0.31602 \nEpoch: 4511  | Training Loss: 0.36819 \nEpoch: 4511  | Training Loss: 0.34628 \nEpoch: 4511  | Training Loss: 0.21231 \nEpoch: 4511  | Training Loss: 0.14700 \nEpoch: 4511  | Validation balanced accuracy : 0.76304 \nEpoch: 4512  | Training Loss: 0.31609 \nEpoch: 4512  | Training Loss: 0.36824 \nEpoch: 4512  | Training Loss: 0.34625 \nEpoch: 4512  | Training Loss: 0.21232 \nEpoch: 4512  | Training Loss: 0.14693 \nEpoch: 4512  | Validation balanced accuracy : 0.76304 \nEpoch: 4513  | Training Loss: 0.31613 \nEpoch: 4513  | Training Loss: 0.36823 \nEpoch: 4513  | Training Loss: 0.34628 \nEpoch: 4513  | Training Loss: 0.21230 \nEpoch: 4513  | Training Loss: 0.14715 \nEpoch: 4513  | Validation balanced accuracy : 0.76304 \nEpoch: 4514  | Training Loss: 0.31594 \nEpoch: 4514  | Training Loss: 0.36812 \nEpoch: 4514  | Training Loss: 0.34634 \nEpoch: 4514  | Training Loss: 0.21229 \nEpoch: 4514  | Training Loss: 0.14725 \nEpoch: 4514  | Validation balanced accuracy : 0.76304 \nEpoch: 4515  | Training Loss: 0.31590 \nEpoch: 4515  | Training Loss: 0.36810 \nEpoch: 4515  | Training Loss: 0.34634 \nEpoch: 4515  | Training Loss: 0.21229 \nEpoch: 4515  | Training Loss: 0.14720 \nEpoch: 4515  | Validation balanced accuracy : 0.76304 \nEpoch: 4516  | Training Loss: 0.31595 \nEpoch: 4516  | Training Loss: 0.36815 \nEpoch: 4516  | Training Loss: 0.34631 \nEpoch: 4516  | Training Loss: 0.21230 \nEpoch: 4516  | Training Loss: 0.14708 \nEpoch: 4516  | Validation balanced accuracy : 0.76304 \nEpoch: 4517  | Training Loss: 0.31604 \nEpoch: 4517  | Training Loss: 0.36821 \nEpoch: 4517  | Training Loss: 0.34627 \nEpoch: 4517  | Training Loss: 0.21231 \nEpoch: 4517  | Training Loss: 0.14698 \nEpoch: 4517  | Validation balanced accuracy : 0.76304 \nEpoch: 4518  | Training Loss: 0.31610 \nEpoch: 4518  | Training Loss: 0.36821 \nEpoch: 4518  | Training Loss: 0.34629 \nEpoch: 4518  | Training Loss: 0.21230 \nEpoch: 4518  | Training Loss: 0.14717 \nEpoch: 4518  | Validation balanced accuracy : 0.76304 \nEpoch: 4519  | Training Loss: 0.31593 \nEpoch: 4519  | Training Loss: 0.36811 \nEpoch: 4519  | Training Loss: 0.34634 \nEpoch: 4519  | Training Loss: 0.21229 \nEpoch: 4519  | Training Loss: 0.14725 \nEpoch: 4519  | Validation balanced accuracy : 0.76304 \nEpoch: 4520  | Training Loss: 0.31590 \nEpoch: 4520  | Training Loss: 0.36811 \nEpoch: 4520  | Training Loss: 0.34634 \nEpoch: 4520  | Training Loss: 0.21229 \nEpoch: 4520  | Training Loss: 0.14719 \nEpoch: 4520  | Validation balanced accuracy : 0.76304 \nEpoch: 4521  | Training Loss: 0.31596 \nEpoch: 4521  | Training Loss: 0.36816 \nEpoch: 4521  | Training Loss: 0.34630 \nEpoch: 4521  | Training Loss: 0.21231 \nEpoch: 4521  | Training Loss: 0.14706 \nEpoch: 4521  | Validation balanced accuracy : 0.76304 \nEpoch: 4522  | Training Loss: 0.31605 \nEpoch: 4522  | Training Loss: 0.36822 \nEpoch: 4522  | Training Loss: 0.34626 \nEpoch: 4522  | Training Loss: 0.21231 \nEpoch: 4522  | Training Loss: 0.14696 \nEpoch: 4522  | Validation balanced accuracy : 0.76304 \nEpoch: 4523  | Training Loss: 0.31611 \nEpoch: 4523  | Training Loss: 0.36822 \nEpoch: 4523  | Training Loss: 0.34629 \nEpoch: 4523  | Training Loss: 0.21230 \nEpoch: 4523  | Training Loss: 0.14715 \nEpoch: 4523  | Validation balanced accuracy : 0.76304 \nEpoch: 4524  | Training Loss: 0.31594 \nEpoch: 4524  | Training Loss: 0.36812 \nEpoch: 4524  | Training Loss: 0.34634 \nEpoch: 4524  | Training Loss: 0.21229 \nEpoch: 4524  | Training Loss: 0.14724 \nEpoch: 4524  | Validation balanced accuracy : 0.76304 \nEpoch: 4525  | Training Loss: 0.31591 \nEpoch: 4525  | Training Loss: 0.36811 \nEpoch: 4525  | Training Loss: 0.34633 \nEpoch: 4525  | Training Loss: 0.21229 \nEpoch: 4525  | Training Loss: 0.14718 \nEpoch: 4525  | Validation balanced accuracy : 0.76304 \nEpoch: 4526  | Training Loss: 0.31596 \nEpoch: 4526  | Training Loss: 0.36816 \nEpoch: 4526  | Training Loss: 0.34630 \nEpoch: 4526  | Training Loss: 0.21230 \nEpoch: 4526  | Training Loss: 0.14706 \nEpoch: 4526  | Validation balanced accuracy : 0.76304 \nEpoch: 4527  | Training Loss: 0.31605 \nEpoch: 4527  | Training Loss: 0.36822 \nEpoch: 4527  | Training Loss: 0.34626 \nEpoch: 4527  | Training Loss: 0.21231 \nEpoch: 4527  | Training Loss: 0.14696 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4527  | Validation balanced accuracy : 0.76304 \nEpoch: 4528  | Training Loss: 0.31611 \nEpoch: 4528  | Training Loss: 0.36822 \nEpoch: 4528  | Training Loss: 0.34629 \nEpoch: 4528  | Training Loss: 0.21230 \nEpoch: 4528  | Training Loss: 0.14718 \nEpoch: 4528  | Validation balanced accuracy : 0.76304 \nEpoch: 4529  | Training Loss: 0.31592 \nEpoch: 4529  | Training Loss: 0.36810 \nEpoch: 4529  | Training Loss: 0.34635 \nEpoch: 4529  | Training Loss: 0.21229 \nEpoch: 4529  | Training Loss: 0.14727 \nEpoch: 4529  | Validation balanced accuracy : 0.76304 \nEpoch: 4530  | Training Loss: 0.31588 \nEpoch: 4530  | Training Loss: 0.36809 \nEpoch: 4530  | Training Loss: 0.34635 \nEpoch: 4530  | Training Loss: 0.21229 \nEpoch: 4530  | Training Loss: 0.14722 \nEpoch: 4530  | Validation balanced accuracy : 0.76304 \nEpoch: 4531  | Training Loss: 0.31593 \nEpoch: 4531  | Training Loss: 0.36814 \nEpoch: 4531  | Training Loss: 0.34631 \nEpoch: 4531  | Training Loss: 0.21230 \nEpoch: 4531  | Training Loss: 0.14708 \nEpoch: 4531  | Validation balanced accuracy : 0.76304 \nEpoch: 4532  | Training Loss: 0.31603 \nEpoch: 4532  | Training Loss: 0.36821 \nEpoch: 4532  | Training Loss: 0.34627 \nEpoch: 4532  | Training Loss: 0.21231 \nEpoch: 4532  | Training Loss: 0.14698 \nEpoch: 4532  | Validation balanced accuracy : 0.76304 \nEpoch: 4533  | Training Loss: 0.31610 \nEpoch: 4533  | Training Loss: 0.36822 \nEpoch: 4533  | Training Loss: 0.34629 \nEpoch: 4533  | Training Loss: 0.21230 \nEpoch: 4533  | Training Loss: 0.14716 \nEpoch: 4533  | Validation balanced accuracy : 0.76304 \nEpoch: 4534  | Training Loss: 0.31594 \nEpoch: 4534  | Training Loss: 0.36812 \nEpoch: 4534  | Training Loss: 0.34634 \nEpoch: 4534  | Training Loss: 0.21229 \nEpoch: 4534  | Training Loss: 0.14724 \nEpoch: 4534  | Validation balanced accuracy : 0.76304 \nEpoch: 4535  | Training Loss: 0.31591 \nEpoch: 4535  | Training Loss: 0.36811 \nEpoch: 4535  | Training Loss: 0.34634 \nEpoch: 4535  | Training Loss: 0.21229 \nEpoch: 4535  | Training Loss: 0.14718 \nEpoch: 4535  | Validation balanced accuracy : 0.76304 \nEpoch: 4536  | Training Loss: 0.31596 \nEpoch: 4536  | Training Loss: 0.36815 \nEpoch: 4536  | Training Loss: 0.34631 \nEpoch: 4536  | Training Loss: 0.21230 \nEpoch: 4536  | Training Loss: 0.14709 \nEpoch: 4536  | Validation balanced accuracy : 0.76304 \nEpoch: 4537  | Training Loss: 0.31602 \nEpoch: 4537  | Training Loss: 0.36820 \nEpoch: 4537  | Training Loss: 0.34629 \nEpoch: 4537  | Training Loss: 0.21231 \nEpoch: 4537  | Training Loss: 0.14702 \nEpoch: 4537  | Validation balanced accuracy : 0.76304 \nEpoch: 4538  | Training Loss: 0.31607 \nEpoch: 4538  | Training Loss: 0.36823 \nEpoch: 4538  | Training Loss: 0.34627 \nEpoch: 4538  | Training Loss: 0.21231 \nEpoch: 4538  | Training Loss: 0.14698 \nEpoch: 4538  | Validation balanced accuracy : 0.76304 \nEpoch: 4539  | Training Loss: 0.31610 \nEpoch: 4539  | Training Loss: 0.36821 \nEpoch: 4539  | Training Loss: 0.34630 \nEpoch: 4539  | Training Loss: 0.21230 \nEpoch: 4539  | Training Loss: 0.14719 \nEpoch: 4539  | Validation balanced accuracy : 0.76304 \nEpoch: 4540  | Training Loss: 0.31591 \nEpoch: 4540  | Training Loss: 0.36810 \nEpoch: 4540  | Training Loss: 0.34635 \nEpoch: 4540  | Training Loss: 0.21228 \nEpoch: 4540  | Training Loss: 0.14728 \nEpoch: 4540  | Validation balanced accuracy : 0.76304 \nEpoch: 4541  | Training Loss: 0.31587 \nEpoch: 4541  | Training Loss: 0.36809 \nEpoch: 4541  | Training Loss: 0.34635 \nEpoch: 4541  | Training Loss: 0.21229 \nEpoch: 4541  | Training Loss: 0.14722 \nEpoch: 4541  | Validation balanced accuracy : 0.76304 \nEpoch: 4542  | Training Loss: 0.31593 \nEpoch: 4542  | Training Loss: 0.36814 \nEpoch: 4542  | Training Loss: 0.34631 \nEpoch: 4542  | Training Loss: 0.21230 \nEpoch: 4542  | Training Loss: 0.14708 \nEpoch: 4542  | Validation balanced accuracy : 0.76304 \nEpoch: 4543  | Training Loss: 0.31604 \nEpoch: 4543  | Training Loss: 0.36821 \nEpoch: 4543  | Training Loss: 0.34627 \nEpoch: 4543  | Training Loss: 0.21231 \nEpoch: 4543  | Training Loss: 0.14697 \nEpoch: 4543  | Validation balanced accuracy : 0.76304 \nEpoch: 4544  | Training Loss: 0.31611 \nEpoch: 4544  | Training Loss: 0.36822 \nEpoch: 4544  | Training Loss: 0.34629 \nEpoch: 4544  | Training Loss: 0.21230 \nEpoch: 4544  | Training Loss: 0.14715 \nEpoch: 4544  | Validation balanced accuracy : 0.76304 \nEpoch: 4545  | Training Loss: 0.31594 \nEpoch: 4545  | Training Loss: 0.36812 \nEpoch: 4545  | Training Loss: 0.34634 \nEpoch: 4545  | Training Loss: 0.21229 \nEpoch: 4545  | Training Loss: 0.14723 \nEpoch: 4545  | Validation balanced accuracy : 0.76304 \nEpoch: 4546  | Training Loss: 0.31591 \nEpoch: 4546  | Training Loss: 0.36812 \nEpoch: 4546  | Training Loss: 0.34634 \nEpoch: 4546  | Training Loss: 0.21229 \nEpoch: 4546  | Training Loss: 0.14717 \nEpoch: 4546  | Validation balanced accuracy : 0.76304 \nEpoch: 4547  | Training Loss: 0.31597 \nEpoch: 4547  | Training Loss: 0.36816 \nEpoch: 4547  | Training Loss: 0.34631 \nEpoch: 4547  | Training Loss: 0.21230 \nEpoch: 4547  | Training Loss: 0.14709 \nEpoch: 4547  | Validation balanced accuracy : 0.76304 \nEpoch: 4548  | Training Loss: 0.31602 \nEpoch: 4548  | Training Loss: 0.36820 \nEpoch: 4548  | Training Loss: 0.34629 \nEpoch: 4548  | Training Loss: 0.21230 \nEpoch: 4548  | Training Loss: 0.14702 \nEpoch: 4548  | Validation balanced accuracy : 0.76304 \nEpoch: 4549  | Training Loss: 0.31607 \nEpoch: 4549  | Training Loss: 0.36823 \nEpoch: 4549  | Training Loss: 0.34627 \nEpoch: 4549  | Training Loss: 0.21231 \nEpoch: 4549  | Training Loss: 0.14699 \nEpoch: 4549  | Validation balanced accuracy : 0.76304 \nEpoch: 4550  | Training Loss: 0.31608 \nEpoch: 4550  | Training Loss: 0.36820 \nEpoch: 4550  | Training Loss: 0.34631 \nEpoch: 4550  | Training Loss: 0.21229 \nEpoch: 4550  | Training Loss: 0.14722 \nEpoch: 4550  | Validation balanced accuracy : 0.76304 \nEpoch: 4551  | Training Loss: 0.31589 \nEpoch: 4551  | Training Loss: 0.36808 \nEpoch: 4551  | Training Loss: 0.34637 \nEpoch: 4551  | Training Loss: 0.21228 \nEpoch: 4551  | Training Loss: 0.14731 \nEpoch: 4551  | Validation balanced accuracy : 0.76304 \nEpoch: 4552  | Training Loss: 0.31585 \nEpoch: 4552  | Training Loss: 0.36807 \nEpoch: 4552  | Training Loss: 0.34636 \nEpoch: 4552  | Training Loss: 0.21228 \nEpoch: 4552  | Training Loss: 0.14724 \nEpoch: 4552  | Validation balanced accuracy : 0.76304 \nEpoch: 4553  | Training Loss: 0.31591 \nEpoch: 4553  | Training Loss: 0.36813 \nEpoch: 4553  | Training Loss: 0.34632 \nEpoch: 4553  | Training Loss: 0.21229 \nEpoch: 4553  | Training Loss: 0.14709 \nEpoch: 4553  | Validation balanced accuracy : 0.76304 \nEpoch: 4554  | Training Loss: 0.31602 \nEpoch: 4554  | Training Loss: 0.36821 \nEpoch: 4554  | Training Loss: 0.34628 \nEpoch: 4554  | Training Loss: 0.21231 \nEpoch: 4554  | Training Loss: 0.14697 \nEpoch: 4554  | Validation balanced accuracy : 0.76304 \nEpoch: 4555  | Training Loss: 0.31610 \nEpoch: 4555  | Training Loss: 0.36822 \nEpoch: 4555  | Training Loss: 0.34630 \nEpoch: 4555  | Training Loss: 0.21230 \nEpoch: 4555  | Training Loss: 0.14715 \nEpoch: 4555  | Validation balanced accuracy : 0.76304 \nEpoch: 4556  | Training Loss: 0.31594 \nEpoch: 4556  | Training Loss: 0.36812 \nEpoch: 4556  | Training Loss: 0.34635 \nEpoch: 4556  | Training Loss: 0.21228 \nEpoch: 4556  | Training Loss: 0.14726 \nEpoch: 4556  | Validation balanced accuracy : 0.76304 \nEpoch: 4557  | Training Loss: 0.31588 \nEpoch: 4557  | Training Loss: 0.36809 \nEpoch: 4557  | Training Loss: 0.34636 \nEpoch: 4557  | Training Loss: 0.21228 \nEpoch: 4557  | Training Loss: 0.14723 \nEpoch: 4557  | Validation balanced accuracy : 0.76304 \nEpoch: 4558  | Training Loss: 0.31592 \nEpoch: 4558  | Training Loss: 0.36813 \nEpoch: 4558  | Training Loss: 0.34633 \nEpoch: 4558  | Training Loss: 0.21229 \nEpoch: 4558  | Training Loss: 0.14710 \nEpoch: 4558  | Validation balanced accuracy : 0.76304 \nEpoch: 4559  | Training Loss: 0.31602 \nEpoch: 4559  | Training Loss: 0.36820 \nEpoch: 4559  | Training Loss: 0.34629 \nEpoch: 4559  | Training Loss: 0.21230 \nEpoch: 4559  | Training Loss: 0.14699 \nEpoch: 4559  | Validation balanced accuracy : 0.76304 \nEpoch: 4560  | Training Loss: 0.31609 \nEpoch: 4560  | Training Loss: 0.36821 \nEpoch: 4560  | Training Loss: 0.34631 \nEpoch: 4560  | Training Loss: 0.21229 \nEpoch: 4560  | Training Loss: 0.14717 \nEpoch: 4560  | Validation balanced accuracy : 0.76304 \nEpoch: 4561  | Training Loss: 0.31593 \nEpoch: 4561  | Training Loss: 0.36811 \nEpoch: 4561  | Training Loss: 0.34635 \nEpoch: 4561  | Training Loss: 0.21228 \nEpoch: 4561  | Training Loss: 0.14724 \nEpoch: 4561  | Validation balanced accuracy : 0.76304 \nEpoch: 4562  | Training Loss: 0.31590 \nEpoch: 4562  | Training Loss: 0.36811 \nEpoch: 4562  | Training Loss: 0.34634 \nEpoch: 4562  | Training Loss: 0.21229 \nEpoch: 4562  | Training Loss: 0.14717 \nEpoch: 4562  | Validation balanced accuracy : 0.76304 \nEpoch: 4563  | Training Loss: 0.31596 \nEpoch: 4563  | Training Loss: 0.36816 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4563  | Training Loss: 0.34632 \nEpoch: 4563  | Training Loss: 0.21230 \nEpoch: 4563  | Training Loss: 0.14708 \nEpoch: 4563  | Validation balanced accuracy : 0.76304 \nEpoch: 4564  | Training Loss: 0.31602 \nEpoch: 4564  | Training Loss: 0.36820 \nEpoch: 4564  | Training Loss: 0.34629 \nEpoch: 4564  | Training Loss: 0.21230 \nEpoch: 4564  | Training Loss: 0.14701 \nEpoch: 4564  | Validation balanced accuracy : 0.76304 \nEpoch: 4565  | Training Loss: 0.31607 \nEpoch: 4565  | Training Loss: 0.36823 \nEpoch: 4565  | Training Loss: 0.34627 \nEpoch: 4565  | Training Loss: 0.21231 \nEpoch: 4565  | Training Loss: 0.14696 \nEpoch: 4565  | Validation balanced accuracy : 0.76304 \nEpoch: 4566  | Training Loss: 0.31610 \nEpoch: 4566  | Training Loss: 0.36821 \nEpoch: 4566  | Training Loss: 0.34631 \nEpoch: 4566  | Training Loss: 0.21229 \nEpoch: 4566  | Training Loss: 0.14720 \nEpoch: 4566  | Validation balanced accuracy : 0.76304 \nEpoch: 4567  | Training Loss: 0.31590 \nEpoch: 4567  | Training Loss: 0.36809 \nEpoch: 4567  | Training Loss: 0.34637 \nEpoch: 4567  | Training Loss: 0.21228 \nEpoch: 4567  | Training Loss: 0.14730 \nEpoch: 4567  | Validation balanced accuracy : 0.76304 \nEpoch: 4568  | Training Loss: 0.31585 \nEpoch: 4568  | Training Loss: 0.36807 \nEpoch: 4568  | Training Loss: 0.34637 \nEpoch: 4568  | Training Loss: 0.21228 \nEpoch: 4568  | Training Loss: 0.14724 \nEpoch: 4568  | Validation balanced accuracy : 0.76304 \nEpoch: 4569  | Training Loss: 0.31591 \nEpoch: 4569  | Training Loss: 0.36813 \nEpoch: 4569  | Training Loss: 0.34633 \nEpoch: 4569  | Training Loss: 0.21229 \nEpoch: 4569  | Training Loss: 0.14710 \nEpoch: 4569  | Validation balanced accuracy : 0.76304 \nEpoch: 4570  | Training Loss: 0.31602 \nEpoch: 4570  | Training Loss: 0.36820 \nEpoch: 4570  | Training Loss: 0.34629 \nEpoch: 4570  | Training Loss: 0.21230 \nEpoch: 4570  | Training Loss: 0.14698 \nEpoch: 4570  | Validation balanced accuracy : 0.76304 \nEpoch: 4571  | Training Loss: 0.31610 \nEpoch: 4571  | Training Loss: 0.36822 \nEpoch: 4571  | Training Loss: 0.34630 \nEpoch: 4571  | Training Loss: 0.21229 \nEpoch: 4571  | Training Loss: 0.14715 \nEpoch: 4571  | Validation balanced accuracy : 0.76304 \nEpoch: 4572  | Training Loss: 0.31594 \nEpoch: 4572  | Training Loss: 0.36812 \nEpoch: 4572  | Training Loss: 0.34635 \nEpoch: 4572  | Training Loss: 0.21228 \nEpoch: 4572  | Training Loss: 0.14722 \nEpoch: 4572  | Validation balanced accuracy : 0.76304 \nEpoch: 4573  | Training Loss: 0.31591 \nEpoch: 4573  | Training Loss: 0.36812 \nEpoch: 4573  | Training Loss: 0.34634 \nEpoch: 4573  | Training Loss: 0.21229 \nEpoch: 4573  | Training Loss: 0.14715 \nEpoch: 4573  | Validation balanced accuracy : 0.76304 \nEpoch: 4574  | Training Loss: 0.31597 \nEpoch: 4574  | Training Loss: 0.36816 \nEpoch: 4574  | Training Loss: 0.34632 \nEpoch: 4574  | Training Loss: 0.21229 \nEpoch: 4574  | Training Loss: 0.14707 \nEpoch: 4574  | Validation balanced accuracy : 0.76304 \nEpoch: 4575  | Training Loss: 0.31603 \nEpoch: 4575  | Training Loss: 0.36820 \nEpoch: 4575  | Training Loss: 0.34629 \nEpoch: 4575  | Training Loss: 0.21230 \nEpoch: 4575  | Training Loss: 0.14700 \nEpoch: 4575  | Validation balanced accuracy : 0.76304 \nEpoch: 4576  | Training Loss: 0.31607 \nEpoch: 4576  | Training Loss: 0.36823 \nEpoch: 4576  | Training Loss: 0.34627 \nEpoch: 4576  | Training Loss: 0.21230 \nEpoch: 4576  | Training Loss: 0.14696 \nEpoch: 4576  | Validation balanced accuracy : 0.76304 \nEpoch: 4577  | Training Loss: 0.31610 \nEpoch: 4577  | Training Loss: 0.36822 \nEpoch: 4577  | Training Loss: 0.34631 \nEpoch: 4577  | Training Loss: 0.21229 \nEpoch: 4577  | Training Loss: 0.14717 \nEpoch: 4577  | Validation balanced accuracy : 0.76304 \nEpoch: 4578  | Training Loss: 0.31592 \nEpoch: 4578  | Training Loss: 0.36810 \nEpoch: 4578  | Training Loss: 0.34636 \nEpoch: 4578  | Training Loss: 0.21228 \nEpoch: 4578  | Training Loss: 0.14726 \nEpoch: 4578  | Validation balanced accuracy : 0.76304 \nEpoch: 4579  | Training Loss: 0.31588 \nEpoch: 4579  | Training Loss: 0.36809 \nEpoch: 4579  | Training Loss: 0.34636 \nEpoch: 4579  | Training Loss: 0.21228 \nEpoch: 4579  | Training Loss: 0.14720 \nEpoch: 4579  | Validation balanced accuracy : 0.76304 \nEpoch: 4580  | Training Loss: 0.31594 \nEpoch: 4580  | Training Loss: 0.36814 \nEpoch: 4580  | Training Loss: 0.34632 \nEpoch: 4580  | Training Loss: 0.21229 \nEpoch: 4580  | Training Loss: 0.14706 \nEpoch: 4580  | Validation balanced accuracy : 0.76304 \nEpoch: 4581  | Training Loss: 0.31604 \nEpoch: 4581  | Training Loss: 0.36821 \nEpoch: 4581  | Training Loss: 0.34628 \nEpoch: 4581  | Training Loss: 0.21230 \nEpoch: 4581  | Training Loss: 0.14696 \nEpoch: 4581  | Validation balanced accuracy : 0.76304 \nEpoch: 4582  | Training Loss: 0.31611 \nEpoch: 4582  | Training Loss: 0.36822 \nEpoch: 4582  | Training Loss: 0.34630 \nEpoch: 4582  | Training Loss: 0.21229 \nEpoch: 4582  | Training Loss: 0.14714 \nEpoch: 4582  | Validation balanced accuracy : 0.76304 \nEpoch: 4583  | Training Loss: 0.31594 \nEpoch: 4583  | Training Loss: 0.36813 \nEpoch: 4583  | Training Loss: 0.34635 \nEpoch: 4583  | Training Loss: 0.21228 \nEpoch: 4583  | Training Loss: 0.14721 \nEpoch: 4583  | Validation balanced accuracy : 0.76304 \nEpoch: 4584  | Training Loss: 0.31591 \nEpoch: 4584  | Training Loss: 0.36812 \nEpoch: 4584  | Training Loss: 0.34634 \nEpoch: 4584  | Training Loss: 0.21228 \nEpoch: 4584  | Training Loss: 0.14715 \nEpoch: 4584  | Validation balanced accuracy : 0.76304 \nEpoch: 4585  | Training Loss: 0.31597 \nEpoch: 4585  | Training Loss: 0.36816 \nEpoch: 4585  | Training Loss: 0.34632 \nEpoch: 4585  | Training Loss: 0.21229 \nEpoch: 4585  | Training Loss: 0.14707 \nEpoch: 4585  | Validation balanced accuracy : 0.76304 \nEpoch: 4586  | Training Loss: 0.31603 \nEpoch: 4586  | Training Loss: 0.36820 \nEpoch: 4586  | Training Loss: 0.34630 \nEpoch: 4586  | Training Loss: 0.21230 \nEpoch: 4586  | Training Loss: 0.14702 \nEpoch: 4586  | Validation balanced accuracy : 0.76304 \nEpoch: 4587  | Training Loss: 0.31605 \nEpoch: 4587  | Training Loss: 0.36822 \nEpoch: 4587  | Training Loss: 0.34629 \nEpoch: 4587  | Training Loss: 0.21230 \nEpoch: 4587  | Training Loss: 0.14699 \nEpoch: 4587  | Validation balanced accuracy : 0.76304 \nEpoch: 4588  | Training Loss: 0.31607 \nEpoch: 4588  | Training Loss: 0.36823 \nEpoch: 4588  | Training Loss: 0.34628 \nEpoch: 4588  | Training Loss: 0.21230 \nEpoch: 4588  | Training Loss: 0.14697 \nEpoch: 4588  | Validation balanced accuracy : 0.76304 \nEpoch: 4589  | Training Loss: 0.31609 \nEpoch: 4589  | Training Loss: 0.36821 \nEpoch: 4589  | Training Loss: 0.34632 \nEpoch: 4589  | Training Loss: 0.21229 \nEpoch: 4589  | Training Loss: 0.14719 \nEpoch: 4589  | Validation balanced accuracy : 0.76304 \nEpoch: 4590  | Training Loss: 0.31590 \nEpoch: 4590  | Training Loss: 0.36809 \nEpoch: 4590  | Training Loss: 0.34637 \nEpoch: 4590  | Training Loss: 0.21227 \nEpoch: 4590  | Training Loss: 0.14728 \nEpoch: 4590  | Validation balanced accuracy : 0.76304 \nEpoch: 4591  | Training Loss: 0.31586 \nEpoch: 4591  | Training Loss: 0.36808 \nEpoch: 4591  | Training Loss: 0.34637 \nEpoch: 4591  | Training Loss: 0.21228 \nEpoch: 4591  | Training Loss: 0.14722 \nEpoch: 4591  | Validation balanced accuracy : 0.76304 \nEpoch: 4592  | Training Loss: 0.31592 \nEpoch: 4592  | Training Loss: 0.36814 \nEpoch: 4592  | Training Loss: 0.34633 \nEpoch: 4592  | Training Loss: 0.21229 \nEpoch: 4592  | Training Loss: 0.14707 \nEpoch: 4592  | Validation balanced accuracy : 0.76304 \nEpoch: 4593  | Training Loss: 0.31603 \nEpoch: 4593  | Training Loss: 0.36821 \nEpoch: 4593  | Training Loss: 0.34629 \nEpoch: 4593  | Training Loss: 0.21230 \nEpoch: 4593  | Training Loss: 0.14696 \nEpoch: 4593  | Validation balanced accuracy : 0.76304 \nEpoch: 4594  | Training Loss: 0.31611 \nEpoch: 4594  | Training Loss: 0.36822 \nEpoch: 4594  | Training Loss: 0.34630 \nEpoch: 4594  | Training Loss: 0.21229 \nEpoch: 4594  | Training Loss: 0.14713 \nEpoch: 4594  | Validation balanced accuracy : 0.76304 \nEpoch: 4595  | Training Loss: 0.31595 \nEpoch: 4595  | Training Loss: 0.36812 \nEpoch: 4595  | Training Loss: 0.34636 \nEpoch: 4595  | Training Loss: 0.21228 \nEpoch: 4595  | Training Loss: 0.14725 \nEpoch: 4595  | Validation balanced accuracy : 0.76304 \nEpoch: 4596  | Training Loss: 0.31588 \nEpoch: 4596  | Training Loss: 0.36809 \nEpoch: 4596  | Training Loss: 0.34637 \nEpoch: 4596  | Training Loss: 0.21228 \nEpoch: 4596  | Training Loss: 0.14721 \nEpoch: 4596  | Validation balanced accuracy : 0.76304 \nEpoch: 4597  | Training Loss: 0.31592 \nEpoch: 4597  | Training Loss: 0.36813 \nEpoch: 4597  | Training Loss: 0.34634 \nEpoch: 4597  | Training Loss: 0.21229 \nEpoch: 4597  | Training Loss: 0.14709 \nEpoch: 4597  | Validation balanced accuracy : 0.76304 \nEpoch: 4598  | Training Loss: 0.31602 \nEpoch: 4598  | Training Loss: 0.36820 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4598  | Training Loss: 0.34630 \nEpoch: 4598  | Training Loss: 0.21230 \nEpoch: 4598  | Training Loss: 0.14698 \nEpoch: 4598  | Validation balanced accuracy : 0.76304 \nEpoch: 4599  | Training Loss: 0.31609 \nEpoch: 4599  | Training Loss: 0.36821 \nEpoch: 4599  | Training Loss: 0.34631 \nEpoch: 4599  | Training Loss: 0.21229 \nEpoch: 4599  | Training Loss: 0.14715 \nEpoch: 4599  | Validation balanced accuracy : 0.76304 \nEpoch: 4600  | Training Loss: 0.31593 \nEpoch: 4600  | Training Loss: 0.36812 \nEpoch: 4600  | Training Loss: 0.34636 \nEpoch: 4600  | Training Loss: 0.21228 \nEpoch: 4600  | Training Loss: 0.14722 \nEpoch: 4600  | Validation balanced accuracy : 0.76304 \nEpoch: 4601  | Training Loss: 0.31591 \nEpoch: 4601  | Training Loss: 0.36811 \nEpoch: 4601  | Training Loss: 0.34635 \nEpoch: 4601  | Training Loss: 0.21228 \nEpoch: 4601  | Training Loss: 0.14715 \nEpoch: 4601  | Validation balanced accuracy : 0.76304 \nEpoch: 4602  | Training Loss: 0.31597 \nEpoch: 4602  | Training Loss: 0.36817 \nEpoch: 4602  | Training Loss: 0.34632 \nEpoch: 4602  | Training Loss: 0.21229 \nEpoch: 4602  | Training Loss: 0.14702 \nEpoch: 4602  | Validation balanced accuracy : 0.76304 \nEpoch: 4603  | Training Loss: 0.31606 \nEpoch: 4603  | Training Loss: 0.36823 \nEpoch: 4603  | Training Loss: 0.34628 \nEpoch: 4603  | Training Loss: 0.21230 \nEpoch: 4603  | Training Loss: 0.14694 \nEpoch: 4603  | Validation balanced accuracy : 0.76304 \nEpoch: 4604  | Training Loss: 0.31611 \nEpoch: 4604  | Training Loss: 0.36822 \nEpoch: 4604  | Training Loss: 0.34631 \nEpoch: 4604  | Training Loss: 0.21229 \nEpoch: 4604  | Training Loss: 0.14715 \nEpoch: 4604  | Validation balanced accuracy : 0.76304 \nEpoch: 4605  | Training Loss: 0.31593 \nEpoch: 4605  | Training Loss: 0.36811 \nEpoch: 4605  | Training Loss: 0.34636 \nEpoch: 4605  | Training Loss: 0.21228 \nEpoch: 4605  | Training Loss: 0.14723 \nEpoch: 4605  | Validation balanced accuracy : 0.76304 \nEpoch: 4606  | Training Loss: 0.31589 \nEpoch: 4606  | Training Loss: 0.36810 \nEpoch: 4606  | Training Loss: 0.34636 \nEpoch: 4606  | Training Loss: 0.21228 \nEpoch: 4606  | Training Loss: 0.14717 \nEpoch: 4606  | Validation balanced accuracy : 0.76304 \nEpoch: 4607  | Training Loss: 0.31595 \nEpoch: 4607  | Training Loss: 0.36815 \nEpoch: 4607  | Training Loss: 0.34633 \nEpoch: 4607  | Training Loss: 0.21229 \nEpoch: 4607  | Training Loss: 0.14709 \nEpoch: 4607  | Validation balanced accuracy : 0.76304 \nEpoch: 4608  | Training Loss: 0.31601 \nEpoch: 4608  | Training Loss: 0.36819 \nEpoch: 4608  | Training Loss: 0.34631 \nEpoch: 4608  | Training Loss: 0.21229 \nEpoch: 4608  | Training Loss: 0.14701 \nEpoch: 4608  | Validation balanced accuracy : 0.76304 \nEpoch: 4609  | Training Loss: 0.31606 \nEpoch: 4609  | Training Loss: 0.36823 \nEpoch: 4609  | Training Loss: 0.34629 \nEpoch: 4609  | Training Loss: 0.21230 \nEpoch: 4609  | Training Loss: 0.14695 \nEpoch: 4609  | Validation balanced accuracy : 0.76304 \nEpoch: 4610  | Training Loss: 0.31610 \nEpoch: 4610  | Training Loss: 0.36821 \nEpoch: 4610  | Training Loss: 0.34632 \nEpoch: 4610  | Training Loss: 0.21228 \nEpoch: 4610  | Training Loss: 0.14716 \nEpoch: 4610  | Validation balanced accuracy : 0.76304 \nEpoch: 4611  | Training Loss: 0.31592 \nEpoch: 4611  | Training Loss: 0.36811 \nEpoch: 4611  | Training Loss: 0.34637 \nEpoch: 4611  | Training Loss: 0.21227 \nEpoch: 4611  | Training Loss: 0.14725 \nEpoch: 4611  | Validation balanced accuracy : 0.76304 \nEpoch: 4612  | Training Loss: 0.31588 \nEpoch: 4612  | Training Loss: 0.36810 \nEpoch: 4612  | Training Loss: 0.34637 \nEpoch: 4612  | Training Loss: 0.21228 \nEpoch: 4612  | Training Loss: 0.14718 \nEpoch: 4612  | Validation balanced accuracy : 0.76304 \nEpoch: 4613  | Training Loss: 0.31594 \nEpoch: 4613  | Training Loss: 0.36815 \nEpoch: 4613  | Training Loss: 0.34633 \nEpoch: 4613  | Training Loss: 0.21229 \nEpoch: 4613  | Training Loss: 0.14705 \nEpoch: 4613  | Validation balanced accuracy : 0.76304 \nEpoch: 4614  | Training Loss: 0.31604 \nEpoch: 4614  | Training Loss: 0.36822 \nEpoch: 4614  | Training Loss: 0.34629 \nEpoch: 4614  | Training Loss: 0.21230 \nEpoch: 4614  | Training Loss: 0.14694 \nEpoch: 4614  | Validation balanced accuracy : 0.76304 \nEpoch: 4615  | Training Loss: 0.31611 \nEpoch: 4615  | Training Loss: 0.36823 \nEpoch: 4615  | Training Loss: 0.34631 \nEpoch: 4615  | Training Loss: 0.21229 \nEpoch: 4615  | Training Loss: 0.14712 \nEpoch: 4615  | Validation balanced accuracy : 0.76304 \nEpoch: 4616  | Training Loss: 0.31595 \nEpoch: 4616  | Training Loss: 0.36813 \nEpoch: 4616  | Training Loss: 0.34636 \nEpoch: 4616  | Training Loss: 0.21228 \nEpoch: 4616  | Training Loss: 0.14720 \nEpoch: 4616  | Validation balanced accuracy : 0.76304 \nEpoch: 4617  | Training Loss: 0.31592 \nEpoch: 4617  | Training Loss: 0.36812 \nEpoch: 4617  | Training Loss: 0.34635 \nEpoch: 4617  | Training Loss: 0.21228 \nEpoch: 4617  | Training Loss: 0.14714 \nEpoch: 4617  | Validation balanced accuracy : 0.76304 \nEpoch: 4618  | Training Loss: 0.31597 \nEpoch: 4618  | Training Loss: 0.36816 \nEpoch: 4618  | Training Loss: 0.34633 \nEpoch: 4618  | Training Loss: 0.21229 \nEpoch: 4618  | Training Loss: 0.14706 \nEpoch: 4618  | Validation balanced accuracy : 0.76304 \nEpoch: 4619  | Training Loss: 0.31603 \nEpoch: 4619  | Training Loss: 0.36820 \nEpoch: 4619  | Training Loss: 0.34630 \nEpoch: 4619  | Training Loss: 0.21229 \nEpoch: 4619  | Training Loss: 0.14699 \nEpoch: 4619  | Validation balanced accuracy : 0.76304 \nEpoch: 4620  | Training Loss: 0.31607 \nEpoch: 4620  | Training Loss: 0.36824 \nEpoch: 4620  | Training Loss: 0.34628 \nEpoch: 4620  | Training Loss: 0.21230 \nEpoch: 4620  | Training Loss: 0.14694 \nEpoch: 4620  | Validation balanced accuracy : 0.76304 \nEpoch: 4621  | Training Loss: 0.31610 \nEpoch: 4621  | Training Loss: 0.36821 \nEpoch: 4621  | Training Loss: 0.34632 \nEpoch: 4621  | Training Loss: 0.21228 \nEpoch: 4621  | Training Loss: 0.14718 \nEpoch: 4621  | Validation balanced accuracy : 0.76304 \nEpoch: 4622  | Training Loss: 0.31590 \nEpoch: 4622  | Training Loss: 0.36809 \nEpoch: 4622  | Training Loss: 0.34638 \nEpoch: 4622  | Training Loss: 0.21227 \nEpoch: 4622  | Training Loss: 0.14728 \nEpoch: 4622  | Validation balanced accuracy : 0.76304 \nEpoch: 4623  | Training Loss: 0.31585 \nEpoch: 4623  | Training Loss: 0.36808 \nEpoch: 4623  | Training Loss: 0.34638 \nEpoch: 4623  | Training Loss: 0.21227 \nEpoch: 4623  | Training Loss: 0.14722 \nEpoch: 4623  | Validation balanced accuracy : 0.76304 \nEpoch: 4624  | Training Loss: 0.31591 \nEpoch: 4624  | Training Loss: 0.36813 \nEpoch: 4624  | Training Loss: 0.34634 \nEpoch: 4624  | Training Loss: 0.21228 \nEpoch: 4624  | Training Loss: 0.14707 \nEpoch: 4624  | Validation balanced accuracy : 0.76304 \nEpoch: 4625  | Training Loss: 0.31602 \nEpoch: 4625  | Training Loss: 0.36821 \nEpoch: 4625  | Training Loss: 0.34630 \nEpoch: 4625  | Training Loss: 0.21229 \nEpoch: 4625  | Training Loss: 0.14695 \nEpoch: 4625  | Validation balanced accuracy : 0.76304 \nEpoch: 4626  | Training Loss: 0.31610 \nEpoch: 4626  | Training Loss: 0.36822 \nEpoch: 4626  | Training Loss: 0.34631 \nEpoch: 4626  | Training Loss: 0.21228 \nEpoch: 4626  | Training Loss: 0.14713 \nEpoch: 4626  | Validation balanced accuracy : 0.76304 \nEpoch: 4627  | Training Loss: 0.31594 \nEpoch: 4627  | Training Loss: 0.36812 \nEpoch: 4627  | Training Loss: 0.34637 \nEpoch: 4627  | Training Loss: 0.21227 \nEpoch: 4627  | Training Loss: 0.14724 \nEpoch: 4627  | Validation balanced accuracy : 0.76304 \nEpoch: 4628  | Training Loss: 0.31588 \nEpoch: 4628  | Training Loss: 0.36809 \nEpoch: 4628  | Training Loss: 0.34637 \nEpoch: 4628  | Training Loss: 0.21227 \nEpoch: 4628  | Training Loss: 0.14720 \nEpoch: 4628  | Validation balanced accuracy : 0.76304 \nEpoch: 4629  | Training Loss: 0.31592 \nEpoch: 4629  | Training Loss: 0.36814 \nEpoch: 4629  | Training Loss: 0.34634 \nEpoch: 4629  | Training Loss: 0.21228 \nEpoch: 4629  | Training Loss: 0.14707 \nEpoch: 4629  | Validation balanced accuracy : 0.76304 \nEpoch: 4630  | Training Loss: 0.31602 \nEpoch: 4630  | Training Loss: 0.36820 \nEpoch: 4630  | Training Loss: 0.34630 \nEpoch: 4630  | Training Loss: 0.21229 \nEpoch: 4630  | Training Loss: 0.14696 \nEpoch: 4630  | Validation balanced accuracy : 0.76304 \nEpoch: 4631  | Training Loss: 0.31609 \nEpoch: 4631  | Training Loss: 0.36821 \nEpoch: 4631  | Training Loss: 0.34632 \nEpoch: 4631  | Training Loss: 0.21228 \nEpoch: 4631  | Training Loss: 0.14714 \nEpoch: 4631  | Validation balanced accuracy : 0.76304 \nEpoch: 4632  | Training Loss: 0.31593 \nEpoch: 4632  | Training Loss: 0.36812 \nEpoch: 4632  | Training Loss: 0.34637 \nEpoch: 4632  | Training Loss: 0.21227 \nEpoch: 4632  | Training Loss: 0.14720 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4632  | Validation balanced accuracy : 0.76304 \nEpoch: 4633  | Training Loss: 0.31591 \nEpoch: 4633  | Training Loss: 0.36812 \nEpoch: 4633  | Training Loss: 0.34636 \nEpoch: 4633  | Training Loss: 0.21228 \nEpoch: 4633  | Training Loss: 0.14714 \nEpoch: 4633  | Validation balanced accuracy : 0.76304 \nEpoch: 4634  | Training Loss: 0.31597 \nEpoch: 4634  | Training Loss: 0.36816 \nEpoch: 4634  | Training Loss: 0.34633 \nEpoch: 4634  | Training Loss: 0.21228 \nEpoch: 4634  | Training Loss: 0.14705 \nEpoch: 4634  | Validation balanced accuracy : 0.76304 \nEpoch: 4635  | Training Loss: 0.31603 \nEpoch: 4635  | Training Loss: 0.36820 \nEpoch: 4635  | Training Loss: 0.34631 \nEpoch: 4635  | Training Loss: 0.21229 \nEpoch: 4635  | Training Loss: 0.14698 \nEpoch: 4635  | Validation balanced accuracy : 0.76304 \nEpoch: 4636  | Training Loss: 0.31608 \nEpoch: 4636  | Training Loss: 0.36824 \nEpoch: 4636  | Training Loss: 0.34629 \nEpoch: 4636  | Training Loss: 0.21229 \nEpoch: 4636  | Training Loss: 0.14693 \nEpoch: 4636  | Validation balanced accuracy : 0.76304 \nEpoch: 4637  | Training Loss: 0.31611 \nEpoch: 4637  | Training Loss: 0.36822 \nEpoch: 4637  | Training Loss: 0.34632 \nEpoch: 4637  | Training Loss: 0.21228 \nEpoch: 4637  | Training Loss: 0.14715 \nEpoch: 4637  | Validation balanced accuracy : 0.76304 \nEpoch: 4638  | Training Loss: 0.31592 \nEpoch: 4638  | Training Loss: 0.36811 \nEpoch: 4638  | Training Loss: 0.34638 \nEpoch: 4638  | Training Loss: 0.21227 \nEpoch: 4638  | Training Loss: 0.14724 \nEpoch: 4638  | Validation balanced accuracy : 0.76304 \nEpoch: 4639  | Training Loss: 0.31588 \nEpoch: 4639  | Training Loss: 0.36810 \nEpoch: 4639  | Training Loss: 0.34637 \nEpoch: 4639  | Training Loss: 0.21227 \nEpoch: 4639  | Training Loss: 0.14718 \nEpoch: 4639  | Validation balanced accuracy : 0.76304 \nEpoch: 4640  | Training Loss: 0.31594 \nEpoch: 4640  | Training Loss: 0.36815 \nEpoch: 4640  | Training Loss: 0.34634 \nEpoch: 4640  | Training Loss: 0.21228 \nEpoch: 4640  | Training Loss: 0.14705 \nEpoch: 4640  | Validation balanced accuracy : 0.76304 \nEpoch: 4641  | Training Loss: 0.31603 \nEpoch: 4641  | Training Loss: 0.36821 \nEpoch: 4641  | Training Loss: 0.34630 \nEpoch: 4641  | Training Loss: 0.21229 \nEpoch: 4641  | Training Loss: 0.14695 \nEpoch: 4641  | Validation balanced accuracy : 0.76304 \nEpoch: 4642  | Training Loss: 0.31610 \nEpoch: 4642  | Training Loss: 0.36822 \nEpoch: 4642  | Training Loss: 0.34632 \nEpoch: 4642  | Training Loss: 0.21228 \nEpoch: 4642  | Training Loss: 0.14713 \nEpoch: 4642  | Validation balanced accuracy : 0.76304 \nEpoch: 4643  | Training Loss: 0.31594 \nEpoch: 4643  | Training Loss: 0.36812 \nEpoch: 4643  | Training Loss: 0.34637 \nEpoch: 4643  | Training Loss: 0.21227 \nEpoch: 4643  | Training Loss: 0.14720 \nEpoch: 4643  | Validation balanced accuracy : 0.76304 \nEpoch: 4644  | Training Loss: 0.31591 \nEpoch: 4644  | Training Loss: 0.36812 \nEpoch: 4644  | Training Loss: 0.34636 \nEpoch: 4644  | Training Loss: 0.21227 \nEpoch: 4644  | Training Loss: 0.14714 \nEpoch: 4644  | Validation balanced accuracy : 0.76304 \nEpoch: 4645  | Training Loss: 0.31597 \nEpoch: 4645  | Training Loss: 0.36816 \nEpoch: 4645  | Training Loss: 0.34634 \nEpoch: 4645  | Training Loss: 0.21228 \nEpoch: 4645  | Training Loss: 0.14705 \nEpoch: 4645  | Validation balanced accuracy : 0.76304 \nEpoch: 4646  | Training Loss: 0.31603 \nEpoch: 4646  | Training Loss: 0.36820 \nEpoch: 4646  | Training Loss: 0.34631 \nEpoch: 4646  | Training Loss: 0.21229 \nEpoch: 4646  | Training Loss: 0.14698 \nEpoch: 4646  | Validation balanced accuracy : 0.76304 \nEpoch: 4647  | Training Loss: 0.31607 \nEpoch: 4647  | Training Loss: 0.36824 \nEpoch: 4647  | Training Loss: 0.34629 \nEpoch: 4647  | Training Loss: 0.21229 \nEpoch: 4647  | Training Loss: 0.14693 \nEpoch: 4647  | Validation balanced accuracy : 0.76304 \nEpoch: 4648  | Training Loss: 0.31611 \nEpoch: 4648  | Training Loss: 0.36822 \nEpoch: 4648  | Training Loss: 0.34633 \nEpoch: 4648  | Training Loss: 0.21228 \nEpoch: 4648  | Training Loss: 0.14717 \nEpoch: 4648  | Validation balanced accuracy : 0.76304 \nEpoch: 4649  | Training Loss: 0.31590 \nEpoch: 4649  | Training Loss: 0.36809 \nEpoch: 4649  | Training Loss: 0.34639 \nEpoch: 4649  | Training Loss: 0.21226 \nEpoch: 4649  | Training Loss: 0.14727 \nEpoch: 4649  | Validation balanced accuracy : 0.76304 \nEpoch: 4650  | Training Loss: 0.31586 \nEpoch: 4650  | Training Loss: 0.36808 \nEpoch: 4650  | Training Loss: 0.34639 \nEpoch: 4650  | Training Loss: 0.21227 \nEpoch: 4650  | Training Loss: 0.14721 \nEpoch: 4650  | Validation balanced accuracy : 0.76304 \nEpoch: 4651  | Training Loss: 0.31592 \nEpoch: 4651  | Training Loss: 0.36813 \nEpoch: 4651  | Training Loss: 0.34635 \nEpoch: 4651  | Training Loss: 0.21228 \nEpoch: 4651  | Training Loss: 0.14706 \nEpoch: 4651  | Validation balanced accuracy : 0.76304 \nEpoch: 4652  | Training Loss: 0.31602 \nEpoch: 4652  | Training Loss: 0.36821 \nEpoch: 4652  | Training Loss: 0.34631 \nEpoch: 4652  | Training Loss: 0.21229 \nEpoch: 4652  | Training Loss: 0.14694 \nEpoch: 4652  | Validation balanced accuracy : 0.76304 \nEpoch: 4653  | Training Loss: 0.31610 \nEpoch: 4653  | Training Loss: 0.36822 \nEpoch: 4653  | Training Loss: 0.34632 \nEpoch: 4653  | Training Loss: 0.21228 \nEpoch: 4653  | Training Loss: 0.14711 \nEpoch: 4653  | Validation balanced accuracy : 0.76304 \nEpoch: 4654  | Training Loss: 0.31594 \nEpoch: 4654  | Training Loss: 0.36812 \nEpoch: 4654  | Training Loss: 0.34638 \nEpoch: 4654  | Training Loss: 0.21227 \nEpoch: 4654  | Training Loss: 0.14723 \nEpoch: 4654  | Validation balanced accuracy : 0.76304 \nEpoch: 4655  | Training Loss: 0.31588 \nEpoch: 4655  | Training Loss: 0.36809 \nEpoch: 4655  | Training Loss: 0.34638 \nEpoch: 4655  | Training Loss: 0.21227 \nEpoch: 4655  | Training Loss: 0.14719 \nEpoch: 4655  | Validation balanced accuracy : 0.76304 \nEpoch: 4656  | Training Loss: 0.31593 \nEpoch: 4656  | Training Loss: 0.36814 \nEpoch: 4656  | Training Loss: 0.34635 \nEpoch: 4656  | Training Loss: 0.21228 \nEpoch: 4656  | Training Loss: 0.14706 \nEpoch: 4656  | Validation balanced accuracy : 0.76304 \nEpoch: 4657  | Training Loss: 0.31602 \nEpoch: 4657  | Training Loss: 0.36820 \nEpoch: 4657  | Training Loss: 0.34631 \nEpoch: 4657  | Training Loss: 0.21229 \nEpoch: 4657  | Training Loss: 0.14695 \nEpoch: 4657  | Validation balanced accuracy : 0.76304 \nEpoch: 4658  | Training Loss: 0.31609 \nEpoch: 4658  | Training Loss: 0.36821 \nEpoch: 4658  | Training Loss: 0.34633 \nEpoch: 4658  | Training Loss: 0.21228 \nEpoch: 4658  | Training Loss: 0.14713 \nEpoch: 4658  | Validation balanced accuracy : 0.76304 \nEpoch: 4659  | Training Loss: 0.31593 \nEpoch: 4659  | Training Loss: 0.36812 \nEpoch: 4659  | Training Loss: 0.34637 \nEpoch: 4659  | Training Loss: 0.21227 \nEpoch: 4659  | Training Loss: 0.14719 \nEpoch: 4659  | Validation balanced accuracy : 0.76304 \nEpoch: 4660  | Training Loss: 0.31591 \nEpoch: 4660  | Training Loss: 0.36812 \nEpoch: 4660  | Training Loss: 0.34637 \nEpoch: 4660  | Training Loss: 0.21227 \nEpoch: 4660  | Training Loss: 0.14713 \nEpoch: 4660  | Validation balanced accuracy : 0.76304 \nEpoch: 4661  | Training Loss: 0.31597 \nEpoch: 4661  | Training Loss: 0.36816 \nEpoch: 4661  | Training Loss: 0.34634 \nEpoch: 4661  | Training Loss: 0.21228 \nEpoch: 4661  | Training Loss: 0.14704 \nEpoch: 4661  | Validation balanced accuracy : 0.76304 \nEpoch: 4662  | Training Loss: 0.31603 \nEpoch: 4662  | Training Loss: 0.36820 \nEpoch: 4662  | Training Loss: 0.34631 \nEpoch: 4662  | Training Loss: 0.21229 \nEpoch: 4662  | Training Loss: 0.14697 \nEpoch: 4662  | Validation balanced accuracy : 0.76304 \nEpoch: 4663  | Training Loss: 0.31608 \nEpoch: 4663  | Training Loss: 0.36824 \nEpoch: 4663  | Training Loss: 0.34630 \nEpoch: 4663  | Training Loss: 0.21229 \nEpoch: 4663  | Training Loss: 0.14692 \nEpoch: 4663  | Validation balanced accuracy : 0.76304 \nEpoch: 4664  | Training Loss: 0.31611 \nEpoch: 4664  | Training Loss: 0.36822 \nEpoch: 4664  | Training Loss: 0.34633 \nEpoch: 4664  | Training Loss: 0.21228 \nEpoch: 4664  | Training Loss: 0.14714 \nEpoch: 4664  | Validation balanced accuracy : 0.76304 \nEpoch: 4665  | Training Loss: 0.31592 \nEpoch: 4665  | Training Loss: 0.36811 \nEpoch: 4665  | Training Loss: 0.34638 \nEpoch: 4665  | Training Loss: 0.21226 \nEpoch: 4665  | Training Loss: 0.14723 \nEpoch: 4665  | Validation balanced accuracy : 0.76304 \nEpoch: 4666  | Training Loss: 0.31588 \nEpoch: 4666  | Training Loss: 0.36810 \nEpoch: 4666  | Training Loss: 0.34638 \nEpoch: 4666  | Training Loss: 0.21227 \nEpoch: 4666  | Training Loss: 0.14717 \nEpoch: 4666  | Validation balanced accuracy : 0.76304 \nEpoch: 4667  | Training Loss: 0.31594 \nEpoch: 4667  | Training Loss: 0.36815 \nEpoch: 4667  | Training Loss: 0.34634 \nEpoch: 4667  | Training Loss: 0.21228 \nEpoch: 4667  | Training Loss: 0.14703 \nEpoch: 4667  | Validation balanced accuracy : 0.76304 \nEpoch: 4668  | Training Loss: 0.31604 \nEpoch: 4668  | Training Loss: 0.36822 \nEpoch: 4668  | Training Loss: 0.34631 \nEpoch: 4668  | Training Loss: 0.21229 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4668  | Training Loss: 0.14694 \nEpoch: 4668  | Validation balanced accuracy : 0.76304 \nEpoch: 4669  | Training Loss: 0.31609 \nEpoch: 4669  | Training Loss: 0.36821 \nEpoch: 4669  | Training Loss: 0.34633 \nEpoch: 4669  | Training Loss: 0.21227 \nEpoch: 4669  | Training Loss: 0.14714 \nEpoch: 4669  | Validation balanced accuracy : 0.76304 \nEpoch: 4670  | Training Loss: 0.31592 \nEpoch: 4670  | Training Loss: 0.36811 \nEpoch: 4670  | Training Loss: 0.34638 \nEpoch: 4670  | Training Loss: 0.21226 \nEpoch: 4670  | Training Loss: 0.14721 \nEpoch: 4670  | Validation balanced accuracy : 0.76304 \nEpoch: 4671  | Training Loss: 0.31589 \nEpoch: 4671  | Training Loss: 0.36811 \nEpoch: 4671  | Training Loss: 0.34638 \nEpoch: 4671  | Training Loss: 0.21227 \nEpoch: 4671  | Training Loss: 0.14715 \nEpoch: 4671  | Validation balanced accuracy : 0.76304 \nEpoch: 4672  | Training Loss: 0.31595 \nEpoch: 4672  | Training Loss: 0.36815 \nEpoch: 4672  | Training Loss: 0.34635 \nEpoch: 4672  | Training Loss: 0.21228 \nEpoch: 4672  | Training Loss: 0.14705 \nEpoch: 4672  | Validation balanced accuracy : 0.76304 \nEpoch: 4673  | Training Loss: 0.31602 \nEpoch: 4673  | Training Loss: 0.36820 \nEpoch: 4673  | Training Loss: 0.34632 \nEpoch: 4673  | Training Loss: 0.21228 \nEpoch: 4673  | Training Loss: 0.14698 \nEpoch: 4673  | Validation balanced accuracy : 0.76304 \nEpoch: 4674  | Training Loss: 0.31607 \nEpoch: 4674  | Training Loss: 0.36823 \nEpoch: 4674  | Training Loss: 0.34630 \nEpoch: 4674  | Training Loss: 0.21229 \nEpoch: 4674  | Training Loss: 0.14692 \nEpoch: 4674  | Validation balanced accuracy : 0.76304 \nEpoch: 4675  | Training Loss: 0.31611 \nEpoch: 4675  | Training Loss: 0.36822 \nEpoch: 4675  | Training Loss: 0.34633 \nEpoch: 4675  | Training Loss: 0.21227 \nEpoch: 4675  | Training Loss: 0.14713 \nEpoch: 4675  | Validation balanced accuracy : 0.76304 \nEpoch: 4676  | Training Loss: 0.31592 \nEpoch: 4676  | Training Loss: 0.36811 \nEpoch: 4676  | Training Loss: 0.34639 \nEpoch: 4676  | Training Loss: 0.21226 \nEpoch: 4676  | Training Loss: 0.14722 \nEpoch: 4676  | Validation balanced accuracy : 0.76304 \nEpoch: 4677  | Training Loss: 0.31589 \nEpoch: 4677  | Training Loss: 0.36810 \nEpoch: 4677  | Training Loss: 0.34638 \nEpoch: 4677  | Training Loss: 0.21227 \nEpoch: 4677  | Training Loss: 0.14716 \nEpoch: 4677  | Validation balanced accuracy : 0.76304 \nEpoch: 4678  | Training Loss: 0.31594 \nEpoch: 4678  | Training Loss: 0.36815 \nEpoch: 4678  | Training Loss: 0.34635 \nEpoch: 4678  | Training Loss: 0.21228 \nEpoch: 4678  | Training Loss: 0.14702 \nEpoch: 4678  | Validation balanced accuracy : 0.76304 \nEpoch: 4679  | Training Loss: 0.31605 \nEpoch: 4679  | Training Loss: 0.36822 \nEpoch: 4679  | Training Loss: 0.34631 \nEpoch: 4679  | Training Loss: 0.21229 \nEpoch: 4679  | Training Loss: 0.14691 \nEpoch: 4679  | Validation balanced accuracy : 0.76304 \nEpoch: 4680  | Training Loss: 0.31612 \nEpoch: 4680  | Training Loss: 0.36823 \nEpoch: 4680  | Training Loss: 0.34632 \nEpoch: 4680  | Training Loss: 0.21228 \nEpoch: 4680  | Training Loss: 0.14710 \nEpoch: 4680  | Validation balanced accuracy : 0.76304 \nEpoch: 4681  | Training Loss: 0.31595 \nEpoch: 4681  | Training Loss: 0.36813 \nEpoch: 4681  | Training Loss: 0.34637 \nEpoch: 4681  | Training Loss: 0.21227 \nEpoch: 4681  | Training Loss: 0.14717 \nEpoch: 4681  | Validation balanced accuracy : 0.76304 \nEpoch: 4682  | Training Loss: 0.31592 \nEpoch: 4682  | Training Loss: 0.36812 \nEpoch: 4682  | Training Loss: 0.34637 \nEpoch: 4682  | Training Loss: 0.21227 \nEpoch: 4682  | Training Loss: 0.14711 \nEpoch: 4682  | Validation balanced accuracy : 0.76304 \nEpoch: 4683  | Training Loss: 0.31597 \nEpoch: 4683  | Training Loss: 0.36816 \nEpoch: 4683  | Training Loss: 0.34634 \nEpoch: 4683  | Training Loss: 0.21228 \nEpoch: 4683  | Training Loss: 0.14703 \nEpoch: 4683  | Validation balanced accuracy : 0.76304 \nEpoch: 4684  | Training Loss: 0.31603 \nEpoch: 4684  | Training Loss: 0.36821 \nEpoch: 4684  | Training Loss: 0.34632 \nEpoch: 4684  | Training Loss: 0.21228 \nEpoch: 4684  | Training Loss: 0.14696 \nEpoch: 4684  | Validation balanced accuracy : 0.76304 \nEpoch: 4685  | Training Loss: 0.31608 \nEpoch: 4685  | Training Loss: 0.36823 \nEpoch: 4685  | Training Loss: 0.34631 \nEpoch: 4685  | Training Loss: 0.21229 \nEpoch: 4685  | Training Loss: 0.14694 \nEpoch: 4685  | Validation balanced accuracy : 0.76304 \nEpoch: 4686  | Training Loss: 0.31609 \nEpoch: 4686  | Training Loss: 0.36820 \nEpoch: 4686  | Training Loss: 0.34634 \nEpoch: 4686  | Training Loss: 0.21227 \nEpoch: 4686  | Training Loss: 0.14717 \nEpoch: 4686  | Validation balanced accuracy : 0.76304 \nEpoch: 4687  | Training Loss: 0.31589 \nEpoch: 4687  | Training Loss: 0.36809 \nEpoch: 4687  | Training Loss: 0.34640 \nEpoch: 4687  | Training Loss: 0.21226 \nEpoch: 4687  | Training Loss: 0.14726 \nEpoch: 4687  | Validation balanced accuracy : 0.76304 \nEpoch: 4688  | Training Loss: 0.31586 \nEpoch: 4688  | Training Loss: 0.36808 \nEpoch: 4688  | Training Loss: 0.34640 \nEpoch: 4688  | Training Loss: 0.21226 \nEpoch: 4688  | Training Loss: 0.14719 \nEpoch: 4688  | Validation balanced accuracy : 0.76304 \nEpoch: 4689  | Training Loss: 0.31592 \nEpoch: 4689  | Training Loss: 0.36814 \nEpoch: 4689  | Training Loss: 0.34636 \nEpoch: 4689  | Training Loss: 0.21227 \nEpoch: 4689  | Training Loss: 0.14704 \nEpoch: 4689  | Validation balanced accuracy : 0.76304 \nEpoch: 4690  | Training Loss: 0.31603 \nEpoch: 4690  | Training Loss: 0.36821 \nEpoch: 4690  | Training Loss: 0.34631 \nEpoch: 4690  | Training Loss: 0.21228 \nEpoch: 4690  | Training Loss: 0.14692 \nEpoch: 4690  | Validation balanced accuracy : 0.76304 \nEpoch: 4691  | Training Loss: 0.31611 \nEpoch: 4691  | Training Loss: 0.36823 \nEpoch: 4691  | Training Loss: 0.34633 \nEpoch: 4691  | Training Loss: 0.21227 \nEpoch: 4691  | Training Loss: 0.14709 \nEpoch: 4691  | Validation balanced accuracy : 0.76304 \nEpoch: 4692  | Training Loss: 0.31595 \nEpoch: 4692  | Training Loss: 0.36812 \nEpoch: 4692  | Training Loss: 0.34638 \nEpoch: 4692  | Training Loss: 0.21226 \nEpoch: 4692  | Training Loss: 0.14721 \nEpoch: 4692  | Validation balanced accuracy : 0.76304 \nEpoch: 4693  | Training Loss: 0.31589 \nEpoch: 4693  | Training Loss: 0.36810 \nEpoch: 4693  | Training Loss: 0.34639 \nEpoch: 4693  | Training Loss: 0.21226 \nEpoch: 4693  | Training Loss: 0.14717 \nEpoch: 4693  | Validation balanced accuracy : 0.76304 \nEpoch: 4694  | Training Loss: 0.31593 \nEpoch: 4694  | Training Loss: 0.36814 \nEpoch: 4694  | Training Loss: 0.34636 \nEpoch: 4694  | Training Loss: 0.21227 \nEpoch: 4694  | Training Loss: 0.14705 \nEpoch: 4694  | Validation balanced accuracy : 0.76304 \nEpoch: 4695  | Training Loss: 0.31602 \nEpoch: 4695  | Training Loss: 0.36820 \nEpoch: 4695  | Training Loss: 0.34632 \nEpoch: 4695  | Training Loss: 0.21228 \nEpoch: 4695  | Training Loss: 0.14694 \nEpoch: 4695  | Validation balanced accuracy : 0.76304 \nEpoch: 4696  | Training Loss: 0.31609 \nEpoch: 4696  | Training Loss: 0.36821 \nEpoch: 4696  | Training Loss: 0.34634 \nEpoch: 4696  | Training Loss: 0.21227 \nEpoch: 4696  | Training Loss: 0.14712 \nEpoch: 4696  | Validation balanced accuracy : 0.76304 \nEpoch: 4697  | Training Loss: 0.31594 \nEpoch: 4697  | Training Loss: 0.36812 \nEpoch: 4697  | Training Loss: 0.34638 \nEpoch: 4697  | Training Loss: 0.21226 \nEpoch: 4697  | Training Loss: 0.14718 \nEpoch: 4697  | Validation balanced accuracy : 0.76304 \nEpoch: 4698  | Training Loss: 0.31591 \nEpoch: 4698  | Training Loss: 0.36812 \nEpoch: 4698  | Training Loss: 0.34638 \nEpoch: 4698  | Training Loss: 0.21227 \nEpoch: 4698  | Training Loss: 0.14712 \nEpoch: 4698  | Validation balanced accuracy : 0.76304 \nEpoch: 4699  | Training Loss: 0.31597 \nEpoch: 4699  | Training Loss: 0.36816 \nEpoch: 4699  | Training Loss: 0.34635 \nEpoch: 4699  | Training Loss: 0.21227 \nEpoch: 4699  | Training Loss: 0.14703 \nEpoch: 4699  | Validation balanced accuracy : 0.76304 \nEpoch: 4700  | Training Loss: 0.31603 \nEpoch: 4700  | Training Loss: 0.36821 \nEpoch: 4700  | Training Loss: 0.34632 \nEpoch: 4700  | Training Loss: 0.21228 \nEpoch: 4700  | Training Loss: 0.14695 \nEpoch: 4700  | Validation balanced accuracy : 0.76304 \nEpoch: 4701  | Training Loss: 0.31608 \nEpoch: 4701  | Training Loss: 0.36824 \nEpoch: 4701  | Training Loss: 0.34630 \nEpoch: 4701  | Training Loss: 0.21228 \nEpoch: 4701  | Training Loss: 0.14691 \nEpoch: 4701  | Validation balanced accuracy : 0.76304 \nEpoch: 4702  | Training Loss: 0.31611 \nEpoch: 4702  | Training Loss: 0.36822 \nEpoch: 4702  | Training Loss: 0.34634 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4702  | Training Loss: 0.21227 \nEpoch: 4702  | Training Loss: 0.14715 \nEpoch: 4702  | Validation balanced accuracy : 0.76304 \nEpoch: 4703  | Training Loss: 0.31591 \nEpoch: 4703  | Training Loss: 0.36809 \nEpoch: 4703  | Training Loss: 0.34640 \nEpoch: 4703  | Training Loss: 0.21226 \nEpoch: 4703  | Training Loss: 0.14725 \nEpoch: 4703  | Validation balanced accuracy : 0.76304 \nEpoch: 4704  | Training Loss: 0.31586 \nEpoch: 4704  | Training Loss: 0.36808 \nEpoch: 4704  | Training Loss: 0.34640 \nEpoch: 4704  | Training Loss: 0.21226 \nEpoch: 4704  | Training Loss: 0.14719 \nEpoch: 4704  | Validation balanced accuracy : 0.76304 \nEpoch: 4705  | Training Loss: 0.31592 \nEpoch: 4705  | Training Loss: 0.36813 \nEpoch: 4705  | Training Loss: 0.34636 \nEpoch: 4705  | Training Loss: 0.21227 \nEpoch: 4705  | Training Loss: 0.14704 \nEpoch: 4705  | Validation balanced accuracy : 0.76304 \nEpoch: 4706  | Training Loss: 0.31603 \nEpoch: 4706  | Training Loss: 0.36821 \nEpoch: 4706  | Training Loss: 0.34632 \nEpoch: 4706  | Training Loss: 0.21228 \nEpoch: 4706  | Training Loss: 0.14692 \nEpoch: 4706  | Validation balanced accuracy : 0.76304 \nEpoch: 4707  | Training Loss: 0.31611 \nEpoch: 4707  | Training Loss: 0.36822 \nEpoch: 4707  | Training Loss: 0.34634 \nEpoch: 4707  | Training Loss: 0.21227 \nEpoch: 4707  | Training Loss: 0.14709 \nEpoch: 4707  | Validation balanced accuracy : 0.76304 \nEpoch: 4708  | Training Loss: 0.31595 \nEpoch: 4708  | Training Loss: 0.36813 \nEpoch: 4708  | Training Loss: 0.34638 \nEpoch: 4708  | Training Loss: 0.21226 \nEpoch: 4708  | Training Loss: 0.14716 \nEpoch: 4708  | Validation balanced accuracy : 0.76304 \nEpoch: 4709  | Training Loss: 0.31592 \nEpoch: 4709  | Training Loss: 0.36812 \nEpoch: 4709  | Training Loss: 0.34638 \nEpoch: 4709  | Training Loss: 0.21227 \nEpoch: 4709  | Training Loss: 0.14710 \nEpoch: 4709  | Validation balanced accuracy : 0.76304 \nEpoch: 4710  | Training Loss: 0.31598 \nEpoch: 4710  | Training Loss: 0.36817 \nEpoch: 4710  | Training Loss: 0.34635 \nEpoch: 4710  | Training Loss: 0.21227 \nEpoch: 4710  | Training Loss: 0.14701 \nEpoch: 4710  | Validation balanced accuracy : 0.76304 \nEpoch: 4711  | Training Loss: 0.31604 \nEpoch: 4711  | Training Loss: 0.36821 \nEpoch: 4711  | Training Loss: 0.34633 \nEpoch: 4711  | Training Loss: 0.21228 \nEpoch: 4711  | Training Loss: 0.14695 \nEpoch: 4711  | Validation balanced accuracy : 0.76304 \nEpoch: 4712  | Training Loss: 0.31608 \nEpoch: 4712  | Training Loss: 0.36824 \nEpoch: 4712  | Training Loss: 0.34631 \nEpoch: 4712  | Training Loss: 0.21228 \nEpoch: 4712  | Training Loss: 0.14690 \nEpoch: 4712  | Validation balanced accuracy : 0.76304 \nEpoch: 4713  | Training Loss: 0.31611 \nEpoch: 4713  | Training Loss: 0.36822 \nEpoch: 4713  | Training Loss: 0.34634 \nEpoch: 4713  | Training Loss: 0.21227 \nEpoch: 4713  | Training Loss: 0.14712 \nEpoch: 4713  | Validation balanced accuracy : 0.76304 \nEpoch: 4714  | Training Loss: 0.31593 \nEpoch: 4714  | Training Loss: 0.36811 \nEpoch: 4714  | Training Loss: 0.34640 \nEpoch: 4714  | Training Loss: 0.21226 \nEpoch: 4714  | Training Loss: 0.14721 \nEpoch: 4714  | Validation balanced accuracy : 0.76304 \nEpoch: 4715  | Training Loss: 0.31589 \nEpoch: 4715  | Training Loss: 0.36810 \nEpoch: 4715  | Training Loss: 0.34639 \nEpoch: 4715  | Training Loss: 0.21226 \nEpoch: 4715  | Training Loss: 0.14715 \nEpoch: 4715  | Validation balanced accuracy : 0.76304 \nEpoch: 4716  | Training Loss: 0.31594 \nEpoch: 4716  | Training Loss: 0.36815 \nEpoch: 4716  | Training Loss: 0.34636 \nEpoch: 4716  | Training Loss: 0.21227 \nEpoch: 4716  | Training Loss: 0.14701 \nEpoch: 4716  | Validation balanced accuracy : 0.76304 \nEpoch: 4717  | Training Loss: 0.31605 \nEpoch: 4717  | Training Loss: 0.36822 \nEpoch: 4717  | Training Loss: 0.34632 \nEpoch: 4717  | Training Loss: 0.21228 \nEpoch: 4717  | Training Loss: 0.14690 \nEpoch: 4717  | Validation balanced accuracy : 0.76304 \nEpoch: 4718  | Training Loss: 0.31612 \nEpoch: 4718  | Training Loss: 0.36823 \nEpoch: 4718  | Training Loss: 0.34634 \nEpoch: 4718  | Training Loss: 0.21227 \nEpoch: 4718  | Training Loss: 0.14708 \nEpoch: 4718  | Validation balanced accuracy : 0.76304 \nEpoch: 4719  | Training Loss: 0.31595 \nEpoch: 4719  | Training Loss: 0.36813 \nEpoch: 4719  | Training Loss: 0.34638 \nEpoch: 4719  | Training Loss: 0.21226 \nEpoch: 4719  | Training Loss: 0.14716 \nEpoch: 4719  | Validation balanced accuracy : 0.76304 \nEpoch: 4720  | Training Loss: 0.31592 \nEpoch: 4720  | Training Loss: 0.36812 \nEpoch: 4720  | Training Loss: 0.34638 \nEpoch: 4720  | Training Loss: 0.21226 \nEpoch: 4720  | Training Loss: 0.14710 \nEpoch: 4720  | Validation balanced accuracy : 0.76304 \nEpoch: 4721  | Training Loss: 0.31598 \nEpoch: 4721  | Training Loss: 0.36817 \nEpoch: 4721  | Training Loss: 0.34635 \nEpoch: 4721  | Training Loss: 0.21227 \nEpoch: 4721  | Training Loss: 0.14697 \nEpoch: 4721  | Validation balanced accuracy : 0.76304 \nEpoch: 4722  | Training Loss: 0.31607 \nEpoch: 4722  | Training Loss: 0.36824 \nEpoch: 4722  | Training Loss: 0.34631 \nEpoch: 4722  | Training Loss: 0.21228 \nEpoch: 4722  | Training Loss: 0.14688 \nEpoch: 4722  | Validation balanced accuracy : 0.76304 \nEpoch: 4723  | Training Loss: 0.31613 \nEpoch: 4723  | Training Loss: 0.36823 \nEpoch: 4723  | Training Loss: 0.34634 \nEpoch: 4723  | Training Loss: 0.21227 \nEpoch: 4723  | Training Loss: 0.14709 \nEpoch: 4723  | Validation balanced accuracy : 0.76304 \nEpoch: 4724  | Training Loss: 0.31594 \nEpoch: 4724  | Training Loss: 0.36812 \nEpoch: 4724  | Training Loss: 0.34639 \nEpoch: 4724  | Training Loss: 0.21226 \nEpoch: 4724  | Training Loss: 0.14719 \nEpoch: 4724  | Validation balanced accuracy : 0.76304 \nEpoch: 4725  | Training Loss: 0.31590 \nEpoch: 4725  | Training Loss: 0.36810 \nEpoch: 4725  | Training Loss: 0.34639 \nEpoch: 4725  | Training Loss: 0.21226 \nEpoch: 4725  | Training Loss: 0.14714 \nEpoch: 4725  | Validation balanced accuracy : 0.76304 \nEpoch: 4726  | Training Loss: 0.31595 \nEpoch: 4726  | Training Loss: 0.36815 \nEpoch: 4726  | Training Loss: 0.34636 \nEpoch: 4726  | Training Loss: 0.21227 \nEpoch: 4726  | Training Loss: 0.14701 \nEpoch: 4726  | Validation balanced accuracy : 0.76304 \nEpoch: 4727  | Training Loss: 0.31605 \nEpoch: 4727  | Training Loss: 0.36822 \nEpoch: 4727  | Training Loss: 0.34632 \nEpoch: 4727  | Training Loss: 0.21228 \nEpoch: 4727  | Training Loss: 0.14690 \nEpoch: 4727  | Validation balanced accuracy : 0.76304 \nEpoch: 4728  | Training Loss: 0.31612 \nEpoch: 4728  | Training Loss: 0.36823 \nEpoch: 4728  | Training Loss: 0.34634 \nEpoch: 4728  | Training Loss: 0.21227 \nEpoch: 4728  | Training Loss: 0.14708 \nEpoch: 4728  | Validation balanced accuracy : 0.76304 \nEpoch: 4729  | Training Loss: 0.31595 \nEpoch: 4729  | Training Loss: 0.36813 \nEpoch: 4729  | Training Loss: 0.34639 \nEpoch: 4729  | Training Loss: 0.21226 \nEpoch: 4729  | Training Loss: 0.14716 \nEpoch: 4729  | Validation balanced accuracy : 0.76304 \nEpoch: 4730  | Training Loss: 0.31592 \nEpoch: 4730  | Training Loss: 0.36812 \nEpoch: 4730  | Training Loss: 0.34638 \nEpoch: 4730  | Training Loss: 0.21226 \nEpoch: 4730  | Training Loss: 0.14710 \nEpoch: 4730  | Validation balanced accuracy : 0.76304 \nEpoch: 4731  | Training Loss: 0.31598 \nEpoch: 4731  | Training Loss: 0.36816 \nEpoch: 4731  | Training Loss: 0.34636 \nEpoch: 4731  | Training Loss: 0.21227 \nEpoch: 4731  | Training Loss: 0.14701 \nEpoch: 4731  | Validation balanced accuracy : 0.76304 \nEpoch: 4732  | Training Loss: 0.31603 \nEpoch: 4732  | Training Loss: 0.36821 \nEpoch: 4732  | Training Loss: 0.34633 \nEpoch: 4732  | Training Loss: 0.21228 \nEpoch: 4732  | Training Loss: 0.14694 \nEpoch: 4732  | Validation balanced accuracy : 0.76304 \nEpoch: 4733  | Training Loss: 0.31608 \nEpoch: 4733  | Training Loss: 0.36824 \nEpoch: 4733  | Training Loss: 0.34632 \nEpoch: 4733  | Training Loss: 0.21228 \nEpoch: 4733  | Training Loss: 0.14690 \nEpoch: 4733  | Validation balanced accuracy : 0.76304 \nEpoch: 4734  | Training Loss: 0.31611 \nEpoch: 4734  | Training Loss: 0.36822 \nEpoch: 4734  | Training Loss: 0.34635 \nEpoch: 4734  | Training Loss: 0.21227 \nEpoch: 4734  | Training Loss: 0.14711 \nEpoch: 4734  | Validation balanced accuracy : 0.76304 \nEpoch: 4735  | Training Loss: 0.31593 \nEpoch: 4735  | Training Loss: 0.36811 \nEpoch: 4735  | Training Loss: 0.34640 \nEpoch: 4735  | Training Loss: 0.21225 \nEpoch: 4735  | Training Loss: 0.14720 \nEpoch: 4735  | Validation balanced accuracy : 0.76304 \nEpoch: 4736  | Training Loss: 0.31589 \nEpoch: 4736  | Training Loss: 0.36810 \nEpoch: 4736  | Training Loss: 0.34640 \nEpoch: 4736  | Training Loss: 0.21226 \nEpoch: 4736  | Training Loss: 0.14714 \nEpoch: 4736  | Validation balanced accuracy : 0.76304 \nEpoch: 4737  | Training Loss: 0.31595 \nEpoch: 4737  | Training Loss: 0.36815 \nEpoch: 4737  | Training Loss: 0.34636 \nEpoch: 4737  | Training Loss: 0.21227 \nEpoch: 4737  | Training Loss: 0.14700 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4737  | Validation balanced accuracy : 0.76304 \nEpoch: 4738  | Training Loss: 0.31605 \nEpoch: 4738  | Training Loss: 0.36822 \nEpoch: 4738  | Training Loss: 0.34632 \nEpoch: 4738  | Training Loss: 0.21228 \nEpoch: 4738  | Training Loss: 0.14689 \nEpoch: 4738  | Validation balanced accuracy : 0.76304 \nEpoch: 4739  | Training Loss: 0.31612 \nEpoch: 4739  | Training Loss: 0.36823 \nEpoch: 4739  | Training Loss: 0.34634 \nEpoch: 4739  | Training Loss: 0.21227 \nEpoch: 4739  | Training Loss: 0.14707 \nEpoch: 4739  | Validation balanced accuracy : 0.76304 \nEpoch: 4740  | Training Loss: 0.31596 \nEpoch: 4740  | Training Loss: 0.36813 \nEpoch: 4740  | Training Loss: 0.34639 \nEpoch: 4740  | Training Loss: 0.21226 \nEpoch: 4740  | Training Loss: 0.14715 \nEpoch: 4740  | Validation balanced accuracy : 0.76304 \nEpoch: 4741  | Training Loss: 0.31592 \nEpoch: 4741  | Training Loss: 0.36812 \nEpoch: 4741  | Training Loss: 0.34639 \nEpoch: 4741  | Training Loss: 0.21226 \nEpoch: 4741  | Training Loss: 0.14709 \nEpoch: 4741  | Validation balanced accuracy : 0.76304 \nEpoch: 4742  | Training Loss: 0.31598 \nEpoch: 4742  | Training Loss: 0.36817 \nEpoch: 4742  | Training Loss: 0.34635 \nEpoch: 4742  | Training Loss: 0.21227 \nEpoch: 4742  | Training Loss: 0.14696 \nEpoch: 4742  | Validation balanced accuracy : 0.76304 \nEpoch: 4743  | Training Loss: 0.31607 \nEpoch: 4743  | Training Loss: 0.36824 \nEpoch: 4743  | Training Loss: 0.34632 \nEpoch: 4743  | Training Loss: 0.21228 \nEpoch: 4743  | Training Loss: 0.14687 \nEpoch: 4743  | Validation balanced accuracy : 0.76304 \nEpoch: 4744  | Training Loss: 0.31613 \nEpoch: 4744  | Training Loss: 0.36823 \nEpoch: 4744  | Training Loss: 0.34634 \nEpoch: 4744  | Training Loss: 0.21227 \nEpoch: 4744  | Training Loss: 0.14709 \nEpoch: 4744  | Validation balanced accuracy : 0.76304 \nEpoch: 4745  | Training Loss: 0.31594 \nEpoch: 4745  | Training Loss: 0.36812 \nEpoch: 4745  | Training Loss: 0.34640 \nEpoch: 4745  | Training Loss: 0.21225 \nEpoch: 4745  | Training Loss: 0.14718 \nEpoch: 4745  | Validation balanced accuracy : 0.76304 \nEpoch: 4746  | Training Loss: 0.31590 \nEpoch: 4746  | Training Loss: 0.36810 \nEpoch: 4746  | Training Loss: 0.34640 \nEpoch: 4746  | Training Loss: 0.21226 \nEpoch: 4746  | Training Loss: 0.14713 \nEpoch: 4746  | Validation balanced accuracy : 0.76304 \nEpoch: 4747  | Training Loss: 0.31595 \nEpoch: 4747  | Training Loss: 0.36815 \nEpoch: 4747  | Training Loss: 0.34637 \nEpoch: 4747  | Training Loss: 0.21227 \nEpoch: 4747  | Training Loss: 0.14700 \nEpoch: 4747  | Validation balanced accuracy : 0.76304 \nEpoch: 4748  | Training Loss: 0.31605 \nEpoch: 4748  | Training Loss: 0.36822 \nEpoch: 4748  | Training Loss: 0.34633 \nEpoch: 4748  | Training Loss: 0.21228 \nEpoch: 4748  | Training Loss: 0.14689 \nEpoch: 4748  | Validation balanced accuracy : 0.76304 \nEpoch: 4749  | Training Loss: 0.31612 \nEpoch: 4749  | Training Loss: 0.36823 \nEpoch: 4749  | Training Loss: 0.34635 \nEpoch: 4749  | Training Loss: 0.21227 \nEpoch: 4749  | Training Loss: 0.14707 \nEpoch: 4749  | Validation balanced accuracy : 0.76304 \nEpoch: 4750  | Training Loss: 0.31595 \nEpoch: 4750  | Training Loss: 0.36813 \nEpoch: 4750  | Training Loss: 0.34639 \nEpoch: 4750  | Training Loss: 0.21226 \nEpoch: 4750  | Training Loss: 0.14715 \nEpoch: 4750  | Validation balanced accuracy : 0.76304 \nEpoch: 4751  | Training Loss: 0.31592 \nEpoch: 4751  | Training Loss: 0.36812 \nEpoch: 4751  | Training Loss: 0.34639 \nEpoch: 4751  | Training Loss: 0.21226 \nEpoch: 4751  | Training Loss: 0.14709 \nEpoch: 4751  | Validation balanced accuracy : 0.76304 \nEpoch: 4752  | Training Loss: 0.31598 \nEpoch: 4752  | Training Loss: 0.36816 \nEpoch: 4752  | Training Loss: 0.34636 \nEpoch: 4752  | Training Loss: 0.21227 \nEpoch: 4752  | Training Loss: 0.14701 \nEpoch: 4752  | Validation balanced accuracy : 0.76304 \nEpoch: 4753  | Training Loss: 0.31603 \nEpoch: 4753  | Training Loss: 0.36821 \nEpoch: 4753  | Training Loss: 0.34634 \nEpoch: 4753  | Training Loss: 0.21227 \nEpoch: 4753  | Training Loss: 0.14694 \nEpoch: 4753  | Validation balanced accuracy : 0.76304 \nEpoch: 4754  | Training Loss: 0.31608 \nEpoch: 4754  | Training Loss: 0.36824 \nEpoch: 4754  | Training Loss: 0.34632 \nEpoch: 4754  | Training Loss: 0.21228 \nEpoch: 4754  | Training Loss: 0.14689 \nEpoch: 4754  | Validation balanced accuracy : 0.76304 \nEpoch: 4755  | Training Loss: 0.31611 \nEpoch: 4755  | Training Loss: 0.36822 \nEpoch: 4755  | Training Loss: 0.34635 \nEpoch: 4755  | Training Loss: 0.21226 \nEpoch: 4755  | Training Loss: 0.14710 \nEpoch: 4755  | Validation balanced accuracy : 0.76304 \nEpoch: 4756  | Training Loss: 0.31593 \nEpoch: 4756  | Training Loss: 0.36811 \nEpoch: 4756  | Training Loss: 0.34641 \nEpoch: 4756  | Training Loss: 0.21225 \nEpoch: 4756  | Training Loss: 0.14719 \nEpoch: 4756  | Validation balanced accuracy : 0.76304 \nEpoch: 4757  | Training Loss: 0.31589 \nEpoch: 4757  | Training Loss: 0.36810 \nEpoch: 4757  | Training Loss: 0.34641 \nEpoch: 4757  | Training Loss: 0.21225 \nEpoch: 4757  | Training Loss: 0.14713 \nEpoch: 4757  | Validation balanced accuracy : 0.76304 \nEpoch: 4758  | Training Loss: 0.31595 \nEpoch: 4758  | Training Loss: 0.36815 \nEpoch: 4758  | Training Loss: 0.34637 \nEpoch: 4758  | Training Loss: 0.21226 \nEpoch: 4758  | Training Loss: 0.14699 \nEpoch: 4758  | Validation balanced accuracy : 0.76304 \nEpoch: 4759  | Training Loss: 0.31605 \nEpoch: 4759  | Training Loss: 0.36822 \nEpoch: 4759  | Training Loss: 0.34633 \nEpoch: 4759  | Training Loss: 0.21228 \nEpoch: 4759  | Training Loss: 0.14688 \nEpoch: 4759  | Validation balanced accuracy : 0.76304 \nEpoch: 4760  | Training Loss: 0.31612 \nEpoch: 4760  | Training Loss: 0.36823 \nEpoch: 4760  | Training Loss: 0.34635 \nEpoch: 4760  | Training Loss: 0.21226 \nEpoch: 4760  | Training Loss: 0.14706 \nEpoch: 4760  | Validation balanced accuracy : 0.76304 \nEpoch: 4761  | Training Loss: 0.31596 \nEpoch: 4761  | Training Loss: 0.36813 \nEpoch: 4761  | Training Loss: 0.34639 \nEpoch: 4761  | Training Loss: 0.21225 \nEpoch: 4761  | Training Loss: 0.14714 \nEpoch: 4761  | Validation balanced accuracy : 0.76304 \nEpoch: 4762  | Training Loss: 0.31593 \nEpoch: 4762  | Training Loss: 0.36812 \nEpoch: 4762  | Training Loss: 0.34639 \nEpoch: 4762  | Training Loss: 0.21226 \nEpoch: 4762  | Training Loss: 0.14708 \nEpoch: 4762  | Validation balanced accuracy : 0.76304 \nEpoch: 4763  | Training Loss: 0.31598 \nEpoch: 4763  | Training Loss: 0.36817 \nEpoch: 4763  | Training Loss: 0.34636 \nEpoch: 4763  | Training Loss: 0.21227 \nEpoch: 4763  | Training Loss: 0.14696 \nEpoch: 4763  | Validation balanced accuracy : 0.76304 \nEpoch: 4764  | Training Loss: 0.31607 \nEpoch: 4764  | Training Loss: 0.36824 \nEpoch: 4764  | Training Loss: 0.34632 \nEpoch: 4764  | Training Loss: 0.21228 \nEpoch: 4764  | Training Loss: 0.14686 \nEpoch: 4764  | Validation balanced accuracy : 0.76304 \nEpoch: 4765  | Training Loss: 0.31613 \nEpoch: 4765  | Training Loss: 0.36824 \nEpoch: 4765  | Training Loss: 0.34635 \nEpoch: 4765  | Training Loss: 0.21226 \nEpoch: 4765  | Training Loss: 0.14708 \nEpoch: 4765  | Validation balanced accuracy : 0.76304 \nEpoch: 4766  | Training Loss: 0.31594 \nEpoch: 4766  | Training Loss: 0.36812 \nEpoch: 4766  | Training Loss: 0.34641 \nEpoch: 4766  | Training Loss: 0.21225 \nEpoch: 4766  | Training Loss: 0.14718 \nEpoch: 4766  | Validation balanced accuracy : 0.76304 \nEpoch: 4767  | Training Loss: 0.31590 \nEpoch: 4767  | Training Loss: 0.36810 \nEpoch: 4767  | Training Loss: 0.34641 \nEpoch: 4767  | Training Loss: 0.21225 \nEpoch: 4767  | Training Loss: 0.14712 \nEpoch: 4767  | Validation balanced accuracy : 0.76304 \nEpoch: 4768  | Training Loss: 0.31595 \nEpoch: 4768  | Training Loss: 0.36815 \nEpoch: 4768  | Training Loss: 0.34637 \nEpoch: 4768  | Training Loss: 0.21226 \nEpoch: 4768  | Training Loss: 0.14699 \nEpoch: 4768  | Validation balanced accuracy : 0.76304 \nEpoch: 4769  | Training Loss: 0.31605 \nEpoch: 4769  | Training Loss: 0.36822 \nEpoch: 4769  | Training Loss: 0.34633 \nEpoch: 4769  | Training Loss: 0.21227 \nEpoch: 4769  | Training Loss: 0.14689 \nEpoch: 4769  | Validation balanced accuracy : 0.76304 \nEpoch: 4770  | Training Loss: 0.31612 \nEpoch: 4770  | Training Loss: 0.36823 \nEpoch: 4770  | Training Loss: 0.34635 \nEpoch: 4770  | Training Loss: 0.21226 \nEpoch: 4770  | Training Loss: 0.14707 \nEpoch: 4770  | Validation balanced accuracy : 0.76304 \nEpoch: 4771  | Training Loss: 0.31595 \nEpoch: 4771  | Training Loss: 0.36813 \nEpoch: 4771  | Training Loss: 0.34640 \nEpoch: 4771  | Training Loss: 0.21225 \nEpoch: 4771  | Training Loss: 0.14714 \nEpoch: 4771  | Validation balanced accuracy : 0.76304 \nEpoch: 4772  | Training Loss: 0.31592 \nEpoch: 4772  | Training Loss: 0.36812 \nEpoch: 4772  | Training Loss: 0.34640 \nEpoch: 4772  | Training Loss: 0.21226 \nEpoch: 4772  | Training Loss: 0.14708 \nEpoch: 4772  | Validation balanced accuracy : 0.76304 \nEpoch: 4773  | Training Loss: 0.31598 \nEpoch: 4773  | Training Loss: 0.36816 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4773  | Training Loss: 0.34637 \nEpoch: 4773  | Training Loss: 0.21226 \nEpoch: 4773  | Training Loss: 0.14700 \nEpoch: 4773  | Validation balanced accuracy : 0.76304 \nEpoch: 4774  | Training Loss: 0.31604 \nEpoch: 4774  | Training Loss: 0.36821 \nEpoch: 4774  | Training Loss: 0.34634 \nEpoch: 4774  | Training Loss: 0.21227 \nEpoch: 4774  | Training Loss: 0.14693 \nEpoch: 4774  | Validation balanced accuracy : 0.76304 \nEpoch: 4775  | Training Loss: 0.31608 \nEpoch: 4775  | Training Loss: 0.36824 \nEpoch: 4775  | Training Loss: 0.34633 \nEpoch: 4775  | Training Loss: 0.21227 \nEpoch: 4775  | Training Loss: 0.14688 \nEpoch: 4775  | Validation balanced accuracy : 0.76304 \nEpoch: 4776  | Training Loss: 0.31611 \nEpoch: 4776  | Training Loss: 0.36822 \nEpoch: 4776  | Training Loss: 0.34636 \nEpoch: 4776  | Training Loss: 0.21226 \nEpoch: 4776  | Training Loss: 0.14710 \nEpoch: 4776  | Validation balanced accuracy : 0.76304 \nEpoch: 4777  | Training Loss: 0.31593 \nEpoch: 4777  | Training Loss: 0.36811 \nEpoch: 4777  | Training Loss: 0.34641 \nEpoch: 4777  | Training Loss: 0.21225 \nEpoch: 4777  | Training Loss: 0.14719 \nEpoch: 4777  | Validation balanced accuracy : 0.76304 \nEpoch: 4778  | Training Loss: 0.31589 \nEpoch: 4778  | Training Loss: 0.36810 \nEpoch: 4778  | Training Loss: 0.34641 \nEpoch: 4778  | Training Loss: 0.21225 \nEpoch: 4778  | Training Loss: 0.14712 \nEpoch: 4778  | Validation balanced accuracy : 0.76304 \nEpoch: 4779  | Training Loss: 0.31595 \nEpoch: 4779  | Training Loss: 0.36815 \nEpoch: 4779  | Training Loss: 0.34637 \nEpoch: 4779  | Training Loss: 0.21226 \nEpoch: 4779  | Training Loss: 0.14699 \nEpoch: 4779  | Validation balanced accuracy : 0.76304 \nEpoch: 4780  | Training Loss: 0.31605 \nEpoch: 4780  | Training Loss: 0.36822 \nEpoch: 4780  | Training Loss: 0.34633 \nEpoch: 4780  | Training Loss: 0.21227 \nEpoch: 4780  | Training Loss: 0.14688 \nEpoch: 4780  | Validation balanced accuracy : 0.76304 \nEpoch: 4781  | Training Loss: 0.31612 \nEpoch: 4781  | Training Loss: 0.36823 \nEpoch: 4781  | Training Loss: 0.34635 \nEpoch: 4781  | Training Loss: 0.21226 \nEpoch: 4781  | Training Loss: 0.14706 \nEpoch: 4781  | Validation balanced accuracy : 0.76304 \nEpoch: 4782  | Training Loss: 0.31596 \nEpoch: 4782  | Training Loss: 0.36813 \nEpoch: 4782  | Training Loss: 0.34640 \nEpoch: 4782  | Training Loss: 0.21225 \nEpoch: 4782  | Training Loss: 0.14713 \nEpoch: 4782  | Validation balanced accuracy : 0.76304 \nEpoch: 4783  | Training Loss: 0.31593 \nEpoch: 4783  | Training Loss: 0.36812 \nEpoch: 4783  | Training Loss: 0.34640 \nEpoch: 4783  | Training Loss: 0.21225 \nEpoch: 4783  | Training Loss: 0.14707 \nEpoch: 4783  | Validation balanced accuracy : 0.76304 \nEpoch: 4784  | Training Loss: 0.31598 \nEpoch: 4784  | Training Loss: 0.36817 \nEpoch: 4784  | Training Loss: 0.34636 \nEpoch: 4784  | Training Loss: 0.21226 \nEpoch: 4784  | Training Loss: 0.14695 \nEpoch: 4784  | Validation balanced accuracy : 0.76304 \nEpoch: 4785  | Training Loss: 0.31607 \nEpoch: 4785  | Training Loss: 0.36824 \nEpoch: 4785  | Training Loss: 0.34633 \nEpoch: 4785  | Training Loss: 0.21227 \nEpoch: 4785  | Training Loss: 0.14685 \nEpoch: 4785  | Validation balanced accuracy : 0.76304 \nEpoch: 4786  | Training Loss: 0.31614 \nEpoch: 4786  | Training Loss: 0.36824 \nEpoch: 4786  | Training Loss: 0.34635 \nEpoch: 4786  | Training Loss: 0.21226 \nEpoch: 4786  | Training Loss: 0.14707 \nEpoch: 4786  | Validation balanced accuracy : 0.76304 \nEpoch: 4787  | Training Loss: 0.31594 \nEpoch: 4787  | Training Loss: 0.36812 \nEpoch: 4787  | Training Loss: 0.34641 \nEpoch: 4787  | Training Loss: 0.21225 \nEpoch: 4787  | Training Loss: 0.14717 \nEpoch: 4787  | Validation balanced accuracy : 0.76304 \nEpoch: 4788  | Training Loss: 0.31590 \nEpoch: 4788  | Training Loss: 0.36810 \nEpoch: 4788  | Training Loss: 0.34641 \nEpoch: 4788  | Training Loss: 0.21225 \nEpoch: 4788  | Training Loss: 0.14711 \nEpoch: 4788  | Validation balanced accuracy : 0.76304 \nEpoch: 4789  | Training Loss: 0.31595 \nEpoch: 4789  | Training Loss: 0.36815 \nEpoch: 4789  | Training Loss: 0.34638 \nEpoch: 4789  | Training Loss: 0.21226 \nEpoch: 4789  | Training Loss: 0.14698 \nEpoch: 4789  | Validation balanced accuracy : 0.76304 \nEpoch: 4790  | Training Loss: 0.31605 \nEpoch: 4790  | Training Loss: 0.36822 \nEpoch: 4790  | Training Loss: 0.34634 \nEpoch: 4790  | Training Loss: 0.21227 \nEpoch: 4790  | Training Loss: 0.14688 \nEpoch: 4790  | Validation balanced accuracy : 0.76304 \nEpoch: 4791  | Training Loss: 0.31612 \nEpoch: 4791  | Training Loss: 0.36827 \nEpoch: 4791  | Training Loss: 0.34631 \nEpoch: 4791  | Training Loss: 0.21228 \nEpoch: 4791  | Training Loss: 0.14682 \nEpoch: 4791  | Validation balanced accuracy : 0.76304 \nEpoch: 4792  | Training Loss: 0.31616 \nEpoch: 4792  | Training Loss: 0.36825 \nEpoch: 4792  | Training Loss: 0.34635 \nEpoch: 4792  | Training Loss: 0.21226 \nEpoch: 4792  | Training Loss: 0.14704 \nEpoch: 4792  | Validation balanced accuracy : 0.76304 \nEpoch: 4793  | Training Loss: 0.31596 \nEpoch: 4793  | Training Loss: 0.36813 \nEpoch: 4793  | Training Loss: 0.34640 \nEpoch: 4793  | Training Loss: 0.21225 \nEpoch: 4793  | Training Loss: 0.14714 \nEpoch: 4793  | Validation balanced accuracy : 0.76304 \nEpoch: 4794  | Training Loss: 0.31592 \nEpoch: 4794  | Training Loss: 0.36812 \nEpoch: 4794  | Training Loss: 0.34641 \nEpoch: 4794  | Training Loss: 0.21225 \nEpoch: 4794  | Training Loss: 0.14710 \nEpoch: 4794  | Validation balanced accuracy : 0.76304 \nEpoch: 4795  | Training Loss: 0.31596 \nEpoch: 4795  | Training Loss: 0.36816 \nEpoch: 4795  | Training Loss: 0.34637 \nEpoch: 4795  | Training Loss: 0.21226 \nEpoch: 4795  | Training Loss: 0.14697 \nEpoch: 4795  | Validation balanced accuracy : 0.76304 \nEpoch: 4796  | Training Loss: 0.31605 \nEpoch: 4796  | Training Loss: 0.36822 \nEpoch: 4796  | Training Loss: 0.34634 \nEpoch: 4796  | Training Loss: 0.21227 \nEpoch: 4796  | Training Loss: 0.14687 \nEpoch: 4796  | Validation balanced accuracy : 0.76304 \nEpoch: 4797  | Training Loss: 0.31612 \nEpoch: 4797  | Training Loss: 0.36823 \nEpoch: 4797  | Training Loss: 0.34636 \nEpoch: 4797  | Training Loss: 0.21226 \nEpoch: 4797  | Training Loss: 0.14706 \nEpoch: 4797  | Validation balanced accuracy : 0.76304 \nEpoch: 4798  | Training Loss: 0.31595 \nEpoch: 4798  | Training Loss: 0.36813 \nEpoch: 4798  | Training Loss: 0.34641 \nEpoch: 4798  | Training Loss: 0.21225 \nEpoch: 4798  | Training Loss: 0.14714 \nEpoch: 4798  | Validation balanced accuracy : 0.76304 \nEpoch: 4799  | Training Loss: 0.31592 \nEpoch: 4799  | Training Loss: 0.36812 \nEpoch: 4799  | Training Loss: 0.34640 \nEpoch: 4799  | Training Loss: 0.21225 \nEpoch: 4799  | Training Loss: 0.14708 \nEpoch: 4799  | Validation balanced accuracy : 0.76304 \nEpoch: 4800  | Training Loss: 0.31598 \nEpoch: 4800  | Training Loss: 0.36817 \nEpoch: 4800  | Training Loss: 0.34637 \nEpoch: 4800  | Training Loss: 0.21226 \nEpoch: 4800  | Training Loss: 0.14695 \nEpoch: 4800  | Validation balanced accuracy : 0.76304 \nEpoch: 4801  | Training Loss: 0.31607 \nEpoch: 4801  | Training Loss: 0.36823 \nEpoch: 4801  | Training Loss: 0.34630 \nEpoch: 4801  | Training Loss: 0.21228 \nEpoch: 4801  | Training Loss: 0.14669 \nEpoch: 4801  | Validation balanced accuracy : 0.76304 \nEpoch: 4802  | Training Loss: 0.31612 \nEpoch: 4802  | Training Loss: 0.36823 \nEpoch: 4802  | Training Loss: 0.34632 \nEpoch: 4802  | Training Loss: 0.21227 \nEpoch: 4802  | Training Loss: 0.14688 \nEpoch: 4802  | Validation balanced accuracy : 0.76304 \nEpoch: 4803  | Training Loss: 0.31596 \nEpoch: 4803  | Training Loss: 0.36813 \nEpoch: 4803  | Training Loss: 0.34638 \nEpoch: 4803  | Training Loss: 0.21226 \nEpoch: 4803  | Training Loss: 0.14698 \nEpoch: 4803  | Validation balanced accuracy : 0.76304 \nEpoch: 4804  | Training Loss: 0.31591 \nEpoch: 4804  | Training Loss: 0.36811 \nEpoch: 4804  | Training Loss: 0.34638 \nEpoch: 4804  | Training Loss: 0.21226 \nEpoch: 4804  | Training Loss: 0.14695 \nEpoch: 4804  | Validation balanced accuracy : 0.76304 \nEpoch: 4805  | Training Loss: 0.31594 \nEpoch: 4805  | Training Loss: 0.36814 \nEpoch: 4805  | Training Loss: 0.34636 \nEpoch: 4805  | Training Loss: 0.21227 \nEpoch: 4805  | Training Loss: 0.14686 \nEpoch: 4805  | Validation balanced accuracy : 0.76304 \nEpoch: 4806  | Training Loss: 0.31601 \nEpoch: 4806  | Training Loss: 0.36819 \nEpoch: 4806  | Training Loss: 0.34633 \nEpoch: 4806  | Training Loss: 0.21227 \nEpoch: 4806  | Training Loss: 0.14679 \nEpoch: 4806  | Validation balanced accuracy : 0.76304 \nEpoch: 4807  | Training Loss: 0.31606 \nEpoch: 4807  | Training Loss: 0.36822 \nEpoch: 4807  | Training Loss: 0.34631 \nEpoch: 4807  | Training Loss: 0.21228 \nEpoch: 4807  | Training Loss: 0.14675 \nEpoch: 4807  | Validation balanced accuracy : 0.76304 \nEpoch: 4808  | Training Loss: 0.31608 \nEpoch: 4808  | Training Loss: 0.36823 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4808  | Training Loss: 0.34631 \nEpoch: 4808  | Training Loss: 0.21228 \nEpoch: 4808  | Training Loss: 0.14674 \nEpoch: 4808  | Validation balanced accuracy : 0.76304 \nEpoch: 4809  | Training Loss: 0.31608 \nEpoch: 4809  | Training Loss: 0.36823 \nEpoch: 4809  | Training Loss: 0.34631 \nEpoch: 4809  | Training Loss: 0.21228 \nEpoch: 4809  | Training Loss: 0.14675 \nEpoch: 4809  | Validation balanced accuracy : 0.76304 \nEpoch: 4810  | Training Loss: 0.31607 \nEpoch: 4810  | Training Loss: 0.36822 \nEpoch: 4810  | Training Loss: 0.34631 \nEpoch: 4810  | Training Loss: 0.21228 \nEpoch: 4810  | Training Loss: 0.14677 \nEpoch: 4810  | Validation balanced accuracy : 0.76304 \nEpoch: 4811  | Training Loss: 0.31606 \nEpoch: 4811  | Training Loss: 0.36822 \nEpoch: 4811  | Training Loss: 0.34631 \nEpoch: 4811  | Training Loss: 0.21227 \nEpoch: 4811  | Training Loss: 0.14678 \nEpoch: 4811  | Validation balanced accuracy : 0.76304 \nEpoch: 4812  | Training Loss: 0.31605 \nEpoch: 4812  | Training Loss: 0.36821 \nEpoch: 4812  | Training Loss: 0.34632 \nEpoch: 4812  | Training Loss: 0.21227 \nEpoch: 4812  | Training Loss: 0.14679 \nEpoch: 4812  | Validation balanced accuracy : 0.76304 \nEpoch: 4813  | Training Loss: 0.31604 \nEpoch: 4813  | Training Loss: 0.36820 \nEpoch: 4813  | Training Loss: 0.34632 \nEpoch: 4813  | Training Loss: 0.21227 \nEpoch: 4813  | Training Loss: 0.14682 \nEpoch: 4813  | Validation balanced accuracy : 0.76304 \nEpoch: 4814  | Training Loss: 0.31602 \nEpoch: 4814  | Training Loss: 0.36819 \nEpoch: 4814  | Training Loss: 0.34633 \nEpoch: 4814  | Training Loss: 0.21227 \nEpoch: 4814  | Training Loss: 0.14684 \nEpoch: 4814  | Validation balanced accuracy : 0.76304 \nEpoch: 4815  | Training Loss: 0.31601 \nEpoch: 4815  | Training Loss: 0.36819 \nEpoch: 4815  | Training Loss: 0.34633 \nEpoch: 4815  | Training Loss: 0.21227 \nEpoch: 4815  | Training Loss: 0.14684 \nEpoch: 4815  | Validation balanced accuracy : 0.76304 \nEpoch: 4816  | Training Loss: 0.31601 \nEpoch: 4816  | Training Loss: 0.36819 \nEpoch: 4816  | Training Loss: 0.34633 \nEpoch: 4816  | Training Loss: 0.21227 \nEpoch: 4816  | Training Loss: 0.14683 \nEpoch: 4816  | Validation balanced accuracy : 0.76304 \nEpoch: 4817  | Training Loss: 0.31602 \nEpoch: 4817  | Training Loss: 0.36819 \nEpoch: 4817  | Training Loss: 0.34633 \nEpoch: 4817  | Training Loss: 0.21227 \nEpoch: 4817  | Training Loss: 0.14682 \nEpoch: 4817  | Validation balanced accuracy : 0.76304 \nEpoch: 4818  | Training Loss: 0.31603 \nEpoch: 4818  | Training Loss: 0.36820 \nEpoch: 4818  | Training Loss: 0.34632 \nEpoch: 4818  | Training Loss: 0.21227 \nEpoch: 4818  | Training Loss: 0.14681 \nEpoch: 4818  | Validation balanced accuracy : 0.76304 \nEpoch: 4819  | Training Loss: 0.31603 \nEpoch: 4819  | Training Loss: 0.36821 \nEpoch: 4819  | Training Loss: 0.34632 \nEpoch: 4819  | Training Loss: 0.21227 \nEpoch: 4819  | Training Loss: 0.14680 \nEpoch: 4819  | Validation balanced accuracy : 0.76304 \nEpoch: 4820  | Training Loss: 0.31604 \nEpoch: 4820  | Training Loss: 0.36821 \nEpoch: 4820  | Training Loss: 0.34631 \nEpoch: 4820  | Training Loss: 0.21227 \nEpoch: 4820  | Training Loss: 0.14679 \nEpoch: 4820  | Validation balanced accuracy : 0.76304 \nEpoch: 4821  | Training Loss: 0.31604 \nEpoch: 4821  | Training Loss: 0.36821 \nEpoch: 4821  | Training Loss: 0.34631 \nEpoch: 4821  | Training Loss: 0.21227 \nEpoch: 4821  | Training Loss: 0.14679 \nEpoch: 4821  | Validation balanced accuracy : 0.76304 \nEpoch: 4822  | Training Loss: 0.31605 \nEpoch: 4822  | Training Loss: 0.36822 \nEpoch: 4822  | Training Loss: 0.34631 \nEpoch: 4822  | Training Loss: 0.21227 \nEpoch: 4822  | Training Loss: 0.14679 \nEpoch: 4822  | Validation balanced accuracy : 0.76304 \nEpoch: 4823  | Training Loss: 0.31605 \nEpoch: 4823  | Training Loss: 0.36818 \nEpoch: 4823  | Training Loss: 0.34635 \nEpoch: 4823  | Training Loss: 0.21225 \nEpoch: 4823  | Training Loss: 0.14703 \nEpoch: 4823  | Validation balanced accuracy : 0.76304 \nEpoch: 4824  | Training Loss: 0.31585 \nEpoch: 4824  | Training Loss: 0.36806 \nEpoch: 4824  | Training Loss: 0.34641 \nEpoch: 4824  | Training Loss: 0.21224 \nEpoch: 4824  | Training Loss: 0.14713 \nEpoch: 4824  | Validation balanced accuracy : 0.76304 \nEpoch: 4825  | Training Loss: 0.31580 \nEpoch: 4825  | Training Loss: 0.36804 \nEpoch: 4825  | Training Loss: 0.34641 \nEpoch: 4825  | Training Loss: 0.21224 \nEpoch: 4825  | Training Loss: 0.14708 \nEpoch: 4825  | Validation balanced accuracy : 0.76304 \nEpoch: 4826  | Training Loss: 0.31585 \nEpoch: 4826  | Training Loss: 0.36809 \nEpoch: 4826  | Training Loss: 0.34638 \nEpoch: 4826  | Training Loss: 0.21225 \nEpoch: 4826  | Training Loss: 0.14695 \nEpoch: 4826  | Validation balanced accuracy : 0.76304 \nEpoch: 4827  | Training Loss: 0.31595 \nEpoch: 4827  | Training Loss: 0.36816 \nEpoch: 4827  | Training Loss: 0.34634 \nEpoch: 4827  | Training Loss: 0.21227 \nEpoch: 4827  | Training Loss: 0.14683 \nEpoch: 4827  | Validation balanced accuracy : 0.76304 \nEpoch: 4828  | Training Loss: 0.31603 \nEpoch: 4828  | Training Loss: 0.36821 \nEpoch: 4828  | Training Loss: 0.34631 \nEpoch: 4828  | Training Loss: 0.21227 \nEpoch: 4828  | Training Loss: 0.14675 \nEpoch: 4828  | Validation balanced accuracy : 0.76304 \nEpoch: 4829  | Training Loss: 0.31608 \nEpoch: 4829  | Training Loss: 0.36821 \nEpoch: 4829  | Training Loss: 0.34633 \nEpoch: 4829  | Training Loss: 0.21226 \nEpoch: 4829  | Training Loss: 0.14693 \nEpoch: 4829  | Validation balanced accuracy : 0.76304 \nEpoch: 4830  | Training Loss: 0.31592 \nEpoch: 4830  | Training Loss: 0.36811 \nEpoch: 4830  | Training Loss: 0.34638 \nEpoch: 4830  | Training Loss: 0.21225 \nEpoch: 4830  | Training Loss: 0.14702 \nEpoch: 4830  | Validation balanced accuracy : 0.76304 \nEpoch: 4831  | Training Loss: 0.31588 \nEpoch: 4831  | Training Loss: 0.36810 \nEpoch: 4831  | Training Loss: 0.34638 \nEpoch: 4831  | Training Loss: 0.21225 \nEpoch: 4831  | Training Loss: 0.14697 \nEpoch: 4831  | Validation balanced accuracy : 0.76304 \nEpoch: 4832  | Training Loss: 0.31592 \nEpoch: 4832  | Training Loss: 0.36813 \nEpoch: 4832  | Training Loss: 0.34636 \nEpoch: 4832  | Training Loss: 0.21226 \nEpoch: 4832  | Training Loss: 0.14691 \nEpoch: 4832  | Validation balanced accuracy : 0.76304 \nEpoch: 4833  | Training Loss: 0.31597 \nEpoch: 4833  | Training Loss: 0.36817 \nEpoch: 4833  | Training Loss: 0.34634 \nEpoch: 4833  | Training Loss: 0.21226 \nEpoch: 4833  | Training Loss: 0.14684 \nEpoch: 4833  | Validation balanced accuracy : 0.76304 \nEpoch: 4834  | Training Loss: 0.31601 \nEpoch: 4834  | Training Loss: 0.36820 \nEpoch: 4834  | Training Loss: 0.34632 \nEpoch: 4834  | Training Loss: 0.21227 \nEpoch: 4834  | Training Loss: 0.14680 \nEpoch: 4834  | Validation balanced accuracy : 0.76304 \nEpoch: 4835  | Training Loss: 0.31604 \nEpoch: 4835  | Training Loss: 0.36822 \nEpoch: 4835  | Training Loss: 0.34631 \nEpoch: 4835  | Training Loss: 0.21227 \nEpoch: 4835  | Training Loss: 0.14677 \nEpoch: 4835  | Validation balanced accuracy : 0.76304 \nEpoch: 4836  | Training Loss: 0.31606 \nEpoch: 4836  | Training Loss: 0.36820 \nEpoch: 4836  | Training Loss: 0.34634 \nEpoch: 4836  | Training Loss: 0.21226 \nEpoch: 4836  | Training Loss: 0.14697 \nEpoch: 4836  | Validation balanced accuracy : 0.76304 \nEpoch: 4837  | Training Loss: 0.31589 \nEpoch: 4837  | Training Loss: 0.36809 \nEpoch: 4837  | Training Loss: 0.34640 \nEpoch: 4837  | Training Loss: 0.21225 \nEpoch: 4837  | Training Loss: 0.14706 \nEpoch: 4837  | Validation balanced accuracy : 0.76304 \nEpoch: 4838  | Training Loss: 0.31585 \nEpoch: 4838  | Training Loss: 0.36808 \nEpoch: 4838  | Training Loss: 0.34640 \nEpoch: 4838  | Training Loss: 0.21225 \nEpoch: 4838  | Training Loss: 0.14701 \nEpoch: 4838  | Validation balanced accuracy : 0.76304 \nEpoch: 4839  | Training Loss: 0.31590 \nEpoch: 4839  | Training Loss: 0.36812 \nEpoch: 4839  | Training Loss: 0.34637 \nEpoch: 4839  | Training Loss: 0.21226 \nEpoch: 4839  | Training Loss: 0.14689 \nEpoch: 4839  | Validation balanced accuracy : 0.76304 \nEpoch: 4840  | Training Loss: 0.31599 \nEpoch: 4840  | Training Loss: 0.36818 \nEpoch: 4840  | Training Loss: 0.34633 \nEpoch: 4840  | Training Loss: 0.21227 \nEpoch: 4840  | Training Loss: 0.14681 \nEpoch: 4840  | Validation balanced accuracy : 0.76304 \nEpoch: 4841  | Training Loss: 0.31604 \nEpoch: 4841  | Training Loss: 0.36822 \nEpoch: 4841  | Training Loss: 0.34631 \nEpoch: 4841  | Training Loss: 0.21227 \nEpoch: 4841  | Training Loss: 0.14675 \nEpoch: 4841  | Validation balanced accuracy : 0.76304 \nEpoch: 4842  | Training Loss: 0.31608 \nEpoch: 4842  | Training Loss: 0.36821 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4842  | Training Loss: 0.34634 \nEpoch: 4842  | Training Loss: 0.21226 \nEpoch: 4842  | Training Loss: 0.14695 \nEpoch: 4842  | Validation balanced accuracy : 0.76304 \nEpoch: 4843  | Training Loss: 0.31591 \nEpoch: 4843  | Training Loss: 0.36810 \nEpoch: 4843  | Training Loss: 0.34639 \nEpoch: 4843  | Training Loss: 0.21225 \nEpoch: 4843  | Training Loss: 0.14703 \nEpoch: 4843  | Validation balanced accuracy : 0.76304 \nEpoch: 4844  | Training Loss: 0.31587 \nEpoch: 4844  | Training Loss: 0.36809 \nEpoch: 4844  | Training Loss: 0.34639 \nEpoch: 4844  | Training Loss: 0.21225 \nEpoch: 4844  | Training Loss: 0.14699 \nEpoch: 4844  | Validation balanced accuracy : 0.76304 \nEpoch: 4845  | Training Loss: 0.31591 \nEpoch: 4845  | Training Loss: 0.36813 \nEpoch: 4845  | Training Loss: 0.34636 \nEpoch: 4845  | Training Loss: 0.21226 \nEpoch: 4845  | Training Loss: 0.14688 \nEpoch: 4845  | Validation balanced accuracy : 0.76304 \nEpoch: 4846  | Training Loss: 0.31600 \nEpoch: 4846  | Training Loss: 0.36819 \nEpoch: 4846  | Training Loss: 0.34633 \nEpoch: 4846  | Training Loss: 0.21227 \nEpoch: 4846  | Training Loss: 0.14679 \nEpoch: 4846  | Validation balanced accuracy : 0.76304 \nEpoch: 4847  | Training Loss: 0.31606 \nEpoch: 4847  | Training Loss: 0.36819 \nEpoch: 4847  | Training Loss: 0.34634 \nEpoch: 4847  | Training Loss: 0.21226 \nEpoch: 4847  | Training Loss: 0.14695 \nEpoch: 4847  | Validation balanced accuracy : 0.76304 \nEpoch: 4848  | Training Loss: 0.31591 \nEpoch: 4848  | Training Loss: 0.36811 \nEpoch: 4848  | Training Loss: 0.34639 \nEpoch: 4848  | Training Loss: 0.21225 \nEpoch: 4848  | Training Loss: 0.14702 \nEpoch: 4848  | Validation balanced accuracy : 0.76304 \nEpoch: 4849  | Training Loss: 0.31588 \nEpoch: 4849  | Training Loss: 0.36810 \nEpoch: 4849  | Training Loss: 0.34638 \nEpoch: 4849  | Training Loss: 0.21225 \nEpoch: 4849  | Training Loss: 0.14697 \nEpoch: 4849  | Validation balanced accuracy : 0.76304 \nEpoch: 4850  | Training Loss: 0.31593 \nEpoch: 4850  | Training Loss: 0.36814 \nEpoch: 4850  | Training Loss: 0.34635 \nEpoch: 4850  | Training Loss: 0.21226 \nEpoch: 4850  | Training Loss: 0.14685 \nEpoch: 4850  | Validation balanced accuracy : 0.76304 \nEpoch: 4851  | Training Loss: 0.31601 \nEpoch: 4851  | Training Loss: 0.36820 \nEpoch: 4851  | Training Loss: 0.34633 \nEpoch: 4851  | Training Loss: 0.21227 \nEpoch: 4851  | Training Loss: 0.14679 \nEpoch: 4851  | Validation balanced accuracy : 0.76304 \nEpoch: 4852  | Training Loss: 0.31605 \nEpoch: 4852  | Training Loss: 0.36822 \nEpoch: 4852  | Training Loss: 0.34631 \nEpoch: 4852  | Training Loss: 0.21227 \nEpoch: 4852  | Training Loss: 0.14675 \nEpoch: 4852  | Validation balanced accuracy : 0.76304 \nEpoch: 4853  | Training Loss: 0.31607 \nEpoch: 4853  | Training Loss: 0.36820 \nEpoch: 4853  | Training Loss: 0.34634 \nEpoch: 4853  | Training Loss: 0.21226 \nEpoch: 4853  | Training Loss: 0.14695 \nEpoch: 4853  | Validation balanced accuracy : 0.76304 \nEpoch: 4854  | Training Loss: 0.31590 \nEpoch: 4854  | Training Loss: 0.36810 \nEpoch: 4854  | Training Loss: 0.34640 \nEpoch: 4854  | Training Loss: 0.21225 \nEpoch: 4854  | Training Loss: 0.14704 \nEpoch: 4854  | Validation balanced accuracy : 0.76304 \nEpoch: 4855  | Training Loss: 0.31586 \nEpoch: 4855  | Training Loss: 0.36808 \nEpoch: 4855  | Training Loss: 0.34640 \nEpoch: 4855  | Training Loss: 0.21225 \nEpoch: 4855  | Training Loss: 0.14700 \nEpoch: 4855  | Validation balanced accuracy : 0.76304 \nEpoch: 4856  | Training Loss: 0.31590 \nEpoch: 4856  | Training Loss: 0.36812 \nEpoch: 4856  | Training Loss: 0.34637 \nEpoch: 4856  | Training Loss: 0.21226 \nEpoch: 4856  | Training Loss: 0.14688 \nEpoch: 4856  | Validation balanced accuracy : 0.76304 \nEpoch: 4857  | Training Loss: 0.31599 \nEpoch: 4857  | Training Loss: 0.36818 \nEpoch: 4857  | Training Loss: 0.34633 \nEpoch: 4857  | Training Loss: 0.21226 \nEpoch: 4857  | Training Loss: 0.14679 \nEpoch: 4857  | Validation balanced accuracy : 0.76304 \nEpoch: 4858  | Training Loss: 0.31605 \nEpoch: 4858  | Training Loss: 0.36823 \nEpoch: 4858  | Training Loss: 0.34631 \nEpoch: 4858  | Training Loss: 0.21227 \nEpoch: 4858  | Training Loss: 0.14673 \nEpoch: 4858  | Validation balanced accuracy : 0.76304 \nEpoch: 4859  | Training Loss: 0.31609 \nEpoch: 4859  | Training Loss: 0.36821 \nEpoch: 4859  | Training Loss: 0.34634 \nEpoch: 4859  | Training Loss: 0.21226 \nEpoch: 4859  | Training Loss: 0.14693 \nEpoch: 4859  | Validation balanced accuracy : 0.76304 \nEpoch: 4860  | Training Loss: 0.31592 \nEpoch: 4860  | Training Loss: 0.36811 \nEpoch: 4860  | Training Loss: 0.34639 \nEpoch: 4860  | Training Loss: 0.21225 \nEpoch: 4860  | Training Loss: 0.14702 \nEpoch: 4860  | Validation balanced accuracy : 0.76304 \nEpoch: 4861  | Training Loss: 0.31588 \nEpoch: 4861  | Training Loss: 0.36810 \nEpoch: 4861  | Training Loss: 0.34639 \nEpoch: 4861  | Training Loss: 0.21225 \nEpoch: 4861  | Training Loss: 0.14698 \nEpoch: 4861  | Validation balanced accuracy : 0.76304 \nEpoch: 4862  | Training Loss: 0.31592 \nEpoch: 4862  | Training Loss: 0.36813 \nEpoch: 4862  | Training Loss: 0.34636 \nEpoch: 4862  | Training Loss: 0.21226 \nEpoch: 4862  | Training Loss: 0.14687 \nEpoch: 4862  | Validation balanced accuracy : 0.76304 \nEpoch: 4863  | Training Loss: 0.31600 \nEpoch: 4863  | Training Loss: 0.36819 \nEpoch: 4863  | Training Loss: 0.34633 \nEpoch: 4863  | Training Loss: 0.21227 \nEpoch: 4863  | Training Loss: 0.14678 \nEpoch: 4863  | Validation balanced accuracy : 0.76304 \nEpoch: 4864  | Training Loss: 0.31606 \nEpoch: 4864  | Training Loss: 0.36820 \nEpoch: 4864  | Training Loss: 0.34635 \nEpoch: 4864  | Training Loss: 0.21225 \nEpoch: 4864  | Training Loss: 0.14695 \nEpoch: 4864  | Validation balanced accuracy : 0.76304 \nEpoch: 4865  | Training Loss: 0.31591 \nEpoch: 4865  | Training Loss: 0.36811 \nEpoch: 4865  | Training Loss: 0.34639 \nEpoch: 4865  | Training Loss: 0.21225 \nEpoch: 4865  | Training Loss: 0.14701 \nEpoch: 4865  | Validation balanced accuracy : 0.76304 \nEpoch: 4866  | Training Loss: 0.31588 \nEpoch: 4866  | Training Loss: 0.36810 \nEpoch: 4866  | Training Loss: 0.34639 \nEpoch: 4866  | Training Loss: 0.21225 \nEpoch: 4866  | Training Loss: 0.14696 \nEpoch: 4866  | Validation balanced accuracy : 0.76304 \nEpoch: 4867  | Training Loss: 0.31593 \nEpoch: 4867  | Training Loss: 0.36814 \nEpoch: 4867  | Training Loss: 0.34636 \nEpoch: 4867  | Training Loss: 0.21226 \nEpoch: 4867  | Training Loss: 0.14685 \nEpoch: 4867  | Validation balanced accuracy : 0.76304 \nEpoch: 4868  | Training Loss: 0.31601 \nEpoch: 4868  | Training Loss: 0.36820 \nEpoch: 4868  | Training Loss: 0.34632 \nEpoch: 4868  | Training Loss: 0.21227 \nEpoch: 4868  | Training Loss: 0.14676 \nEpoch: 4868  | Validation balanced accuracy : 0.76304 \nEpoch: 4869  | Training Loss: 0.31607 \nEpoch: 4869  | Training Loss: 0.36820 \nEpoch: 4869  | Training Loss: 0.34634 \nEpoch: 4869  | Training Loss: 0.21226 \nEpoch: 4869  | Training Loss: 0.14693 \nEpoch: 4869  | Validation balanced accuracy : 0.76304 \nEpoch: 4870  | Training Loss: 0.31592 \nEpoch: 4870  | Training Loss: 0.36811 \nEpoch: 4870  | Training Loss: 0.34639 \nEpoch: 4870  | Training Loss: 0.21225 \nEpoch: 4870  | Training Loss: 0.14700 \nEpoch: 4870  | Validation balanced accuracy : 0.76304 \nEpoch: 4871  | Training Loss: 0.31588 \nEpoch: 4871  | Training Loss: 0.36810 \nEpoch: 4871  | Training Loss: 0.34639 \nEpoch: 4871  | Training Loss: 0.21225 \nEpoch: 4871  | Training Loss: 0.14696 \nEpoch: 4871  | Validation balanced accuracy : 0.76304 \nEpoch: 4872  | Training Loss: 0.31593 \nEpoch: 4872  | Training Loss: 0.36814 \nEpoch: 4872  | Training Loss: 0.34636 \nEpoch: 4872  | Training Loss: 0.21226 \nEpoch: 4872  | Training Loss: 0.14685 \nEpoch: 4872  | Validation balanced accuracy : 0.76304 \nEpoch: 4873  | Training Loss: 0.31601 \nEpoch: 4873  | Training Loss: 0.36820 \nEpoch: 4873  | Training Loss: 0.34633 \nEpoch: 4873  | Training Loss: 0.21226 \nEpoch: 4873  | Training Loss: 0.14678 \nEpoch: 4873  | Validation balanced accuracy : 0.76304 \nEpoch: 4874  | Training Loss: 0.31605 \nEpoch: 4874  | Training Loss: 0.36822 \nEpoch: 4874  | Training Loss: 0.34632 \nEpoch: 4874  | Training Loss: 0.21227 \nEpoch: 4874  | Training Loss: 0.14675 \nEpoch: 4874  | Validation balanced accuracy : 0.76304 \nEpoch: 4875  | Training Loss: 0.31607 \nEpoch: 4875  | Training Loss: 0.36820 \nEpoch: 4875  | Training Loss: 0.34635 \nEpoch: 4875  | Training Loss: 0.21225 \nEpoch: 4875  | Training Loss: 0.14695 \nEpoch: 4875  | Validation balanced accuracy : 0.76304 \nEpoch: 4876  | Training Loss: 0.31590 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4876  | Training Loss: 0.36810 \nEpoch: 4876  | Training Loss: 0.34640 \nEpoch: 4876  | Training Loss: 0.21224 \nEpoch: 4876  | Training Loss: 0.14704 \nEpoch: 4876  | Validation balanced accuracy : 0.76304 \nEpoch: 4877  | Training Loss: 0.31586 \nEpoch: 4877  | Training Loss: 0.36808 \nEpoch: 4877  | Training Loss: 0.34640 \nEpoch: 4877  | Training Loss: 0.21224 \nEpoch: 4877  | Training Loss: 0.14699 \nEpoch: 4877  | Validation balanced accuracy : 0.76304 \nEpoch: 4878  | Training Loss: 0.31590 \nEpoch: 4878  | Training Loss: 0.36812 \nEpoch: 4878  | Training Loss: 0.34637 \nEpoch: 4878  | Training Loss: 0.21225 \nEpoch: 4878  | Training Loss: 0.14688 \nEpoch: 4878  | Validation balanced accuracy : 0.76304 \nEpoch: 4879  | Training Loss: 0.31599 \nEpoch: 4879  | Training Loss: 0.36818 \nEpoch: 4879  | Training Loss: 0.34634 \nEpoch: 4879  | Training Loss: 0.21226 \nEpoch: 4879  | Training Loss: 0.14678 \nEpoch: 4879  | Validation balanced accuracy : 0.76304 \nEpoch: 4880  | Training Loss: 0.31605 \nEpoch: 4880  | Training Loss: 0.36823 \nEpoch: 4880  | Training Loss: 0.34631 \nEpoch: 4880  | Training Loss: 0.21227 \nEpoch: 4880  | Training Loss: 0.14673 \nEpoch: 4880  | Validation balanced accuracy : 0.76304 \nEpoch: 4881  | Training Loss: 0.31609 \nEpoch: 4881  | Training Loss: 0.36822 \nEpoch: 4881  | Training Loss: 0.34634 \nEpoch: 4881  | Training Loss: 0.21226 \nEpoch: 4881  | Training Loss: 0.14692 \nEpoch: 4881  | Validation balanced accuracy : 0.76304 \nEpoch: 4882  | Training Loss: 0.31592 \nEpoch: 4882  | Training Loss: 0.36811 \nEpoch: 4882  | Training Loss: 0.34639 \nEpoch: 4882  | Training Loss: 0.21224 \nEpoch: 4882  | Training Loss: 0.14701 \nEpoch: 4882  | Validation balanced accuracy : 0.76304 \nEpoch: 4883  | Training Loss: 0.31588 \nEpoch: 4883  | Training Loss: 0.36810 \nEpoch: 4883  | Training Loss: 0.34639 \nEpoch: 4883  | Training Loss: 0.21225 \nEpoch: 4883  | Training Loss: 0.14697 \nEpoch: 4883  | Validation balanced accuracy : 0.76304 \nEpoch: 4884  | Training Loss: 0.31592 \nEpoch: 4884  | Training Loss: 0.36814 \nEpoch: 4884  | Training Loss: 0.34637 \nEpoch: 4884  | Training Loss: 0.21225 \nEpoch: 4884  | Training Loss: 0.14686 \nEpoch: 4884  | Validation balanced accuracy : 0.76304 \nEpoch: 4885  | Training Loss: 0.31600 \nEpoch: 4885  | Training Loss: 0.36819 \nEpoch: 4885  | Training Loss: 0.34633 \nEpoch: 4885  | Training Loss: 0.21226 \nEpoch: 4885  | Training Loss: 0.14677 \nEpoch: 4885  | Validation balanced accuracy : 0.76304 \nEpoch: 4886  | Training Loss: 0.31606 \nEpoch: 4886  | Training Loss: 0.36820 \nEpoch: 4886  | Training Loss: 0.34635 \nEpoch: 4886  | Training Loss: 0.21225 \nEpoch: 4886  | Training Loss: 0.14694 \nEpoch: 4886  | Validation balanced accuracy : 0.76304 \nEpoch: 4887  | Training Loss: 0.31591 \nEpoch: 4887  | Training Loss: 0.36811 \nEpoch: 4887  | Training Loss: 0.34639 \nEpoch: 4887  | Training Loss: 0.21224 \nEpoch: 4887  | Training Loss: 0.14701 \nEpoch: 4887  | Validation balanced accuracy : 0.76304 \nEpoch: 4888  | Training Loss: 0.31588 \nEpoch: 4888  | Training Loss: 0.36810 \nEpoch: 4888  | Training Loss: 0.34639 \nEpoch: 4888  | Training Loss: 0.21225 \nEpoch: 4888  | Training Loss: 0.14696 \nEpoch: 4888  | Validation balanced accuracy : 0.76304 \nEpoch: 4889  | Training Loss: 0.31593 \nEpoch: 4889  | Training Loss: 0.36814 \nEpoch: 4889  | Training Loss: 0.34636 \nEpoch: 4889  | Training Loss: 0.21226 \nEpoch: 4889  | Training Loss: 0.14684 \nEpoch: 4889  | Validation balanced accuracy : 0.76304 \nEpoch: 4890  | Training Loss: 0.31601 \nEpoch: 4890  | Training Loss: 0.36820 \nEpoch: 4890  | Training Loss: 0.34633 \nEpoch: 4890  | Training Loss: 0.21226 \nEpoch: 4890  | Training Loss: 0.14676 \nEpoch: 4890  | Validation balanced accuracy : 0.76304 \nEpoch: 4891  | Training Loss: 0.31607 \nEpoch: 4891  | Training Loss: 0.36820 \nEpoch: 4891  | Training Loss: 0.34635 \nEpoch: 4891  | Training Loss: 0.21225 \nEpoch: 4891  | Training Loss: 0.14693 \nEpoch: 4891  | Validation balanced accuracy : 0.76304 \nEpoch: 4892  | Training Loss: 0.31592 \nEpoch: 4892  | Training Loss: 0.36811 \nEpoch: 4892  | Training Loss: 0.34639 \nEpoch: 4892  | Training Loss: 0.21224 \nEpoch: 4892  | Training Loss: 0.14700 \nEpoch: 4892  | Validation balanced accuracy : 0.76304 \nEpoch: 4893  | Training Loss: 0.31589 \nEpoch: 4893  | Training Loss: 0.36810 \nEpoch: 4893  | Training Loss: 0.34639 \nEpoch: 4893  | Training Loss: 0.21225 \nEpoch: 4893  | Training Loss: 0.14695 \nEpoch: 4893  | Validation balanced accuracy : 0.76304 \nEpoch: 4894  | Training Loss: 0.31593 \nEpoch: 4894  | Training Loss: 0.36814 \nEpoch: 4894  | Training Loss: 0.34636 \nEpoch: 4894  | Training Loss: 0.21225 \nEpoch: 4894  | Training Loss: 0.14684 \nEpoch: 4894  | Validation balanced accuracy : 0.76304 \nEpoch: 4895  | Training Loss: 0.31601 \nEpoch: 4895  | Training Loss: 0.36820 \nEpoch: 4895  | Training Loss: 0.34633 \nEpoch: 4895  | Training Loss: 0.21226 \nEpoch: 4895  | Training Loss: 0.14678 \nEpoch: 4895  | Validation balanced accuracy : 0.76304 \nEpoch: 4896  | Training Loss: 0.31605 \nEpoch: 4896  | Training Loss: 0.36822 \nEpoch: 4896  | Training Loss: 0.34632 \nEpoch: 4896  | Training Loss: 0.21226 \nEpoch: 4896  | Training Loss: 0.14674 \nEpoch: 4896  | Validation balanced accuracy : 0.76304 \nEpoch: 4897  | Training Loss: 0.31607 \nEpoch: 4897  | Training Loss: 0.36820 \nEpoch: 4897  | Training Loss: 0.34635 \nEpoch: 4897  | Training Loss: 0.21225 \nEpoch: 4897  | Training Loss: 0.14694 \nEpoch: 4897  | Validation balanced accuracy : 0.76304 \nEpoch: 4898  | Training Loss: 0.31590 \nEpoch: 4898  | Training Loss: 0.36810 \nEpoch: 4898  | Training Loss: 0.34640 \nEpoch: 4898  | Training Loss: 0.21224 \nEpoch: 4898  | Training Loss: 0.14703 \nEpoch: 4898  | Validation balanced accuracy : 0.76304 \nEpoch: 4899  | Training Loss: 0.31586 \nEpoch: 4899  | Training Loss: 0.36808 \nEpoch: 4899  | Training Loss: 0.34640 \nEpoch: 4899  | Training Loss: 0.21224 \nEpoch: 4899  | Training Loss: 0.14699 \nEpoch: 4899  | Validation balanced accuracy : 0.76304 \nEpoch: 4900  | Training Loss: 0.31590 \nEpoch: 4900  | Training Loss: 0.36812 \nEpoch: 4900  | Training Loss: 0.34637 \nEpoch: 4900  | Training Loss: 0.21225 \nEpoch: 4900  | Training Loss: 0.14687 \nEpoch: 4900  | Validation balanced accuracy : 0.76304 \nEpoch: 4901  | Training Loss: 0.31599 \nEpoch: 4901  | Training Loss: 0.36819 \nEpoch: 4901  | Training Loss: 0.34634 \nEpoch: 4901  | Training Loss: 0.21226 \nEpoch: 4901  | Training Loss: 0.14678 \nEpoch: 4901  | Validation balanced accuracy : 0.76304 \nEpoch: 4902  | Training Loss: 0.31605 \nEpoch: 4902  | Training Loss: 0.36823 \nEpoch: 4902  | Training Loss: 0.34632 \nEpoch: 4902  | Training Loss: 0.21227 \nEpoch: 4902  | Training Loss: 0.14672 \nEpoch: 4902  | Validation balanced accuracy : 0.76304 \nEpoch: 4903  | Training Loss: 0.31609 \nEpoch: 4903  | Training Loss: 0.36822 \nEpoch: 4903  | Training Loss: 0.34634 \nEpoch: 4903  | Training Loss: 0.21225 \nEpoch: 4903  | Training Loss: 0.14691 \nEpoch: 4903  | Validation balanced accuracy : 0.76304 \nEpoch: 4904  | Training Loss: 0.31592 \nEpoch: 4904  | Training Loss: 0.36811 \nEpoch: 4904  | Training Loss: 0.34639 \nEpoch: 4904  | Training Loss: 0.21224 \nEpoch: 4904  | Training Loss: 0.14700 \nEpoch: 4904  | Validation balanced accuracy : 0.76304 \nEpoch: 4905  | Training Loss: 0.31588 \nEpoch: 4905  | Training Loss: 0.36810 \nEpoch: 4905  | Training Loss: 0.34640 \nEpoch: 4905  | Training Loss: 0.21224 \nEpoch: 4905  | Training Loss: 0.14696 \nEpoch: 4905  | Validation balanced accuracy : 0.76304 \nEpoch: 4906  | Training Loss: 0.31592 \nEpoch: 4906  | Training Loss: 0.36814 \nEpoch: 4906  | Training Loss: 0.34637 \nEpoch: 4906  | Training Loss: 0.21225 \nEpoch: 4906  | Training Loss: 0.14686 \nEpoch: 4906  | Validation balanced accuracy : 0.76304 \nEpoch: 4907  | Training Loss: 0.31600 \nEpoch: 4907  | Training Loss: 0.36819 \nEpoch: 4907  | Training Loss: 0.34634 \nEpoch: 4907  | Training Loss: 0.21226 \nEpoch: 4907  | Training Loss: 0.14677 \nEpoch: 4907  | Validation balanced accuracy : 0.76304 \nEpoch: 4908  | Training Loss: 0.31606 \nEpoch: 4908  | Training Loss: 0.36820 \nEpoch: 4908  | Training Loss: 0.34635 \nEpoch: 4908  | Training Loss: 0.21225 \nEpoch: 4908  | Training Loss: 0.14693 \nEpoch: 4908  | Validation balanced accuracy : 0.76304 \nEpoch: 4909  | Training Loss: 0.31591 \nEpoch: 4909  | Training Loss: 0.36811 \nEpoch: 4909  | Training Loss: 0.34640 \nEpoch: 4909  | Training Loss: 0.21224 \nEpoch: 4909  | Training Loss: 0.14700 \nEpoch: 4909  | Validation balanced accuracy : 0.76304 \nEpoch: 4910  | Training Loss: 0.31588 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4910  | Training Loss: 0.36810 \nEpoch: 4910  | Training Loss: 0.34640 \nEpoch: 4910  | Training Loss: 0.21224 \nEpoch: 4910  | Training Loss: 0.14695 \nEpoch: 4910  | Validation balanced accuracy : 0.76304 \nEpoch: 4911  | Training Loss: 0.31593 \nEpoch: 4911  | Training Loss: 0.36814 \nEpoch: 4911  | Training Loss: 0.34637 \nEpoch: 4911  | Training Loss: 0.21225 \nEpoch: 4911  | Training Loss: 0.14684 \nEpoch: 4911  | Validation balanced accuracy : 0.76304 \nEpoch: 4912  | Training Loss: 0.31601 \nEpoch: 4912  | Training Loss: 0.36820 \nEpoch: 4912  | Training Loss: 0.34633 \nEpoch: 4912  | Training Loss: 0.21226 \nEpoch: 4912  | Training Loss: 0.14675 \nEpoch: 4912  | Validation balanced accuracy : 0.76304 \nEpoch: 4913  | Training Loss: 0.31607 \nEpoch: 4913  | Training Loss: 0.36820 \nEpoch: 4913  | Training Loss: 0.34635 \nEpoch: 4913  | Training Loss: 0.21225 \nEpoch: 4913  | Training Loss: 0.14693 \nEpoch: 4913  | Validation balanced accuracy : 0.76304 \nEpoch: 4914  | Training Loss: 0.31591 \nEpoch: 4914  | Training Loss: 0.36811 \nEpoch: 4914  | Training Loss: 0.34640 \nEpoch: 4914  | Training Loss: 0.21224 \nEpoch: 4914  | Training Loss: 0.14701 \nEpoch: 4914  | Validation balanced accuracy : 0.76304 \nEpoch: 4915  | Training Loss: 0.31587 \nEpoch: 4915  | Training Loss: 0.36809 \nEpoch: 4915  | Training Loss: 0.34640 \nEpoch: 4915  | Training Loss: 0.21224 \nEpoch: 4915  | Training Loss: 0.14696 \nEpoch: 4915  | Validation balanced accuracy : 0.76304 \nEpoch: 4916  | Training Loss: 0.31592 \nEpoch: 4916  | Training Loss: 0.36814 \nEpoch: 4916  | Training Loss: 0.34637 \nEpoch: 4916  | Training Loss: 0.21225 \nEpoch: 4916  | Training Loss: 0.14685 \nEpoch: 4916  | Validation balanced accuracy : 0.76304 \nEpoch: 4917  | Training Loss: 0.31600 \nEpoch: 4917  | Training Loss: 0.36819 \nEpoch: 4917  | Training Loss: 0.34634 \nEpoch: 4917  | Training Loss: 0.21226 \nEpoch: 4917  | Training Loss: 0.14676 \nEpoch: 4917  | Validation balanced accuracy : 0.76304 \nEpoch: 4918  | Training Loss: 0.31606 \nEpoch: 4918  | Training Loss: 0.36820 \nEpoch: 4918  | Training Loss: 0.34636 \nEpoch: 4918  | Training Loss: 0.21225 \nEpoch: 4918  | Training Loss: 0.14692 \nEpoch: 4918  | Validation balanced accuracy : 0.76304 \nEpoch: 4919  | Training Loss: 0.31591 \nEpoch: 4919  | Training Loss: 0.36811 \nEpoch: 4919  | Training Loss: 0.34640 \nEpoch: 4919  | Training Loss: 0.21224 \nEpoch: 4919  | Training Loss: 0.14700 \nEpoch: 4919  | Validation balanced accuracy : 0.76304 \nEpoch: 4920  | Training Loss: 0.31588 \nEpoch: 4920  | Training Loss: 0.36810 \nEpoch: 4920  | Training Loss: 0.34640 \nEpoch: 4920  | Training Loss: 0.21224 \nEpoch: 4920  | Training Loss: 0.14695 \nEpoch: 4920  | Validation balanced accuracy : 0.76304 \nEpoch: 4921  | Training Loss: 0.31593 \nEpoch: 4921  | Training Loss: 0.36814 \nEpoch: 4921  | Training Loss: 0.34637 \nEpoch: 4921  | Training Loss: 0.21225 \nEpoch: 4921  | Training Loss: 0.14683 \nEpoch: 4921  | Validation balanced accuracy : 0.76304 \nEpoch: 4922  | Training Loss: 0.31601 \nEpoch: 4922  | Training Loss: 0.36820 \nEpoch: 4922  | Training Loss: 0.34633 \nEpoch: 4922  | Training Loss: 0.21226 \nEpoch: 4922  | Training Loss: 0.14675 \nEpoch: 4922  | Validation balanced accuracy : 0.76304 \nEpoch: 4923  | Training Loss: 0.31607 \nEpoch: 4923  | Training Loss: 0.36820 \nEpoch: 4923  | Training Loss: 0.34635 \nEpoch: 4923  | Training Loss: 0.21225 \nEpoch: 4923  | Training Loss: 0.14692 \nEpoch: 4923  | Validation balanced accuracy : 0.76304 \nEpoch: 4924  | Training Loss: 0.31592 \nEpoch: 4924  | Training Loss: 0.36811 \nEpoch: 4924  | Training Loss: 0.34640 \nEpoch: 4924  | Training Loss: 0.21224 \nEpoch: 4924  | Training Loss: 0.14699 \nEpoch: 4924  | Validation balanced accuracy : 0.76304 \nEpoch: 4925  | Training Loss: 0.31589 \nEpoch: 4925  | Training Loss: 0.36810 \nEpoch: 4925  | Training Loss: 0.34640 \nEpoch: 4925  | Training Loss: 0.21224 \nEpoch: 4925  | Training Loss: 0.14694 \nEpoch: 4925  | Validation balanced accuracy : 0.76304 \nEpoch: 4926  | Training Loss: 0.31593 \nEpoch: 4926  | Training Loss: 0.36814 \nEpoch: 4926  | Training Loss: 0.34637 \nEpoch: 4926  | Training Loss: 0.21225 \nEpoch: 4926  | Training Loss: 0.14683 \nEpoch: 4926  | Validation balanced accuracy : 0.76304 \nEpoch: 4927  | Training Loss: 0.31601 \nEpoch: 4927  | Training Loss: 0.36820 \nEpoch: 4927  | Training Loss: 0.34634 \nEpoch: 4927  | Training Loss: 0.21226 \nEpoch: 4927  | Training Loss: 0.14675 \nEpoch: 4927  | Validation balanced accuracy : 0.76304 \nEpoch: 4928  | Training Loss: 0.31607 \nEpoch: 4928  | Training Loss: 0.36820 \nEpoch: 4928  | Training Loss: 0.34636 \nEpoch: 4928  | Training Loss: 0.21225 \nEpoch: 4928  | Training Loss: 0.14694 \nEpoch: 4928  | Validation balanced accuracy : 0.76304 \nEpoch: 4929  | Training Loss: 0.31590 \nEpoch: 4929  | Training Loss: 0.36810 \nEpoch: 4929  | Training Loss: 0.34641 \nEpoch: 4929  | Training Loss: 0.21224 \nEpoch: 4929  | Training Loss: 0.14702 \nEpoch: 4929  | Validation balanced accuracy : 0.76304 \nEpoch: 4930  | Training Loss: 0.31586 \nEpoch: 4930  | Training Loss: 0.36808 \nEpoch: 4930  | Training Loss: 0.34641 \nEpoch: 4930  | Training Loss: 0.21224 \nEpoch: 4930  | Training Loss: 0.14698 \nEpoch: 4930  | Validation balanced accuracy : 0.76304 \nEpoch: 4931  | Training Loss: 0.31591 \nEpoch: 4931  | Training Loss: 0.36813 \nEpoch: 4931  | Training Loss: 0.34638 \nEpoch: 4931  | Training Loss: 0.21225 \nEpoch: 4931  | Training Loss: 0.14686 \nEpoch: 4931  | Validation balanced accuracy : 0.76304 \nEpoch: 4932  | Training Loss: 0.31599 \nEpoch: 4932  | Training Loss: 0.36819 \nEpoch: 4932  | Training Loss: 0.34635 \nEpoch: 4932  | Training Loss: 0.21226 \nEpoch: 4932  | Training Loss: 0.14677 \nEpoch: 4932  | Validation balanced accuracy : 0.76304 \nEpoch: 4933  | Training Loss: 0.31606 \nEpoch: 4933  | Training Loss: 0.36823 \nEpoch: 4933  | Training Loss: 0.34632 \nEpoch: 4933  | Training Loss: 0.21226 \nEpoch: 4933  | Training Loss: 0.14671 \nEpoch: 4933  | Validation balanced accuracy : 0.76304 \nEpoch: 4934  | Training Loss: 0.31609 \nEpoch: 4934  | Training Loss: 0.36822 \nEpoch: 4934  | Training Loss: 0.34635 \nEpoch: 4934  | Training Loss: 0.21225 \nEpoch: 4934  | Training Loss: 0.14690 \nEpoch: 4934  | Validation balanced accuracy : 0.76304 \nEpoch: 4935  | Training Loss: 0.31592 \nEpoch: 4935  | Training Loss: 0.36811 \nEpoch: 4935  | Training Loss: 0.34640 \nEpoch: 4935  | Training Loss: 0.21224 \nEpoch: 4935  | Training Loss: 0.14699 \nEpoch: 4935  | Validation balanced accuracy : 0.76304 \nEpoch: 4936  | Training Loss: 0.31588 \nEpoch: 4936  | Training Loss: 0.36810 \nEpoch: 4936  | Training Loss: 0.34640 \nEpoch: 4936  | Training Loss: 0.21224 \nEpoch: 4936  | Training Loss: 0.14696 \nEpoch: 4936  | Validation balanced accuracy : 0.76304 \nEpoch: 4937  | Training Loss: 0.31592 \nEpoch: 4937  | Training Loss: 0.36813 \nEpoch: 4937  | Training Loss: 0.34638 \nEpoch: 4937  | Training Loss: 0.21225 \nEpoch: 4937  | Training Loss: 0.14685 \nEpoch: 4937  | Validation balanced accuracy : 0.76304 \nEpoch: 4938  | Training Loss: 0.31600 \nEpoch: 4938  | Training Loss: 0.36819 \nEpoch: 4938  | Training Loss: 0.34634 \nEpoch: 4938  | Training Loss: 0.21226 \nEpoch: 4938  | Training Loss: 0.14676 \nEpoch: 4938  | Validation balanced accuracy : 0.76304 \nEpoch: 4939  | Training Loss: 0.31606 \nEpoch: 4939  | Training Loss: 0.36823 \nEpoch: 4939  | Training Loss: 0.34632 \nEpoch: 4939  | Training Loss: 0.21226 \nEpoch: 4939  | Training Loss: 0.14671 \nEpoch: 4939  | Validation balanced accuracy : 0.76304 \nEpoch: 4940  | Training Loss: 0.31609 \nEpoch: 4940  | Training Loss: 0.36822 \nEpoch: 4940  | Training Loss: 0.34635 \nEpoch: 4940  | Training Loss: 0.21225 \nEpoch: 4940  | Training Loss: 0.14691 \nEpoch: 4940  | Validation balanced accuracy : 0.76304 \nEpoch: 4941  | Training Loss: 0.31592 \nEpoch: 4941  | Training Loss: 0.36811 \nEpoch: 4941  | Training Loss: 0.34640 \nEpoch: 4941  | Training Loss: 0.21224 \nEpoch: 4941  | Training Loss: 0.14700 \nEpoch: 4941  | Validation balanced accuracy : 0.76304 \nEpoch: 4942  | Training Loss: 0.31588 \nEpoch: 4942  | Training Loss: 0.36810 \nEpoch: 4942  | Training Loss: 0.34640 \nEpoch: 4942  | Training Loss: 0.21224 \nEpoch: 4942  | Training Loss: 0.14696 \nEpoch: 4942  | Validation balanced accuracy : 0.76304 \nEpoch: 4943  | Training Loss: 0.31592 \nEpoch: 4943  | Training Loss: 0.36813 \nEpoch: 4943  | Training Loss: 0.34638 \nEpoch: 4943  | Training Loss: 0.21225 \nEpoch: 4943  | Training Loss: 0.14685 \nEpoch: 4943  | Validation balanced accuracy : 0.76304 \nEpoch: 4944  | Training Loss: 0.31600 \nEpoch: 4944  | Training Loss: 0.36819 \nEpoch: 4944  | Training Loss: 0.34634 \nEpoch: 4944  | Training Loss: 0.21226 \nEpoch: 4944  | Training Loss: 0.14676 \nEpoch: 4944  | Validation balanced accuracy : 0.76304 \nEpoch: 4945  | Training Loss: 0.31606 \nEpoch: 4945  | Training Loss: 0.36820 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4945  | Training Loss: 0.34636 \nEpoch: 4945  | Training Loss: 0.21225 \nEpoch: 4945  | Training Loss: 0.14693 \nEpoch: 4945  | Validation balanced accuracy : 0.76304 \nEpoch: 4946  | Training Loss: 0.31591 \nEpoch: 4946  | Training Loss: 0.36811 \nEpoch: 4946  | Training Loss: 0.34641 \nEpoch: 4946  | Training Loss: 0.21224 \nEpoch: 4946  | Training Loss: 0.14699 \nEpoch: 4946  | Validation balanced accuracy : 0.76304 \nEpoch: 4947  | Training Loss: 0.31588 \nEpoch: 4947  | Training Loss: 0.36810 \nEpoch: 4947  | Training Loss: 0.34640 \nEpoch: 4947  | Training Loss: 0.21224 \nEpoch: 4947  | Training Loss: 0.14694 \nEpoch: 4947  | Validation balanced accuracy : 0.76304 \nEpoch: 4948  | Training Loss: 0.31593 \nEpoch: 4948  | Training Loss: 0.36814 \nEpoch: 4948  | Training Loss: 0.34637 \nEpoch: 4948  | Training Loss: 0.21225 \nEpoch: 4948  | Training Loss: 0.14683 \nEpoch: 4948  | Validation balanced accuracy : 0.76304 \nEpoch: 4949  | Training Loss: 0.31601 \nEpoch: 4949  | Training Loss: 0.36820 \nEpoch: 4949  | Training Loss: 0.34634 \nEpoch: 4949  | Training Loss: 0.21226 \nEpoch: 4949  | Training Loss: 0.14674 \nEpoch: 4949  | Validation balanced accuracy : 0.76304 \nEpoch: 4950  | Training Loss: 0.31607 \nEpoch: 4950  | Training Loss: 0.36820 \nEpoch: 4950  | Training Loss: 0.34636 \nEpoch: 4950  | Training Loss: 0.21224 \nEpoch: 4950  | Training Loss: 0.14693 \nEpoch: 4950  | Validation balanced accuracy : 0.76304 \nEpoch: 4951  | Training Loss: 0.31590 \nEpoch: 4951  | Training Loss: 0.36810 \nEpoch: 4951  | Training Loss: 0.34641 \nEpoch: 4951  | Training Loss: 0.21223 \nEpoch: 4951  | Training Loss: 0.14702 \nEpoch: 4951  | Validation balanced accuracy : 0.76304 \nEpoch: 4952  | Training Loss: 0.31586 \nEpoch: 4952  | Training Loss: 0.36809 \nEpoch: 4952  | Training Loss: 0.34641 \nEpoch: 4952  | Training Loss: 0.21224 \nEpoch: 4952  | Training Loss: 0.14697 \nEpoch: 4952  | Validation balanced accuracy : 0.76304 \nEpoch: 4953  | Training Loss: 0.31591 \nEpoch: 4953  | Training Loss: 0.36813 \nEpoch: 4953  | Training Loss: 0.34638 \nEpoch: 4953  | Training Loss: 0.21225 \nEpoch: 4953  | Training Loss: 0.14685 \nEpoch: 4953  | Validation balanced accuracy : 0.76304 \nEpoch: 4954  | Training Loss: 0.31600 \nEpoch: 4954  | Training Loss: 0.36819 \nEpoch: 4954  | Training Loss: 0.34635 \nEpoch: 4954  | Training Loss: 0.21225 \nEpoch: 4954  | Training Loss: 0.14676 \nEpoch: 4954  | Validation balanced accuracy : 0.76304 \nEpoch: 4955  | Training Loss: 0.31606 \nEpoch: 4955  | Training Loss: 0.36823 \nEpoch: 4955  | Training Loss: 0.34633 \nEpoch: 4955  | Training Loss: 0.21226 \nEpoch: 4955  | Training Loss: 0.14670 \nEpoch: 4955  | Validation balanced accuracy : 0.76304 \nEpoch: 4956  | Training Loss: 0.31609 \nEpoch: 4956  | Training Loss: 0.36822 \nEpoch: 4956  | Training Loss: 0.34635 \nEpoch: 4956  | Training Loss: 0.21225 \nEpoch: 4956  | Training Loss: 0.14690 \nEpoch: 4956  | Validation balanced accuracy : 0.76304 \nEpoch: 4957  | Training Loss: 0.31592 \nEpoch: 4957  | Training Loss: 0.36811 \nEpoch: 4957  | Training Loss: 0.34640 \nEpoch: 4957  | Training Loss: 0.21224 \nEpoch: 4957  | Training Loss: 0.14699 \nEpoch: 4957  | Validation balanced accuracy : 0.76304 \nEpoch: 4958  | Training Loss: 0.31588 \nEpoch: 4958  | Training Loss: 0.36810 \nEpoch: 4958  | Training Loss: 0.34641 \nEpoch: 4958  | Training Loss: 0.21224 \nEpoch: 4958  | Training Loss: 0.14695 \nEpoch: 4958  | Validation balanced accuracy : 0.76304 \nEpoch: 4959  | Training Loss: 0.31592 \nEpoch: 4959  | Training Loss: 0.36813 \nEpoch: 4959  | Training Loss: 0.34638 \nEpoch: 4959  | Training Loss: 0.21225 \nEpoch: 4959  | Training Loss: 0.14684 \nEpoch: 4959  | Validation balanced accuracy : 0.76304 \nEpoch: 4960  | Training Loss: 0.31600 \nEpoch: 4960  | Training Loss: 0.36819 \nEpoch: 4960  | Training Loss: 0.34635 \nEpoch: 4960  | Training Loss: 0.21225 \nEpoch: 4960  | Training Loss: 0.14675 \nEpoch: 4960  | Validation balanced accuracy : 0.76304 \nEpoch: 4961  | Training Loss: 0.31606 \nEpoch: 4961  | Training Loss: 0.36823 \nEpoch: 4961  | Training Loss: 0.34633 \nEpoch: 4961  | Training Loss: 0.21226 \nEpoch: 4961  | Training Loss: 0.14670 \nEpoch: 4961  | Validation balanced accuracy : 0.76304 \nEpoch: 4962  | Training Loss: 0.31609 \nEpoch: 4962  | Training Loss: 0.36822 \nEpoch: 4962  | Training Loss: 0.34635 \nEpoch: 4962  | Training Loss: 0.21225 \nEpoch: 4962  | Training Loss: 0.14690 \nEpoch: 4962  | Validation balanced accuracy : 0.76304 \nEpoch: 4963  | Training Loss: 0.31592 \nEpoch: 4963  | Training Loss: 0.36811 \nEpoch: 4963  | Training Loss: 0.34641 \nEpoch: 4963  | Training Loss: 0.21223 \nEpoch: 4963  | Training Loss: 0.14699 \nEpoch: 4963  | Validation balanced accuracy : 0.76304 \nEpoch: 4964  | Training Loss: 0.31588 \nEpoch: 4964  | Training Loss: 0.36810 \nEpoch: 4964  | Training Loss: 0.34641 \nEpoch: 4964  | Training Loss: 0.21224 \nEpoch: 4964  | Training Loss: 0.14695 \nEpoch: 4964  | Validation balanced accuracy : 0.76304 \nEpoch: 4965  | Training Loss: 0.31592 \nEpoch: 4965  | Training Loss: 0.36813 \nEpoch: 4965  | Training Loss: 0.34638 \nEpoch: 4965  | Training Loss: 0.21224 \nEpoch: 4965  | Training Loss: 0.14684 \nEpoch: 4965  | Validation balanced accuracy : 0.76304 \nEpoch: 4966  | Training Loss: 0.31600 \nEpoch: 4966  | Training Loss: 0.36819 \nEpoch: 4966  | Training Loss: 0.34635 \nEpoch: 4966  | Training Loss: 0.21225 \nEpoch: 4966  | Training Loss: 0.14675 \nEpoch: 4966  | Validation balanced accuracy : 0.76304 \nEpoch: 4967  | Training Loss: 0.31606 \nEpoch: 4967  | Training Loss: 0.36820 \nEpoch: 4967  | Training Loss: 0.34637 \nEpoch: 4967  | Training Loss: 0.21224 \nEpoch: 4967  | Training Loss: 0.14692 \nEpoch: 4967  | Validation balanced accuracy : 0.76304 \nEpoch: 4968  | Training Loss: 0.31591 \nEpoch: 4968  | Training Loss: 0.36811 \nEpoch: 4968  | Training Loss: 0.34641 \nEpoch: 4968  | Training Loss: 0.21223 \nEpoch: 4968  | Training Loss: 0.14699 \nEpoch: 4968  | Validation balanced accuracy : 0.76304 \nEpoch: 4969  | Training Loss: 0.31588 \nEpoch: 4969  | Training Loss: 0.36810 \nEpoch: 4969  | Training Loss: 0.34641 \nEpoch: 4969  | Training Loss: 0.21224 \nEpoch: 4969  | Training Loss: 0.14694 \nEpoch: 4969  | Validation balanced accuracy : 0.76304 \nEpoch: 4970  | Training Loss: 0.31593 \nEpoch: 4970  | Training Loss: 0.36814 \nEpoch: 4970  | Training Loss: 0.34638 \nEpoch: 4970  | Training Loss: 0.21225 \nEpoch: 4970  | Training Loss: 0.14682 \nEpoch: 4970  | Validation balanced accuracy : 0.76304 \nEpoch: 4971  | Training Loss: 0.31601 \nEpoch: 4971  | Training Loss: 0.36820 \nEpoch: 4971  | Training Loss: 0.34634 \nEpoch: 4971  | Training Loss: 0.21225 \nEpoch: 4971  | Training Loss: 0.14673 \nEpoch: 4971  | Validation balanced accuracy : 0.76304 \nEpoch: 4972  | Training Loss: 0.31607 \nEpoch: 4972  | Training Loss: 0.36820 \nEpoch: 4972  | Training Loss: 0.34637 \nEpoch: 4972  | Training Loss: 0.21224 \nEpoch: 4972  | Training Loss: 0.14692 \nEpoch: 4972  | Validation balanced accuracy : 0.76304 \nEpoch: 4973  | Training Loss: 0.31590 \nEpoch: 4973  | Training Loss: 0.36810 \nEpoch: 4973  | Training Loss: 0.34642 \nEpoch: 4973  | Training Loss: 0.21223 \nEpoch: 4973  | Training Loss: 0.14701 \nEpoch: 4973  | Validation balanced accuracy : 0.76304 \nEpoch: 4974  | Training Loss: 0.31586 \nEpoch: 4974  | Training Loss: 0.36809 \nEpoch: 4974  | Training Loss: 0.34642 \nEpoch: 4974  | Training Loss: 0.21223 \nEpoch: 4974  | Training Loss: 0.14696 \nEpoch: 4974  | Validation balanced accuracy : 0.76304 \nEpoch: 4975  | Training Loss: 0.31591 \nEpoch: 4975  | Training Loss: 0.36813 \nEpoch: 4975  | Training Loss: 0.34639 \nEpoch: 4975  | Training Loss: 0.21224 \nEpoch: 4975  | Training Loss: 0.14685 \nEpoch: 4975  | Validation balanced accuracy : 0.76304 \nEpoch: 4976  | Training Loss: 0.31600 \nEpoch: 4976  | Training Loss: 0.36819 \nEpoch: 4976  | Training Loss: 0.34635 \nEpoch: 4976  | Training Loss: 0.21225 \nEpoch: 4976  | Training Loss: 0.14675 \nEpoch: 4976  | Validation balanced accuracy : 0.76304 \nEpoch: 4977  | Training Loss: 0.31606 \nEpoch: 4977  | Training Loss: 0.36823 \nEpoch: 4977  | Training Loss: 0.34633 \nEpoch: 4977  | Training Loss: 0.21226 \nEpoch: 4977  | Training Loss: 0.14670 \nEpoch: 4977  | Validation balanced accuracy : 0.76304 \nEpoch: 4978  | Training Loss: 0.31609 \n","name":"stdout"},{"output_type":"stream","text":"Epoch: 4978  | Training Loss: 0.36822 \nEpoch: 4978  | Training Loss: 0.34636 \nEpoch: 4978  | Training Loss: 0.21224 \nEpoch: 4978  | Training Loss: 0.14689 \nEpoch: 4978  | Validation balanced accuracy : 0.76304 \nEpoch: 4979  | Training Loss: 0.31592 \nEpoch: 4979  | Training Loss: 0.36811 \nEpoch: 4979  | Training Loss: 0.34641 \nEpoch: 4979  | Training Loss: 0.21223 \nEpoch: 4979  | Training Loss: 0.14698 \nEpoch: 4979  | Validation balanced accuracy : 0.76304 \nEpoch: 4980  | Training Loss: 0.31588 \nEpoch: 4980  | Training Loss: 0.36810 \nEpoch: 4980  | Training Loss: 0.34641 \nEpoch: 4980  | Training Loss: 0.21223 \nEpoch: 4980  | Training Loss: 0.14694 \nEpoch: 4980  | Validation balanced accuracy : 0.76304 \nEpoch: 4981  | Training Loss: 0.31592 \nEpoch: 4981  | Training Loss: 0.36814 \nEpoch: 4981  | Training Loss: 0.34638 \nEpoch: 4981  | Training Loss: 0.21224 \nEpoch: 4981  | Training Loss: 0.14684 \nEpoch: 4981  | Validation balanced accuracy : 0.76304 \nEpoch: 4982  | Training Loss: 0.31600 \nEpoch: 4982  | Training Loss: 0.36819 \nEpoch: 4982  | Training Loss: 0.34635 \nEpoch: 4982  | Training Loss: 0.21225 \nEpoch: 4982  | Training Loss: 0.14675 \nEpoch: 4982  | Validation balanced accuracy : 0.76304 \nEpoch: 4983  | Training Loss: 0.31606 \nEpoch: 4983  | Training Loss: 0.36823 \nEpoch: 4983  | Training Loss: 0.34633 \nEpoch: 4983  | Training Loss: 0.21226 \nEpoch: 4983  | Training Loss: 0.14670 \nEpoch: 4983  | Validation balanced accuracy : 0.76304 \nEpoch: 4984  | Training Loss: 0.31609 \nEpoch: 4984  | Training Loss: 0.36822 \nEpoch: 4984  | Training Loss: 0.34636 \nEpoch: 4984  | Training Loss: 0.21224 \nEpoch: 4984  | Training Loss: 0.14689 \nEpoch: 4984  | Validation balanced accuracy : 0.76304 \nEpoch: 4985  | Training Loss: 0.31592 \nEpoch: 4985  | Training Loss: 0.36811 \nEpoch: 4985  | Training Loss: 0.34641 \nEpoch: 4985  | Training Loss: 0.21223 \nEpoch: 4985  | Training Loss: 0.14699 \nEpoch: 4985  | Validation balanced accuracy : 0.76304 \nEpoch: 4986  | Training Loss: 0.31588 \nEpoch: 4986  | Training Loss: 0.36810 \nEpoch: 4986  | Training Loss: 0.34641 \nEpoch: 4986  | Training Loss: 0.21223 \nEpoch: 4986  | Training Loss: 0.14695 \nEpoch: 4986  | Validation balanced accuracy : 0.76304 \nEpoch: 4987  | Training Loss: 0.31592 \nEpoch: 4987  | Training Loss: 0.36813 \nEpoch: 4987  | Training Loss: 0.34638 \nEpoch: 4987  | Training Loss: 0.21224 \nEpoch: 4987  | Training Loss: 0.14684 \nEpoch: 4987  | Validation balanced accuracy : 0.76304 \nEpoch: 4988  | Training Loss: 0.31600 \nEpoch: 4988  | Training Loss: 0.36819 \nEpoch: 4988  | Training Loss: 0.34635 \nEpoch: 4988  | Training Loss: 0.21225 \nEpoch: 4988  | Training Loss: 0.14675 \nEpoch: 4988  | Validation balanced accuracy : 0.76304 \nEpoch: 4989  | Training Loss: 0.31606 \nEpoch: 4989  | Training Loss: 0.36820 \nEpoch: 4989  | Training Loss: 0.34637 \nEpoch: 4989  | Training Loss: 0.21224 \nEpoch: 4989  | Training Loss: 0.14691 \nEpoch: 4989  | Validation balanced accuracy : 0.76304 \nEpoch: 4990  | Training Loss: 0.31591 \nEpoch: 4990  | Training Loss: 0.36811 \nEpoch: 4990  | Training Loss: 0.34641 \nEpoch: 4990  | Training Loss: 0.21223 \nEpoch: 4990  | Training Loss: 0.14698 \nEpoch: 4990  | Validation balanced accuracy : 0.76304 \nEpoch: 4991  | Training Loss: 0.31588 \nEpoch: 4991  | Training Loss: 0.36810 \nEpoch: 4991  | Training Loss: 0.34641 \nEpoch: 4991  | Training Loss: 0.21223 \nEpoch: 4991  | Training Loss: 0.14693 \nEpoch: 4991  | Validation balanced accuracy : 0.76304 \nEpoch: 4992  | Training Loss: 0.31593 \nEpoch: 4992  | Training Loss: 0.36814 \nEpoch: 4992  | Training Loss: 0.34638 \nEpoch: 4992  | Training Loss: 0.21224 \nEpoch: 4992  | Training Loss: 0.14682 \nEpoch: 4992  | Validation balanced accuracy : 0.76304 \nEpoch: 4993  | Training Loss: 0.31601 \nEpoch: 4993  | Training Loss: 0.36820 \nEpoch: 4993  | Training Loss: 0.34635 \nEpoch: 4993  | Training Loss: 0.21225 \nEpoch: 4993  | Training Loss: 0.14673 \nEpoch: 4993  | Validation balanced accuracy : 0.76304 \nEpoch: 4994  | Training Loss: 0.31607 \nEpoch: 4994  | Training Loss: 0.36820 \nEpoch: 4994  | Training Loss: 0.34637 \nEpoch: 4994  | Training Loss: 0.21224 \nEpoch: 4994  | Training Loss: 0.14692 \nEpoch: 4994  | Validation balanced accuracy : 0.76304 \nEpoch: 4995  | Training Loss: 0.31590 \nEpoch: 4995  | Training Loss: 0.36810 \nEpoch: 4995  | Training Loss: 0.34642 \nEpoch: 4995  | Training Loss: 0.21223 \nEpoch: 4995  | Training Loss: 0.14700 \nEpoch: 4995  | Validation balanced accuracy : 0.76304 \nEpoch: 4996  | Training Loss: 0.31586 \nEpoch: 4996  | Training Loss: 0.36809 \nEpoch: 4996  | Training Loss: 0.34642 \nEpoch: 4996  | Training Loss: 0.21223 \nEpoch: 4996  | Training Loss: 0.14696 \nEpoch: 4996  | Validation balanced accuracy : 0.76304 \nEpoch: 4997  | Training Loss: 0.31591 \nEpoch: 4997  | Training Loss: 0.36813 \nEpoch: 4997  | Training Loss: 0.34639 \nEpoch: 4997  | Training Loss: 0.21224 \nEpoch: 4997  | Training Loss: 0.14684 \nEpoch: 4997  | Validation balanced accuracy : 0.76304 \nEpoch: 4998  | Training Loss: 0.31600 \nEpoch: 4998  | Training Loss: 0.36819 \nEpoch: 4998  | Training Loss: 0.34636 \nEpoch: 4998  | Training Loss: 0.21225 \nEpoch: 4998  | Training Loss: 0.14675 \nEpoch: 4998  | Validation balanced accuracy : 0.76304 \nEpoch: 4999  | Training Loss: 0.31606 \nEpoch: 4999  | Training Loss: 0.36823 \nEpoch: 4999  | Training Loss: 0.34633 \nEpoch: 4999  | Training Loss: 0.21225 \nEpoch: 4999  | Training Loss: 0.14669 \nEpoch: 4999  | Validation balanced accuracy : 0.76304 \nEpoch: 5000  | Training Loss: 0.31609 \nEpoch: 5000  | Training Loss: 0.36822 \nEpoch: 5000  | Training Loss: 0.34636 \nEpoch: 5000  | Training Loss: 0.21224 \nEpoch: 5000  | Training Loss: 0.14689 \nEpoch: 5000  | Validation balanced accuracy : 0.76304 \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\ncsvfile=\"/kaggle/input/3md3070-dlmi/testset/testset_data.csv\"\ndf_test=pd.read_csv(csvfile) \n##sometimes you need to execute this cell twice for the csv file to be properly saved\nmyCsv = csv.writer(open('/kaggle/working/pred_ANN.csv', 'w'))\nmyCsv.writerow([\"ID\", \"Predicted\"])\nX_test=df_test.iloc[:,-2:]\nY_test=df_test.iloc[:,1]\nX_test.iloc[:,0]=X_test.iloc[:,0].str[-4:]\nX_test.iloc[:,0]=pd.to_numeric(X_test.DOB)\nX_test = torch.FloatTensor(X_test.values)\nY_test = torch.FloatTensor(Y_test.values)\ntest_data = TensorDataset(X_test, Y_test)\nmodel0.eval()\nfor i in range(len(test_data)):\n    X,Y=test_data[i]\n    pred0=model0(X)\n\n    if (pred0.item()>0.5):\n        res=1\n\n    else:\n        res=0\n\n    myCsv.writerow([df_test.iloc[i,0], int(res)])\n    print([df_test.iloc[i,0], int(res)])","execution_count":48,"outputs":[{"output_type":"stream","text":"['P71', 1]\n['P16', 1]\n['P114', 0]\n['P170', 0]\n['P98', 1]\n['P69', 1]\n['P92', 1]\n['P132', 1]\n['P81', 1]\n['P73', 0]\n['P143', 1]\n['P175', 1]\n['P56', 1]\n['P139', 1]\n['P152', 1]\n['P203', 1]\n['P75', 1]\n['P9', 1]\n['P24', 0]\n['P4', 0]\n['P32', 1]\n['P120', 1]\n['P138', 1]\n['P172', 1]\n['P57', 0]\n['P195', 1]\n['P68', 0]\n['P133', 1]\n['P14', 1]\n['P119', 1]\n['P7', 0]\n['P49', 1]\n['P93', 1]\n['P178', 0]\n['P58', 0]\n['P108', 1]\n['P197', 1]\n['P196', 1]\n['P86', 0]\n['P18', 0]\n['P188', 0]\n['P148', 0]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## XGB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train=df_train.iloc[:,-2:]\nY_train=df_train.iloc[:,1]\nX_train.iloc[:,0]=X_train.iloc[:,0].str[-4:]\nX_train.iloc[:,0]=pd.to_numeric(X_train.DOB)\nX_val=df_val.iloc[:,-2:]\nY_val=df_val.iloc[:,1]\nX_val.iloc[:,0]=X_val.iloc[:,0].str[-4:]\nX_val.iloc[:,0]=pd.to_numeric(X_val.DOB)\n","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = XGBClassifier(n_estimators=1000,max_depth=100)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg.fit(X_train,Y_train)\n\n","execution_count":30,"outputs":[{"output_type":"stream","text":"[15:29:12] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n","name":"stderr"},{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=100,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=1000, n_jobs=2, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = xg.predict(X_val)\npreds_prob = xg.predict_proba(X_val)\n","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\n\nprint(\"Validation balanced accuracy:\",balanced_accuracy_score(Y_val, preds))","execution_count":32,"outputs":[{"output_type":"stream","text":"Validation balanced accuracy: 0.8347826086956522\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n#test submission score :0.78961\n##sometimes you need to execute this cell twice for the csv file to be properly saved\ncsvfile=\"/kaggle/input/3md3070-dlmi/testset/testset_data.csv\"\ntest_df=pd.read_csv(csvfile)  \nX_test=test_df.iloc[:,-2:]\nX_test.iloc[:,0]=X_test.iloc[:,0].str[-4:]\nX_test.iloc[:,0]=pd.to_numeric(X_test.DOB)\nmyCsv = csv.writer(open('pred_xgb.csv', 'w'))\nmyCsv.writerow([\"ID\", \"Predicted\"])\npred_y_test=xg.predict(X_test)\npreds_prob_test = xg.predict_proba(X_test)\nfor i in range(len(pred_y_test)):\n    label=pred_y_test[i]\n            \n    myCsv.writerow([test_df.iloc[i,0], int(label)])\n    print([test_df.iloc[i,0], int(label)])","execution_count":33,"outputs":[{"output_type":"stream","text":"['P71', 0]\n['P16', 1]\n['P114', 1]\n['P170', 1]\n['P98', 0]\n['P69', 0]\n['P92', 1]\n['P132', 1]\n['P81', 1]\n['P73', 0]\n['P143', 1]\n['P175', 1]\n['P56', 0]\n['P139', 1]\n['P152', 1]\n['P203', 0]\n['P75', 1]\n['P9', 1]\n['P24', 0]\n['P4', 0]\n['P32', 1]\n['P120', 1]\n['P138', 1]\n['P172', 1]\n['P57', 0]\n['P195', 1]\n['P68', 0]\n['P133', 1]\n['P14', 1]\n['P119', 1]\n['P7', 0]\n['P49', 1]\n['P93', 1]\n['P178', 0]\n['P58', 1]\n['P108', 1]\n['P197', 0]\n['P196', 0]\n['P86', 0]\n['P18', 1]\n['P188', 1]\n['P148', 0]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Hybrid Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"  \nimport torch\nfrom torch import Tensor\nimport torch.nn as nn\n\nfrom typing import Type, Any, Callable, Union, List, Optional\n\n\n__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n           'wide_resnet50_2', 'wide_resnet101_2']\n\n\nmodel_urls = {\n    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n}\n\n\ndef conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n\n\ndef conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n    \"\"\"1x1 convolution\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n\n\nclass BasicBlock(nn.Module):\n    expansion: int = 1\n\n    def __init__(\n        self,\n        inplanes: int,\n        planes: int,\n        stride: int = 1,\n        downsample: Optional[nn.Module] = None,\n        groups: int = 1,\n        base_width: int = 64,\n        dilation: int = 1,\n        norm_layer: Optional[Callable[..., nn.Module]] = None\n    ) -> None:\n        super(BasicBlock, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        if groups != 1 or base_width != 64:\n            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n        if dilation > 1:\n            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = norm_layer(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = norm_layer(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x: Tensor) -> Tensor:\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass Bottleneck(nn.Module):\n    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n    # This variant is also known as ResNet V1.5 and improves accuracy according to\n    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n\n    expansion: int = 4\n\n    def __init__(\n        self,\n        inplanes: int,\n        planes: int,\n        stride: int = 1,\n        downsample: Optional[nn.Module] = None,\n        groups: int = 1,\n        base_width: int = 64,\n        dilation: int = 1,\n        norm_layer: Optional[Callable[..., nn.Module]] = None\n    ) -> None:\n        super(Bottleneck, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        width = int(planes * (base_width / 64.)) * groups\n        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n        self.conv1 = conv1x1(inplanes, width)\n        self.bn1 = norm_layer(width)\n        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n        self.bn2 = norm_layer(width)\n        self.conv3 = conv1x1(width, planes * self.expansion)\n        self.bn3 = norm_layer(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x: Tensor) -> Tensor:\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n\n        return out\n\n\nclass ResNet(nn.Module):\n\n    def __init__(\n        self,\n        block: Type[Union[BasicBlock, Bottleneck]],\n        layers: List[int],\n        num_classes: int = 1000,\n        zero_init_residual: bool = False,\n        groups: int = 1,\n        width_per_group: int = 64,\n        replace_stride_with_dilation: Optional[List[bool]] = None,\n        norm_layer: Optional[Callable[..., nn.Module]] = None\n    ) -> None:\n        super(ResNet, self).__init__()\n        if norm_layer is None:\n            norm_layer = nn.BatchNorm2d\n        self._norm_layer = norm_layer\n\n        self.inplanes = 64\n        self.dilation = 1\n        if replace_stride_with_dilation is None:\n            # each element in the tuple indicates if we should replace\n            # the 2x2 stride with a dilated convolution instead\n            replace_stride_with_dilation = [False, False, False]\n        if len(replace_stride_with_dilation) != 3:\n            raise ValueError(\"replace_stride_with_dilation should be None \"\n                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n        self.groups = groups\n        self.base_width = width_per_group\n        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = norm_layer(self.inplanes)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64//4, layers[0])\n        self.layer2 = self._make_layer(block, 128//4, layers[1], stride=2,\n                                       dilate=replace_stride_with_dilation[0])\n        self.layer3 = self._make_layer(block, 256//4, layers[2], stride=2,\n                                       dilate=replace_stride_with_dilation[1])\n        self.layer4 = self._make_layer(block, 512//4, layers[3], stride=2,\n                                       dilate=replace_stride_with_dilation[2])\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512//4 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n        # Zero-initialize the last BN in each residual branch,\n        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n        if zero_init_residual:\n            for m in self.modules():\n                if isinstance(m, Bottleneck):\n                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n                elif isinstance(m, BasicBlock):\n                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n\n    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,\n                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n        norm_layer = self._norm_layer\n        downsample = None\n        previous_dilation = self.dilation\n        if dilate:\n            self.dilation *= stride\n            stride = 1\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                conv1x1(self.inplanes, planes * block.expansion, stride),\n                norm_layer(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n                            self.base_width, previous_dilation, norm_layer))\n        self.inplanes = planes * block.expansion\n        for _ in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups=self.groups,\n                                base_width=self.base_width, dilation=self.dilation,\n                                norm_layer=norm_layer))\n\n        return nn.Sequential(*layers)\n\n    def _forward_impl(self, x: Tensor) -> Tensor:\n        # See note [TorchScript super()]\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n\n\n        return x\n\n    def forward(self, x: Tensor) -> Tensor:\n        return self._forward_impl(x)\n\n\ndef _resnet(\n    arch: str,\n    block: Type[Union[BasicBlock, Bottleneck]],\n    layers: List[int],\n    pretrained: bool,\n    progress: bool,\n    **kwargs: Any\n) -> ResNet:\n    model = ResNet(block, layers, **kwargs)\n\n    return model\n\n\ndef resnet_medical( progress: bool = True, **kwargs: Any) -> ResNet:\n    r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"\n    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], False, progress,\n                   **kwargs)","execution_count":49,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.models as models\nclass Hybrid1(nn.Module):\n    \n    def __init__(self):\n        super(Hybrid1, self).__init__()\n\n        res_net = resnet_medical()\n        modell=res_net.to(device)\n        self.feature_extractor = modell \n        self.data_classif = nn.Sequential(nn.Linear(2, 2),\n                                           nn.Linear(2, 2),\n                                           nn.Sigmoid(),\n                                           nn.Linear(2, 1),\n                                           nn.Sigmoid()\n                                           )\n        \n\n        self.classifier = nn.Sequential(\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n        \n\n\n\n    def forward(self, x,data):\n\n        images=x[0] #use batch size 1\n\n        features=self.feature_extractor(images)\n\n        features= torch.squeeze(features, axis=2) \n\n        features=torch.mean(features, dim=0)\n\n\n        features=torch.flatten(features)\n\n\n        Y_data=self.data_classif(data)\n        \n        Y_im = self.classifier(features)\n        Z=torch.cat(((Y_data.view(-1, 1)).to(device), (Y_im.view(-1, 1)).to(device)), dim=1).to(device)\n        Z=torch.mean(Z)\n\n        Y=Z.view(-1,1)\n        return Y\n\n    def train(self, mode=True):\n        r\"\"\"Sets the module in training mode.\"\"\"      \n        self.training = mode\n        for module in self.children():\n            module.train(mode)\n        self.feature_extractor.train()\n        return self\n    def eval(self):\n        r\"\"\"Sets the module in evaluation mode.\"\"\"\n        self.feature_extractor.train(False)\n        return self.train(False)","execution_count":141,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torchvision.transforms as transforms_\nfrom torch.utils.data import DataLoader, Dataset\nimport os\nimport cv2\nfrom PIL import Image\n\nclass DLMI_data_2(Dataset):\n    def __init__(self, dataframe, root_dir, transforms = None):\n        \"\"\"\n        Args:\n            dataframe \n            mode(string) = \"train\",\"valid\",\"test\" \n            root_dir (string): Directory with the images.\n            transform (optional): Data augmentation\n        \"\"\"        \n        super().__init__()\n        self.df = dataframe\n        self.image_dir = root_dir\n        self.transforms = transforms    \n        self.labels_list=list(self.df.iloc[:,1])\n    \n    def __len__(self):\n        return len(self.labels_list)\n\n\n    def __getitem__(self, index):\n        self.bag_list=[]\n        name=self.df.iloc[index,0]\n        path, dirs, files = next(os.walk(self.image_dir+name))\n        i=0\n\n        for file in files:\n\n            image = Image.open(self.image_dir+name+\"/\"+file)\n\n            \n            if(self.transforms!=None):\n                image=self.transforms(image)\n\n            self.bag_list.append(image.to(device))\n        \n        label = [name, self.labels_list[index]]\n        data=[]\n\n        data.append(float(df.iloc[index,-2][-4:]))\n        data.append(float(df.iloc[index,-1]))\n\n\n\n        return torch.stack(self.bag_list),torch.tensor(data), label\n\n\n","execution_count":143,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train2(model,epoch):\n    model.train()\n    train_loss = 0.\n    train_error = 0.\n    criterion=nn.BCELoss()\n    model.train()\n    scheduler= torch.optim.lr_scheduler.StepLR(optimizer, step_size=96000, gamma=0.9)\n    for iter_idx, (ima,data, label) in enumerate(train_loader):\n        bag_label = (label[1].type(torch.FloatTensor)).view(-1,1)\n\n\n        optimizer.zero_grad()\n        pred=model(ima.to(device),data.to(device))\n\n\n\n        loss = criterion(pred,bag_label.to(device))\n\n        train_loss += loss\n\n\n        loss.backward()\n\n        optimizer.step()\n        scheduler.step\n\n    # calculate loss and error for epoch\n    train_loss /= len(train_loader)\n    train_error /= len(train_loader)\n    print(train_loss)\n    print('Epoch: {}, Loss: {:.4f}'.format(epoch, train_loss))\ndef valid2(model):\n    model.eval()\n    test_loss = 0.\n    test_error = 0.\n    prediction=[]\n    true_y=[]\n    aff=[]\n    for iter_idx, (ima,data, label) in enumerate(valid_loader):\n        bag_label = label[1]\n\n        pred_val=model(ima.to(device),data.to(device))\n        true_y.append(label[1].item())\n\n        aff.append(pred_val.item())\n        if (pred_val.item()>0.5):\n            prediction.append(1)\n        else:\n            prediction.append(0)\n\n\n    print(prediction,true_y)\n\n\n\n    print('\\n Validation balanced accuracy: {:.4f}'.format(balanced_accuracy_score( true_y,prediction)))","execution_count":146,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.RandomRotation(15),\n    torchvision.transforms.RandomHorizontalFlip(),\n    \n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\nval_data_transforms = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_dataset=DLMI_data_2(df_train,\"/kaggle/input/3md3070-dlmi/trainset/\",train_data_transforms)\nval_dataset=DLMI_data_2(df_val,\"/kaggle/input/3md3070-dlmi/trainset/\",val_data_transforms)\ntrain_loader = DataLoader(train_dataset,\n    batch_size = 1,\n    shuffle = True,\n    num_workers = 0,\n)\nvalid_loader = DataLoader(val_dataset,\n    batch_size = 1,\n    shuffle = True,\n    num_workers = 0,\n)","execution_count":147,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\ntorch.multiprocessing.set_start_method('spawn', force=True)\nimport torch.optim as optim\nfrom torch.autograd import Variable\nepoch_nb=200\n\nmodel = Hybrid1()\nif torch.cuda.is_available():\n    model.cuda()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay= 0.0005) #0.0005 model 3 with max  #lr = 0.001 model 0 with max #\n\nprint('Start Training')\nfor epoch in range(1, epoch_nb + 1):\n    t0 = time.time()\n    train2(model,epoch)\n    print(time.time()-t0,\"ms\")\n    valid2(model)\nprint('Start Testing')\n#test()","execution_count":148,"outputs":[{"output_type":"stream","text":"Start Training\ntensor(0.6297, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 1, Loss: 0.6297\n71.99591279029846 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6185, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 2, Loss: 0.6185\n72.66937613487244 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6209, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 3, Loss: 0.6209\n72.62542986869812 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6159, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 4, Loss: 0.6159\n72.26918768882751 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6162, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 5, Loss: 0.6162\n73.04483485221863 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6117, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 6, Loss: 0.6117\n72.8209056854248 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6039, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 7, Loss: 0.6039\n72.85554313659668 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.5000\ntensor(0.6109, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 8, Loss: 0.6109\n73.3541042804718 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.5979, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 9, Loss: 0.5979\n72.33650255203247 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.5967, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 10, Loss: 0.5967\n72.6058623790741 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.5943, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 11, Loss: 0.5943\n72.78033018112183 ms\n[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1] [0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6283\ntensor(0.5838, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 12, Loss: 0.5838\n73.61835479736328 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.5758, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 13, Loss: 0.5758\n72.15655875205994 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.5783\ntensor(0.5683, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 14, Loss: 0.5683\n72.30389332771301 ms\n[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n\n Validation balanced accuracy: 0.6283\ntensor(0.5693, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 15, Loss: 0.5693\n72.3630142211914 ms\n[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.5783\ntensor(0.5591, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 16, Loss: 0.5591\n72.11837363243103 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.4783\ntensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 17, Loss: 0.5621\n72.7799882888794 ms\n[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1] [1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6413\ntensor(0.5538, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 18, Loss: 0.5538\n71.88136601448059 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1] [0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5783\ntensor(0.5533, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 19, Loss: 0.5533\n72.26625442504883 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n\n Validation balanced accuracy: 0.6913\ntensor(0.5473, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 20, Loss: 0.5473\n72.17996335029602 ms\n[1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0] [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.7478\ntensor(0.5105, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 21, Loss: 0.5105\n72.92153334617615 ms\n[1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0] [0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.7913\ntensor(0.5383, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 22, Loss: 0.5383\n73.0149245262146 ms\n[1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0] [1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.5034, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 23, Loss: 0.5034\n72.51773190498352 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6087\ntensor(0.5001, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 24, Loss: 0.5001\n73.57814407348633 ms\n[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.6739\ntensor(0.5011, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 25, Loss: 0.5011\n72.80868172645569 ms\n","name":"stdout"},{"output_type":"stream","text":"[1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.4879, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 26, Loss: 0.4879\n72.16068315505981 ms\n[0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1] [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.6957\ntensor(0.5156, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 27, Loss: 0.5156\n71.93527698516846 ms\n[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1] [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.4875, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 28, Loss: 0.4875\n72.3019585609436 ms\n[1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1] [1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7543\ntensor(0.4806, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 29, Loss: 0.4806\n72.75161051750183 ms\n[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6087\ntensor(0.4790, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 30, Loss: 0.4790\n71.93722200393677 ms\n[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0] [0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6739\ntensor(0.4866, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 31, Loss: 0.4866\n72.97771668434143 ms\n[0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1] [1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7478\ntensor(0.4795, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 32, Loss: 0.4795\n72.26176428794861 ms\n[0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0] [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6739\ntensor(0.4514, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 33, Loss: 0.4514\n72.8036859035492 ms\n[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.6522\ntensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 34, Loss: 0.4478\n72.78007555007935 ms\n[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.6522\ntensor(0.4736, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 35, Loss: 0.4736\n71.40689635276794 ms\n[0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0] [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6522\ntensor(0.4761, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 36, Loss: 0.4761\n71.68145298957825 ms\n[0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1] [0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7696\ntensor(0.4743, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 37, Loss: 0.4743\n71.54165554046631 ms\n[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0] [1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7609\ntensor(0.4319, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 38, Loss: 0.4319\n71.588623046875 ms\n[0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1] [0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7826\ntensor(0.4725, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 39, Loss: 0.4725\n72.27302980422974 ms\n[0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.6065\ntensor(0.4792, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 40, Loss: 0.4792\n72.11159300804138 ms\n[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1] [0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6065\ntensor(0.4610, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 41, Loss: 0.4610\n71.8373498916626 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.5435\ntensor(0.4431, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 42, Loss: 0.4431\n71.587238073349 ms\n[0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0] [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6739\ntensor(0.4222, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 43, Loss: 0.4222\n72.62565875053406 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0] [0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6087\ntensor(0.4238, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 44, Loss: 0.4238\n71.93467545509338 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1] [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]\n\n Validation balanced accuracy: 0.6304\ntensor(0.4212, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 45, Loss: 0.4212\n72.20207500457764 ms\n[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0] [1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6304\ntensor(0.4306, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 46, Loss: 0.4306\n72.23019027709961 ms\n[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.5652\ntensor(0.4429, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 47, Loss: 0.4429\n72.17618989944458 ms\n[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0] [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.7826\ntensor(0.4732, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 48, Loss: 0.4732\n72.6964499950409 ms\n[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6739\ntensor(0.4342, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 49, Loss: 0.4342\n72.28146815299988 ms\n[0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0] [0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6957\n","name":"stdout"},{"output_type":"stream","text":"tensor(0.4130, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 50, Loss: 0.4130\n72.47750329971313 ms\n[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0] [0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6957\ntensor(0.3892, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 51, Loss: 0.3892\n72.12445998191833 ms\n[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0] [1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6739\ntensor(0.3940, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 52, Loss: 0.3940\n72.46782755851746 ms\n[1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0] [1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6739\ntensor(0.3865, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 53, Loss: 0.3865\n71.90242600440979 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1] [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.7609\ntensor(0.4489, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 54, Loss: 0.4489\n71.9367949962616 ms\n[0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0] [1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7196\ntensor(0.4308, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 55, Loss: 0.4308\n71.58960890769958 ms\n[0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1] [0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.5130\ntensor(0.4088, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 56, Loss: 0.4088\n72.24572920799255 ms\n[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1] [0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.5130\ntensor(0.3659, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 57, Loss: 0.3659\n72.28884387016296 ms\n[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0] [1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.7826\ntensor(0.3676, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 58, Loss: 0.3676\n72.62503385543823 ms\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0] [1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.7391\ntensor(0.3746, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 59, Loss: 0.3746\n72.13181495666504 ms\n[0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0] [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.7261\ntensor(0.3567, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 60, Loss: 0.3567\n72.23515558242798 ms\n[1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1] [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7196\ntensor(0.3629, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 61, Loss: 0.3629\n71.12882804870605 ms\n[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.6087\ntensor(0.3680, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 62, Loss: 0.3680\n71.71297025680542 ms\n[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.3816, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 63, Loss: 0.3816\n71.47126340866089 ms\n[0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0] [1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.7761\ntensor(0.3509, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 64, Loss: 0.3509\n71.68456792831421 ms\n[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0] [0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6957\ntensor(0.3858, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 65, Loss: 0.3858\n71.62827968597412 ms\n[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1] [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7326\ntensor(0.3550, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 66, Loss: 0.3550\n71.39909338951111 ms\n[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7609\ntensor(0.3222, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 67, Loss: 0.3222\n71.91233897209167 ms\n[1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1] [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7609\ntensor(0.4177, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 68, Loss: 0.4177\n71.48599672317505 ms\n[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1] [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.5630\ntensor(0.3722, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 69, Loss: 0.3722\n71.38039135932922 ms\n[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0] [0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6826\ntensor(0.3767, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 70, Loss: 0.3767\n71.48022317886353 ms\n[0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n\n Validation balanced accuracy: 0.7826\ntensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 71, Loss: 0.3343\n71.61318683624268 ms\n[0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0] [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.6348\ntensor(0.3336, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 72, Loss: 0.3336\n71.2344753742218 ms\n[0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0] [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.8043\ntensor(0.3328, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 73, Loss: 0.3328\n71.77889609336853 ms\n[1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1] [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7543\ntensor(0.3378, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 74, Loss: 0.3378\n70.94771313667297 ms\n","name":"stdout"},{"output_type":"stream","text":"[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0] [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.3356, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 75, Loss: 0.3356\n71.70201325416565 ms\n[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1] [1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.3771, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 76, Loss: 0.3771\n72.00786995887756 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0] [0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6522\ntensor(0.3314, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 77, Loss: 0.3314\n71.73271799087524 ms\n[0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0] [0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7609\ntensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 78, Loss: 0.3161\n72.22001838684082 ms\n[0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1] [0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6761\ntensor(0.3712, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 79, Loss: 0.3712\n70.89490270614624 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0] [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7609\ntensor(0.3240, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 80, Loss: 0.3240\n71.90578818321228 ms\n[1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1] [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7543\ntensor(0.3303, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 81, Loss: 0.3303\n72.0028645992279 ms\n[1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1] [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7326\ntensor(0.3120, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 82, Loss: 0.3120\n71.82407784461975 ms\n[0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1] [0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6891\ntensor(0.3341, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 83, Loss: 0.3341\n72.33677697181702 ms\n[1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6674\ntensor(0.3195, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 84, Loss: 0.3195\n72.48417687416077 ms\n[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0] [0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 85, Loss: 0.2922\n72.22211337089539 ms\n[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0] [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.3277, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 86, Loss: 0.3277\n72.20231437683105 ms\n[1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0] [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.7826\ntensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 87, Loss: 0.2912\n71.93028354644775 ms\n[0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1] [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7826\ntensor(0.3107, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 88, Loss: 0.3107\n72.47546076774597 ms\n[0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1] [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.7326\ntensor(0.3125, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 89, Loss: 0.3125\n73.31489539146423 ms\n[0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6630\ntensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 90, Loss: 0.3339\n72.66175055503845 ms\n[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0] [1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6891\ntensor(0.3228, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 91, Loss: 0.3228\n71.75999784469604 ms\n[1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0] [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.7109\ntensor(0.3056, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 92, Loss: 0.3056\n72.05169749259949 ms\n[0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1] [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 93, Loss: 0.2922\n71.62614250183105 ms\n[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0] [1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6891\ntensor(0.2978, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 94, Loss: 0.2978\n71.8379418849945 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5217\ntensor(0.4017, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 95, Loss: 0.4017\n71.51571297645569 ms\n[0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0] [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6826\ntensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 96, Loss: 0.3007\n72.12094569206238 ms\n[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0] [0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7543\ntensor(0.3052, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 97, Loss: 0.3052\n71.87123012542725 ms\n[0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0] [1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 98, Loss: 0.3038\n71.79056167602539 ms\n[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] [1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6522\n","name":"stdout"},{"output_type":"stream","text":"tensor(0.3489, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 99, Loss: 0.3489\n71.67646932601929 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5217\ntensor(0.3570, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 100, Loss: 0.3570\n72.40809679031372 ms\n[0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0] [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.8130\ntensor(0.3331, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 101, Loss: 0.3331\n72.17075967788696 ms\n[0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1] [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.7543\ntensor(0.3034, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 102, Loss: 0.3034\n72.74028253555298 ms\n[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1] [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6413\ntensor(0.2952, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 103, Loss: 0.2952\n71.7338125705719 ms\n[1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0] [1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n\n Validation balanced accuracy: 0.7543\ntensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 104, Loss: 0.2898\n71.55184984207153 ms\n[1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5913\ntensor(0.2998, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 105, Loss: 0.2998\n71.41645741462708 ms\n[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0] [0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.3208, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 106, Loss: 0.3208\n71.89163994789124 ms\n[1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1] [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.5913\ntensor(0.2977, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 107, Loss: 0.2977\n71.6467866897583 ms\n[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5413\ntensor(0.3032, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 108, Loss: 0.3032\n71.70468378067017 ms\n[0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0] [0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7174\ntensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 109, Loss: 0.3265\n72.45904588699341 ms\n[1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5630\ntensor(0.2856, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 110, Loss: 0.2856\n71.965017080307 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0]\n\n Validation balanced accuracy: 0.5130\ntensor(0.2845, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 111, Loss: 0.2845\n71.97728419303894 ms\n[1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0] [0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.5413\ntensor(0.2734, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 112, Loss: 0.2734\n71.94187688827515 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.2701, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 113, Loss: 0.2701\n72.86070442199707 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.6000\ntensor(0.3598, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 114, Loss: 0.3598\n71.97734379768372 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.4306, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 115, Loss: 0.4306\n72.29524612426758 ms\n[1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1] [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.6196\ntensor(0.2738, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 116, Loss: 0.2738\n72.44488787651062 ms\n[0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0] [0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n\n Validation balanced accuracy: 0.5913\ntensor(0.2663, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 117, Loss: 0.2663\n73.49526977539062 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1] [1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5413\ntensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 118, Loss: 0.2649\n73.12555932998657 ms\n[1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.5413\ntensor(0.2640, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 119, Loss: 0.2640\n72.7570858001709 ms\n[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0] [1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.5413\ntensor(0.2629, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 120, Loss: 0.2629\n72.08005428314209 ms\n[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0] [1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.5413\ntensor(0.3041, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 121, Loss: 0.3041\n72.28440618515015 ms\n[1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0] [1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6957\ntensor(0.2872, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 122, Loss: 0.2872\n72.52699995040894 ms\n[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.5630\ntensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 123, Loss: 0.2960\n73.64986515045166 ms\n","name":"stdout"},{"output_type":"stream","text":"[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.5630\ntensor(0.2945, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 124, Loss: 0.2945\n74.19043779373169 ms\n[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6957\ntensor(0.2841, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 125, Loss: 0.2841\n73.05144739151001 ms\n[0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0] [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6978\ntensor(0.2725, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 126, Loss: 0.2725\n72.1619005203247 ms\n[1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 127, Loss: 0.2566\n72.59963345527649 ms\n[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1] [1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7391\ntensor(0.2668, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 128, Loss: 0.2668\n73.00582337379456 ms\n[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0] [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 129, Loss: 0.2597\n72.76049184799194 ms\n[0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1] [0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.7326\ntensor(0.2552, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 130, Loss: 0.2552\n73.23271751403809 ms\n[0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0] [1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7043\ntensor(0.3160, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 131, Loss: 0.3160\n73.29083728790283 ms\n[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.5587\ntensor(0.3002, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 132, Loss: 0.3002\n72.23786091804504 ms\n[0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1] [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.5891\ntensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 133, Loss: 0.2615\n72.52870178222656 ms\n[0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] [0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6087\ntensor(0.2677, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 134, Loss: 0.2677\n72.65508532524109 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.4783\ntensor(0.3234, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 135, Loss: 0.3234\n72.25805473327637 ms\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] [1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5000\ntensor(0.2883, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 136, Loss: 0.2883\n73.21954393386841 ms\n[0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1] [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6630\ntensor(0.2782, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 137, Loss: 0.2782\n71.61102080345154 ms\n[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1] [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.5630\ntensor(0.2811, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 138, Loss: 0.2811\n73.33464241027832 ms\n[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1] [1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5870\ntensor(0.3197, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 139, Loss: 0.3197\n72.9776120185852 ms\n[0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0] [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.6891\ntensor(0.2548, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 140, Loss: 0.2548\n72.49145603179932 ms\n[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0] [0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.7109\ntensor(0.2523, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 141, Loss: 0.2523\n71.78720045089722 ms\n[1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0] [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7326\ntensor(0.2557, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 142, Loss: 0.2557\n73.04700565338135 ms\n[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0] [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6522\ntensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 143, Loss: 0.2531\n73.15669465065002 ms\n[0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1] [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.6978\ntensor(0.2736, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 144, Loss: 0.2736\n73.06354570388794 ms\n[0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1] [1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6457\ntensor(0.2608, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 145, Loss: 0.2608\n73.2521824836731 ms\n[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0] [1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6978\ntensor(0.2512, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 146, Loss: 0.2512\n72.29662871360779 ms\n[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1] [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6761\ntensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 147, Loss: 0.2483\n72.12658500671387 ms\n[1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1] [1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6913\n","name":"stdout"},{"output_type":"stream","text":"tensor(0.3133, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 148, Loss: 0.3133\n72.9253659248352 ms\n[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0] [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5587\ntensor(0.3074, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 149, Loss: 0.3074\n72.56126379966736 ms\n[0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0] [0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0]\n\n Validation balanced accuracy: 0.7543\ntensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 150, Loss: 0.2593\n72.77173709869385 ms\n[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1] [1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7196\ntensor(0.2649, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 151, Loss: 0.2649\n73.14065670967102 ms\n[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0] [1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6457\ntensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 152, Loss: 0.2489\n72.4175796508789 ms\n[1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1] [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7478\ntensor(0.2482, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 153, Loss: 0.2482\n72.62612628936768 ms\n[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1] [1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6348\ntensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 154, Loss: 0.3065\n72.38608431816101 ms\n[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1] [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6739\ntensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 155, Loss: 0.2838\n72.05632829666138 ms\n[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1] [1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6848\ntensor(0.2569, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 156, Loss: 0.2569\n71.98857045173645 ms\n[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1] [1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6348\ntensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 157, Loss: 0.2536\n72.02732276916504 ms\n[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n\n Validation balanced accuracy: 0.6283\ntensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 158, Loss: 0.2393\n72.36570882797241 ms\n[0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1] [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n\n Validation balanced accuracy: 0.6130\ntensor(0.3040, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 159, Loss: 0.3040\n71.86699271202087 ms\n[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1] [1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.3316, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 160, Loss: 0.3316\n72.25134563446045 ms\n[0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0] [0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n\n Validation balanced accuracy: 0.6891\ntensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 161, Loss: 0.2739\n72.41588544845581 ms\n[0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0] [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.5674\ntensor(0.2878, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 162, Loss: 0.2878\n71.49681949615479 ms\n[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1] [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6413\ntensor(0.2481, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 163, Loss: 0.2481\n72.45485925674438 ms\n[0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0] [1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.5913\ntensor(0.2454, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 164, Loss: 0.2454\n74.44674754142761 ms\n[0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1] [0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6130\ntensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 165, Loss: 0.2393\n72.47585844993591 ms\n[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1] [0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.6848\ntensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 166, Loss: 0.2377\n73.00434231758118 ms\n[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1] [0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.6630\ntensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 167, Loss: 0.2396\n74.10348510742188 ms\n[1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0] [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6826\ntensor(0.2380, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 168, Loss: 0.2380\n74.319584608078 ms\n[1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1] [1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.6913\ntensor(0.2489, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 169, Loss: 0.2489\n72.6335883140564 ms\n[0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0] [1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6891\ntensor(0.2664, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 170, Loss: 0.2664\n73.5076756477356 ms\n[1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1] [1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7696\ntensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 171, Loss: 0.2366\n73.38087773323059 ms\n[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1] [1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7478\ntensor(0.2364, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 172, Loss: 0.2364\n72.41882681846619 ms\n","name":"stdout"},{"output_type":"stream","text":"[1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0] [1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.7913\ntensor(0.2357, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 173, Loss: 0.2357\n73.17849397659302 ms\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1] [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.7261\ntensor(0.2838, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 174, Loss: 0.2838\n72.82276701927185 ms\n[0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1] [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7543\ntensor(0.2912, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 175, Loss: 0.2912\n72.86330723762512 ms\n[0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1] [1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6174\ntensor(0.3783, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 176, Loss: 0.3783\n72.71960997581482 ms\n[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.4935\ntensor(0.3161, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 177, Loss: 0.3161\n72.75572299957275 ms\n[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1] [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.5478\ntensor(0.2792, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 178, Loss: 0.2792\n73.02306699752808 ms\n[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0] [1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6674\ntensor(0.3055, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 179, Loss: 0.3055\n72.81877207756042 ms\n[0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0] [1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6326\ntensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 180, Loss: 0.2587\n73.05323338508606 ms\n[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.5804\ntensor(0.2504, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 181, Loss: 0.2504\n72.7880322933197 ms\n[1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1] [1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n\n Validation balanced accuracy: 0.5761\ntensor(0.2904, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 182, Loss: 0.2904\n73.42858219146729 ms\n[0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1] [0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6696\ntensor(0.2831, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 183, Loss: 0.2831\n72.71235656738281 ms\n[0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1] [0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6761\ntensor(0.2688, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 184, Loss: 0.2688\n73.07798910140991 ms\n[0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1] [0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.5696\ntensor(0.2367, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 185, Loss: 0.2367\n72.73598265647888 ms\n[0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1] [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n\n Validation balanced accuracy: 0.6043\ntensor(0.2344, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 186, Loss: 0.2344\n72.28197693824768 ms\n[1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1] [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6043\ntensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 187, Loss: 0.2416\n72.33241200447083 ms\n[0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1] [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1]\n\n Validation balanced accuracy: 0.5804\ntensor(0.2669, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 188, Loss: 0.2669\n71.97073888778687 ms\n[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7196\ntensor(0.2350, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 189, Loss: 0.2350\n73.61685109138489 ms\n[1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0] [0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n\n Validation balanced accuracy: 0.7196\ntensor(0.2410, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 190, Loss: 0.2410\n72.70001792907715 ms\n[1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1] [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.6978\ntensor(0.2501, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 191, Loss: 0.2501\n72.44590640068054 ms\n[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0] [1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n\n Validation balanced accuracy: 0.6239\ntensor(0.2406, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 192, Loss: 0.2406\n72.77325963973999 ms\n[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0] [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2328, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 193, Loss: 0.2328\n73.11784267425537 ms\n[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0] [1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2324, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 194, Loss: 0.2324\n73.68136143684387 ms\n[0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1] [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2322, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 195, Loss: 0.2322\n73.08557057380676 ms\n[0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0] [1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2320, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 196, Loss: 0.2320\n72.80109882354736 ms\n[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0] [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n\n Validation balanced accuracy: 0.7109\n","name":"stdout"},{"output_type":"stream","text":"tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 197, Loss: 0.2315\n71.51007604598999 ms\n[1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1] [1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n\n Validation balanced accuracy: 0.6826\ntensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 198, Loss: 0.2315\n72.46101784706116 ms\n[0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0] [0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7043\ntensor(0.2312, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 199, Loss: 0.2312\n72.27710819244385 ms\n[0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1] [0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.6826\ntensor(0.2311, device='cuda:0', grad_fn=<DivBackward0>)\nEpoch: 200, Loss: 0.2311\n72.31661891937256 ms\n[0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1] [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1]\n\n Validation balanced accuracy: 0.7043\nStart Testing\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvfile=\"/kaggle/input/3md3070-dlmi/testset/testset_data.csv\"\ntest_df=pd.read_csv(csvfile)  \ntest_dataset=DLMI_data_2(test_df,\"/kaggle/input/3md3070-dlmi/testset/\",train_data_transforms)\ntest_loader = DataLoader(test_dataset,\n    batch_size = 1,\n    num_workers = 0,\n)","execution_count":150,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n##sometimes you need to execute this cell twice for the csv file to be properly saved\nmyCsv = csv.writer(open('/kaggle/working/pred_hybrid.csv', 'w'))\nmyCsv.writerow([\"ID\", \"Predicted\"])\natt=[]\nmodel.eval()\nfor batch_idx, (ima,data, label) in enumerate(test_loader):\n    bag_label = label[1]\n\n    Y=model(ima.to(device),data.to(device))\n\n    if (Y.item()>0.5):\n        ress=1\n\n    else:\n        ress=0\n\n    myCsv.writerow([label[0][0], int(ress)])\n    #print([label[0][0], int(predicted_label)])\n    ","execution_count":154,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Droped"},{"metadata":{},"cell_type":"markdown","source":"### Attention"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nclass DLMI_data(Dataset):\n    def __init__(self, dataframe, root_dir, transforms = None):\n        \"\"\"\n        Args:\n            dataframe \n            mode(string) = \"train\",\"valid\",\"test\" \n            root_dir (string): Directory with the images.\n            transform (optional): Data augmentation\n        \"\"\"        \n        super().__init__()\n        self.df = dataframe\n        self.image_dir = root_dir\n        self.transforms = transforms    \n        self.labels_list=list(self.df.iloc[:,1])\n    \n    def __len__(self):\n        return len(self.labels_list)\n\n\n    def __getitem__(self, index):\n        self.bag_list=[]\n        name=self.df.iloc[index,0]\n        path, dirs, files = next(os.walk(self.image_dir+name))\n        files_resample=files\n        i=0\n        while(len(files_resample)<50):\n            files_resample.append(files[i])\n            i=(i+1)%len(files)\n\n        for file in files:\n\n            image = Image.open(self.image_dir+name+\"/\"+file)\n\n            if(self.transforms!=None):\n                image=self.transforms(image)\n\n            self.bag_list.append(image.numpy())\n        \n        label = [name, self.labels_list[index]]\n\n        return torch.tensor(self.bag_list), label\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_transforms0 = torchvision.transforms.Compose([\n\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.RandomRotation(15),\n    torchvision.transforms.RandomHorizontalFlip(),\n    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ntrain_dataset=DLMI_data(df_train,\"/kaggle/input/3md3070-dlmi/trainset/\",train_data_transforms0)\nval_dataset=DLMI_data(df_val,\"/kaggle/input/3md3070-dlmi/trainset/\",train_data_transforms)\ntrain_loader = DataLoader(train_dataset,\n    batch_size = 1,\n    shuffle = True,\n    num_workers = 2,\n)\nvalid_loader = DataLoader(val_dataset,\n    batch_size = 1,\n    shuffle = True,\n    num_workers = 2,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Attention(nn.Module):\n    def __init__(self):\n        super(Attention, self).__init__()\n        self.L = 500\n        self.D = 128\n        self.K = 1\n\n        self.feature_extractor_part1 = nn.Sequential(\n            nn.Conv2d(3, 40, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2),\n            nn.Conv2d(40,30, kernel_size=5),\n            nn.ReLU(),\n            nn.MaxPool2d(2, stride=2)\n        )\n\n        self.feature_extractor_part2 = nn.Sequential(\n            nn.Linear(84270, self.L),\n            nn.ReLU(),\n        )\n\n        self.attention = nn.Sequential(\n            nn.Linear(self.L, self.D),\n            nn.Tanh(),\n            nn.Linear(self.D, self.K)\n        )\n\n        self.classifier = nn.Sequential(\n            nn.Linear(self.L*self.K, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        y_probs=[]\n        y_probs_ima=[]\n        y_hats=[]\n        for y in x:\n\n            for imag in y:\n\n                imag=imag.unsqueeze(0)\n                H = self.feature_extractor_part1(imag)\n\n                H = H.view(-1, 84270)\n                H = self.feature_extractor_part2(H)  # NxL\n\n                A = self.attention(H)  # NxK\n                A = torch.transpose(A, 1, 0)  # KxN\n                A = F.softmax(A, dim=1)  # softmax over N\n\n                M = torch.mm(A, H)  # KxL\n\n                Y_prob = self.classifier(M)\n                \n                y_probs_ima.append(Y_prob) #.item()\n\n            y_probs_ima=torch.FloatTensor(y_probs_ima)\n            y_probs.append(torch.mean(y_probs_ima))\n            Y_hat = torch.ge(torch.mean(y_probs_ima), 0.5).float()\n            y_hats.append(Y_hat)\n                \n\n        return y_probs, y_hats, A\n\n    # AUXILIARY METHODS\n    def calculate_classification_error(self, X, Y):\n        Y = Y.float()\n        _, Y_hat, _ = self.forward(X)\n        Y_hat=torch.FloatTensor(Y_hat)\n        Y_hat=Y_hat.to(\"cuda\")\n        error = 1. - Y_hat.eq(Y).cpu().float().mean().item()\n\n        return error, Y_hat\n\n    def calculate_objective(self, X, Y):\n        Y = Y.float()\n        Y_prob, _, A = self.forward(X)\n        Y_prob = torch.clamp(torch.FloatTensor(Y_prob), min=1e-5, max=1. - 1e-5)\n        Y_prob=Y_prob.to(\"cuda\")\n\n        neg_log_likelihood = -1. * (Y * torch.log(Y_prob) + (1. - Y) * torch.log(1. - Y_prob))  # negative log bernoulli\n\n        return neg_log_likelihood, A\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\nfrom torch.autograd import Variable\n\ndef train(model,epoch):\n    model.train()\n    train_loss = 0.\n    train_error = 0.\n    for batch_idx, (data, label) in enumerate(train_loader):\n        bag_label = label[1]\n        if torch.cuda.is_available():\n            data, bag_label = data.cuda(), bag_label.cuda()\n        data, bag_label = Variable(data), Variable(bag_label)\n\n        # reset gradients\n        optimizer.zero_grad()\n        # calculate loss and metrics\n        loss, _ = model.calculate_objective(data, bag_label)\n        train_loss += loss.data[0]\n        error, _ = model.calculate_classification_error(data, bag_label)\n        train_error += error\n        # backward pass\n        loss = Variable(loss, requires_grad = True)\n        loss.backward()\n        # step\n        optimizer.step()\n\n    # calculate loss and error for epoch\n    train_loss /= len(train_loader)\n    train_error /= len(train_loader)\n\n    print('Epoch: {}, Loss: {:.4f}, Train error: {:.4f}'.format(epoch, train_loss.cpu().numpy()[0], train_error))\n\n\ndef valid(model):\n    model.eval()\n    test_loss = 0.\n    test_error = 0.\n    prediction=[]\n    true_y=[]\n    for batch_idx, (data, label) in enumerate(valid_loader):\n        bag_label = label[1]\n        if torch.cuda.is_available():\n            data, bag_label = data.cuda(), bag_label.cuda()\n        data, bag_label = Variable(data), Variable(bag_label)\n        Y_prob, Y_hat, A=model(data)\n        prediction.append(Y_hat.item())\n        #print(prediction)\n        true_y.append(label[1].item())\n        #print(true_y)\n\n\n\n    print('\\n Validation balanced accuracy: {:.4f}'.format(balanced_accuracy_score( true_y,prediction)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\nfrom torch.autograd import Variable\nmodel_type='attention'\nepoch_nb=9\nlr=0.00008\nmomentum=0.65\nif model_type=='attention':\n    model = Attention()\nif torch.cuda.is_available():\n    model.cuda()\noptimizer = torch.optim.SGD(model.parameters(), lr=lr,momentum=momentum, weight_decay=0.005)\n#optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n#optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), weight_decay=10e-5)\nprint('Start Training')\nfor epoch in range(1, epoch_nb + 1):\n    train(model,epoch)\n    valid(model)\nprint('Start Testing')\n#test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csvfile=\"/kaggle/input/3md3070-dlmi/testset/testset_data.csv\"\ntest_df=pd.read_csv(csvfile)  \ntest_dataset=DLMI_data(test_df,\"/kaggle/input/3md3070-dlmi/testset/\",train_data_transforms)\ntest_loader = DataLoader(test_dataset,\n    batch_size = 1,\n    num_workers = 1,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\nmyCsv = csv.writer(open('pred_attention.csv', 'w'))\nmyCsv.writerow([\"ID\", \"Predicted\"])\n\nfor batch_idx, (data, label) in enumerate(test_loader):\n    model.eval()\n    bag_label = label[1]\n    \n  \n    if torch.cuda.is_available():\n        data, bag_label = data.cuda(), bag_label.cuda()\n    data, bag_label = Variable(data), Variable(bag_label)\n    Y=model(data)\n    if (Y.item()>0.5):\n        ress=1\n        prob=Y.item()\n    else:\n        ress=0\n        prob=1-Y.item()\n\n    myCsv.writerow([label[0][0], int(ress)])\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}